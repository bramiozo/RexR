\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Clinical data}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Pre-processing}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Cohort-bias removal}{1}}
\citation{Alter2000}
\citation{Price2006}
\citation{Zang2016}
\citation{Benito2005}
\citation{Johnson2007}
\citation{Johnson2007}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Workflow for the model generation and prediction\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:workflow}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Two sets of distributions prior the bias correct, for, (left) a strong predictor and (right) a weak predictor\relax }}{2}}
\newlabel{fig:expression_distribution_cohorts}{{2}{2}}
\citation{Shlens2014}
\citation{Yoav1995}
\citation{Sun1996}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two sets of distributions with L/S cohort correct, for, (left) a strong predictor and (right) a weak predictor\relax }}{3}}
\newlabel{fig:expression_distribution_cohorts_withBiasCorrection}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dimension reduction}{3}}
\citation{Breiman2001}
\citation{Geurts2006}
\citation{Chen2016}
\citation{Ke2017}
\citation{Breiman1997}
\citation{lecun2015deep}
\citation{Lecun98}
\citation{khan2001classification}
\citation{Lecun98}
\citation{Lecun98}
\citation{Ribeiro2016}
\@writefile{toc}{\contentsline {section}{\numberline {3}Classification}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tree based}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Neural networks}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A generic architecture for a deep feedforward neural network.\relax }}{4}}
\newlabel{fig:dnn_architecture}{{4}{4}}
\citation{Sandberg2001}
\citation{Ferrari2006}
\citation{DePristo2011}
\citation{Chu2005}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A typical convolutional neural network architecture for image classification from \cite  {Lecun98}.\relax }}{5}}
\newlabel{fig:cnn_architecture}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Linear methods}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Bayesian methods}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model Evaluation}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Training strategy $\mathcal  {I}$}{5}}
\citation{Breiman2001}
\citation{Geurts2006}
\citation{Chen2016}
\citation{Ke2017}
\citation{lecun2015deep}
\citation{Lecun98}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Training strategy $\mathcal  {I}$. Mean accuracies in $\%$ over $10$ runs with $5\%$ added random noise per run, with $10$ folds for the cross-validation. $d$ denotes the number of features\relax }}{6}}
\newlabel{tab:diversitymetrics}{{1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training strategy $\mathcal  {II}$}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Post-processing}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Distribution of (a) weights and (b) importances associated with genomic expression values with regard to their influence on several models for training strategy $\mathcal  {I}$\relax }}{6}}
\newlabel{fig:weightsFromModels}{{6}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Top $30$ probesets in terms of median absolute importances (weights) for the RF, ET, XGB and LGBM models\relax }}{7}}
\newlabel{fig:weightsFromModels}{{7}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Top $30$ probesets in terms of median absolute weights for the lSVM and LR models\relax }}{7}}
\newlabel{fig:coeffsFromModels}{{8}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summarising}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{8}}
\bibstyle{plain}
\bibdata{methods}
\bibcite{Alter2000}{1}
\bibcite{Benito2005}{2}
\bibcite{Yoav1995}{3}
\bibcite{Breiman2001}{4}
\bibcite{Breiman1997}{5}
\bibcite{Chen2016}{6}
\bibcite{Chu2005}{7}
\bibcite{Ferrari2006}{8}
\bibcite{DePristo2011}{9}
\bibcite{Geurts2006}{10}
\bibcite{Johnson2007}{11}
\bibcite{Ke2017}{12}
\bibcite{khan2001classification}{13}
\bibcite{lecun2015deep}{14}
\bibcite{Lecun98}{15}
\bibcite{Price2006}{16}
\bibcite{Ribeiro2016}{17}
\bibcite{Sandberg2001}{18}
\bibcite{Shlens2014}{19}
\bibcite{Sun1996}{20}
\bibcite{Zang2016}{21}
