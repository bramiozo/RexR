\relax 
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Workflow for the model generation and prediction\relax }}{1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:workflow}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Clinical data}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Pre-processing}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Cohort-bias removal}{1}\protected@file@percent }
\citation{Alter2000}
\citation{Price2006}
\citation{Zang2016}
\citation{Benito2005}
\citation{Johnson2007}
\citation{Johnson2007}
\citation{Shlens2014}
\citation{Yoav1995}
\citation{Sun1996}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Two sets of distributions prior the bias correct, for, (left) a strong predictor and (right) a weak predictor\relax }}{2}\protected@file@percent }
\newlabel{fig:expression_distribution_cohorts}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two sets of distributions with L/S cohort correct, for, (left) a strong predictor and (right) a weak predictor\relax }}{2}\protected@file@percent }
\newlabel{fig:expression_distribution_cohorts_withBiasCorrection}{{3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dimension reduction}{2}\protected@file@percent }
\citation{Breiman2001}
\citation{Geurts2006}
\citation{Chen2016}
\citation{Ke2017}
\citation{Breiman1997}
\citation{lecun2015deep}
\citation{Lecun98}
\citation{khan2001classification}
\citation{Lecun98}
\citation{Lecun98}
\citation{Ribeiro2016}
\@writefile{toc}{\contentsline {section}{\numberline {3}Classification}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tree based}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Neural networks}{3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A generic architecture for a deep feedforward neural network.\relax }}{3}\protected@file@percent }
\newlabel{fig:dnn_architecture}{{4}{3}}
\citation{Pohar2004}
\citation{Yong2015}
\citation{Gokcen2002}
\citation{Sandberg2001}
\citation{Ferrari2006}
\citation{DePristo2011}
\citation{Chu2005}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A typical convolutional neural network architecture for image classification from \cite  {Lecun98}.\relax }}{4}\protected@file@percent }
\newlabel{fig:cnn_architecture}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Linear methods}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Bayesian methods}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Stacking}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model Evaluation}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Training strategy $\mathcal  {I}$}{5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Training strategy $\mathcal  {I}$. Mean accuracies in $\%$ over $10$ runs with $5\%$ added random noise per run, with $10$ folds for the cross-validation. $d$ denotes the number of features\relax }}{5}\protected@file@percent }
\newlabel{tab:diversitymetrics}{{1}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Training strategy $\mathcal  {I}$. Mean accuracies in $\%$ over $10$ runs with $5\%$ added random noise per run, with $10$ folds for the cross-validation. $d$ denotes the number of features\relax }}{5}\protected@file@percent }
\newlabel{tab:diversitymetrics_ensemble}{{2}{5}}
\citation{Breiman2001}
\citation{Geurts2006}
\citation{Chen2016}
\citation{Ke2017}
\citation{lecun2015deep}
\citation{Lecun98}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training strategy $\mathcal  {II}$}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Post-processing}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Distribution of (a) weights and (b) importances associated with genomic expression values with regard to their influence on several models for training strategy $\mathcal  {I}$\relax }}{6}\protected@file@percent }
\newlabel{fig:weightsFromModels}{{6}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Top $30$ probesets in terms of median absolute importances (weights) for the RF, ET, XGB and LGBM models\relax }}{6}\protected@file@percent }
\newlabel{fig:weightsFromModels}{{7}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Top $30$ probesets in terms of median absolute weights for the lSVM and LR models\relax }}{6}\protected@file@percent }
\newlabel{fig:coeffsFromModels}{{8}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summarising}{6}\protected@file@percent }
\bibstyle{plain}
\bibdata{methods}
\bibcite{Gokcen2002}{1}
\bibcite{Alter2000}{2}
\bibcite{Benito2005}{3}
\bibcite{Yoav1995}{4}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{7}\protected@file@percent }
\bibcite{Breiman2001}{5}
\bibcite{Breiman1997}{6}
\bibcite{Chen2016}{7}
\bibcite{Chu2005}{8}
\bibcite{Ferrari2006}{9}
\bibcite{DePristo2011}{10}
\bibcite{Geurts2006}{11}
\bibcite{Johnson2007}{12}
\bibcite{Ke2017}{13}
\bibcite{khan2001classification}{14}
\bibcite{lecun2015deep}{15}
\bibcite{Lecun98}{16}
\bibcite{Pohar2004}{17}
\bibcite{Price2006}{18}
\bibcite{Ribeiro2016}{19}
\bibcite{Sandberg2001}{20}
\bibcite{Shlens2014}{21}
\bibcite{Sun1996}{22}
\bibcite{Yong2015}{23}
\bibcite{Zang2016}{24}
