{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++ Firing up RexR! ++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from RexR import *\n",
    "import _helpers\n",
    "Rocket = RexR(datalocation = None, #'_data/genomic_data/data.pkl', \n",
    "              seed = 3123, \n",
    "              debug = False, \n",
    "              write_out=True,\n",
    "              set_name = 'MELA') # data to read in ALL_10, or MELA\n",
    "Rocket.load_probeset_data();\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllResults = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: ET accuracy:  0.915662650602 +/-: 0.000909496715897\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: RF accuracy:  0.89156626506 +/-: 0.00242139121096\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: GBM accuracy:  0.915662650602 +/-: 0.000909496715897\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: ADA accuracy:  0.927710843373 +/-: 0.00341176897526\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: LR accuracy:  0.939759036145 +/-: 0.00146493130566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: SVM accuracy:  0.939759036145 +/-: 0.00146493130566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: MLNN accuracy:  0.879518072289 +/-: 0.0155159973701\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: XGB accuracy:  0.927710843373 +/-: 0.0021272190107\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "Initial alpha = [[ 0.02910706]]\n",
      "   1 - L=-361.1054524 - Gamma= 1.9999420 (M=   2) - s=0.0100\n",
      "   2 - L=-252.5886776 - Gamma= 2.9998708 (M=   3) - s=0.0100\n",
      "   3 - L=-185.7297189 - Gamma= 3.9997252 (M=   4) - s=0.0100\n",
      "   4 - L=-142.2656475 - Gamma= 4.9995304 (M=   5) - s=0.0100\n",
      "   5 - L=-113.6267476 - Gamma= 5.9992443 (M=   6) - s=0.0100\n",
      "   6 - L=-85.5940164 - Gamma= 6.9989574 (M=   7) - s=0.0100\n",
      "   7 - L=-58.3343087 - Gamma= 7.9985784 (M=   8) - s=0.0100\n",
      "   8 - L=-45.5628005 - Gamma= 8.9979482 (M=   9) - s=0.0100\n",
      "   9 - L=-33.1292031 - Gamma= 9.9972369 (M=  10) - s=0.0100\n",
      "  10 - L=-23.7738764 - Gamma=10.9963528 (M=  11) - s=0.0100\n",
      "  11 - L=-18.4460555 - Gamma=11.9948605 (M=  12) - s=0.0100\n",
      "  12 - L=-14.0556584 - Gamma=12.9926997 (M=  13) - s=0.0100\n",
      "  13 - L=-9.1585709 - Gamma=13.9908843 (M=  14) - s=0.0100\n",
      "  14 - L=-6.2970448 - Gamma=14.9879764 (M=  15) - s=0.0100\n",
      "  15 - L=-3.3864611 - Gamma=15.9851641 (M=  16) - s=0.0100\n",
      "  16 - L=-1.3435461 - Gamma=16.9810522 (M=  17) - s=0.0100\n",
      "  17 - L= 0.0877509 - Gamma=17.9756352 (M=  18) - s=0.0100\n",
      "  18 - L= 0.8810048 - Gamma=18.9654153 (M=  19) - s=0.0100\n",
      "  19 - L= 1.4945293 - Gamma=19.9532538 (M=  20) - s=0.0100\n",
      "  20 - L= 1.9983702 - Gamma=20.9368047 (M=  21) - s=0.0100\n",
      "  21 - L= 2.2909481 - Gamma=21.9121216 (M=  22) - s=0.0100\n",
      "  22 - L= 2.5133050 - Gamma=22.8802576 (M=  23) - s=0.0100\n",
      "  23 - L= 2.6491418 - Gamma=23.8303771 (M=  24) - s=0.0100\n",
      "  24 - L= 2.7476019 - Gamma=24.7684779 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8151885 - Gamma=25.6803536 (M=  26) - s=0.0100\n",
      "  26 - L= 2.8559834 - Gamma=26.5538395 (M=  27) - s=0.0100\n",
      "  27 - L= 2.8775382 - Gamma=27.3534361 (M=  28) - s=0.0100\n",
      "  28 - L= 2.8897399 - Gamma=28.0779723 (M=  29) - s=0.0100\n",
      "  29 - L= 2.8991094 - Gamma=28.0789585 (M=  29) - s=0.0100\n",
      "  30 - L= 2.9068532 - Gamma=28.7500969 (M=  30) - s=0.0100\n",
      "  31 - L= 2.9128795 - Gamma=28.7514975 (M=  30) - s=0.0100\n",
      "  32 - L= 2.9167508 - Gamma=28.7526327 (M=  30) - s=0.0100\n",
      "  33 - L= 2.9205781 - Gamma=28.7733048 (M=  30) - s=0.0100\n",
      "  34 - L= 2.9243818 - Gamma=28.7486269 (M=  30) - s=0.0100\n",
      "  35 - L= 2.9279167 - Gamma=28.7576956 (M=  30) - s=0.0100\n",
      "  36 - L= 2.9309572 - Gamma=29.2698972 (M=  31) - s=0.0100\n",
      "  37 - L= 2.9338710 - Gamma=29.2700771 (M=  31) - s=0.0100\n",
      "  38 - L= 2.9367526 - Gamma=29.2701760 (M=  31) - s=0.0100\n",
      "  39 - L= 2.9392100 - Gamma=29.0772239 (M=  31) - s=0.0100\n",
      "  40 - L= 2.9416717 - Gamma=29.0777447 (M=  31) - s=0.0100\n",
      "  41 - L= 2.9436196 - Gamma=29.5371477 (M=  32) - s=0.0100\n",
      "  42 - L= 2.9454359 - Gamma=29.5371113 (M=  32) - s=0.0100\n",
      "  43 - L= 2.9470363 - Gamma=29.5373035 (M=  32) - s=0.0100\n",
      "  44 - L= 2.9483869 - Gamma=29.5446062 (M=  32) - s=0.0100\n",
      "  45 - L= 2.9497264 - Gamma=29.5470207 (M=  32) - s=0.0100\n",
      "  46 - L= 2.9508901 - Gamma=29.5471873 (M=  32) - s=0.0100\n",
      "  47 - L= 2.9517645 - Gamma=29.4850195 (M=  32) - s=0.0100\n",
      "  48 - L= 2.9525657 - Gamma=29.4846929 (M=  32) - s=0.0100\n",
      "  49 - L= 2.9532808 - Gamma=29.4844713 (M=  32) - s=0.0100\n",
      "  50 - L= 2.9539572 - Gamma=29.4848999 (M=  32) - s=0.0100\n",
      "  51 - L= 2.9546274 - Gamma=29.4458723 (M=  32) - s=0.0100\n",
      "  52 - L= 2.9550852 - Gamma=29.7074842 (M=  33) - s=0.0100\n",
      "  53 - L= 2.9554605 - Gamma=29.7085850 (M=  33) - s=0.0100\n",
      "  54 - L= 2.9556697 - Gamma=29.7100651 (M=  33) - s=0.0100\n",
      "  55 - L= 2.9558643 - Gamma=29.7099369 (M=  33) - s=0.0100\n",
      "  56 - L= 2.9560593 - Gamma=29.7564134 (M=  33) - s=0.0100\n",
      "  57 - L= 2.9562465 - Gamma=29.8153060 (M=  33) - s=0.0100\n",
      "  58 - L= 2.9564098 - Gamma=29.8489796 (M=  33) - s=0.0100\n",
      "  59 - L= 2.9565668 - Gamma=29.8484208 (M=  33) - s=0.0100\n",
      "  60 - L= 2.9567052 - Gamma=29.8530666 (M=  33) - s=0.0100\n",
      "  61 - L= 2.9568144 - Gamma=29.8524477 (M=  33) - s=0.0100\n",
      "  62 - L= 2.9569156 - Gamma=29.8436484 (M=  33) - s=0.0100\n",
      "  63 - L= 2.9569937 - Gamma=29.7927052 (M=  33) - s=0.0100\n",
      "  64 - L= 2.9570603 - Gamma=29.7182726 (M=  33) - s=0.0100\n",
      "  65 - L= 2.9571081 - Gamma=29.7139674 (M=  33) - s=0.0100\n",
      "  66 - L= 2.9571520 - Gamma=29.8067017 (M=  34) - s=0.0100\n",
      "  67 - L= 2.9571860 - Gamma=29.7639720 (M=  34) - s=0.0100\n",
      "  68 - L= 2.9572145 - Gamma=29.7795332 (M=  34) - s=0.0100\n",
      "  69 - L= 2.9572346 - Gamma=29.7783821 (M=  34) - s=0.0100\n",
      "  70 - L= 2.9572408 - Gamma=29.7843157 (M=  34) - s=0.0100\n",
      "  71 - L= 2.9572460 - Gamma=29.7840491 (M=  34) - s=0.0100\n",
      "  72 - L= 2.9572498 - Gamma=29.7721084 (M=  34) - s=0.0100\n",
      "  73 - L= 2.9572530 - Gamma=29.7958052 (M=  34) - s=0.0100\n",
      "  74 - L= 2.9572581 - Gamma=29.7707491 (M=  34) - s=0.0100\n",
      "  75 - L= 2.9572599 - Gamma=29.7808929 (M=  34) - s=0.0100\n",
      "  76 - L= 2.9572621 - Gamma=29.7666300 (M=  34) - s=0.0100\n",
      "  77 - L= 2.9572646 - Gamma=29.7872739 (M=  34) - s=0.0100\n",
      "  78 - L= 2.9572681 - Gamma=29.7915381 (M=  34) - s=0.0100\n",
      "  79 - L= 2.9572705 - Gamma=29.7957963 (M=  34) - s=0.0100\n",
      "  80 - L= 2.9572726 - Gamma=29.7790815 (M=  34) - s=0.0100\n",
      "  81 - L= 2.9572745 - Gamma=29.7966023 (M=  34) - s=0.0100\n",
      "  82 - L= 2.9572765 - Gamma=29.7960798 (M=  34) - s=0.0100\n",
      "  83 - L= 2.9572783 - Gamma=29.7927214 (M=  34) - s=0.0100\n",
      "  84 - L= 2.9572803 - Gamma=29.8031212 (M=  34) - s=0.0100\n",
      "  85 - L= 2.9572817 - Gamma=29.7892075 (M=  34) - s=0.0100\n",
      "  86 - L= 2.9572835 - Gamma=29.7921609 (M=  34) - s=0.0100\n",
      "  87 - L= 2.9572847 - Gamma=29.8058529 (M=  34) - s=0.0100\n",
      "  88 - L= 2.9572859 - Gamma=29.8065432 (M=  34) - s=0.0100\n",
      "  89 - L= 2.9572872 - Gamma=29.7993295 (M=  34) - s=0.0100\n",
      "  90 - L= 2.9572884 - Gamma=29.7886687 (M=  34) - s=0.0100\n",
      "  91 - L= 2.9572893 - Gamma=29.7913699 (M=  34) - s=0.0100\n",
      "  92 - L= 2.9572901 - Gamma=29.7897699 (M=  34) - s=0.0100\n",
      "  93 - L= 2.9572908 - Gamma=29.7897596 (M=  34) - s=0.0100\n",
      "  94 - L= 2.9572913 - Gamma=29.7987061 (M=  34) - s=0.0100\n",
      "  95 - L= 2.9572922 - Gamma=29.7873691 (M=  34) - s=0.0100\n",
      "  96 - L= 2.9572934 - Gamma=29.7951704 (M=  34) - s=0.0100\n",
      "  97 - L= 2.9572945 - Gamma=29.7974671 (M=  34) - s=0.0100\n",
      "  98 - L= 2.9572951 - Gamma=29.7973741 (M=  34) - s=0.0100\n",
      "  99 - L= 2.9572958 - Gamma=29.7953931 (M=  34) - s=0.0100\n",
      " 100 - L= 2.9572965 - Gamma=29.8056513 (M=  34) - s=0.0100\n",
      " 101 - L= 2.9572975 - Gamma=29.7935029 (M=  34) - s=0.0100\n",
      " 102 - L= 2.9572981 - Gamma=29.7991058 (M=  34) - s=0.0100\n",
      " 103 - L= 2.9572987 - Gamma=29.7990709 (M=  34) - s=0.0100\n",
      " 104 - L= 2.9572992 - Gamma=29.7990258 (M=  34) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 105 - L= 2.9572996 - Gamma=29.7996455 (M=  34) - s=0.0100\n",
      " 106 - L= 2.9573000 - Gamma=29.8009225 (M=  34) - s=0.0100\n",
      " 107 - L= 2.9573005 - Gamma=29.8092560 (M=  34) - s=0.0100\n",
      " 108 - L= 2.9573011 - Gamma=29.7992953 (M=  34) - s=0.0100\n",
      " 109 - L= 2.9573018 - Gamma=29.8014292 (M=  34) - s=0.0100\n",
      " 110 - L= 2.9573021 - Gamma=29.8079277 (M=  34) - s=0.0100\n",
      " 111 - L= 2.9573024 - Gamma=29.8041113 (M=  34) - s=0.0100\n",
      " 112 - L= 2.9573027 - Gamma=29.7986754 (M=  34) - s=0.0100\n",
      " 113 - L= 2.9573031 - Gamma=29.8000061 (M=  34) - s=0.0100\n",
      " 114 - L= 2.9573035 - Gamma=29.8044332 (M=  34) - s=0.0100\n",
      " 115 - L= 2.9573040 - Gamma=29.8149978 (M=  35) - s=0.0100\n",
      " 116 - L= 2.9573044 - Gamma=29.8069109 (M=  35) - s=0.0100\n",
      " 117 - L= 2.9573050 - Gamma=29.8161825 (M=  35) - s=0.0100\n",
      " 118 - L= 2.9573055 - Gamma=29.8144294 (M=  35) - s=0.0100\n",
      " 119 - L= 2.9573059 - Gamma=29.8186208 (M=  35) - s=0.0100\n",
      " 120 - L= 2.9573062 - Gamma=29.8116392 (M=  35) - s=0.0100\n",
      " 121 - L= 2.9573066 - Gamma=29.8130016 (M=  35) - s=0.0100\n",
      " 122 - L= 2.9573069 - Gamma=29.8212448 (M=  35) - s=0.0100\n",
      " 123 - L= 2.9573072 - Gamma=29.8277187 (M=  35) - s=0.0100\n",
      " 124 - L= 2.9573077 - Gamma=29.8208763 (M=  35) - s=0.0100\n",
      " 125 - L= 2.9573079 - Gamma=29.8243829 (M=  35) - s=0.0100\n",
      " 126 - L= 2.9573082 - Gamma=29.8173912 (M=  35) - s=0.0100\n",
      " 127 - L= 2.9573085 - Gamma=29.8171906 (M=  35) - s=0.0100\n",
      " 128 - L= 2.9573088 - Gamma=29.8250991 (M=  35) - s=0.0100\n",
      " 129 - L= 2.9573091 - Gamma=29.8314185 (M=  35) - s=0.0100\n",
      " 130 - L= 2.9573094 - Gamma=29.8325317 (M=  35) - s=0.0100\n",
      " 131 - L= 2.9573097 - Gamma=29.8288070 (M=  35) - s=0.0100\n",
      " 132 - L= 2.9573101 - Gamma=29.8305368 (M=  35) - s=0.0100\n",
      " 133 - L= 2.9573104 - Gamma=29.8236439 (M=  35) - s=0.0100\n",
      " 134 - L= 2.9573108 - Gamma=29.8301173 (M=  35) - s=0.0100\n",
      " 135 - L= 2.9573111 - Gamma=29.8340061 (M=  35) - s=0.0100\n",
      " 136 - L= 2.9573115 - Gamma=29.8323743 (M=  35) - s=0.0100\n",
      " 137 - L= 2.9573118 - Gamma=29.8323022 (M=  35) - s=0.0100\n",
      " 138 - L= 2.9573121 - Gamma=29.8321649 (M=  35) - s=0.0100\n",
      " 139 - L= 2.9573123 - Gamma=29.8321368 (M=  35) - s=0.0100\n",
      " 140 - L= 2.9573126 - Gamma=29.8321105 (M=  35) - s=0.0100\n",
      " 141 - L= 2.9573128 - Gamma=29.8321039 (M=  35) - s=0.0100\n",
      " 142 - L= 2.9573130 - Gamma=29.8330696 (M=  35) - s=0.0100\n",
      " 143 - L= 2.9573134 - Gamma=29.8257999 (M=  35) - s=0.0100\n",
      " 144 - L= 2.9573137 - Gamma=29.8347583 (M=  35) - s=0.0100\n",
      " 145 - L= 2.9573141 - Gamma=29.8388275 (M=  35) - s=0.0100\n",
      " 146 - L= 2.9573144 - Gamma=29.8453911 (M=  35) - s=0.0100\n",
      " 147 - L= 2.9573149 - Gamma=29.8384039 (M=  35) - s=0.0100\n",
      " 148 - L= 2.9573151 - Gamma=29.8324262 (M=  35) - s=0.0100\n",
      " 149 - L= 2.9573154 - Gamma=29.8335371 (M=  35) - s=0.0100\n",
      " 150 - L= 2.9573157 - Gamma=29.8391882 (M=  35) - s=0.0100\n",
      " 151 - L= 2.9573160 - Gamma=29.8471598 (M=  35) - s=0.0100\n",
      " 152 - L= 2.9573162 - Gamma=29.8474853 (M=  35) - s=0.0100\n",
      " 153 - L= 2.9573165 - Gamma=29.8439210 (M=  35) - s=0.0100\n",
      " 154 - L= 2.9573167 - Gamma=29.8380289 (M=  35) - s=0.0100\n",
      " 155 - L= 2.9573171 - Gamma=29.8420752 (M=  35) - s=0.0100\n",
      " 156 - L= 2.9573173 - Gamma=29.8407891 (M=  35) - s=0.0100\n",
      " 157 - L= 2.9573175 - Gamma=29.8459219 (M=  35) - s=0.0100\n",
      " 158 - L= 2.9573178 - Gamma=29.8472543 (M=  35) - s=0.0100\n",
      " 159 - L= 2.9573180 - Gamma=29.8482504 (M=  35) - s=0.0100\n",
      " 160 - L= 2.9573184 - Gamma=29.8406403 (M=  35) - s=0.0100\n",
      " 161 - L= 2.9573186 - Gamma=29.8410829 (M=  35) - s=0.0100\n",
      " 162 - L= 2.9573188 - Gamma=29.8462827 (M=  35) - s=0.0100\n",
      " 163 - L= 2.9573191 - Gamma=29.8535522 (M=  35) - s=0.0100\n",
      " 164 - L= 2.9573194 - Gamma=29.8571364 (M=  35) - s=0.0100\n",
      " 165 - L= 2.9573197 - Gamma=29.8512153 (M=  35) - s=0.0100\n",
      " 166 - L= 2.9573199 - Gamma=29.8511843 (M=  35) - s=0.0100\n",
      " 167 - L= 2.9573201 - Gamma=29.8455034 (M=  35) - s=0.0100\n",
      " 168 - L= 2.9573204 - Gamma=29.8465149 (M=  35) - s=0.0100\n",
      " 169 - L= 2.9573207 - Gamma=29.8523315 (M=  35) - s=0.0100\n",
      " 170 - L= 2.9573209 - Gamma=29.8521464 (M=  35) - s=0.0100\n",
      " 171 - L= 2.9573211 - Gamma=29.8589845 (M=  35) - s=0.0100\n",
      " 172 - L= 2.9573214 - Gamma=29.8520184 (M=  35) - s=0.0100\n",
      " 173 - L= 2.9573217 - Gamma=29.8558597 (M=  35) - s=0.0100\n",
      " 174 - L= 2.9573219 - Gamma=29.8546853 (M=  35) - s=0.0100\n",
      " 175 - L= 2.9573221 - Gamma=29.8546327 (M=  35) - s=0.0100\n",
      " 176 - L= 2.9573223 - Gamma=29.8518703 (M=  35) - s=0.0100\n",
      " 177 - L= 2.9573225 - Gamma=29.8570169 (M=  35) - s=0.0100\n",
      " 178 - L= 2.9573227 - Gamma=29.8579427 (M=  35) - s=0.0100\n",
      " 179 - L= 2.9573230 - Gamma=29.8513564 (M=  35) - s=0.0100\n",
      " 180 - L= 2.9573233 - Gamma=29.8594451 (M=  36) - s=0.0100\n",
      " 181 - L= 2.9573236 - Gamma=29.8530030 (M=  36) - s=0.0100\n",
      " 182 - L= 2.9573239 - Gamma=29.8590021 (M=  36) - s=0.0100\n",
      " 183 - L= 2.9573241 - Gamma=29.8602973 (M=  36) - s=0.0100\n",
      " 184 - L= 2.9573244 - Gamma=29.8551603 (M=  36) - s=0.0100\n",
      " 185 - L= 2.9573246 - Gamma=29.8561768 (M=  36) - s=0.0100\n",
      " 186 - L= 2.9573249 - Gamma=29.8633219 (M=  36) - s=0.0100\n",
      " 187 - L= 2.9573255 - Gamma=29.8530873 (M=  36) - s=0.0100\n",
      " 188 - L= 2.9573259 - Gamma=29.8602156 (M=  36) - s=0.0100\n",
      " 189 - L= 2.9573263 - Gamma=29.8681744 (M=  36) - s=0.0100\n",
      " 190 - L= 2.9573269 - Gamma=29.8570551 (M=  36) - s=0.0100\n",
      " 191 - L= 2.9573274 - Gamma=29.8657300 (M=  36) - s=0.0100\n",
      " 192 - L= 2.9573278 - Gamma=29.8670814 (M=  36) - s=0.0100\n",
      " 193 - L= 2.9573283 - Gamma=29.8574899 (M=  36) - s=0.0100\n",
      " 194 - L= 2.9573290 - Gamma=29.8664277 (M=  36) - s=0.0100\n",
      " 195 - L= 2.9573295 - Gamma=29.8616172 (M=  36) - s=0.0100\n",
      " 196 - L= 2.9573301 - Gamma=29.8714831 (M=  36) - s=0.0100\n",
      " 197 - L= 2.9573310 - Gamma=29.8583210 (M=  36) - s=0.0100\n",
      " 198 - L= 2.9573316 - Gamma=29.8682411 (M=  36) - s=0.0100\n",
      " 199 - L= 2.9573325 - Gamma=29.8579666 (M=  36) - s=0.0100\n",
      " 200 - L= 2.9573334 - Gamma=29.8597738 (M=  36) - s=0.0100\n",
      "Initial alpha = [[ 0.02981614]]\n",
      "   1 - L=-385.5067142 - Gamma= 1.9999487 (M=   2) - s=0.0100\n",
      "   2 - L=-240.6675310 - Gamma= 2.9998955 (M=   3) - s=0.0100\n",
      "   3 - L=-171.5434460 - Gamma= 3.9997575 (M=   4) - s=0.0100\n",
      "   4 - L=-128.9584985 - Gamma= 4.9995422 (M=   5) - s=0.0100\n",
      "   5 - L=-99.9485300 - Gamma= 5.9992707 (M=   6) - s=0.0100\n",
      "   6 - L=-81.4869898 - Gamma= 6.9988220 (M=   7) - s=0.0100\n",
      "   7 - L=-58.4318482 - Gamma= 7.9983980 (M=   8) - s=0.0100\n",
      "   8 - L=-45.2354482 - Gamma= 8.9977739 (M=   9) - s=0.0100\n",
      "   9 - L=-32.4479860 - Gamma= 9.9971114 (M=  10) - s=0.0100\n",
      "  10 - L=-23.9898362 - Gamma=10.9959995 (M=  11) - s=0.0100\n",
      "  11 - L=-18.6699226 - Gamma=11.9945022 (M=  12) - s=0.0100\n",
      "  12 - L=-12.0332768 - Gamma=12.9931371 (M=  13) - s=0.0100\n",
      "  13 - L=-7.4492399 - Gamma=13.9913682 (M=  14) - s=0.0100\n",
      "  14 - L=-4.8118829 - Gamma=14.9882244 (M=  15) - s=0.0100\n",
      "  15 - L=-2.6913316 - Gamma=15.9841502 (M=  16) - s=0.0100\n",
      "  16 - L=-1.0643705 - Gamma=16.9790619 (M=  17) - s=0.0100\n",
      "  17 - L= 0.1965035 - Gamma=17.9723308 (M=  18) - s=0.0100\n",
      "  18 - L= 0.9618276 - Gamma=18.9624466 (M=  19) - s=0.0100\n",
      "  19 - L= 1.7707148 - Gamma=19.9530548 (M=  20) - s=0.0100\n",
      "  20 - L= 2.0984530 - Gamma=20.9301391 (M=  21) - s=0.0100\n",
      "  21 - L= 2.4082835 - Gamma=21.9066696 (M=  22) - s=0.0100\n",
      "  22 - L= 2.6031715 - Gamma=22.8717382 (M=  23) - s=0.0100\n",
      "  23 - L= 2.7477266 - Gamma=23.8256177 (M=  24) - s=0.0100\n",
      "  24 - L= 2.8392321 - Gamma=24.7576339 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8914426 - Gamma=25.6569923 (M=  26) - s=0.0100\n",
      "  26 - L= 2.9279507 - Gamma=26.5232672 (M=  27) - s=0.0100\n",
      "  27 - L= 2.9508212 - Gamma=27.3412607 (M=  28) - s=0.0100\n",
      "  28 - L= 2.9644431 - Gamma=28.0920509 (M=  29) - s=0.0100\n",
      "  29 - L= 2.9716208 - Gamma=28.7446706 (M=  30) - s=0.0100\n",
      "  30 - L= 2.9775023 - Gamma=28.7472027 (M=  30) - s=0.0100\n",
      "  31 - L= 2.9827903 - Gamma=28.7470688 (M=  30) - s=0.0100\n",
      "  32 - L= 2.9871035 - Gamma=28.7475086 (M=  30) - s=0.0100\n",
      "  33 - L= 2.9908350 - Gamma=28.7566957 (M=  30) - s=0.0100\n",
      "  34 - L= 2.9940273 - Gamma=28.7563125 (M=  30) - s=0.0100\n",
      "  35 - L= 2.9971388 - Gamma=28.7566204 (M=  30) - s=0.0100\n",
      "  36 - L= 3.0001648 - Gamma=29.2888244 (M=  31) - s=0.0100\n",
      "  37 - L= 3.0029837 - Gamma=29.2897211 (M=  31) - s=0.0100\n",
      "  38 - L= 3.0053404 - Gamma=29.2869789 (M=  31) - s=0.0100\n",
      "  39 - L= 3.0066731 - Gamma=29.2893502 (M=  31) - s=0.0100\n",
      "  40 - L= 3.0078850 - Gamma=29.6835080 (M=  32) - s=0.0100\n",
      "  41 - L= 3.0089905 - Gamma=29.6758945 (M=  32) - s=0.0100\n",
      "  42 - L= 3.0100610 - Gamma=29.6751845 (M=  32) - s=0.0100\n",
      "  43 - L= 3.0110790 - Gamma=29.6754722 (M=  32) - s=0.0100\n",
      "  44 - L= 3.0117906 - Gamma=29.9966577 (M=  33) - s=0.0100\n",
      "  45 - L= 3.0124829 - Gamma=29.9967475 (M=  33) - s=0.0100\n",
      "  46 - L= 3.0130941 - Gamma=29.9256043 (M=  33) - s=0.0100\n",
      "  47 - L= 3.0136371 - Gamma=29.9243418 (M=  33) - s=0.0100\n",
      "  48 - L= 3.0141110 - Gamma=29.9243847 (M=  33) - s=0.0100\n",
      "  49 - L= 3.0144897 - Gamma=29.9237219 (M=  33) - s=0.0100\n",
      "  50 - L= 3.0148509 - Gamma=29.9514796 (M=  33) - s=0.0100\n",
      "  51 - L= 3.0151888 - Gamma=29.9510706 (M=  33) - s=0.0100\n",
      "  52 - L= 3.0154786 - Gamma=29.9567964 (M=  33) - s=0.0100\n",
      "  53 - L= 3.0156929 - Gamma=30.1523345 (M=  34) - s=0.0100\n",
      "  54 - L= 3.0159064 - Gamma=30.1424124 (M=  34) - s=0.0100\n",
      "  55 - L= 3.0160349 - Gamma=30.1431876 (M=  34) - s=0.0100\n",
      "  56 - L= 3.0161362 - Gamma=30.1431156 (M=  34) - s=0.0100\n",
      "  57 - L= 3.0162337 - Gamma=30.1308641 (M=  34) - s=0.0100\n",
      "  58 - L= 3.0163335 - Gamma=30.0139985 (M=  34) - s=0.0100\n",
      "  59 - L= 3.0164609 - Gamma=30.1627631 (M=  35) - s=0.0100\n",
      "  60 - L= 3.0166301 - Gamma=30.0528446 (M=  35) - s=0.0100\n",
      "  61 - L= 3.0166803 - Gamma=30.1540326 (M=  36) - s=0.0100\n",
      "  62 - L= 3.0167503 - Gamma=30.1191272 (M=  36) - s=0.0100\n",
      "  63 - L= 3.0167944 - Gamma=30.0322003 (M=  36) - s=0.0100\n",
      "  64 - L= 3.0168801 - Gamma=30.1522048 (M=  37) - s=0.0100\n",
      "  65 - L= 3.0169694 - Gamma=30.2576120 (M=  37) - s=0.0100\n",
      "  66 - L= 3.0170610 - Gamma=30.1600671 (M=  36) - s=0.0100\n",
      "  67 - L= 3.0171266 - Gamma=30.2540912 (M=  36) - s=0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in log\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n",
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in absolute\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68 - L= 3.0172128 - Gamma=30.1611288 (M=  36) - s=0.0100\n",
      "  69 - L= 3.0172980 - Gamma=30.2673147 (M=  36) - s=0.0100\n",
      "  70 - L= 3.0174021 - Gamma=30.2092803 (M=  36) - s=0.0100\n",
      "  71 - L= 3.0174381 - Gamma=30.2101779 (M=  36) - s=0.0100\n",
      "  72 - L= 3.0174659 - Gamma=30.2785622 (M=  36) - s=0.0100\n",
      "  73 - L= 3.0174953 - Gamma=30.2534637 (M=  36) - s=0.0100\n",
      "  74 - L= 3.0175277 - Gamma=30.3116447 (M=  36) - s=0.0100\n",
      "  75 - L= 3.0175740 - Gamma=30.2346244 (M=  36) - s=0.0100\n",
      "  76 - L= 3.0176203 - Gamma=30.3017791 (M=  36) - s=0.0100\n",
      "  77 - L= 3.0176455 - Gamma=30.3651395 (M=  37) - s=0.0100\n",
      "  78 - L= 3.0176719 - Gamma=30.3664901 (M=  37) - s=0.0100\n",
      "  79 - L= 3.0176986 - Gamma=30.4280441 (M=  37) - s=0.0100\n",
      "  80 - L= 3.0177198 - Gamma=30.4049329 (M=  37) - s=0.0100\n",
      "  81 - L= 3.0177372 - Gamma=30.4078010 (M=  37) - s=0.0100\n",
      "  82 - L= 3.0177570 - Gamma=30.3529531 (M=  37) - s=0.0100\n",
      "  83 - L= 3.0177845 - Gamma=30.4022224 (M=  37) - s=0.0100\n",
      "  84 - L= 3.0178026 - Gamma=30.3752860 (M=  37) - s=0.0100\n",
      "  85 - L= 3.0178186 - Gamma=30.3802077 (M=  37) - s=0.0100\n",
      "  86 - L= 3.0178339 - Gamma=30.3687625 (M=  37) - s=0.0100\n",
      "  87 - L= 3.0178475 - Gamma=30.4122939 (M=  37) - s=0.0100\n",
      "  88 - L= 3.0178623 - Gamma=30.4069291 (M=  37) - s=0.0100\n",
      "  89 - L= 3.0178757 - Gamma=30.4476259 (M=  37) - s=0.0100\n",
      "  90 - L= 3.0178872 - Gamma=30.4147234 (M=  37) - s=0.0100\n",
      "  91 - L= 3.0178996 - Gamma=30.3759728 (M=  37) - s=0.0100\n",
      "  92 - L= 3.0179202 - Gamma=30.4266116 (M=  37) - s=0.0100\n",
      "  93 - L= 3.0179361 - Gamma=30.4128744 (M=  37) - s=0.0100\n",
      "  94 - L= 3.0179507 - Gamma=30.4477396 (M=  37) - s=0.0100\n",
      "  95 - L= 3.0179700 - Gamma=30.3971007 (M=  37) - s=0.0100\n",
      "  96 - L= 3.0179881 - Gamma=30.4422165 (M=  37) - s=0.0100\n",
      "  97 - L= 3.0180137 - Gamma=30.4146178 (M=  37) - s=0.0100\n",
      "  98 - L= 3.0180374 - Gamma=30.4649513 (M=  37) - s=0.0100\n",
      "  99 - L= 3.0180682 - Gamma=30.4067753 (M=  37) - s=0.0100\n",
      " 100 - L= 3.0181071 - Gamma=30.3291614 (M=  37) - s=0.0100\n",
      " 101 - L= 3.0181616 - Gamma=30.4025102 (M=  37) - s=0.0100\n",
      " 102 - L= 3.0181911 - Gamma=30.3650474 (M=  36) - s=0.0100\n",
      " 103 - L= 3.0182082 - Gamma=30.3407373 (M=  36) - s=0.0100\n",
      " 104 - L= 3.0182272 - Gamma=30.3826546 (M=  36) - s=0.0100\n",
      " 105 - L= 3.0182502 - Gamma=30.3278671 (M=  36) - s=0.0100\n",
      " 106 - L= 3.0182799 - Gamma=30.3738810 (M=  36) - s=0.0100\n",
      " 107 - L= 3.0183092 - Gamma=30.3566307 (M=  36) - s=0.0100\n",
      " 108 - L= 3.0183231 - Gamma=30.3890147 (M=  36) - s=0.0100\n",
      " 109 - L= 3.0183343 - Gamma=30.3451016 (M=  36) - s=0.0100\n",
      " 110 - L= 3.0183494 - Gamma=30.3801622 (M=  36) - s=0.0100\n",
      " 111 - L= 3.0183664 - Gamma=30.3541214 (M=  36) - s=0.0100\n",
      " 112 - L= 3.0183922 - Gamma=30.4008171 (M=  36) - s=0.0100\n",
      " 113 - L= 3.0184062 - Gamma=30.3869776 (M=  36) - s=0.0100\n",
      " 114 - L= 3.0184185 - Gamma=30.3894666 (M=  36) - s=0.0100\n",
      " 115 - L= 3.0184301 - Gamma=30.3480956 (M=  36) - s=0.0100\n",
      " 116 - L= 3.0184435 - Gamma=30.3504485 (M=  36) - s=0.0100\n",
      " 117 - L= 3.0184548 - Gamma=30.3453770 (M=  36) - s=0.0100\n",
      " 118 - L= 3.0184624 - Gamma=30.3073788 (M=  36) - s=0.0100\n",
      " 119 - L= 3.0184742 - Gamma=30.3569559 (M=  37) - s=0.0100\n",
      " 120 - L= 3.0184839 - Gamma=30.3817013 (M=  37) - s=0.0100\n",
      " 121 - L= 3.0184926 - Gamma=30.3807442 (M=  37) - s=0.0100\n",
      " 122 - L= 3.0185000 - Gamma=30.3814186 (M=  37) - s=0.0100\n",
      " 123 - L= 3.0185064 - Gamma=30.4030565 (M=  37) - s=0.0100\n",
      " 124 - L= 3.0185135 - Gamma=30.3647204 (M=  37) - s=0.0100\n",
      " 125 - L= 3.0185200 - Gamma=30.3477545 (M=  37) - s=0.0100\n",
      " 126 - L= 3.0185288 - Gamma=30.3733559 (M=  37) - s=0.0100\n",
      " 127 - L= 3.0185371 - Gamma=30.3620949 (M=  37) - s=0.0100\n",
      " 128 - L= 3.0185422 - Gamma=30.3624123 (M=  37) - s=0.0100\n",
      " 129 - L= 3.0185474 - Gamma=30.3337359 (M=  37) - s=0.0100\n",
      " 130 - L= 3.0185537 - Gamma=30.3704070 (M=  38) - s=0.0100\n",
      " 131 - L= 3.0185585 - Gamma=30.3712624 (M=  38) - s=0.0100\n",
      " 132 - L= 3.0185635 - Gamma=30.3897353 (M=  38) - s=0.0100\n",
      " 133 - L= 3.0185701 - Gamma=30.3810365 (M=  38) - s=0.0100\n",
      " 134 - L= 3.0185765 - Gamma=30.3635496 (M=  38) - s=0.0100\n",
      " 135 - L= 3.0185832 - Gamma=30.3293539 (M=  38) - s=0.0100\n",
      " 136 - L= 3.0185912 - Gamma=30.3506818 (M=  38) - s=0.0100\n",
      " 137 - L= 3.0185959 - Gamma=30.3505968 (M=  38) - s=0.0100\n",
      " 138 - L= 3.0186005 - Gamma=30.3507204 (M=  38) - s=0.0100\n",
      " 139 - L= 3.0186047 - Gamma=30.3669442 (M=  38) - s=0.0100\n",
      " 140 - L= 3.0186110 - Gamma=30.3291318 (M=  38) - s=0.0100\n",
      " 141 - L= 3.0186208 - Gamma=30.3727100 (M=  38) - s=0.0100\n",
      " 142 - L= 3.0186216 - Gamma=30.3664560 (M=  37) - s=0.0100\n",
      " 143 - L= 3.0186289 - Gamma=30.3469418 (M=  37) - s=0.0100\n",
      " 144 - L= 3.0186403 - Gamma=30.3745776 (M=  37) - s=0.0100\n",
      " 145 - L= 3.0186479 - Gamma=30.3701880 (M=  37) - s=0.0100\n",
      " 146 - L= 3.0186537 - Gamma=30.3370429 (M=  37) - s=0.0100\n",
      " 147 - L= 3.0186603 - Gamma=30.3567248 (M=  37) - s=0.0100\n",
      " 148 - L= 3.0186679 - Gamma=30.3935142 (M=  37) - s=0.0100\n",
      " 149 - L= 3.0186766 - Gamma=30.3711571 (M=  37) - s=0.0100\n",
      " 150 - L= 3.0186835 - Gamma=30.3727612 (M=  37) - s=0.0100\n",
      " 151 - L= 3.0186901 - Gamma=30.3362329 (M=  37) - s=0.0100\n",
      " 152 - L= 3.0186980 - Gamma=30.3262523 (M=  37) - s=0.0100\n",
      " 153 - L= 3.0187041 - Gamma=30.3232165 (M=  37) - s=0.0100\n",
      " 154 - L= 3.0187101 - Gamma=30.3132169 (M=  37) - s=0.0100\n",
      " 155 - L= 3.0187174 - Gamma=30.3301464 (M=  37) - s=0.0100\n",
      " 156 - L= 3.0187239 - Gamma=30.3501228 (M=  37) - s=0.0100\n",
      " 157 - L= 3.0187293 - Gamma=30.3673033 (M=  37) - s=0.0100\n",
      " 158 - L= 3.0187353 - Gamma=30.3984611 (M=  37) - s=0.0100\n",
      " 159 - L= 3.0187461 - Gamma=30.3721381 (M=  37) - s=0.0100\n",
      " 160 - L= 3.0187576 - Gamma=30.3214238 (M=  37) - s=0.0100\n",
      " 161 - L= 3.0187658 - Gamma=30.3421717 (M=  37) - s=0.0100\n",
      " 162 - L= 3.0187717 - Gamma=30.3721353 (M=  37) - s=0.0100\n",
      " 163 - L= 3.0187733 - Gamma=30.3595039 (M=  36) - s=0.0100\n",
      " 164 - L= 3.0187791 - Gamma=30.3767590 (M=  36) - s=0.0100\n",
      " 165 - L= 3.0187867 - Gamma=30.3536568 (M=  36) - s=0.0100\n",
      " 166 - L= 3.0187926 - Gamma=30.3552927 (M=  36) - s=0.0100\n",
      " 167 - L= 3.0187976 - Gamma=30.3552600 (M=  36) - s=0.0100\n",
      " 168 - L= 3.0188022 - Gamma=30.3473460 (M=  36) - s=0.0100\n",
      " 169 - L= 3.0188067 - Gamma=30.3473397 (M=  36) - s=0.0100\n",
      " 170 - L= 3.0188105 - Gamma=30.3441252 (M=  36) - s=0.0100\n",
      " 171 - L= 3.0188155 - Gamma=30.3608113 (M=  36) - s=0.0100\n",
      " 172 - L= 3.0188203 - Gamma=30.3514863 (M=  36) - s=0.0100\n",
      " 173 - L= 3.0188250 - Gamma=30.3775339 (M=  36) - s=0.0100\n",
      " 174 - L= 3.0188309 - Gamma=30.3565396 (M=  36) - s=0.0100\n",
      " 175 - L= 3.0188375 - Gamma=30.3922174 (M=  36) - s=0.0100\n",
      " 176 - L= 3.0188410 - Gamma=30.3920107 (M=  36) - s=0.0100\n",
      " 177 - L= 3.0188441 - Gamma=30.3924328 (M=  36) - s=0.0100\n",
      " 178 - L= 3.0188462 - Gamma=30.3906105 (M=  36) - s=0.0100\n",
      " 179 - L= 3.0188481 - Gamma=30.3882998 (M=  36) - s=0.0100\n",
      " 180 - L= 3.0188499 - Gamma=30.4039192 (M=  36) - s=0.0100\n",
      " 181 - L= 3.0188522 - Gamma=30.3901907 (M=  36) - s=0.0100\n",
      " 182 - L= 3.0188554 - Gamma=30.4008401 (M=  36) - s=0.0100\n",
      " 183 - L= 3.0188583 - Gamma=30.3933431 (M=  36) - s=0.0100\n",
      " 184 - L= 3.0188614 - Gamma=30.4177358 (M=  37) - s=0.0100\n",
      " 185 - L= 3.0188640 - Gamma=30.4037460 (M=  37) - s=0.0100\n",
      " 186 - L= 3.0188659 - Gamma=30.4133185 (M=  37) - s=0.0100\n",
      " 187 - L= 3.0188679 - Gamma=30.4141674 (M=  37) - s=0.0100\n",
      " 188 - L= 3.0188692 - Gamma=30.4141370 (M=  37) - s=0.0100\n",
      " 189 - L= 3.0188705 - Gamma=30.4140743 (M=  37) - s=0.0100\n",
      " 190 - L= 3.0188717 - Gamma=30.4039644 (M=  37) - s=0.0100\n",
      " 191 - L= 3.0188737 - Gamma=30.4121351 (M=  37) - s=0.0100\n",
      " 192 - L= 3.0188749 - Gamma=30.4274641 (M=  37) - s=0.0100\n",
      " 193 - L= 3.0188773 - Gamma=30.4205501 (M=  37) - s=0.0100\n",
      " 194 - L= 3.0188788 - Gamma=30.4189658 (M=  37) - s=0.0100\n",
      " 195 - L= 3.0188803 - Gamma=30.4077633 (M=  37) - s=0.0100\n",
      " 196 - L= 3.0188817 - Gamma=30.4236849 (M=  37) - s=0.0100\n",
      " 197 - L= 3.0188834 - Gamma=30.4312142 (M=  37) - s=0.0100\n",
      " 198 - L= 3.0188849 - Gamma=30.4312827 (M=  37) - s=0.0100\n",
      " 199 - L= 3.0188860 - Gamma=30.4265476 (M=  37) - s=0.0100\n",
      " 200 - L= 3.0188872 - Gamma=30.4162830 (M=  37) - s=0.0100\n",
      "Initial alpha = [[ 0.02907605]]\n",
      "   1 - L=-412.0991692 - Gamma= 1.9999474 (M=   2) - s=0.0100\n",
      "   2 - L=-240.4065093 - Gamma= 2.9998959 (M=   3) - s=0.0100\n",
      "   3 - L=-181.7394880 - Gamma= 3.9997413 (M=   4) - s=0.0100\n",
      "   4 - L=-128.0318158 - Gamma= 4.9995827 (M=   5) - s=0.0100\n",
      "   5 - L=-100.6011406 - Gamma= 5.9992903 (M=   6) - s=0.0100\n",
      "   6 - L=-80.8505149 - Gamma= 6.9988861 (M=   7) - s=0.0100\n",
      "   7 - L=-58.7744373 - Gamma= 7.9985403 (M=   8) - s=0.0100\n",
      "   8 - L=-44.4073399 - Gamma= 8.9979322 (M=   9) - s=0.0100\n",
      "   9 - L=-35.2818697 - Gamma= 9.9970833 (M=  10) - s=0.0100\n",
      "  10 - L=-26.2282063 - Gamma=10.9961541 (M=  11) - s=0.0100\n",
      "  11 - L=-20.2748488 - Gamma=11.9948688 (M=  12) - s=0.0100\n",
      "  12 - L=-14.0565636 - Gamma=12.9935967 (M=  13) - s=0.0100\n",
      "  13 - L=-9.4396418 - Gamma=13.9916267 (M=  14) - s=0.0100\n",
      "  14 - L=-6.2064367 - Gamma=14.9892260 (M=  15) - s=0.0100\n",
      "  15 - L=-3.7994828 - Gamma=15.9859597 (M=  16) - s=0.0100\n",
      "  16 - L=-1.9416188 - Gamma=16.9817608 (M=  17) - s=0.0100\n",
      "  17 - L=-0.5334119 - Gamma=17.9763478 (M=  18) - s=0.0100\n",
      "  18 - L= 0.4484499 - Gamma=18.9679653 (M=  19) - s=0.0100\n",
      "  19 - L= 1.1606165 - Gamma=19.9565608 (M=  20) - s=0.0100\n",
      "  20 - L= 1.7993974 - Gamma=20.9447434 (M=  21) - s=0.0100\n",
      "  21 - L= 2.1845969 - Gamma=21.9253550 (M=  22) - s=0.0100\n",
      "  22 - L= 2.4257901 - Gamma=22.8941978 (M=  23) - s=0.0100\n",
      "  23 - L= 2.6339355 - Gamma=23.8568352 (M=  24) - s=0.0100\n",
      "  24 - L= 2.7399260 - Gamma=24.7978071 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8270170 - Gamma=25.7294981 (M=  26) - s=0.0100\n",
      "  26 - L= 2.8662690 - Gamma=26.6033998 (M=  27) - s=0.0100\n",
      "  27 - L= 2.8959220 - Gamma=27.4507763 (M=  28) - s=0.0100\n",
      "  28 - L= 2.9110896 - Gamma=28.2197226 (M=  29) - s=0.0100\n",
      "  29 - L= 2.9200296 - Gamma=28.2195092 (M=  29) - s=0.0100\n",
      "  30 - L= 2.9271911 - Gamma=28.2433705 (M=  29) - s=0.0100\n",
      "  31 - L= 2.9349558 - Gamma=28.9202351 (M=  30) - s=0.0100\n",
      "  32 - L= 2.9418692 - Gamma=28.9216017 (M=  30) - s=0.0100\n",
      "  33 - L= 2.9470285 - Gamma=28.9224639 (M=  30) - s=0.0100\n",
      "  34 - L= 2.9509911 - Gamma=28.9262248 (M=  30) - s=0.0100\n",
      "  35 - L= 2.9549196 - Gamma=28.9080969 (M=  30) - s=0.0100\n",
      "  36 - L= 2.9587834 - Gamma=28.9097858 (M=  30) - s=0.0100\n",
      "  37 - L= 2.9624873 - Gamma=29.4727281 (M=  31) - s=0.0100\n",
      "  38 - L= 2.9659189 - Gamma=29.4736288 (M=  31) - s=0.0100\n",
      "  39 - L= 2.9691448 - Gamma=29.4741258 (M=  31) - s=0.0100\n",
      "  40 - L= 2.9720758 - Gamma=29.4744466 (M=  31) - s=0.0100\n",
      "  41 - L= 2.9749360 - Gamma=29.4728020 (M=  31) - s=0.0100\n",
      "  42 - L= 2.9770792 - Gamma=29.4723282 (M=  31) - s=0.0100\n",
      "  43 - L= 2.9783473 - Gamma=29.4757456 (M=  31) - s=0.0100\n",
      "  44 - L= 2.9793974 - Gamma=29.4985925 (M=  31) - s=0.0100\n",
      "  45 - L= 2.9804605 - Gamma=29.5119191 (M=  31) - s=0.0100\n",
      "  46 - L= 2.9813027 - Gamma=29.8503666 (M=  32) - s=0.0100\n",
      "  47 - L= 2.9817915 - Gamma=29.8396756 (M=  32) - s=0.0100\n",
      "  48 - L= 2.9822416 - Gamma=29.8397206 (M=  32) - s=0.0100\n",
      "  49 - L= 2.9826288 - Gamma=30.0860128 (M=  33) - s=0.0100\n",
      "  50 - L= 2.9830156 - Gamma=30.0586164 (M=  33) - s=0.0100\n",
      "  51 - L= 2.9833026 - Gamma=30.2366566 (M=  34) - s=0.0100\n",
      "  52 - L= 2.9835426 - Gamma=30.2646567 (M=  34) - s=0.0100\n",
      "  53 - L= 2.9837616 - Gamma=30.2646819 (M=  34) - s=0.0100\n",
      "  54 - L= 2.9839404 - Gamma=30.2615407 (M=  34) - s=0.0100\n",
      "  55 - L= 2.9841120 - Gamma=30.4318191 (M=  35) - s=0.0100\n",
      "  56 - L= 2.9844645 - Gamma=30.2003097 (M=  35) - s=0.0100\n",
      "  57 - L= 2.9846472 - Gamma=30.2007397 (M=  35) - s=0.0100\n",
      "  58 - L= 2.9847779 - Gamma=30.2007774 (M=  35) - s=0.0100\n",
      "  59 - L= 2.9848869 - Gamma=30.2030721 (M=  35) - s=0.0100\n",
      "  60 - L= 2.9849923 - Gamma=30.2038261 (M=  35) - s=0.0100\n",
      "  61 - L= 2.9850952 - Gamma=30.2056240 (M=  35) - s=0.0100\n",
      "  62 - L= 2.9851868 - Gamma=30.2056816 (M=  35) - s=0.0100\n",
      "  63 - L= 2.9852771 - Gamma=30.3109558 (M=  35) - s=0.0100\n",
      "  64 - L= 2.9853511 - Gamma=30.3865685 (M=  35) - s=0.0100\n",
      "  65 - L= 2.9854854 - Gamma=30.3216637 (M=  35) - s=0.0100\n",
      "  66 - L= 2.9855611 - Gamma=30.2983001 (M=  35) - s=0.0100\n",
      "  67 - L= 2.9856276 - Gamma=30.2931613 (M=  35) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68 - L= 2.9857089 - Gamma=30.3599065 (M=  35) - s=0.0100\n",
      "  69 - L= 2.9857765 - Gamma=30.3457010 (M=  35) - s=0.0100\n",
      "  70 - L= 2.9858262 - Gamma=30.2557089 (M=  34) - s=0.0100\n",
      "  71 - L= 2.9859363 - Gamma=30.3544311 (M=  34) - s=0.0100\n",
      "  72 - L= 2.9860120 - Gamma=30.2961524 (M=  34) - s=0.0100\n",
      "  73 - L= 2.9860849 - Gamma=30.2626591 (M=  34) - s=0.0100\n",
      "  74 - L= 2.9861686 - Gamma=30.3199446 (M=  34) - s=0.0100\n",
      "  75 - L= 2.9862513 - Gamma=30.2075088 (M=  34) - s=0.0100\n",
      "  76 - L= 2.9863506 - Gamma=30.2225022 (M=  34) - s=0.0100\n",
      "  77 - L= 2.9864304 - Gamma=30.1514611 (M=  34) - s=0.0100\n",
      "  78 - L= 2.9865208 - Gamma=30.2099525 (M=  34) - s=0.0100\n",
      "  79 - L= 2.9866379 - Gamma=30.2668431 (M=  34) - s=0.0100\n",
      "  80 - L= 2.9867144 - Gamma=30.1842676 (M=  34) - s=0.0100\n",
      "  81 - L= 2.9868063 - Gamma=30.0505207 (M=  33) - s=0.0100\n",
      "  82 - L= 2.9870391 - Gamma=30.2575497 (M=  34) - s=0.0100\n",
      "  83 - L= 2.9872264 - Gamma=30.1909190 (M=  34) - s=0.0100\n",
      "  84 - L= 2.9872979 - Gamma=30.3123168 (M=  35) - s=0.0100\n",
      "  85 - L= 2.9873985 - Gamma=30.2014680 (M=  35) - s=0.0100\n",
      "  86 - L= 2.9875989 - Gamma=30.2619461 (M=  35) - s=0.0100\n",
      "  87 - L= 2.9876930 - Gamma=30.1839094 (M=  34) - s=0.0100\n",
      "  88 - L= 2.9877711 - Gamma=30.1767078 (M=  34) - s=0.0100\n",
      "  89 - L= 2.9878480 - Gamma=30.1489300 (M=  34) - s=0.0100\n",
      "  90 - L= 2.9879251 - Gamma=30.2596487 (M=  34) - s=0.0100\n",
      "  91 - L= 2.9879837 - Gamma=30.2699033 (M=  34) - s=0.0100\n",
      "  92 - L= 2.9880273 - Gamma=30.3060714 (M=  34) - s=0.0100\n",
      "  93 - L= 2.9880786 - Gamma=30.3328028 (M=  34) - s=0.0100\n",
      "  94 - L= 2.9881159 - Gamma=30.3289685 (M=  34) - s=0.0100\n",
      "  95 - L= 2.9881429 - Gamma=30.3188019 (M=  34) - s=0.0100\n",
      "  96 - L= 2.9881641 - Gamma=30.2932164 (M=  34) - s=0.0100\n",
      "  97 - L= 2.9881762 - Gamma=30.2480930 (M=  34) - s=0.0100\n",
      "  98 - L= 2.9881941 - Gamma=30.3075691 (M=  35) - s=0.0100\n",
      "  99 - L= 2.9882015 - Gamma=30.3109616 (M=  35) - s=0.0100\n",
      " 100 - L= 2.9882085 - Gamma=30.3114054 (M=  35) - s=0.0100\n",
      " 101 - L= 2.9882152 - Gamma=30.3114835 (M=  35) - s=0.0100\n",
      " 102 - L= 2.9882213 - Gamma=30.3241673 (M=  35) - s=0.0100\n",
      " 103 - L= 2.9882280 - Gamma=30.3008598 (M=  35) - s=0.0100\n",
      " 104 - L= 2.9882339 - Gamma=30.3093594 (M=  35) - s=0.0100\n",
      " 105 - L= 2.9882387 - Gamma=30.3351221 (M=  35) - s=0.0100\n",
      " 106 - L= 2.9882446 - Gamma=30.3329493 (M=  35) - s=0.0100\n",
      " 107 - L= 2.9882502 - Gamma=30.3647479 (M=  35) - s=0.0100\n",
      " 108 - L= 2.9882575 - Gamma=30.3281804 (M=  35) - s=0.0100\n",
      " 109 - L= 2.9882622 - Gamma=30.3280828 (M=  35) - s=0.0100\n",
      " 110 - L= 2.9882661 - Gamma=30.3279471 (M=  35) - s=0.0100\n",
      " 111 - L= 2.9882685 - Gamma=30.3279148 (M=  35) - s=0.0100\n",
      " 112 - L= 2.9882708 - Gamma=30.3280399 (M=  35) - s=0.0100\n",
      " 113 - L= 2.9882730 - Gamma=30.3275210 (M=  35) - s=0.0100\n",
      " 114 - L= 2.9882752 - Gamma=30.3265457 (M=  35) - s=0.0100\n",
      " 115 - L= 2.9882773 - Gamma=30.3259781 (M=  35) - s=0.0100\n",
      " 116 - L= 2.9882792 - Gamma=30.3418153 (M=  35) - s=0.0100\n",
      " 117 - L= 2.9882813 - Gamma=30.3285966 (M=  35) - s=0.0100\n",
      " 118 - L= 2.9882858 - Gamma=30.3559801 (M=  35) - s=0.0100\n",
      " 119 - L= 2.9882888 - Gamma=30.3458796 (M=  35) - s=0.0100\n",
      " 120 - L= 2.9882920 - Gamma=30.3480444 (M=  35) - s=0.0100\n",
      " 121 - L= 2.9882950 - Gamma=30.3539204 (M=  35) - s=0.0100\n",
      " 122 - L= 2.9882975 - Gamma=30.3390794 (M=  35) - s=0.0100\n",
      " 123 - L= 2.9883006 - Gamma=30.3478722 (M=  35) - s=0.0100\n",
      " 124 - L= 2.9883032 - Gamma=30.3680218 (M=  35) - s=0.0100\n",
      " 125 - L= 2.9883058 - Gamma=30.3712176 (M=  35) - s=0.0100\n",
      " 126 - L= 2.9883080 - Gamma=30.3568295 (M=  35) - s=0.0100\n",
      " 127 - L= 2.9883094 - Gamma=30.3716659 (M=  35) - s=0.0100\n",
      " 128 - L= 2.9883110 - Gamma=30.3542612 (M=  35) - s=0.0100\n",
      " 129 - L= 2.9883129 - Gamma=30.3695247 (M=  35) - s=0.0100\n",
      " 130 - L= 2.9883140 - Gamma=30.3631290 (M=  35) - s=0.0100\n",
      " 131 - L= 2.9883151 - Gamma=30.3631377 (M=  35) - s=0.0100\n",
      " 132 - L= 2.9883161 - Gamma=30.3631579 (M=  35) - s=0.0100\n",
      " 133 - L= 2.9883171 - Gamma=30.3643451 (M=  35) - s=0.0100\n",
      " 134 - L= 2.9883182 - Gamma=30.3639292 (M=  35) - s=0.0100\n",
      " 135 - L= 2.9883191 - Gamma=30.3639179 (M=  35) - s=0.0100\n",
      " 136 - L= 2.9883200 - Gamma=30.3639136 (M=  35) - s=0.0100\n",
      " 137 - L= 2.9883208 - Gamma=30.3639190 (M=  35) - s=0.0100\n",
      " 138 - L= 2.9883216 - Gamma=30.3551849 (M=  35) - s=0.0100\n",
      " 139 - L= 2.9883233 - Gamma=30.3708067 (M=  35) - s=0.0100\n",
      " 140 - L= 2.9883243 - Gamma=30.3701228 (M=  35) - s=0.0100\n",
      " 141 - L= 2.9883251 - Gamma=30.3730500 (M=  35) - s=0.0100\n",
      " 142 - L= 2.9883258 - Gamma=30.3722716 (M=  35) - s=0.0100\n",
      " 143 - L= 2.9883264 - Gamma=30.3646688 (M=  35) - s=0.0100\n",
      " 144 - L= 2.9883272 - Gamma=30.3782092 (M=  36) - s=0.0100\n",
      " 145 - L= 2.9883286 - Gamma=30.3839331 (M=  36) - s=0.0100\n",
      " 146 - L= 2.9883293 - Gamma=30.3723046 (M=  36) - s=0.0100\n",
      " 147 - L= 2.9883301 - Gamma=30.3828925 (M=  36) - s=0.0100\n",
      " 148 - L= 2.9883309 - Gamma=30.3738764 (M=  36) - s=0.0100\n",
      " 149 - L= 2.9883316 - Gamma=30.3860341 (M=  36) - s=0.0100\n",
      " 150 - L= 2.9883325 - Gamma=30.3803080 (M=  36) - s=0.0100\n",
      " 151 - L= 2.9883332 - Gamma=30.3803423 (M=  36) - s=0.0100\n",
      " 152 - L= 2.9883337 - Gamma=30.3817508 (M=  36) - s=0.0100\n",
      " 153 - L= 2.9883342 - Gamma=30.3899771 (M=  36) - s=0.0100\n",
      " 154 - L= 2.9883349 - Gamma=30.3812991 (M=  36) - s=0.0100\n",
      " 155 - L= 2.9883356 - Gamma=30.3851389 (M=  36) - s=0.0100\n",
      " 156 - L= 2.9883361 - Gamma=30.3874527 (M=  36) - s=0.0100\n",
      " 157 - L= 2.9883365 - Gamma=30.3974895 (M=  36) - s=0.0100\n",
      " 158 - L= 2.9883370 - Gamma=30.3976605 (M=  36) - s=0.0100\n",
      " 159 - L= 2.9883375 - Gamma=30.3976633 (M=  36) - s=0.0100\n",
      " 160 - L= 2.9883379 - Gamma=30.3976343 (M=  36) - s=0.0100\n",
      " 161 - L= 2.9883382 - Gamma=30.3976325 (M=  36) - s=0.0100\n",
      " 162 - L= 2.9883384 - Gamma=30.3982584 (M=  36) - s=0.0100\n",
      " 163 - L= 2.9883388 - Gamma=30.4047652 (M=  36) - s=0.0100\n",
      " 164 - L= 2.9883394 - Gamma=30.3966321 (M=  36) - s=0.0100\n",
      " 165 - L= 2.9883398 - Gamma=30.3926215 (M=  36) - s=0.0100\n",
      " 166 - L= 2.9883402 - Gamma=30.3955490 (M=  36) - s=0.0100\n",
      " 167 - L= 2.9883406 - Gamma=30.4026133 (M=  36) - s=0.0100\n",
      " 168 - L= 2.9883409 - Gamma=30.3969851 (M=  36) - s=0.0100\n",
      " 169 - L= 2.9883412 - Gamma=30.4050889 (M=  36) - s=0.0100\n",
      " 170 - L= 2.9883415 - Gamma=30.4049917 (M=  36) - s=0.0100\n",
      " 171 - L= 2.9883418 - Gamma=30.4046196 (M=  36) - s=0.0100\n",
      " 172 - L= 2.9883421 - Gamma=30.3964719 (M=  36) - s=0.0100\n",
      " 173 - L= 2.9883424 - Gamma=30.4025134 (M=  36) - s=0.0100\n",
      " 174 - L= 2.9883427 - Gamma=30.4023158 (M=  36) - s=0.0100\n",
      " 175 - L= 2.9883429 - Gamma=30.4039549 (M=  36) - s=0.0100\n",
      " 176 - L= 2.9883431 - Gamma=30.4039485 (M=  36) - s=0.0100\n",
      " 177 - L= 2.9883434 - Gamma=30.4089639 (M=  36) - s=0.0100\n",
      " 178 - L= 2.9883436 - Gamma=30.4034889 (M=  36) - s=0.0100\n",
      " 179 - L= 2.9883439 - Gamma=30.4057172 (M=  36) - s=0.0100\n",
      " 180 - L= 2.9883441 - Gamma=30.4028393 (M=  36) - s=0.0100\n",
      " 181 - L= 2.9883443 - Gamma=30.4034067 (M=  36) - s=0.0100\n",
      " 182 - L= 2.9883446 - Gamma=30.4091755 (M=  36) - s=0.0100\n",
      " 183 - L= 2.9883448 - Gamma=30.4041185 (M=  36) - s=0.0100\n",
      " 184 - L= 2.9883450 - Gamma=30.4040866 (M=  36) - s=0.0100\n",
      " 185 - L= 2.9883452 - Gamma=30.4049230 (M=  36) - s=0.0100\n",
      " 186 - L= 2.9883453 - Gamma=30.4062146 (M=  36) - s=0.0100\n",
      " 187 - L= 2.9883455 - Gamma=30.4062139 (M=  36) - s=0.0100\n",
      " 188 - L= 2.9883456 - Gamma=30.4062178 (M=  36) - s=0.0100\n",
      " 189 - L= 2.9883457 - Gamma=30.4099056 (M=  36) - s=0.0100\n",
      " 190 - L= 2.9883459 - Gamma=30.4041067 (M=  36) - s=0.0100\n",
      " 191 - L= 2.9883460 - Gamma=30.4089152 (M=  36) - s=0.0100\n",
      " 192 - L= 2.9883462 - Gamma=30.4046128 (M=  36) - s=0.0100\n",
      " 193 - L= 2.9883463 - Gamma=30.4063729 (M=  36) - s=0.0100\n",
      " 194 - L= 2.9883464 - Gamma=30.4101246 (M=  36) - s=0.0100\n",
      " 195 - L= 2.9883465 - Gamma=30.4112353 (M=  36) - s=0.0100\n",
      " 196 - L= 2.9883467 - Gamma=30.4089573 (M=  36) - s=0.0100\n",
      " 197 - L= 2.9883468 - Gamma=30.4056303 (M=  36) - s=0.0100\n",
      " 198 - L= 2.9883469 - Gamma=30.4115844 (M=  36) - s=0.0100\n",
      " 199 - L= 2.9883470 - Gamma=30.4113640 (M=  36) - s=0.0100\n",
      " 200 - L= 2.9883471 - Gamma=30.4127297 (M=  36) - s=0.0100\n",
      "Initial alpha = [[ 0.02863823]]\n",
      "   1 - L=-361.6706974 - Gamma= 1.9999435 (M=   2) - s=0.0100\n",
      "   2 - L=-220.4136706 - Gamma= 2.9998896 (M=   3) - s=0.0100\n",
      "   3 - L=-169.6370343 - Gamma= 3.9997335 (M=   4) - s=0.0100\n",
      "   4 - L=-128.7756958 - Gamma= 4.9994769 (M=   5) - s=0.0100\n",
      "   5 - L=-85.4377554 - Gamma= 5.9992756 (M=   6) - s=0.0100\n",
      "   6 - L=-68.0388460 - Gamma= 6.9988012 (M=   7) - s=0.0100\n",
      "   7 - L=-55.0434086 - Gamma= 7.9981930 (M=   8) - s=0.0100\n",
      "   8 - L=-43.9062631 - Gamma= 8.9974938 (M=   9) - s=0.0100\n",
      "   9 - L=-30.0686675 - Gamma= 9.9968330 (M=  10) - s=0.0100\n",
      "  10 - L=-23.3801276 - Gamma=10.9956317 (M=  11) - s=0.0100\n",
      "  11 - L=-17.9487107 - Gamma=11.9940590 (M=  12) - s=0.0100\n",
      "  12 - L=-13.0531783 - Gamma=12.9924731 (M=  13) - s=0.0100\n",
      "  13 - L=-8.5331744 - Gamma=13.9907153 (M=  14) - s=0.0100\n",
      "  14 - L=-5.5419812 - Gamma=14.9881335 (M=  15) - s=0.0100\n",
      "  15 - L=-2.9649073 - Gamma=15.9843547 (M=  16) - s=0.0100\n",
      "  16 - L=-1.0980871 - Gamma=16.9800461 (M=  17) - s=0.0100\n",
      "  17 - L= 0.0497685 - Gamma=17.9734399 (M=  18) - s=0.0100\n",
      "  18 - L= 0.8987812 - Gamma=18.9643689 (M=  19) - s=0.0100\n",
      "  19 - L= 1.6004262 - Gamma=19.9533550 (M=  20) - s=0.0100\n",
      "  20 - L= 1.9726012 - Gamma=20.9332944 (M=  21) - s=0.0100\n",
      "  21 - L= 2.3413328 - Gamma=21.9131129 (M=  22) - s=0.0100\n",
      "  22 - L= 2.5537400 - Gamma=22.8805160 (M=  23) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  23 - L= 2.7069345 - Gamma=23.8346713 (M=  24) - s=0.0100\n",
      "  24 - L= 2.8195625 - Gamma=24.7779865 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8927725 - Gamma=25.6948145 (M=  26) - s=0.0100\n",
      "  26 - L= 2.9285511 - Gamma=26.5568518 (M=  27) - s=0.0100\n",
      "  27 - L= 2.9635536 - Gamma=27.4185391 (M=  28) - s=0.0100\n",
      "  28 - L= 2.9814295 - Gamma=27.4134019 (M=  28) - s=0.0100\n",
      "  29 - L= 2.9944074 - Gamma=28.1687307 (M=  29) - s=0.0100\n",
      "  30 - L= 3.0054065 - Gamma=28.1683903 (M=  29) - s=0.0100\n",
      "  31 - L= 3.0139978 - Gamma=28.1687645 (M=  29) - s=0.0100\n",
      "  32 - L= 3.0220696 - Gamma=28.1713632 (M=  29) - s=0.0100\n",
      "  33 - L= 3.0295731 - Gamma=28.8353123 (M=  30) - s=0.0100\n",
      "  34 - L= 3.0366991 - Gamma=28.8367961 (M=  30) - s=0.0100\n",
      "  35 - L= 3.0423513 - Gamma=28.8338503 (M=  30) - s=0.0100\n",
      "  36 - L= 3.0458639 - Gamma=29.3911778 (M=  31) - s=0.0100\n",
      "  37 - L= 3.0479005 - Gamma=29.8655929 (M=  32) - s=0.0100\n",
      "  38 - L= 3.0497771 - Gamma=29.8759479 (M=  32) - s=0.0100\n",
      "  39 - L= 3.0513921 - Gamma=29.8761637 (M=  32) - s=0.0100\n",
      "  40 - L= 3.0528254 - Gamma=29.8757083 (M=  32) - s=0.0100\n",
      "  41 - L= 3.0538925 - Gamma=29.8760572 (M=  32) - s=0.0100\n",
      "  42 - L= 3.0549128 - Gamma=29.9067317 (M=  32) - s=0.0100\n",
      "  43 - L= 3.0558140 - Gamma=29.9058056 (M=  32) - s=0.0100\n",
      "  44 - L= 3.0566531 - Gamma=29.9067094 (M=  32) - s=0.0100\n",
      "  45 - L= 3.0573338 - Gamma=29.9009288 (M=  32) - s=0.0100\n",
      "  46 - L= 3.0579753 - Gamma=30.2091011 (M=  33) - s=0.0100\n",
      "  47 - L= 3.0585846 - Gamma=30.5047120 (M=  34) - s=0.0100\n",
      "  48 - L= 3.0591142 - Gamma=30.5037440 (M=  34) - s=0.0100\n",
      "  49 - L= 3.0595329 - Gamma=30.5073709 (M=  34) - s=0.0100\n",
      "  50 - L= 3.0599058 - Gamma=30.5070609 (M=  34) - s=0.0100\n",
      "  51 - L= 3.0601804 - Gamma=30.5070020 (M=  34) - s=0.0100\n",
      "  52 - L= 3.0604069 - Gamma=30.3828913 (M=  34) - s=0.0100\n",
      "  53 - L= 3.0605842 - Gamma=30.4075131 (M=  34) - s=0.0100\n",
      "  54 - L= 3.0606836 - Gamma=30.4149529 (M=  34) - s=0.0100\n",
      "  55 - L= 3.0607789 - Gamma=30.5080989 (M=  34) - s=0.0100\n",
      "  56 - L= 3.0608533 - Gamma=30.5086989 (M=  34) - s=0.0100\n",
      "  57 - L= 3.0609165 - Gamma=30.5102892 (M=  34) - s=0.0100\n",
      "  58 - L= 3.0609738 - Gamma=30.4683536 (M=  34) - s=0.0100\n",
      "  59 - L= 3.0610287 - Gamma=30.4676760 (M=  34) - s=0.0100\n",
      "  60 - L= 3.0610761 - Gamma=30.4608315 (M=  34) - s=0.0100\n",
      "  61 - L= 3.0611169 - Gamma=30.4461643 (M=  34) - s=0.0100\n",
      "  62 - L= 3.0611650 - Gamma=30.5136269 (M=  34) - s=0.0100\n",
      "  63 - L= 3.0612141 - Gamma=30.4457242 (M=  34) - s=0.0100\n",
      "  64 - L= 3.0612546 - Gamma=30.4458370 (M=  34) - s=0.0100\n",
      "  65 - L= 3.0612813 - Gamma=30.4900116 (M=  34) - s=0.0100\n",
      "  66 - L= 3.0613032 - Gamma=30.4706680 (M=  34) - s=0.0100\n",
      "  67 - L= 3.0613153 - Gamma=30.4704306 (M=  34) - s=0.0100\n",
      "  68 - L= 3.0613270 - Gamma=30.4726130 (M=  34) - s=0.0100\n",
      "  69 - L= 3.0613364 - Gamma=30.4733801 (M=  34) - s=0.0100\n",
      "  70 - L= 3.0613463 - Gamma=30.5017758 (M=  34) - s=0.0100\n",
      "  71 - L= 3.0613561 - Gamma=30.4830633 (M=  34) - s=0.0100\n",
      "  72 - L= 3.0613669 - Gamma=30.4487651 (M=  34) - s=0.0100\n",
      "  73 - L= 3.0613766 - Gamma=30.4410260 (M=  34) - s=0.0100\n",
      "  74 - L= 3.0613829 - Gamma=30.4411211 (M=  34) - s=0.0100\n",
      "  75 - L= 3.0613888 - Gamma=30.4606488 (M=  34) - s=0.0100\n",
      "  76 - L= 3.0613952 - Gamma=30.4976800 (M=  35) - s=0.0100\n",
      "  77 - L= 3.0614000 - Gamma=30.4938108 (M=  35) - s=0.0100\n",
      "  78 - L= 3.0614037 - Gamma=30.4944855 (M=  35) - s=0.0100\n",
      "  79 - L= 3.0614074 - Gamma=30.4928784 (M=  35) - s=0.0100\n",
      "  80 - L= 3.0614110 - Gamma=30.5093309 (M=  35) - s=0.0100\n",
      "  81 - L= 3.0614153 - Gamma=30.4865830 (M=  35) - s=0.0100\n",
      "  82 - L= 3.0614189 - Gamma=30.4864012 (M=  35) - s=0.0100\n",
      "  83 - L= 3.0614222 - Gamma=30.4845047 (M=  35) - s=0.0100\n",
      "  84 - L= 3.0614248 - Gamma=30.4833748 (M=  35) - s=0.0100\n",
      "  85 - L= 3.0614282 - Gamma=30.4719348 (M=  35) - s=0.0100\n",
      "  86 - L= 3.0614303 - Gamma=30.4722097 (M=  35) - s=0.0100\n",
      "  87 - L= 3.0614323 - Gamma=30.4722377 (M=  35) - s=0.0100\n",
      "  88 - L= 3.0614339 - Gamma=30.4689669 (M=  35) - s=0.0100\n",
      "  89 - L= 3.0614360 - Gamma=30.4802866 (M=  35) - s=0.0100\n",
      "  90 - L= 3.0614385 - Gamma=30.4937262 (M=  35) - s=0.0100\n",
      "  91 - L= 3.0614406 - Gamma=30.4773545 (M=  35) - s=0.0100\n",
      "  92 - L= 3.0614420 - Gamma=30.4772960 (M=  35) - s=0.0100\n",
      "  93 - L= 3.0614427 - Gamma=30.4888601 (M=  35) - s=0.0100\n",
      "  94 - L= 3.0614432 - Gamma=30.4842261 (M=  35) - s=0.0100\n",
      "  95 - L= 3.0614439 - Gamma=30.4904059 (M=  35) - s=0.0100\n",
      "  96 - L= 3.0614445 - Gamma=30.4883856 (M=  35) - s=0.0100\n",
      "  97 - L= 3.0614450 - Gamma=30.4854464 (M=  35) - s=0.0100\n",
      "  98 - L= 3.0614454 - Gamma=30.4779597 (M=  35) - s=0.0100\n",
      "  99 - L= 3.0614460 - Gamma=30.4842562 (M=  35) - s=0.0100\n",
      " 100 - L= 3.0614464 - Gamma=30.4844175 (M=  35) - s=0.0100\n",
      " 101 - L= 3.0614468 - Gamma=30.4843719 (M=  35) - s=0.0100\n",
      " 102 - L= 3.0614471 - Gamma=30.4843695 (M=  35) - s=0.0100\n",
      " 103 - L= 3.0614474 - Gamma=30.4843646 (M=  35) - s=0.0100\n",
      " 104 - L= 3.0614476 - Gamma=30.4839672 (M=  35) - s=0.0100\n",
      " 105 - L= 3.0614479 - Gamma=30.4836335 (M=  35) - s=0.0100\n",
      " 106 - L= 3.0614481 - Gamma=30.4836035 (M=  35) - s=0.0100\n",
      " 107 - L= 3.0614483 - Gamma=30.4806630 (M=  35) - s=0.0100\n",
      " 108 - L= 3.0614485 - Gamma=30.4845484 (M=  35) - s=0.0100\n",
      " 109 - L= 3.0614488 - Gamma=30.4789318 (M=  35) - s=0.0100\n",
      " 110 - L= 3.0614490 - Gamma=30.4825363 (M=  35) - s=0.0100\n",
      " 111 - L= 3.0614492 - Gamma=30.4817277 (M=  35) - s=0.0100\n",
      " 112 - L= 3.0614493 - Gamma=30.4812900 (M=  35) - s=0.0100\n",
      " 113 - L= 3.0614495 - Gamma=30.4802048 (M=  35) - s=0.0100\n",
      " 114 - L= 3.0614497 - Gamma=30.4859339 (M=  35) - s=0.0100\n",
      " 115 - L= 3.0614500 - Gamma=30.4813688 (M=  35) - s=0.0100\n",
      " 116 - L= 3.0614501 - Gamma=30.4813825 (M=  35) - s=0.0100\n",
      " 117 - L= 3.0614502 - Gamma=30.4813850 (M=  35) - s=0.0100\n",
      " 118 - L= 3.0614503 - Gamma=30.4813908 (M=  35) - s=0.0100\n",
      " 119 - L= 3.0614504 - Gamma=30.4813320 (M=  35) - s=0.0100\n",
      " 120 - L= 3.0614505 - Gamma=30.4778511 (M=  35) - s=0.0100\n",
      " 121 - L= 3.0614507 - Gamma=30.4807327 (M=  35) - s=0.0100\n",
      " 122 - L= 3.0614508 - Gamma=30.4855782 (M=  35) - s=0.0100\n",
      " 123 - L= 3.0614509 - Gamma=30.4838845 (M=  35) - s=0.0100\n",
      " 124 - L= 3.0614509 - Gamma=30.4808074 (M=  35) - s=0.0100\n",
      " 125 - L= 3.0614510 - Gamma=30.4825766 (M=  35) - s=0.0100\n",
      " 126 - L= 3.0614510 - Gamma=30.4819988 (M=  35) - s=0.0100\n",
      " 127 - L= 3.0614511 - Gamma=30.4835088 (M=  35) - s=0.0100\n",
      " 128 - L= 3.0614511 - Gamma=30.4835062 (M=  35) - s=0.0100\n",
      " 129 - L= 3.0614511 - Gamma=30.4835067 (M=  35) - s=0.0100\n",
      " 130 - L= 3.0614511 - Gamma=30.4835094 (M=  35) - s=0.0100\n",
      " 131 - L= 3.0614512 - Gamma=30.4833386 (M=  35) - s=0.0100\n",
      " 132 - L= 3.0614512 - Gamma=30.4833368 (M=  35) - s=0.0100\n",
      " 133 - L= 3.0614512 - Gamma=30.4820494 (M=  35) - s=0.0100\n",
      " 134 - L= 3.0614512 - Gamma=30.4802527 (M=  35) - s=0.0100\n",
      " 135 - L= 3.0614513 - Gamma=30.4825886 (M=  35) - s=0.0100\n",
      " 136 - L= 3.0614513 - Gamma=30.4822954 (M=  35) - s=0.0100\n",
      " 137 - L= 3.0614513 - Gamma=30.4822883 (M=  35) - s=0.0100\n",
      " 138 - L= 3.0614513 - Gamma=30.4821713 (M=  35) - s=0.0100\n",
      " 139 - L= 3.0614514 - Gamma=30.4813283 (M=  35) - s=0.0100\n",
      " 140 - L= 3.0614514 - Gamma=30.4813481 (M=  35) - s=0.0100\n",
      " 141 - L= 3.0614514 - Gamma=30.4813895 (M=  35) - s=0.0100\n",
      " 142 - L= 3.0614514 - Gamma=30.4813873 (M=  35) - s=0.0100\n",
      " 143 - L= 3.0614514 - Gamma=30.4813081 (M=  35) - s=0.0100\n",
      " 144 - L= 3.0614514 - Gamma=30.4822703 (M=  35) - s=0.0100\n",
      " 145 - L= 3.0614514 - Gamma=30.4822969 (M=  35) - s=0.0100\n",
      " 146 - L= 3.0614514 - Gamma=30.4810159 (M=  35) - s=0.0100\n",
      " 147 - L= 3.0614515 - Gamma=30.4819440 (M=  35) - s=0.0100\n",
      " 148 - L= 3.0614515 - Gamma=30.4815943 (M=  35) - s=0.0100\n",
      " 149 - L= 3.0614515 - Gamma=30.4815330 (M=  35) - s=0.0100\n",
      " 150 - L= 3.0614515 - Gamma=30.4815304 (M=  35) - s=0.0100\n",
      " 151 - L= 3.0614515 - Gamma=30.4811404 (M=  35) - s=0.0100\n",
      " 152 - L= 3.0614515 - Gamma=30.4811561 (M=  35) - s=0.0100\n",
      " 153 - L= 3.0614515 - Gamma=30.4806306 (M=  35) - s=0.0100\n",
      " 154 - L= 3.0614515 - Gamma=30.4806383 (M=  35) - s=0.0100\n",
      " 155 - L= 3.0614515 - Gamma=30.4806386 (M=  35) - s=0.0100\n",
      " 156 - L= 3.0614515 - Gamma=30.4797813 (M=  35) - s=0.0100\n",
      " 157 - L= 3.0614515 - Gamma=30.4805514 (M=  35) - s=0.0100\n",
      " 158 - L= 3.0614516 - Gamma=30.4799280 (M=  35) - s=0.0100\n",
      " 159 - L= 3.0614516 - Gamma=30.4811855 (M=  35) - s=0.0100\n",
      " 160 - L= 3.0614516 - Gamma=30.4811802 (M=  35) - s=0.0100\n",
      " 161 - L= 3.0614516 - Gamma=30.4817347 (M=  35) - s=0.0100\n",
      " 162 - L= 3.0614516 - Gamma=30.4807832 (M=  35) - s=0.0100\n",
      " 163 - L= 3.0614516 - Gamma=30.4807899 (M=  35) - s=0.0100\n",
      " 164 - L= 3.0614516 - Gamma=30.4807247 (M=  35) - s=0.0100\n",
      " 165 - L= 3.0614516 - Gamma=30.4805883 (M=  35) - s=0.0100\n",
      " 166 - L= 3.0614516 - Gamma=30.4802717 (M=  35) - s=0.0100\n",
      " 167 - L= 3.0614516 - Gamma=30.4806027 (M=  35) - s=0.0100\n",
      " 168 - L= 3.0614516 - Gamma=30.4806027 (M=  35) - s=0.0100\n",
      "Stopping at iteration 168 - max_delta_ml=1.2662355251054792e-07\n",
      "L=3.061451595542213 - Gamma=30.480602656962823 (M=35) - s=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alpha = [[ 0.02967984]]\n",
      "   1 - L=-440.0027237 - Gamma= 1.9999516 (M=   2) - s=0.0100\n",
      "   2 - L=-242.1600900 - Gamma= 2.9999127 (M=   3) - s=0.0100\n",
      "   3 - L=-178.7680600 - Gamma= 3.9997714 (M=   4) - s=0.0100\n",
      "   4 - L=-136.5609996 - Gamma= 4.9995626 (M=   5) - s=0.0100\n",
      "   5 - L=-108.9337577 - Gamma= 5.9992851 (M=   6) - s=0.0100\n",
      "   6 - L=-81.4387663 - Gamma= 6.9990076 (M=   7) - s=0.0100\n",
      "   7 - L=-61.3024072 - Gamma= 7.9985828 (M=   8) - s=0.0100\n",
      "   8 - L=-47.1007120 - Gamma= 8.9980313 (M=   9) - s=0.0100\n",
      "   9 - L=-34.9864936 - Gamma= 9.9973794 (M=  10) - s=0.0100\n",
      "  10 - L=-25.6355473 - Gamma=10.9965190 (M=  11) - s=0.0100\n",
      "  11 - L=-19.4837866 - Gamma=11.9952301 (M=  12) - s=0.0100\n",
      "  12 - L=-12.2524960 - Gamma=12.9939785 (M=  13) - s=0.0100\n",
      "  13 - L=-8.9296024 - Gamma=13.9916182 (M=  14) - s=0.0100\n",
      "  14 - L=-6.2652346 - Gamma=14.9887325 (M=  15) - s=0.0100\n",
      "  15 - L=-4.1545445 - Gamma=15.9845366 (M=  16) - s=0.0100\n",
      "  16 - L=-2.7428045 - Gamma=16.9791109 (M=  17) - s=0.0100\n",
      "  17 - L=-1.4949233 - Gamma=17.9726252 (M=  18) - s=0.0100\n",
      "  18 - L=-0.1957800 - Gamma=18.9665404 (M=  19) - s=0.0100\n",
      "  19 - L= 0.6573673 - Gamma=19.9573233 (M=  20) - s=0.0100\n",
      "  20 - L= 1.3770410 - Gamma=20.9467305 (M=  21) - s=0.0100\n",
      "  21 - L= 1.7698003 - Gamma=21.9283273 (M=  22) - s=0.0100\n",
      "  22 - L= 2.0797169 - Gamma=22.9055872 (M=  23) - s=0.0100\n",
      "  23 - L= 2.3513479 - Gamma=23.8799650 (M=  24) - s=0.0100\n",
      "  24 - L= 2.5541655 - Gamma=24.8450389 (M=  25) - s=0.0100\n",
      "  25 - L= 2.7141015 - Gamma=25.8024954 (M=  26) - s=0.0100\n",
      "  26 - L= 2.7891025 - Gamma=26.7188935 (M=  27) - s=0.0100\n",
      "  27 - L= 2.8399760 - Gamma=27.6157959 (M=  28) - s=0.0100\n",
      "  28 - L= 2.8726494 - Gamma=28.4719528 (M=  29) - s=0.0100\n",
      "  29 - L= 2.8855543 - Gamma=29.2239691 (M=  30) - s=0.0100\n",
      "  30 - L= 2.8939546 - Gamma=29.9167432 (M=  31) - s=0.0100\n",
      "  31 - L= 2.8994149 - Gamma=29.9165248 (M=  31) - s=0.0100\n",
      "  32 - L= 2.9046586 - Gamma=29.9166876 (M=  31) - s=0.0100\n",
      "  33 - L= 2.9093134 - Gamma=29.9163236 (M=  31) - s=0.0100\n",
      "  34 - L= 2.9139066 - Gamma=29.9123469 (M=  31) - s=0.0100\n",
      "  35 - L= 2.9184506 - Gamma=30.5082413 (M=  32) - s=0.0100\n",
      "  36 - L= 2.9214797 - Gamma=30.5091622 (M=  32) - s=0.0100\n",
      "  37 - L= 2.9241247 - Gamma=30.5101758 (M=  32) - s=0.0100\n",
      "  38 - L= 2.9267677 - Gamma=30.5123398 (M=  32) - s=0.0100\n",
      "  39 - L= 2.9290456 - Gamma=30.5160315 (M=  32) - s=0.0100\n",
      "  40 - L= 2.9309635 - Gamma=30.5113932 (M=  32) - s=0.0100\n",
      "  41 - L= 2.9328891 - Gamma=30.5349862 (M=  32) - s=0.0100\n",
      "  42 - L= 2.9347006 - Gamma=30.5355724 (M=  32) - s=0.0100\n",
      "  43 - L= 2.9363508 - Gamma=30.5358086 (M=  32) - s=0.0100\n",
      "  44 - L= 2.9378793 - Gamma=30.9682223 (M=  33) - s=0.0100\n",
      "  45 - L= 2.9393036 - Gamma=30.9685563 (M=  33) - s=0.0100\n",
      "  46 - L= 2.9404102 - Gamma=30.9824320 (M=  33) - s=0.0100\n",
      "  47 - L= 2.9414596 - Gamma=30.9863144 (M=  33) - s=0.0100\n",
      "  48 - L= 2.9421199 - Gamma=30.9864884 (M=  33) - s=0.0100\n",
      "  49 - L= 2.9427711 - Gamma=30.9882233 (M=  33) - s=0.0100\n",
      "  50 - L= 2.9434227 - Gamma=31.3040308 (M=  34) - s=0.0100\n",
      "  51 - L= 2.9438361 - Gamma=31.5565851 (M=  35) - s=0.0100\n",
      "  52 - L= 2.9442162 - Gamma=31.5565345 (M=  35) - s=0.0100\n",
      "  53 - L= 2.9445226 - Gamma=31.4722310 (M=  35) - s=0.0100\n",
      "  54 - L= 2.9448197 - Gamma=31.4725491 (M=  35) - s=0.0100\n",
      "  55 - L= 2.9450403 - Gamma=31.4938465 (M=  35) - s=0.0100\n",
      "  56 - L= 2.9451484 - Gamma=31.4967153 (M=  35) - s=0.0100\n",
      "  57 - L= 2.9452418 - Gamma=31.4833770 (M=  35) - s=0.0100\n",
      "  58 - L= 2.9453166 - Gamma=31.6061047 (M=  36) - s=0.0100\n",
      "  59 - L= 2.9453895 - Gamma=31.6093207 (M=  36) - s=0.0100\n",
      "  60 - L= 2.9454471 - Gamma=31.6100575 (M=  36) - s=0.0100\n",
      "  61 - L= 2.9454924 - Gamma=31.6108998 (M=  36) - s=0.0100\n",
      "  62 - L= 2.9455125 - Gamma=31.6088685 (M=  36) - s=0.0100\n",
      "  63 - L= 2.9455281 - Gamma=31.6507378 (M=  36) - s=0.0100\n",
      "  64 - L= 2.9455420 - Gamma=31.6157531 (M=  36) - s=0.0100\n",
      "  65 - L= 2.9455541 - Gamma=31.6232151 (M=  36) - s=0.0100\n",
      "  66 - L= 2.9455652 - Gamma=31.6014305 (M=  36) - s=0.0100\n",
      "  67 - L= 2.9455724 - Gamma=31.6014427 (M=  36) - s=0.0100\n",
      "  68 - L= 2.9455780 - Gamma=31.6009362 (M=  36) - s=0.0100\n",
      "  69 - L= 2.9455820 - Gamma=31.6007281 (M=  36) - s=0.0100\n",
      "  70 - L= 2.9455845 - Gamma=31.6241558 (M=  37) - s=0.0100\n",
      "  71 - L= 2.9455871 - Gamma=31.6219797 (M=  37) - s=0.0100\n",
      "  72 - L= 2.9455894 - Gamma=31.6214302 (M=  37) - s=0.0100\n",
      "  73 - L= 2.9455911 - Gamma=31.6208028 (M=  37) - s=0.0100\n",
      "  74 - L= 2.9455928 - Gamma=31.6380364 (M=  37) - s=0.0100\n",
      "  75 - L= 2.9455950 - Gamma=31.6235537 (M=  37) - s=0.0100\n",
      "  76 - L= 2.9455966 - Gamma=31.6237272 (M=  37) - s=0.0100\n",
      "  77 - L= 2.9455979 - Gamma=31.6408966 (M=  38) - s=0.0100\n",
      "  78 - L= 2.9455993 - Gamma=31.6330319 (M=  38) - s=0.0100\n",
      "  79 - L= 2.9456004 - Gamma=31.6489549 (M=  39) - s=0.0100\n",
      "  80 - L= 2.9456015 - Gamma=31.6438781 (M=  39) - s=0.0100\n",
      "  81 - L= 2.9456022 - Gamma=31.6356838 (M=  39) - s=0.0100\n",
      "  82 - L= 2.9456029 - Gamma=31.6354556 (M=  39) - s=0.0100\n",
      "  83 - L= 2.9456036 - Gamma=31.6459861 (M=  39) - s=0.0100\n",
      "  84 - L= 2.9456045 - Gamma=31.6595407 (M=  40) - s=0.0100\n",
      "  85 - L= 2.9456051 - Gamma=31.6594947 (M=  40) - s=0.0100\n",
      "  86 - L= 2.9456056 - Gamma=31.6598371 (M=  40) - s=0.0100\n",
      "  87 - L= 2.9456062 - Gamma=31.6548265 (M=  40) - s=0.0100\n",
      "  88 - L= 2.9456065 - Gamma=31.6551219 (M=  40) - s=0.0100\n",
      "  89 - L= 2.9456069 - Gamma=31.6612048 (M=  40) - s=0.0100\n",
      "  90 - L= 2.9456073 - Gamma=31.6548404 (M=  40) - s=0.0100\n",
      "  91 - L= 2.9456078 - Gamma=31.6637163 (M=  40) - s=0.0100\n",
      "  92 - L= 2.9456081 - Gamma=31.6725277 (M=  40) - s=0.0100\n",
      "  93 - L= 2.9456086 - Gamma=31.6687487 (M=  40) - s=0.0100\n",
      "  94 - L= 2.9456091 - Gamma=31.6790983 (M=  40) - s=0.0100\n",
      "  95 - L= 2.9456096 - Gamma=31.6714412 (M=  40) - s=0.0100\n",
      "  96 - L= 2.9456104 - Gamma=31.6582787 (M=  40) - s=0.0100\n",
      "  97 - L= 2.9456113 - Gamma=31.6716676 (M=  40) - s=0.0100\n",
      "  98 - L= 2.9456119 - Gamma=31.6705125 (M=  40) - s=0.0100\n",
      "  99 - L= 2.9456124 - Gamma=31.6669490 (M=  40) - s=0.0100\n",
      " 100 - L= 2.9456129 - Gamma=31.6569519 (M=  39) - s=0.0100\n",
      " 101 - L= 2.9456139 - Gamma=31.6705072 (M=  39) - s=0.0100\n",
      " 102 - L= 2.9456149 - Gamma=31.6851900 (M=  39) - s=0.0100\n",
      " 103 - L= 2.9456161 - Gamma=31.6732279 (M=  39) - s=0.0100\n",
      " 104 - L= 2.9456166 - Gamma=31.6657608 (M=  39) - s=0.0100\n",
      " 105 - L= 2.9456176 - Gamma=31.6799547 (M=  39) - s=0.0100\n",
      " 106 - L= 2.9456185 - Gamma=31.6921007 (M=  39) - s=0.0100\n",
      " 107 - L= 2.9456191 - Gamma=31.6877700 (M=  39) - s=0.0100\n",
      " 108 - L= 2.9456197 - Gamma=31.6827092 (M=  39) - s=0.0100\n",
      " 109 - L= 2.9456202 - Gamma=31.6827958 (M=  39) - s=0.0100\n",
      " 110 - L= 2.9456207 - Gamma=31.6752873 (M=  39) - s=0.0100\n",
      " 111 - L= 2.9456214 - Gamma=31.6838698 (M=  39) - s=0.0100\n",
      " 112 - L= 2.9456220 - Gamma=31.6949257 (M=  39) - s=0.0100\n",
      " 113 - L= 2.9456226 - Gamma=31.6948527 (M=  39) - s=0.0100\n",
      " 114 - L= 2.9456232 - Gamma=31.6864658 (M=  39) - s=0.0100\n",
      " 115 - L= 2.9456241 - Gamma=31.7001211 (M=  39) - s=0.0100\n",
      " 116 - L= 2.9456249 - Gamma=31.6909928 (M=  39) - s=0.0100\n",
      " 117 - L= 2.9456254 - Gamma=31.6907978 (M=  39) - s=0.0100\n",
      " 118 - L= 2.9456259 - Gamma=31.6869491 (M=  39) - s=0.0100\n",
      " 119 - L= 2.9456266 - Gamma=31.6984070 (M=  39) - s=0.0100\n",
      " 120 - L= 2.9456271 - Gamma=31.6987543 (M=  39) - s=0.0100\n",
      " 121 - L= 2.9456277 - Gamma=31.6976544 (M=  39) - s=0.0100\n",
      " 122 - L= 2.9456284 - Gamma=31.7089974 (M=  39) - s=0.0100\n",
      " 123 - L= 2.9456293 - Gamma=31.7040798 (M=  39) - s=0.0100\n",
      " 124 - L= 2.9456298 - Gamma=31.7040382 (M=  39) - s=0.0100\n",
      " 125 - L= 2.9456302 - Gamma=31.7118617 (M=  39) - s=0.0100\n",
      " 126 - L= 2.9456308 - Gamma=31.7065049 (M=  39) - s=0.0100\n",
      " 127 - L= 2.9456313 - Gamma=31.7163461 (M=  39) - s=0.0100\n",
      " 128 - L= 2.9456320 - Gamma=31.7072362 (M=  39) - s=0.0100\n",
      " 129 - L= 2.9456326 - Gamma=31.6991698 (M=  39) - s=0.0100\n",
      " 130 - L= 2.9456334 - Gamma=31.7123609 (M=  39) - s=0.0100\n",
      " 131 - L= 2.9456339 - Gamma=31.7126067 (M=  39) - s=0.0100\n",
      " 132 - L= 2.9456344 - Gamma=31.7088826 (M=  39) - s=0.0100\n",
      " 133 - L= 2.9456350 - Gamma=31.7198112 (M=  39) - s=0.0100\n",
      " 134 - L= 2.9456355 - Gamma=31.7119756 (M=  39) - s=0.0100\n",
      " 135 - L= 2.9456359 - Gamma=31.7045732 (M=  39) - s=0.0100\n",
      " 136 - L= 2.9456367 - Gamma=31.7151666 (M=  39) - s=0.0100\n",
      " 137 - L= 2.9456372 - Gamma=31.7250423 (M=  39) - s=0.0100\n",
      " 138 - L= 2.9456376 - Gamma=31.7202542 (M=  39) - s=0.0100\n",
      " 139 - L= 2.9456380 - Gamma=31.7193734 (M=  39) - s=0.0100\n",
      " 140 - L= 2.9456383 - Gamma=31.7192976 (M=  39) - s=0.0100\n",
      " 141 - L= 2.9456386 - Gamma=31.7134287 (M=  39) - s=0.0100\n",
      " 142 - L= 2.9456390 - Gamma=31.7225440 (M=  39) - s=0.0100\n",
      " 143 - L= 2.9456395 - Gamma=31.7144372 (M=  39) - s=0.0100\n",
      " 144 - L= 2.9456400 - Gamma=31.7239934 (M=  39) - s=0.0100\n",
      " 145 - L= 2.9456406 - Gamma=31.7201441 (M=  39) - s=0.0100\n",
      " 146 - L= 2.9456409 - Gamma=31.7201627 (M=  39) - s=0.0100\n",
      " 147 - L= 2.9456412 - Gamma=31.7268965 (M=  39) - s=0.0100\n",
      " 148 - L= 2.9456415 - Gamma=31.7271412 (M=  39) - s=0.0100\n",
      " 149 - L= 2.9456418 - Gamma=31.7271962 (M=  39) - s=0.0100\n",
      " 150 - L= 2.9456421 - Gamma=31.7270569 (M=  39) - s=0.0100\n",
      " 151 - L= 2.9456424 - Gamma=31.7344722 (M=  39) - s=0.0100\n",
      " 152 - L= 2.9456428 - Gamma=31.7274259 (M=  39) - s=0.0100\n",
      " 153 - L= 2.9456433 - Gamma=31.7226571 (M=  39) - s=0.0100\n",
      " 154 - L= 2.9456437 - Gamma=31.7319522 (M=  39) - s=0.0100\n",
      " 155 - L= 2.9456443 - Gamma=31.7277833 (M=  39) - s=0.0100\n",
      " 156 - L= 2.9456446 - Gamma=31.7354000 (M=  39) - s=0.0100\n",
      " 157 - L= 2.9456450 - Gamma=31.7278875 (M=  39) - s=0.0100\n",
      " 158 - L= 2.9456453 - Gamma=31.7218863 (M=  39) - s=0.0100\n",
      " 159 - L= 2.9456457 - Gamma=31.7303735 (M=  39) - s=0.0100\n",
      " 160 - L= 2.9456460 - Gamma=31.7304401 (M=  39) - s=0.0100\n",
      " 161 - L= 2.9456463 - Gamma=31.7304493 (M=  39) - s=0.0100\n",
      " 162 - L= 2.9456466 - Gamma=31.7296098 (M=  39) - s=0.0100\n",
      " 163 - L= 2.9456470 - Gamma=31.7374543 (M=  39) - s=0.0100\n",
      " 164 - L= 2.9456475 - Gamma=31.7339179 (M=  39) - s=0.0100\n",
      " 165 - L= 2.9456478 - Gamma=31.7338649 (M=  39) - s=0.0100\n",
      " 166 - L= 2.9456481 - Gamma=31.7406344 (M=  39) - s=0.0100\n",
      " 167 - L= 2.9456484 - Gamma=31.7408146 (M=  39) - s=0.0100\n",
      " 168 - L= 2.9456486 - Gamma=31.7408588 (M=  39) - s=0.0100\n",
      " 169 - L= 2.9456489 - Gamma=31.7408284 (M=  39) - s=0.0100\n",
      " 170 - L= 2.9456491 - Gamma=31.7472468 (M=  39) - s=0.0100\n",
      " 171 - L= 2.9456495 - Gamma=31.7403867 (M=  39) - s=0.0100\n",
      " 172 - L= 2.9456498 - Gamma=31.7333592 (M=  39) - s=0.0100\n",
      " 173 - L= 2.9456502 - Gamma=31.7409259 (M=  39) - s=0.0100\n",
      " 174 - L= 2.9456505 - Gamma=31.7375546 (M=  39) - s=0.0100\n",
      " 175 - L= 2.9456509 - Gamma=31.7455146 (M=  39) - s=0.0100\n",
      " 176 - L= 2.9456512 - Gamma=31.7453011 (M=  39) - s=0.0100\n",
      " 177 - L= 2.9456515 - Gamma=31.7411457 (M=  39) - s=0.0100\n",
      " 178 - L= 2.9456518 - Gamma=31.7412625 (M=  39) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 179 - L= 2.9456521 - Gamma=31.7415046 (M=  39) - s=0.0100\n",
      " 180 - L= 2.9456524 - Gamma=31.7354439 (M=  39) - s=0.0100\n",
      " 181 - L= 2.9456528 - Gamma=31.7427482 (M=  39) - s=0.0100\n",
      " 182 - L= 2.9456531 - Gamma=31.7498089 (M=  39) - s=0.0100\n",
      " 183 - L= 2.9456535 - Gamma=31.7415701 (M=  39) - s=0.0100\n",
      " 184 - L= 2.9456538 - Gamma=31.7417912 (M=  39) - s=0.0100\n",
      " 185 - L= 2.9456540 - Gamma=31.7365318 (M=  39) - s=0.0100\n",
      " 186 - L= 2.9456543 - Gamma=31.7443715 (M=  39) - s=0.0100\n",
      " 187 - L= 2.9456546 - Gamma=31.7409304 (M=  39) - s=0.0100\n",
      " 188 - L= 2.9456549 - Gamma=31.7477716 (M=  39) - s=0.0100\n",
      " 189 - L= 2.9456551 - Gamma=31.7476388 (M=  39) - s=0.0100\n",
      " 190 - L= 2.9456553 - Gamma=31.7468807 (M=  39) - s=0.0100\n",
      " 191 - L= 2.9456555 - Gamma=31.7445831 (M=  39) - s=0.0100\n",
      " 192 - L= 2.9456557 - Gamma=31.7495123 (M=  39) - s=0.0100\n",
      " 193 - L= 2.9456560 - Gamma=31.7557739 (M=  39) - s=0.0100\n",
      " 194 - L= 2.9456562 - Gamma=31.7503640 (M=  39) - s=0.0100\n",
      " 195 - L= 2.9456564 - Gamma=31.7447998 (M=  39) - s=0.0100\n",
      " 196 - L= 2.9456566 - Gamma=31.7510846 (M=  39) - s=0.0100\n",
      " 197 - L= 2.9456570 - Gamma=31.7476772 (M=  39) - s=0.0100\n",
      " 198 - L= 2.9456572 - Gamma=31.7537820 (M=  39) - s=0.0100\n",
      " 199 - L= 2.9456574 - Gamma=31.7505030 (M=  39) - s=0.0100\n",
      " 200 - L= 2.9456576 - Gamma=31.7504762 (M=  39) - s=0.0100\n",
      "MODEL: RVM accuracy:  0.771084337349 +/-: 0.00487082988225\n",
      "Initial alpha = [[ 0.02358065]]\n",
      "   1 - L=-417.8044950 - Gamma= 1.9999581 (M=   2) - s=0.0100\n",
      "   2 - L=-247.8326549 - Gamma= 2.9999154 (M=   3) - s=0.0100\n",
      "   3 - L=-207.9998705 - Gamma= 3.9997591 (M=   4) - s=0.0100\n",
      "   4 - L=-172.6273341 - Gamma= 4.9995612 (M=   5) - s=0.0100\n",
      "   5 - L=-137.1635220 - Gamma= 5.9993804 (M=   6) - s=0.0100\n",
      "   6 - L=-111.6903459 - Gamma= 6.9991179 (M=   7) - s=0.0100\n",
      "   7 - L=-91.4036104 - Gamma= 7.9988007 (M=   8) - s=0.0100\n",
      "   8 - L=-72.1083001 - Gamma= 8.9984804 (M=   9) - s=0.0100\n",
      "   9 - L=-56.4100458 - Gamma= 9.9980328 (M=  10) - s=0.0100\n",
      "  10 - L=-43.7536692 - Gamma=10.9974904 (M=  11) - s=0.0100\n",
      "  11 - L=-34.8565873 - Gamma=11.9967415 (M=  12) - s=0.0100\n",
      "  12 - L=-28.7495713 - Gamma=12.9955799 (M=  13) - s=0.0100\n",
      "  13 - L=-22.7015313 - Gamma=13.9944863 (M=  14) - s=0.0100\n",
      "  14 - L=-18.3125930 - Gamma=14.9930570 (M=  15) - s=0.0100\n",
      "  15 - L=-13.9312777 - Gamma=15.9915631 (M=  16) - s=0.0100\n",
      "  16 - L=-11.3605541 - Gamma=16.9891476 (M=  17) - s=0.0100\n",
      "  17 - L=-8.8955713 - Gamma=17.9865585 (M=  18) - s=0.0100\n",
      "  18 - L=-6.7775206 - Gamma=18.9835038 (M=  19) - s=0.0100\n",
      "  19 - L=-4.4708707 - Gamma=19.9805790 (M=  20) - s=0.0100\n",
      "  20 - L=-2.8547028 - Gamma=20.9768175 (M=  21) - s=0.0100\n",
      "  21 - L=-1.5486732 - Gamma=21.9718312 (M=  22) - s=0.0100\n",
      "  22 - L=-0.5967144 - Gamma=22.9653690 (M=  23) - s=0.0100\n",
      "  23 - L= 0.3384057 - Gamma=23.9588068 (M=  24) - s=0.0100\n",
      "  24 - L= 0.9389708 - Gamma=24.9485240 (M=  25) - s=0.0100\n",
      "  25 - L= 1.4716965 - Gamma=25.9372448 (M=  26) - s=0.0100\n",
      "  26 - L= 1.8721882 - Gamma=26.9223016 (M=  27) - s=0.0100\n",
      "  27 - L= 2.2494144 - Gamma=27.9061914 (M=  28) - s=0.0100\n",
      "  28 - L= 2.4384107 - Gamma=28.8769934 (M=  29) - s=0.0100\n",
      "  29 - L= 2.5795406 - Gamma=29.8380678 (M=  30) - s=0.0100\n",
      "  30 - L= 2.6743860 - Gamma=30.7844563 (M=  31) - s=0.0100\n",
      "  31 - L= 2.7452092 - Gamma=31.7179649 (M=  32) - s=0.0100\n",
      "  32 - L= 2.7964335 - Gamma=32.6250977 (M=  33) - s=0.0100\n",
      "  33 - L= 2.8379276 - Gamma=33.5185157 (M=  34) - s=0.0100\n",
      "  34 - L= 2.8725628 - Gamma=34.4005875 (M=  35) - s=0.0100\n",
      "  35 - L= 2.9066801 - Gamma=35.2675310 (M=  36) - s=0.0100\n",
      "  36 - L= 2.9199567 - Gamma=36.0508609 (M=  37) - s=0.0100\n",
      "  37 - L= 2.9296575 - Gamma=36.7928649 (M=  38) - s=0.0100\n",
      "  38 - L= 2.9356463 - Gamma=37.4635828 (M=  39) - s=0.0100\n",
      "  39 - L= 2.9412266 - Gamma=37.4628617 (M=  39) - s=0.0100\n",
      "  40 - L= 2.9455718 - Gamma=37.4633734 (M=  39) - s=0.0100\n",
      "  41 - L= 2.9491033 - Gamma=37.4625359 (M=  39) - s=0.0100\n",
      "  42 - L= 2.9519784 - Gamma=38.0211322 (M=  40) - s=0.0100\n",
      "  43 - L= 2.9541229 - Gamma=38.0787745 (M=  40) - s=0.0100\n",
      "  44 - L= 2.9560412 - Gamma=38.0789053 (M=  40) - s=0.0100\n",
      "  45 - L= 2.9579499 - Gamma=38.0781854 (M=  40) - s=0.0100\n",
      "  46 - L= 2.9598504 - Gamma=38.0789548 (M=  40) - s=0.0100\n",
      "  47 - L= 2.9617495 - Gamma=38.0788991 (M=  40) - s=0.0100\n",
      "  48 - L= 2.9635117 - Gamma=38.0797082 (M=  40) - s=0.0100\n",
      "  49 - L= 2.9645671 - Gamma=38.0798355 (M=  40) - s=0.0100\n",
      "  50 - L= 2.9654664 - Gamma=38.4519122 (M=  41) - s=0.0100\n",
      "  51 - L= 2.9663739 - Gamma=38.8306091 (M=  42) - s=0.0100\n",
      "  52 - L= 2.9672478 - Gamma=38.8321495 (M=  42) - s=0.0100\n",
      "  53 - L= 2.9680675 - Gamma=38.8326841 (M=  42) - s=0.0100\n",
      "  54 - L= 2.9687184 - Gamma=38.8368768 (M=  42) - s=0.0100\n",
      "  55 - L= 2.9693200 - Gamma=38.8016715 (M=  42) - s=0.0100\n",
      "  56 - L= 2.9699511 - Gamma=39.1233814 (M=  43) - s=0.0100\n",
      "  57 - L= 2.9705444 - Gamma=39.1337248 (M=  43) - s=0.0100\n",
      "  58 - L= 2.9709858 - Gamma=39.1253314 (M=  43) - s=0.0100\n",
      "  59 - L= 2.9713436 - Gamma=39.1266576 (M=  43) - s=0.0100\n",
      "  60 - L= 2.9716775 - Gamma=39.1257344 (M=  43) - s=0.0100\n",
      "  61 - L= 2.9719708 - Gamma=39.1308801 (M=  43) - s=0.0100\n",
      "  62 - L= 2.9722464 - Gamma=39.1307694 (M=  43) - s=0.0100\n",
      "  63 - L= 2.9724521 - Gamma=39.1308975 (M=  43) - s=0.0100\n",
      "  64 - L= 2.9726183 - Gamma=39.3208773 (M=  44) - s=0.0100\n",
      "  65 - L= 2.9727999 - Gamma=39.2481136 (M=  44) - s=0.0100\n",
      "  66 - L= 2.9729531 - Gamma=39.2482171 (M=  44) - s=0.0100\n",
      "  67 - L= 2.9731004 - Gamma=39.2494361 (M=  44) - s=0.0100\n",
      "  68 - L= 2.9732462 - Gamma=39.2501061 (M=  44) - s=0.0100\n",
      "  69 - L= 2.9733634 - Gamma=39.2496544 (M=  44) - s=0.0100\n",
      "  70 - L= 2.9734230 - Gamma=39.2505956 (M=  44) - s=0.0100\n",
      "  71 - L= 2.9734821 - Gamma=39.2506828 (M=  44) - s=0.0100\n",
      "  72 - L= 2.9735357 - Gamma=39.2496399 (M=  44) - s=0.0100\n",
      "  73 - L= 2.9735839 - Gamma=39.2596364 (M=  44) - s=0.0100\n",
      "  74 - L= 2.9736206 - Gamma=39.2600770 (M=  44) - s=0.0100\n",
      "  75 - L= 2.9736554 - Gamma=39.1946185 (M=  44) - s=0.0100\n",
      "  76 - L= 2.9736828 - Gamma=39.2788803 (M=  45) - s=0.0100\n",
      "  77 - L= 2.9737215 - Gamma=39.2271851 (M=  45) - s=0.0100\n",
      "  78 - L= 2.9737647 - Gamma=39.3315399 (M=  46) - s=0.0100\n",
      "  79 - L= 2.9738005 - Gamma=39.2949075 (M=  46) - s=0.0100\n",
      "  80 - L= 2.9738278 - Gamma=39.2831009 (M=  46) - s=0.0100\n",
      "  81 - L= 2.9738466 - Gamma=39.2865058 (M=  46) - s=0.0100\n",
      "  82 - L= 2.9738704 - Gamma=39.2270945 (M=  46) - s=0.0100\n",
      "  83 - L= 2.9738894 - Gamma=39.2833892 (M=  46) - s=0.0100\n",
      "  84 - L= 2.9739027 - Gamma=39.2769824 (M=  46) - s=0.0100\n",
      "  85 - L= 2.9739162 - Gamma=39.3137699 (M=  46) - s=0.0100\n",
      "  86 - L= 2.9739285 - Gamma=39.2822582 (M=  46) - s=0.0100\n",
      "  87 - L= 2.9739522 - Gamma=39.3572649 (M=  47) - s=0.0100\n",
      "  88 - L= 2.9739656 - Gamma=39.3555036 (M=  47) - s=0.0100\n",
      "  89 - L= 2.9739782 - Gamma=39.3414438 (M=  47) - s=0.0100\n",
      "  90 - L= 2.9739943 - Gamma=39.2888926 (M=  47) - s=0.0100\n",
      "  91 - L= 2.9740086 - Gamma=39.2637510 (M=  47) - s=0.0100\n",
      "  92 - L= 2.9740214 - Gamma=39.3013642 (M=  47) - s=0.0100\n",
      "  93 - L= 2.9740332 - Gamma=39.2686163 (M=  47) - s=0.0100\n",
      "  94 - L= 2.9740503 - Gamma=39.3334272 (M=  48) - s=0.0100\n",
      "  95 - L= 2.9740602 - Gamma=39.3291668 (M=  48) - s=0.0100\n",
      "  96 - L= 2.9740726 - Gamma=39.2798521 (M=  48) - s=0.0100\n",
      "  97 - L= 2.9740918 - Gamma=39.3493876 (M=  49) - s=0.0100\n",
      "  98 - L= 2.9741067 - Gamma=39.4047922 (M=  49) - s=0.0100\n",
      "  99 - L= 2.9741320 - Gamma=39.3531350 (M=  49) - s=0.0100\n",
      " 100 - L= 2.9741538 - Gamma=39.2833023 (M=  49) - s=0.0100\n",
      " 101 - L= 2.9741886 - Gamma=39.3731923 (M=  50) - s=0.0100\n",
      " 102 - L= 2.9742023 - Gamma=39.3193481 (M=  49) - s=0.0100\n",
      " 103 - L= 2.9742528 - Gamma=39.4012691 (M=  49) - s=0.0100\n",
      " 104 - L= 2.9742957 - Gamma=39.4962412 (M=  49) - s=0.0100\n",
      " 105 - L= 2.9743301 - Gamma=39.4294438 (M=  49) - s=0.0100\n",
      " 106 - L= 2.9743718 - Gamma=39.3820012 (M=  49) - s=0.0100\n",
      " 107 - L= 2.9744057 - Gamma=39.3733791 (M=  49) - s=0.0100\n",
      " 108 - L= 2.9744497 - Gamma=39.4763664 (M=  50) - s=0.0100\n",
      " 109 - L= 2.9744777 - Gamma=39.5309899 (M=  50) - s=0.0100\n",
      " 110 - L= 2.9745042 - Gamma=39.5346937 (M=  50) - s=0.0100\n",
      " 111 - L= 2.9745242 - Gamma=39.4789448 (M=  50) - s=0.0100\n",
      " 112 - L= 2.9745531 - Gamma=39.5503416 (M=  50) - s=0.0100\n",
      " 113 - L= 2.9745814 - Gamma=39.4662148 (M=  50) - s=0.0100\n",
      " 114 - L= 2.9746033 - Gamma=39.5320070 (M=  50) - s=0.0100\n",
      " 115 - L= 2.9746071 - Gamma=39.5184843 (M=  49) - s=0.0100\n",
      " 116 - L= 2.9746361 - Gamma=39.4848273 (M=  49) - s=0.0100\n",
      " 117 - L= 2.9746562 - Gamma=39.4487240 (M=  49) - s=0.0100\n",
      " 118 - L= 2.9746779 - Gamma=39.5148117 (M=  49) - s=0.0100\n",
      " 119 - L= 2.9747067 - Gamma=39.4419009 (M=  49) - s=0.0100\n",
      " 120 - L= 2.9747357 - Gamma=39.5122356 (M=  49) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 121 - L= 2.9747801 - Gamma=39.5739591 (M=  49) - s=0.0100\n",
      " 122 - L= 2.9748142 - Gamma=39.4918693 (M=  48) - s=0.0100\n",
      " 123 - L= 2.9748342 - Gamma=39.4928696 (M=  48) - s=0.0100\n",
      " 124 - L= 2.9748529 - Gamma=39.4985071 (M=  48) - s=0.0100\n",
      " 125 - L= 2.9748713 - Gamma=39.4962197 (M=  48) - s=0.0100\n",
      " 126 - L= 2.9748883 - Gamma=39.4884431 (M=  48) - s=0.0100\n",
      " 127 - L= 2.9749046 - Gamma=39.4712250 (M=  48) - s=0.0100\n",
      " 128 - L= 2.9749209 - Gamma=39.5210952 (M=  48) - s=0.0100\n",
      " 129 - L= 2.9749423 - Gamma=39.4566931 (M=  47) - s=0.0100\n",
      " 130 - L= 2.9749699 - Gamma=39.5251260 (M=  47) - s=0.0100\n",
      " 131 - L= 2.9749939 - Gamma=39.4820914 (M=  47) - s=0.0100\n",
      " 132 - L= 2.9750203 - Gamma=39.4049856 (M=  47) - s=0.0100\n",
      " 133 - L= 2.9750462 - Gamma=39.4845255 (M=  48) - s=0.0100\n",
      " 134 - L= 2.9750661 - Gamma=39.5358484 (M=  48) - s=0.0100\n",
      " 135 - L= 2.9750903 - Gamma=39.4632014 (M=  47) - s=0.0100\n",
      " 136 - L= 2.9751176 - Gamma=39.5251347 (M=  47) - s=0.0100\n",
      " 137 - L= 2.9751503 - Gamma=39.4982343 (M=  47) - s=0.0100\n",
      " 138 - L= 2.9751812 - Gamma=39.4597593 (M=  47) - s=0.0100\n",
      " 139 - L= 2.9752343 - Gamma=39.5616506 (M=  47) - s=0.0100\n",
      " 140 - L= 2.9752717 - Gamma=39.5017486 (M=  47) - s=0.0100\n",
      " 141 - L= 2.9753064 - Gamma=39.5645439 (M=  47) - s=0.0100\n",
      " 142 - L= 2.9753346 - Gamma=39.6149057 (M=  47) - s=0.0100\n",
      " 143 - L= 2.9753662 - Gamma=39.5719567 (M=  47) - s=0.0100\n",
      " 144 - L= 2.9754023 - Gamma=39.6262832 (M=  47) - s=0.0100\n",
      " 145 - L= 2.9754307 - Gamma=39.6929822 (M=  47) - s=0.0100\n",
      " 146 - L= 2.9754598 - Gamma=39.6343051 (M=  47) - s=0.0100\n",
      " 147 - L= 2.9754895 - Gamma=39.6449043 (M=  47) - s=0.0100\n",
      " 148 - L= 2.9755165 - Gamma=39.6009412 (M=  47) - s=0.0100\n",
      " 149 - L= 2.9755528 - Gamma=39.6523318 (M=  47) - s=0.0100\n",
      " 150 - L= 2.9755788 - Gamma=39.6397443 (M=  47) - s=0.0100\n",
      " 151 - L= 2.9756014 - Gamma=39.6858641 (M=  47) - s=0.0100\n",
      " 152 - L= 2.9756309 - Gamma=39.7473934 (M=  47) - s=0.0100\n",
      " 153 - L= 2.9756668 - Gamma=39.7158386 (M=  47) - s=0.0100\n",
      " 154 - L= 2.9756968 - Gamma=39.6498257 (M=  47) - s=0.0100\n",
      " 155 - L= 2.9757306 - Gamma=39.5952747 (M=  47) - s=0.0100\n",
      " 156 - L= 2.9757590 - Gamma=39.6364027 (M=  47) - s=0.0100\n",
      " 157 - L= 2.9758060 - Gamma=39.5425161 (M=  47) - s=0.0100\n",
      " 158 - L= 2.9758464 - Gamma=39.6072212 (M=  47) - s=0.0100\n",
      " 159 - L= 2.9758870 - Gamma=39.6628356 (M=  47) - s=0.0100\n",
      " 160 - L= 2.9759223 - Gamma=39.5829755 (M=  47) - s=0.0100\n",
      " 161 - L= 2.9759619 - Gamma=39.5940250 (M=  47) - s=0.0100\n",
      " 162 - L= 2.9759972 - Gamma=39.6355170 (M=  47) - s=0.0100\n",
      " 163 - L= 2.9760493 - Gamma=39.5584338 (M=  47) - s=0.0100\n",
      " 164 - L= 2.9760854 - Gamma=39.6131244 (M=  47) - s=0.0100\n",
      " 165 - L= 2.9761258 - Gamma=39.5147258 (M=  47) - s=0.0100\n",
      " 166 - L= 2.9761571 - Gamma=39.4307246 (M=  47) - s=0.0100\n",
      " 167 - L= 2.9761954 - Gamma=39.4791519 (M=  47) - s=0.0100\n",
      " 168 - L= 2.9762316 - Gamma=39.5170871 (M=  47) - s=0.0100\n",
      " 169 - L= 2.9762415 - Gamma=39.4786249 (M=  46) - s=0.0100\n",
      " 170 - L= 2.9762831 - Gamma=39.4401570 (M=  46) - s=0.0100\n",
      " 171 - L= 2.9763043 - Gamma=39.3681148 (M=  45) - s=0.0100\n",
      " 172 - L= 2.9763448 - Gamma=39.2908519 (M=  45) - s=0.0100\n",
      " 173 - L= 2.9764126 - Gamma=39.3569078 (M=  45) - s=0.0100\n",
      " 174 - L= 2.9764602 - Gamma=39.4122864 (M=  45) - s=0.0100\n",
      " 175 - L= 2.9764985 - Gamma=39.3952573 (M=  45) - s=0.0100\n",
      " 176 - L= 2.9765432 - Gamma=39.3031636 (M=  45) - s=0.0100\n",
      " 177 - L= 2.9765903 - Gamma=39.3417219 (M=  45) - s=0.0100\n",
      " 178 - L= 2.9766412 - Gamma=39.3529390 (M=  45) - s=0.0100\n",
      " 179 - L= 2.9766832 - Gamma=39.3513818 (M=  45) - s=0.0100\n",
      " 180 - L= 2.9767197 - Gamma=39.3428456 (M=  45) - s=0.0100\n",
      " 181 - L= 2.9767541 - Gamma=39.3382763 (M=  45) - s=0.0100\n",
      " 182 - L= 2.9767950 - Gamma=39.2760632 (M=  45) - s=0.0100\n",
      " 183 - L= 2.9768336 - Gamma=39.3712735 (M=  46) - s=0.0100\n",
      " 184 - L= 2.9768613 - Gamma=39.3691849 (M=  46) - s=0.0100\n",
      " 185 - L= 2.9768892 - Gamma=39.2885234 (M=  46) - s=0.0100\n",
      " 186 - L= 2.9769239 - Gamma=39.3308427 (M=  46) - s=0.0100\n",
      " 187 - L= 2.9769314 - Gamma=39.2960932 (M=  45) - s=0.0100\n",
      " 188 - L= 2.9769641 - Gamma=39.3364895 (M=  45) - s=0.0100\n",
      " 189 - L= 2.9769982 - Gamma=39.2973979 (M=  45) - s=0.0100\n",
      " 190 - L= 2.9770546 - Gamma=39.4039876 (M=  46) - s=0.0100\n",
      " 191 - L= 2.9771002 - Gamma=39.4375950 (M=  46) - s=0.0100\n",
      " 192 - L= 2.9771474 - Gamma=39.3359474 (M=  46) - s=0.0100\n",
      " 193 - L= 2.9772011 - Gamma=39.2559162 (M=  46) - s=0.0100\n",
      " 194 - L= 2.9772603 - Gamma=39.1973154 (M=  46) - s=0.0100\n",
      " 195 - L= 2.9772747 - Gamma=39.1403702 (M=  45) - s=0.0100\n",
      " 196 - L= 2.9773541 - Gamma=39.2314674 (M=  45) - s=0.0100\n",
      " 197 - L= 2.9774174 - Gamma=39.3305941 (M=  45) - s=0.0100\n",
      " 198 - L= 2.9774579 - Gamma=39.2394496 (M=  44) - s=0.0100\n",
      " 199 - L= 2.9775661 - Gamma=39.3021781 (M=  44) - s=0.0100\n",
      " 200 - L= 2.9776906 - Gamma=39.3701543 (M=  44) - s=0.0100\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 0s - loss: 0.7800 - acc: 0.6154 - val_loss: 0.6716 - val_acc: 0.6111\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 0s - loss: 0.6654 - acc: 0.6308 - val_loss: 0.6766 - val_acc: 0.6111\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 0s - loss: 0.6824 - acc: 0.6308 - val_loss: 0.6709 - val_acc: 0.6111\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 0s - loss: 0.6824 - acc: 0.6308 - val_loss: 0.6667 - val_acc: 0.6111\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 0s - loss: 0.6709 - acc: 0.6308 - val_loss: 0.6655 - val_acc: 0.6111\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s - loss: 0.6755 - acc: 0.6212 - val_loss: 0.6606 - val_acc: 0.6471\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s - loss: 0.6592 - acc: 0.6212 - val_loss: 0.6456 - val_acc: 0.6471\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s - loss: 0.6636 - acc: 0.6212 - val_loss: 0.6552 - val_acc: 0.6471\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s - loss: 0.6691 - acc: 0.6061 - val_loss: 0.6526 - val_acc: 0.6471\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s - loss: 0.6717 - acc: 0.6212 - val_loss: 0.6750 - val_acc: 0.6471\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.7031 - acc: 0.6119 - val_loss: 0.6774 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.6697 - acc: 0.6269 - val_loss: 0.6710 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.6668 - acc: 0.6269 - val_loss: 0.6561 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6633 - acc: 0.633 - 0s - loss: 0.6638 - acc: 0.6269 - val_loss: 0.6571 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.6807 - acc: 0.6269 - val_loss: 0.6598 - val_acc: 0.6250\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6710 - acc: 0.616 - 0s - loss: 0.6605 - acc: 0.6269 - val_loss: 0.6613 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.6769 - acc: 0.6269 - val_loss: 0.6579 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.6420 - acc: 0.6269 - val_loss: 0.6562 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.6517 - acc: 0.6269 - val_loss: 0.6162 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6102 - acc: 0.650 - 0s - loss: 0.6292 - acc: 0.6269 - val_loss: 0.6640 - val_acc: 0.6250\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.6081 - acc: 0.6269 - val_loss: 0.5360 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.6624 - acc: 0.6119 - val_loss: 0.6778 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.6750 - acc: 0.6269 - val_loss: 0.6526 - val_acc: 0.6250\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s - loss: 0.6291 - acc: 0.6269 - val_loss: 0.5340 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.6035 - acc: 0.6119 - val_loss: 0.6734 - val_acc: 0.6250\n",
      "MODEL: DNN accuracy:  0.626506024096 +/-: 0.000139229253418\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215, 1) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 2s - loss: 1.3410 - acc: 0.5692 - val_loss: 0.5957 - val_acc: 0.7778\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 1s - loss: 0.6366 - acc: 0.6769 - val_loss: 0.5955 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 2s - loss: 0.5143 - acc: 0.7231 - val_loss: 0.5811 - val_acc: 0.8889\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 2s - loss: 0.4157 - acc: 0.8308 - val_loss: 0.3304 - val_acc: 0.8889\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 2s - loss: 0.2166 - acc: 0.9385 - val_loss: 0.2618 - val_acc: 0.8889\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 2s - loss: 0.0864 - acc: 0.9848 - val_loss: 0.0308 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 2s - loss: 0.0744 - acc: 0.9848 - val_loss: 0.2575 - val_acc: 0.8235\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 2s - loss: 0.1737 - acc: 0.9091 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 2s - loss: 0.0425 - acc: 0.9848 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 2s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1458 - val_acc: 0.8824\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 2s - loss: 0.7177 - acc: 0.8507 - val_loss: 0.0453 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s - loss: 0.0452 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 2s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 2s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 2s - loss: 0.1409 - acc: 0.9552 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s - loss: 0.0046 - acc: 1.0000 - val_loss: 4.7662e-04 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s - loss: 0.0034 - acc: 1.0000 - val_loss: 1.5134e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 1s - loss: 0.0065 - acc: 1.0000 - val_loss: 2.6752e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 1s - loss: 0.0142 - acc: 1.0000 - val_loss: 2.4881e-04 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 2s - loss: 0.0034 - acc: 1.0000 - val_loss: 1.3963e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s - loss: 0.0176 - acc: 1.0000 - val_loss: 1.0744e-04 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s - loss: 6.9060e-04 - acc: 1.0000 - val_loss: 6.0995e-05 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 2s - loss: 0.0018 - acc: 1.0000 - val_loss: 4.2922e-05 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 2s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.1720e-06 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.951807228916 +/-: 0.00318970187388\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: ET accuracy:  0.939759036145 +/-: 0.0031481347075\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: RF accuracy:  0.915662650602 +/-: 0.000791377178926\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: GBM accuracy:  0.903614457831 +/-: 0.0022756985893\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: ADA accuracy:  0.927710843373 +/-: 0.00341176897526\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: LR accuracy:  0.939759036145 +/-: 0.00146493130566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: SVM accuracy:  0.939759036145 +/-: 0.00146493130566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: MLNN accuracy:  0.879518072289 +/-: 0.0155159973701\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "MODEL: XGB accuracy:  0.927710843373 +/-: 0.0021272190107\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "Initial alpha = [[ 0.02910706]]\n",
      "   1 - L=-361.1054524 - Gamma= 1.9999420 (M=   2) - s=0.0100\n",
      "   2 - L=-252.5886776 - Gamma= 2.9998708 (M=   3) - s=0.0100\n",
      "   3 - L=-185.7297189 - Gamma= 3.9997252 (M=   4) - s=0.0100\n",
      "   4 - L=-142.2656475 - Gamma= 4.9995304 (M=   5) - s=0.0100\n",
      "   5 - L=-113.6267476 - Gamma= 5.9992443 (M=   6) - s=0.0100\n",
      "   6 - L=-85.5940164 - Gamma= 6.9989574 (M=   7) - s=0.0100\n",
      "   7 - L=-58.3343087 - Gamma= 7.9985784 (M=   8) - s=0.0100\n",
      "   8 - L=-45.5628005 - Gamma= 8.9979482 (M=   9) - s=0.0100\n",
      "   9 - L=-33.1292031 - Gamma= 9.9972369 (M=  10) - s=0.0100\n",
      "  10 - L=-23.7738764 - Gamma=10.9963528 (M=  11) - s=0.0100\n",
      "  11 - L=-18.4460555 - Gamma=11.9948605 (M=  12) - s=0.0100\n",
      "  12 - L=-14.0556584 - Gamma=12.9926997 (M=  13) - s=0.0100\n",
      "  13 - L=-9.1585709 - Gamma=13.9908843 (M=  14) - s=0.0100\n",
      "  14 - L=-6.2970448 - Gamma=14.9879764 (M=  15) - s=0.0100\n",
      "  15 - L=-3.3864611 - Gamma=15.9851641 (M=  16) - s=0.0100\n",
      "  16 - L=-1.3435461 - Gamma=16.9810522 (M=  17) - s=0.0100\n",
      "  17 - L= 0.0877509 - Gamma=17.9756352 (M=  18) - s=0.0100\n",
      "  18 - L= 0.8810048 - Gamma=18.9654153 (M=  19) - s=0.0100\n",
      "  19 - L= 1.4945293 - Gamma=19.9532538 (M=  20) - s=0.0100\n",
      "  20 - L= 1.9983702 - Gamma=20.9368047 (M=  21) - s=0.0100\n",
      "  21 - L= 2.2909481 - Gamma=21.9121216 (M=  22) - s=0.0100\n",
      "  22 - L= 2.5133050 - Gamma=22.8802576 (M=  23) - s=0.0100\n",
      "  23 - L= 2.6491418 - Gamma=23.8303771 (M=  24) - s=0.0100\n",
      "  24 - L= 2.7476019 - Gamma=24.7684779 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8151885 - Gamma=25.6803536 (M=  26) - s=0.0100\n",
      "  26 - L= 2.8559834 - Gamma=26.5538395 (M=  27) - s=0.0100\n",
      "  27 - L= 2.8775382 - Gamma=27.3534361 (M=  28) - s=0.0100\n",
      "  28 - L= 2.8897399 - Gamma=28.0779723 (M=  29) - s=0.0100\n",
      "  29 - L= 2.8991094 - Gamma=28.0789585 (M=  29) - s=0.0100\n",
      "  30 - L= 2.9068532 - Gamma=28.7500969 (M=  30) - s=0.0100\n",
      "  31 - L= 2.9128795 - Gamma=28.7514975 (M=  30) - s=0.0100\n",
      "  32 - L= 2.9167508 - Gamma=28.7526327 (M=  30) - s=0.0100\n",
      "  33 - L= 2.9205781 - Gamma=28.7733048 (M=  30) - s=0.0100\n",
      "  34 - L= 2.9243818 - Gamma=28.7486269 (M=  30) - s=0.0100\n",
      "  35 - L= 2.9279167 - Gamma=28.7576956 (M=  30) - s=0.0100\n",
      "  36 - L= 2.9309572 - Gamma=29.2698972 (M=  31) - s=0.0100\n",
      "  37 - L= 2.9338710 - Gamma=29.2700771 (M=  31) - s=0.0100\n",
      "  38 - L= 2.9367526 - Gamma=29.2701760 (M=  31) - s=0.0100\n",
      "  39 - L= 2.9392100 - Gamma=29.0772239 (M=  31) - s=0.0100\n",
      "  40 - L= 2.9416717 - Gamma=29.0777447 (M=  31) - s=0.0100\n",
      "  41 - L= 2.9436196 - Gamma=29.5371477 (M=  32) - s=0.0100\n",
      "  42 - L= 2.9454359 - Gamma=29.5371113 (M=  32) - s=0.0100\n",
      "  43 - L= 2.9470363 - Gamma=29.5373035 (M=  32) - s=0.0100\n",
      "  44 - L= 2.9483869 - Gamma=29.5446062 (M=  32) - s=0.0100\n",
      "  45 - L= 2.9497264 - Gamma=29.5470207 (M=  32) - s=0.0100\n",
      "  46 - L= 2.9508901 - Gamma=29.5471873 (M=  32) - s=0.0100\n",
      "  47 - L= 2.9517645 - Gamma=29.4850195 (M=  32) - s=0.0100\n",
      "  48 - L= 2.9525657 - Gamma=29.4846929 (M=  32) - s=0.0100\n",
      "  49 - L= 2.9532808 - Gamma=29.4844713 (M=  32) - s=0.0100\n",
      "  50 - L= 2.9539572 - Gamma=29.4848999 (M=  32) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  51 - L= 2.9546274 - Gamma=29.4458723 (M=  32) - s=0.0100\n",
      "  52 - L= 2.9550852 - Gamma=29.7074842 (M=  33) - s=0.0100\n",
      "  53 - L= 2.9554605 - Gamma=29.7085850 (M=  33) - s=0.0100\n",
      "  54 - L= 2.9556697 - Gamma=29.7100651 (M=  33) - s=0.0100\n",
      "  55 - L= 2.9558643 - Gamma=29.7099369 (M=  33) - s=0.0100\n",
      "  56 - L= 2.9560593 - Gamma=29.7564134 (M=  33) - s=0.0100\n",
      "  57 - L= 2.9562465 - Gamma=29.8153060 (M=  33) - s=0.0100\n",
      "  58 - L= 2.9564098 - Gamma=29.8489796 (M=  33) - s=0.0100\n",
      "  59 - L= 2.9565668 - Gamma=29.8484208 (M=  33) - s=0.0100\n",
      "  60 - L= 2.9567052 - Gamma=29.8530666 (M=  33) - s=0.0100\n",
      "  61 - L= 2.9568144 - Gamma=29.8524477 (M=  33) - s=0.0100\n",
      "  62 - L= 2.9569156 - Gamma=29.8436484 (M=  33) - s=0.0100\n",
      "  63 - L= 2.9569937 - Gamma=29.7927052 (M=  33) - s=0.0100\n",
      "  64 - L= 2.9570603 - Gamma=29.7182726 (M=  33) - s=0.0100\n",
      "  65 - L= 2.9571081 - Gamma=29.7139674 (M=  33) - s=0.0100\n",
      "  66 - L= 2.9571520 - Gamma=29.8067017 (M=  34) - s=0.0100\n",
      "  67 - L= 2.9571860 - Gamma=29.7639720 (M=  34) - s=0.0100\n",
      "  68 - L= 2.9572145 - Gamma=29.7795332 (M=  34) - s=0.0100\n",
      "  69 - L= 2.9572346 - Gamma=29.7783821 (M=  34) - s=0.0100\n",
      "  70 - L= 2.9572408 - Gamma=29.7843157 (M=  34) - s=0.0100\n",
      "  71 - L= 2.9572460 - Gamma=29.7840491 (M=  34) - s=0.0100\n",
      "  72 - L= 2.9572498 - Gamma=29.7721084 (M=  34) - s=0.0100\n",
      "  73 - L= 2.9572530 - Gamma=29.7958052 (M=  34) - s=0.0100\n",
      "  74 - L= 2.9572581 - Gamma=29.7707491 (M=  34) - s=0.0100\n",
      "  75 - L= 2.9572599 - Gamma=29.7808929 (M=  34) - s=0.0100\n",
      "  76 - L= 2.9572621 - Gamma=29.7666300 (M=  34) - s=0.0100\n",
      "  77 - L= 2.9572646 - Gamma=29.7872739 (M=  34) - s=0.0100\n",
      "  78 - L= 2.9572681 - Gamma=29.7915381 (M=  34) - s=0.0100\n",
      "  79 - L= 2.9572705 - Gamma=29.7957963 (M=  34) - s=0.0100\n",
      "  80 - L= 2.9572726 - Gamma=29.7790815 (M=  34) - s=0.0100\n",
      "  81 - L= 2.9572745 - Gamma=29.7966023 (M=  34) - s=0.0100\n",
      "  82 - L= 2.9572765 - Gamma=29.7960798 (M=  34) - s=0.0100\n",
      "  83 - L= 2.9572783 - Gamma=29.7927214 (M=  34) - s=0.0100\n",
      "  84 - L= 2.9572803 - Gamma=29.8031212 (M=  34) - s=0.0100\n",
      "  85 - L= 2.9572817 - Gamma=29.7892075 (M=  34) - s=0.0100\n",
      "  86 - L= 2.9572835 - Gamma=29.7921609 (M=  34) - s=0.0100\n",
      "  87 - L= 2.9572847 - Gamma=29.8058529 (M=  34) - s=0.0100\n",
      "  88 - L= 2.9572859 - Gamma=29.8065432 (M=  34) - s=0.0100\n",
      "  89 - L= 2.9572872 - Gamma=29.7993295 (M=  34) - s=0.0100\n",
      "  90 - L= 2.9572884 - Gamma=29.7886687 (M=  34) - s=0.0100\n",
      "  91 - L= 2.9572893 - Gamma=29.7913699 (M=  34) - s=0.0100\n",
      "  92 - L= 2.9572901 - Gamma=29.7897699 (M=  34) - s=0.0100\n",
      "  93 - L= 2.9572908 - Gamma=29.7897596 (M=  34) - s=0.0100\n",
      "  94 - L= 2.9572913 - Gamma=29.7987061 (M=  34) - s=0.0100\n",
      "  95 - L= 2.9572922 - Gamma=29.7873691 (M=  34) - s=0.0100\n",
      "  96 - L= 2.9572934 - Gamma=29.7951704 (M=  34) - s=0.0100\n",
      "  97 - L= 2.9572945 - Gamma=29.7974671 (M=  34) - s=0.0100\n",
      "  98 - L= 2.9572951 - Gamma=29.7973741 (M=  34) - s=0.0100\n",
      "  99 - L= 2.9572958 - Gamma=29.7953931 (M=  34) - s=0.0100\n",
      " 100 - L= 2.9572965 - Gamma=29.8056513 (M=  34) - s=0.0100\n",
      " 101 - L= 2.9572975 - Gamma=29.7935029 (M=  34) - s=0.0100\n",
      " 102 - L= 2.9572981 - Gamma=29.7991058 (M=  34) - s=0.0100\n",
      " 103 - L= 2.9572987 - Gamma=29.7990709 (M=  34) - s=0.0100\n",
      " 104 - L= 2.9572992 - Gamma=29.7990258 (M=  34) - s=0.0100\n",
      " 105 - L= 2.9572996 - Gamma=29.7996455 (M=  34) - s=0.0100\n",
      " 106 - L= 2.9573000 - Gamma=29.8009225 (M=  34) - s=0.0100\n",
      " 107 - L= 2.9573005 - Gamma=29.8092560 (M=  34) - s=0.0100\n",
      " 108 - L= 2.9573011 - Gamma=29.7992953 (M=  34) - s=0.0100\n",
      " 109 - L= 2.9573018 - Gamma=29.8014292 (M=  34) - s=0.0100\n",
      " 110 - L= 2.9573021 - Gamma=29.8079277 (M=  34) - s=0.0100\n",
      " 111 - L= 2.9573024 - Gamma=29.8041113 (M=  34) - s=0.0100\n",
      " 112 - L= 2.9573027 - Gamma=29.7986754 (M=  34) - s=0.0100\n",
      " 113 - L= 2.9573031 - Gamma=29.8000061 (M=  34) - s=0.0100\n",
      " 114 - L= 2.9573035 - Gamma=29.8044332 (M=  34) - s=0.0100\n",
      " 115 - L= 2.9573040 - Gamma=29.8149978 (M=  35) - s=0.0100\n",
      " 116 - L= 2.9573044 - Gamma=29.8069109 (M=  35) - s=0.0100\n",
      " 117 - L= 2.9573050 - Gamma=29.8161825 (M=  35) - s=0.0100\n",
      " 118 - L= 2.9573055 - Gamma=29.8144294 (M=  35) - s=0.0100\n",
      " 119 - L= 2.9573059 - Gamma=29.8186208 (M=  35) - s=0.0100\n",
      " 120 - L= 2.9573062 - Gamma=29.8116392 (M=  35) - s=0.0100\n",
      " 121 - L= 2.9573066 - Gamma=29.8130016 (M=  35) - s=0.0100\n",
      " 122 - L= 2.9573069 - Gamma=29.8212448 (M=  35) - s=0.0100\n",
      " 123 - L= 2.9573072 - Gamma=29.8277187 (M=  35) - s=0.0100\n",
      " 124 - L= 2.9573077 - Gamma=29.8208763 (M=  35) - s=0.0100\n",
      " 125 - L= 2.9573079 - Gamma=29.8243829 (M=  35) - s=0.0100\n",
      " 126 - L= 2.9573082 - Gamma=29.8173912 (M=  35) - s=0.0100\n",
      " 127 - L= 2.9573085 - Gamma=29.8171906 (M=  35) - s=0.0100\n",
      " 128 - L= 2.9573088 - Gamma=29.8250991 (M=  35) - s=0.0100\n",
      " 129 - L= 2.9573091 - Gamma=29.8314185 (M=  35) - s=0.0100\n",
      " 130 - L= 2.9573094 - Gamma=29.8325317 (M=  35) - s=0.0100\n",
      " 131 - L= 2.9573097 - Gamma=29.8288070 (M=  35) - s=0.0100\n",
      " 132 - L= 2.9573101 - Gamma=29.8305368 (M=  35) - s=0.0100\n",
      " 133 - L= 2.9573104 - Gamma=29.8236439 (M=  35) - s=0.0100\n",
      " 134 - L= 2.9573108 - Gamma=29.8301173 (M=  35) - s=0.0100\n",
      " 135 - L= 2.9573111 - Gamma=29.8340061 (M=  35) - s=0.0100\n",
      " 136 - L= 2.9573115 - Gamma=29.8323743 (M=  35) - s=0.0100\n",
      " 137 - L= 2.9573118 - Gamma=29.8323022 (M=  35) - s=0.0100\n",
      " 138 - L= 2.9573121 - Gamma=29.8321649 (M=  35) - s=0.0100\n",
      " 139 - L= 2.9573123 - Gamma=29.8321368 (M=  35) - s=0.0100\n",
      " 140 - L= 2.9573126 - Gamma=29.8321105 (M=  35) - s=0.0100\n",
      " 141 - L= 2.9573128 - Gamma=29.8321039 (M=  35) - s=0.0100\n",
      " 142 - L= 2.9573130 - Gamma=29.8330696 (M=  35) - s=0.0100\n",
      " 143 - L= 2.9573134 - Gamma=29.8257999 (M=  35) - s=0.0100\n",
      " 144 - L= 2.9573137 - Gamma=29.8347583 (M=  35) - s=0.0100\n",
      " 145 - L= 2.9573141 - Gamma=29.8388275 (M=  35) - s=0.0100\n",
      " 146 - L= 2.9573144 - Gamma=29.8453911 (M=  35) - s=0.0100\n",
      " 147 - L= 2.9573149 - Gamma=29.8384039 (M=  35) - s=0.0100\n",
      " 148 - L= 2.9573151 - Gamma=29.8324262 (M=  35) - s=0.0100\n",
      " 149 - L= 2.9573154 - Gamma=29.8335371 (M=  35) - s=0.0100\n",
      " 150 - L= 2.9573157 - Gamma=29.8391882 (M=  35) - s=0.0100\n",
      " 151 - L= 2.9573160 - Gamma=29.8471598 (M=  35) - s=0.0100\n",
      " 152 - L= 2.9573162 - Gamma=29.8474853 (M=  35) - s=0.0100\n",
      " 153 - L= 2.9573165 - Gamma=29.8439210 (M=  35) - s=0.0100\n",
      " 154 - L= 2.9573167 - Gamma=29.8380289 (M=  35) - s=0.0100\n",
      " 155 - L= 2.9573171 - Gamma=29.8420752 (M=  35) - s=0.0100\n",
      " 156 - L= 2.9573173 - Gamma=29.8407891 (M=  35) - s=0.0100\n",
      " 157 - L= 2.9573175 - Gamma=29.8459219 (M=  35) - s=0.0100\n",
      " 158 - L= 2.9573178 - Gamma=29.8472543 (M=  35) - s=0.0100\n",
      " 159 - L= 2.9573180 - Gamma=29.8482504 (M=  35) - s=0.0100\n",
      " 160 - L= 2.9573184 - Gamma=29.8406403 (M=  35) - s=0.0100\n",
      " 161 - L= 2.9573186 - Gamma=29.8410829 (M=  35) - s=0.0100\n",
      " 162 - L= 2.9573188 - Gamma=29.8462827 (M=  35) - s=0.0100\n",
      " 163 - L= 2.9573191 - Gamma=29.8535522 (M=  35) - s=0.0100\n",
      " 164 - L= 2.9573194 - Gamma=29.8571364 (M=  35) - s=0.0100\n",
      " 165 - L= 2.9573197 - Gamma=29.8512153 (M=  35) - s=0.0100\n",
      " 166 - L= 2.9573199 - Gamma=29.8511843 (M=  35) - s=0.0100\n",
      " 167 - L= 2.9573201 - Gamma=29.8455034 (M=  35) - s=0.0100\n",
      " 168 - L= 2.9573204 - Gamma=29.8465149 (M=  35) - s=0.0100\n",
      " 169 - L= 2.9573207 - Gamma=29.8523315 (M=  35) - s=0.0100\n",
      " 170 - L= 2.9573209 - Gamma=29.8521464 (M=  35) - s=0.0100\n",
      " 171 - L= 2.9573211 - Gamma=29.8589845 (M=  35) - s=0.0100\n",
      " 172 - L= 2.9573214 - Gamma=29.8520184 (M=  35) - s=0.0100\n",
      " 173 - L= 2.9573217 - Gamma=29.8558597 (M=  35) - s=0.0100\n",
      " 174 - L= 2.9573219 - Gamma=29.8546853 (M=  35) - s=0.0100\n",
      " 175 - L= 2.9573221 - Gamma=29.8546327 (M=  35) - s=0.0100\n",
      " 176 - L= 2.9573223 - Gamma=29.8518703 (M=  35) - s=0.0100\n",
      " 177 - L= 2.9573225 - Gamma=29.8570169 (M=  35) - s=0.0100\n",
      " 178 - L= 2.9573227 - Gamma=29.8579427 (M=  35) - s=0.0100\n",
      " 179 - L= 2.9573230 - Gamma=29.8513564 (M=  35) - s=0.0100\n",
      " 180 - L= 2.9573233 - Gamma=29.8594451 (M=  36) - s=0.0100\n",
      " 181 - L= 2.9573236 - Gamma=29.8530030 (M=  36) - s=0.0100\n",
      " 182 - L= 2.9573239 - Gamma=29.8590021 (M=  36) - s=0.0100\n",
      " 183 - L= 2.9573241 - Gamma=29.8602973 (M=  36) - s=0.0100\n",
      " 184 - L= 2.9573244 - Gamma=29.8551603 (M=  36) - s=0.0100\n",
      " 185 - L= 2.9573246 - Gamma=29.8561768 (M=  36) - s=0.0100\n",
      " 186 - L= 2.9573249 - Gamma=29.8633219 (M=  36) - s=0.0100\n",
      " 187 - L= 2.9573255 - Gamma=29.8530873 (M=  36) - s=0.0100\n",
      " 188 - L= 2.9573259 - Gamma=29.8602156 (M=  36) - s=0.0100\n",
      " 189 - L= 2.9573263 - Gamma=29.8681744 (M=  36) - s=0.0100\n",
      " 190 - L= 2.9573269 - Gamma=29.8570551 (M=  36) - s=0.0100\n",
      " 191 - L= 2.9573274 - Gamma=29.8657300 (M=  36) - s=0.0100\n",
      " 192 - L= 2.9573278 - Gamma=29.8670814 (M=  36) - s=0.0100\n",
      " 193 - L= 2.9573283 - Gamma=29.8574899 (M=  36) - s=0.0100\n",
      " 194 - L= 2.9573290 - Gamma=29.8664277 (M=  36) - s=0.0100\n",
      " 195 - L= 2.9573295 - Gamma=29.8616172 (M=  36) - s=0.0100\n",
      " 196 - L= 2.9573301 - Gamma=29.8714831 (M=  36) - s=0.0100\n",
      " 197 - L= 2.9573310 - Gamma=29.8583210 (M=  36) - s=0.0100\n",
      " 198 - L= 2.9573316 - Gamma=29.8682411 (M=  36) - s=0.0100\n",
      " 199 - L= 2.9573325 - Gamma=29.8579666 (M=  36) - s=0.0100\n",
      " 200 - L= 2.9573334 - Gamma=29.8597738 (M=  36) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alpha = [[ 0.02981614]]\n",
      "   1 - L=-385.5067142 - Gamma= 1.9999487 (M=   2) - s=0.0100\n",
      "   2 - L=-240.6675310 - Gamma= 2.9998955 (M=   3) - s=0.0100\n",
      "   3 - L=-171.5434460 - Gamma= 3.9997575 (M=   4) - s=0.0100\n",
      "   4 - L=-128.9584985 - Gamma= 4.9995422 (M=   5) - s=0.0100\n",
      "   5 - L=-99.9485300 - Gamma= 5.9992707 (M=   6) - s=0.0100\n",
      "   6 - L=-81.4869898 - Gamma= 6.9988220 (M=   7) - s=0.0100\n",
      "   7 - L=-58.4318482 - Gamma= 7.9983980 (M=   8) - s=0.0100\n",
      "   8 - L=-45.2354482 - Gamma= 8.9977739 (M=   9) - s=0.0100\n",
      "   9 - L=-32.4479860 - Gamma= 9.9971114 (M=  10) - s=0.0100\n",
      "  10 - L=-23.9898362 - Gamma=10.9959995 (M=  11) - s=0.0100\n",
      "  11 - L=-18.6699226 - Gamma=11.9945022 (M=  12) - s=0.0100\n",
      "  12 - L=-12.0332768 - Gamma=12.9931371 (M=  13) - s=0.0100\n",
      "  13 - L=-7.4492399 - Gamma=13.9913682 (M=  14) - s=0.0100\n",
      "  14 - L=-4.8118829 - Gamma=14.9882244 (M=  15) - s=0.0100\n",
      "  15 - L=-2.6913316 - Gamma=15.9841502 (M=  16) - s=0.0100\n",
      "  16 - L=-1.0643705 - Gamma=16.9790619 (M=  17) - s=0.0100\n",
      "  17 - L= 0.1965035 - Gamma=17.9723308 (M=  18) - s=0.0100\n",
      "  18 - L= 0.9618276 - Gamma=18.9624466 (M=  19) - s=0.0100\n",
      "  19 - L= 1.7707148 - Gamma=19.9530548 (M=  20) - s=0.0100\n",
      "  20 - L= 2.0984530 - Gamma=20.9301391 (M=  21) - s=0.0100\n",
      "  21 - L= 2.4082835 - Gamma=21.9066696 (M=  22) - s=0.0100\n",
      "  22 - L= 2.6031715 - Gamma=22.8717382 (M=  23) - s=0.0100\n",
      "  23 - L= 2.7477266 - Gamma=23.8256177 (M=  24) - s=0.0100\n",
      "  24 - L= 2.8392321 - Gamma=24.7576339 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8914426 - Gamma=25.6569923 (M=  26) - s=0.0100\n",
      "  26 - L= 2.9279507 - Gamma=26.5232672 (M=  27) - s=0.0100\n",
      "  27 - L= 2.9508212 - Gamma=27.3412607 (M=  28) - s=0.0100\n",
      "  28 - L= 2.9644431 - Gamma=28.0920509 (M=  29) - s=0.0100\n",
      "  29 - L= 2.9716208 - Gamma=28.7446706 (M=  30) - s=0.0100\n",
      "  30 - L= 2.9775023 - Gamma=28.7472027 (M=  30) - s=0.0100\n",
      "  31 - L= 2.9827903 - Gamma=28.7470688 (M=  30) - s=0.0100\n",
      "  32 - L= 2.9871035 - Gamma=28.7475086 (M=  30) - s=0.0100\n",
      "  33 - L= 2.9908350 - Gamma=28.7566957 (M=  30) - s=0.0100\n",
      "  34 - L= 2.9940273 - Gamma=28.7563125 (M=  30) - s=0.0100\n",
      "  35 - L= 2.9971388 - Gamma=28.7566204 (M=  30) - s=0.0100\n",
      "  36 - L= 3.0001648 - Gamma=29.2888244 (M=  31) - s=0.0100\n",
      "  37 - L= 3.0029837 - Gamma=29.2897211 (M=  31) - s=0.0100\n",
      "  38 - L= 3.0053404 - Gamma=29.2869789 (M=  31) - s=0.0100\n",
      "  39 - L= 3.0066731 - Gamma=29.2893502 (M=  31) - s=0.0100\n",
      "  40 - L= 3.0078850 - Gamma=29.6835080 (M=  32) - s=0.0100\n",
      "  41 - L= 3.0089905 - Gamma=29.6758945 (M=  32) - s=0.0100\n",
      "  42 - L= 3.0100610 - Gamma=29.6751845 (M=  32) - s=0.0100\n",
      "  43 - L= 3.0110790 - Gamma=29.6754722 (M=  32) - s=0.0100\n",
      "  44 - L= 3.0117906 - Gamma=29.9966577 (M=  33) - s=0.0100\n",
      "  45 - L= 3.0124829 - Gamma=29.9967475 (M=  33) - s=0.0100\n",
      "  46 - L= 3.0130941 - Gamma=29.9256043 (M=  33) - s=0.0100\n",
      "  47 - L= 3.0136371 - Gamma=29.9243418 (M=  33) - s=0.0100\n",
      "  48 - L= 3.0141110 - Gamma=29.9243847 (M=  33) - s=0.0100\n",
      "  49 - L= 3.0144897 - Gamma=29.9237219 (M=  33) - s=0.0100\n",
      "  50 - L= 3.0148509 - Gamma=29.9514796 (M=  33) - s=0.0100\n",
      "  51 - L= 3.0151888 - Gamma=29.9510706 (M=  33) - s=0.0100\n",
      "  52 - L= 3.0154786 - Gamma=29.9567964 (M=  33) - s=0.0100\n",
      "  53 - L= 3.0156929 - Gamma=30.1523345 (M=  34) - s=0.0100\n",
      "  54 - L= 3.0159064 - Gamma=30.1424124 (M=  34) - s=0.0100\n",
      "  55 - L= 3.0160349 - Gamma=30.1431876 (M=  34) - s=0.0100\n",
      "  56 - L= 3.0161362 - Gamma=30.1431156 (M=  34) - s=0.0100\n",
      "  57 - L= 3.0162337 - Gamma=30.1308641 (M=  34) - s=0.0100\n",
      "  58 - L= 3.0163335 - Gamma=30.0139985 (M=  34) - s=0.0100\n",
      "  59 - L= 3.0164609 - Gamma=30.1627631 (M=  35) - s=0.0100\n",
      "  60 - L= 3.0166301 - Gamma=30.0528446 (M=  35) - s=0.0100\n",
      "  61 - L= 3.0166803 - Gamma=30.1540326 (M=  36) - s=0.0100\n",
      "  62 - L= 3.0167503 - Gamma=30.1191272 (M=  36) - s=0.0100\n",
      "  63 - L= 3.0167944 - Gamma=30.0322003 (M=  36) - s=0.0100\n",
      "  64 - L= 3.0168801 - Gamma=30.1522048 (M=  37) - s=0.0100\n",
      "  65 - L= 3.0169694 - Gamma=30.2576120 (M=  37) - s=0.0100\n",
      "  66 - L= 3.0170610 - Gamma=30.1600671 (M=  36) - s=0.0100\n",
      "  67 - L= 3.0171266 - Gamma=30.2540912 (M=  36) - s=0.0100\n",
      "  68 - L= 3.0172128 - Gamma=30.1611288 (M=  36) - s=0.0100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in log\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n",
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in absolute\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  69 - L= 3.0172980 - Gamma=30.2673147 (M=  36) - s=0.0100\n",
      "  70 - L= 3.0174021 - Gamma=30.2092803 (M=  36) - s=0.0100\n",
      "  71 - L= 3.0174381 - Gamma=30.2101779 (M=  36) - s=0.0100\n",
      "  72 - L= 3.0174659 - Gamma=30.2785622 (M=  36) - s=0.0100\n",
      "  73 - L= 3.0174953 - Gamma=30.2534637 (M=  36) - s=0.0100\n",
      "  74 - L= 3.0175277 - Gamma=30.3116447 (M=  36) - s=0.0100\n",
      "  75 - L= 3.0175740 - Gamma=30.2346244 (M=  36) - s=0.0100\n",
      "  76 - L= 3.0176203 - Gamma=30.3017791 (M=  36) - s=0.0100\n",
      "  77 - L= 3.0176455 - Gamma=30.3651395 (M=  37) - s=0.0100\n",
      "  78 - L= 3.0176719 - Gamma=30.3664901 (M=  37) - s=0.0100\n",
      "  79 - L= 3.0176986 - Gamma=30.4280441 (M=  37) - s=0.0100\n",
      "  80 - L= 3.0177198 - Gamma=30.4049329 (M=  37) - s=0.0100\n",
      "  81 - L= 3.0177372 - Gamma=30.4078010 (M=  37) - s=0.0100\n",
      "  82 - L= 3.0177570 - Gamma=30.3529531 (M=  37) - s=0.0100\n",
      "  83 - L= 3.0177845 - Gamma=30.4022224 (M=  37) - s=0.0100\n",
      "  84 - L= 3.0178026 - Gamma=30.3752860 (M=  37) - s=0.0100\n",
      "  85 - L= 3.0178186 - Gamma=30.3802077 (M=  37) - s=0.0100\n",
      "  86 - L= 3.0178339 - Gamma=30.3687625 (M=  37) - s=0.0100\n",
      "  87 - L= 3.0178475 - Gamma=30.4122939 (M=  37) - s=0.0100\n",
      "  88 - L= 3.0178623 - Gamma=30.4069291 (M=  37) - s=0.0100\n",
      "  89 - L= 3.0178757 - Gamma=30.4476259 (M=  37) - s=0.0100\n",
      "  90 - L= 3.0178872 - Gamma=30.4147234 (M=  37) - s=0.0100\n",
      "  91 - L= 3.0178996 - Gamma=30.3759728 (M=  37) - s=0.0100\n",
      "  92 - L= 3.0179202 - Gamma=30.4266116 (M=  37) - s=0.0100\n",
      "  93 - L= 3.0179361 - Gamma=30.4128744 (M=  37) - s=0.0100\n",
      "  94 - L= 3.0179507 - Gamma=30.4477396 (M=  37) - s=0.0100\n",
      "  95 - L= 3.0179700 - Gamma=30.3971007 (M=  37) - s=0.0100\n",
      "  96 - L= 3.0179881 - Gamma=30.4422165 (M=  37) - s=0.0100\n",
      "  97 - L= 3.0180137 - Gamma=30.4146178 (M=  37) - s=0.0100\n",
      "  98 - L= 3.0180374 - Gamma=30.4649513 (M=  37) - s=0.0100\n",
      "  99 - L= 3.0180682 - Gamma=30.4067753 (M=  37) - s=0.0100\n",
      " 100 - L= 3.0181071 - Gamma=30.3291614 (M=  37) - s=0.0100\n",
      " 101 - L= 3.0181616 - Gamma=30.4025102 (M=  37) - s=0.0100\n",
      " 102 - L= 3.0181911 - Gamma=30.3650474 (M=  36) - s=0.0100\n",
      " 103 - L= 3.0182082 - Gamma=30.3407373 (M=  36) - s=0.0100\n",
      " 104 - L= 3.0182272 - Gamma=30.3826546 (M=  36) - s=0.0100\n",
      " 105 - L= 3.0182502 - Gamma=30.3278671 (M=  36) - s=0.0100\n",
      " 106 - L= 3.0182799 - Gamma=30.3738810 (M=  36) - s=0.0100\n",
      " 107 - L= 3.0183092 - Gamma=30.3566307 (M=  36) - s=0.0100\n",
      " 108 - L= 3.0183231 - Gamma=30.3890147 (M=  36) - s=0.0100\n",
      " 109 - L= 3.0183343 - Gamma=30.3451016 (M=  36) - s=0.0100\n",
      " 110 - L= 3.0183494 - Gamma=30.3801622 (M=  36) - s=0.0100\n",
      " 111 - L= 3.0183664 - Gamma=30.3541214 (M=  36) - s=0.0100\n",
      " 112 - L= 3.0183922 - Gamma=30.4008171 (M=  36) - s=0.0100\n",
      " 113 - L= 3.0184062 - Gamma=30.3869776 (M=  36) - s=0.0100\n",
      " 114 - L= 3.0184185 - Gamma=30.3894666 (M=  36) - s=0.0100\n",
      " 115 - L= 3.0184301 - Gamma=30.3480956 (M=  36) - s=0.0100\n",
      " 116 - L= 3.0184435 - Gamma=30.3504485 (M=  36) - s=0.0100\n",
      " 117 - L= 3.0184548 - Gamma=30.3453770 (M=  36) - s=0.0100\n",
      " 118 - L= 3.0184624 - Gamma=30.3073788 (M=  36) - s=0.0100\n",
      " 119 - L= 3.0184742 - Gamma=30.3569559 (M=  37) - s=0.0100\n",
      " 120 - L= 3.0184839 - Gamma=30.3817013 (M=  37) - s=0.0100\n",
      " 121 - L= 3.0184926 - Gamma=30.3807442 (M=  37) - s=0.0100\n",
      " 122 - L= 3.0185000 - Gamma=30.3814186 (M=  37) - s=0.0100\n",
      " 123 - L= 3.0185064 - Gamma=30.4030565 (M=  37) - s=0.0100\n",
      " 124 - L= 3.0185135 - Gamma=30.3647204 (M=  37) - s=0.0100\n",
      " 125 - L= 3.0185200 - Gamma=30.3477545 (M=  37) - s=0.0100\n",
      " 126 - L= 3.0185288 - Gamma=30.3733559 (M=  37) - s=0.0100\n",
      " 127 - L= 3.0185371 - Gamma=30.3620949 (M=  37) - s=0.0100\n",
      " 128 - L= 3.0185422 - Gamma=30.3624123 (M=  37) - s=0.0100\n",
      " 129 - L= 3.0185474 - Gamma=30.3337359 (M=  37) - s=0.0100\n",
      " 130 - L= 3.0185537 - Gamma=30.3704070 (M=  38) - s=0.0100\n",
      " 131 - L= 3.0185585 - Gamma=30.3712624 (M=  38) - s=0.0100\n",
      " 132 - L= 3.0185635 - Gamma=30.3897353 (M=  38) - s=0.0100\n",
      " 133 - L= 3.0185701 - Gamma=30.3810365 (M=  38) - s=0.0100\n",
      " 134 - L= 3.0185765 - Gamma=30.3635496 (M=  38) - s=0.0100\n",
      " 135 - L= 3.0185832 - Gamma=30.3293539 (M=  38) - s=0.0100\n",
      " 136 - L= 3.0185912 - Gamma=30.3506818 (M=  38) - s=0.0100\n",
      " 137 - L= 3.0185959 - Gamma=30.3505968 (M=  38) - s=0.0100\n",
      " 138 - L= 3.0186005 - Gamma=30.3507204 (M=  38) - s=0.0100\n",
      " 139 - L= 3.0186047 - Gamma=30.3669442 (M=  38) - s=0.0100\n",
      " 140 - L= 3.0186110 - Gamma=30.3291318 (M=  38) - s=0.0100\n",
      " 141 - L= 3.0186208 - Gamma=30.3727100 (M=  38) - s=0.0100\n",
      " 142 - L= 3.0186216 - Gamma=30.3664560 (M=  37) - s=0.0100\n",
      " 143 - L= 3.0186289 - Gamma=30.3469418 (M=  37) - s=0.0100\n",
      " 144 - L= 3.0186403 - Gamma=30.3745776 (M=  37) - s=0.0100\n",
      " 145 - L= 3.0186479 - Gamma=30.3701880 (M=  37) - s=0.0100\n",
      " 146 - L= 3.0186537 - Gamma=30.3370429 (M=  37) - s=0.0100\n",
      " 147 - L= 3.0186603 - Gamma=30.3567248 (M=  37) - s=0.0100\n",
      " 148 - L= 3.0186679 - Gamma=30.3935142 (M=  37) - s=0.0100\n",
      " 149 - L= 3.0186766 - Gamma=30.3711571 (M=  37) - s=0.0100\n",
      " 150 - L= 3.0186835 - Gamma=30.3727612 (M=  37) - s=0.0100\n",
      " 151 - L= 3.0186901 - Gamma=30.3362329 (M=  37) - s=0.0100\n",
      " 152 - L= 3.0186980 - Gamma=30.3262523 (M=  37) - s=0.0100\n",
      " 153 - L= 3.0187041 - Gamma=30.3232165 (M=  37) - s=0.0100\n",
      " 154 - L= 3.0187101 - Gamma=30.3132169 (M=  37) - s=0.0100\n",
      " 155 - L= 3.0187174 - Gamma=30.3301464 (M=  37) - s=0.0100\n",
      " 156 - L= 3.0187239 - Gamma=30.3501228 (M=  37) - s=0.0100\n",
      " 157 - L= 3.0187293 - Gamma=30.3673033 (M=  37) - s=0.0100\n",
      " 158 - L= 3.0187353 - Gamma=30.3984611 (M=  37) - s=0.0100\n",
      " 159 - L= 3.0187461 - Gamma=30.3721381 (M=  37) - s=0.0100\n",
      " 160 - L= 3.0187576 - Gamma=30.3214238 (M=  37) - s=0.0100\n",
      " 161 - L= 3.0187658 - Gamma=30.3421717 (M=  37) - s=0.0100\n",
      " 162 - L= 3.0187717 - Gamma=30.3721353 (M=  37) - s=0.0100\n",
      " 163 - L= 3.0187733 - Gamma=30.3595039 (M=  36) - s=0.0100\n",
      " 164 - L= 3.0187791 - Gamma=30.3767590 (M=  36) - s=0.0100\n",
      " 165 - L= 3.0187867 - Gamma=30.3536568 (M=  36) - s=0.0100\n",
      " 166 - L= 3.0187926 - Gamma=30.3552927 (M=  36) - s=0.0100\n",
      " 167 - L= 3.0187976 - Gamma=30.3552600 (M=  36) - s=0.0100\n",
      " 168 - L= 3.0188022 - Gamma=30.3473460 (M=  36) - s=0.0100\n",
      " 169 - L= 3.0188067 - Gamma=30.3473397 (M=  36) - s=0.0100\n",
      " 170 - L= 3.0188105 - Gamma=30.3441252 (M=  36) - s=0.0100\n",
      " 171 - L= 3.0188155 - Gamma=30.3608113 (M=  36) - s=0.0100\n",
      " 172 - L= 3.0188203 - Gamma=30.3514863 (M=  36) - s=0.0100\n",
      " 173 - L= 3.0188250 - Gamma=30.3775339 (M=  36) - s=0.0100\n",
      " 174 - L= 3.0188309 - Gamma=30.3565396 (M=  36) - s=0.0100\n",
      " 175 - L= 3.0188375 - Gamma=30.3922174 (M=  36) - s=0.0100\n",
      " 176 - L= 3.0188410 - Gamma=30.3920107 (M=  36) - s=0.0100\n",
      " 177 - L= 3.0188441 - Gamma=30.3924328 (M=  36) - s=0.0100\n",
      " 178 - L= 3.0188462 - Gamma=30.3906105 (M=  36) - s=0.0100\n",
      " 179 - L= 3.0188481 - Gamma=30.3882998 (M=  36) - s=0.0100\n",
      " 180 - L= 3.0188499 - Gamma=30.4039192 (M=  36) - s=0.0100\n",
      " 181 - L= 3.0188522 - Gamma=30.3901907 (M=  36) - s=0.0100\n",
      " 182 - L= 3.0188554 - Gamma=30.4008401 (M=  36) - s=0.0100\n",
      " 183 - L= 3.0188583 - Gamma=30.3933431 (M=  36) - s=0.0100\n",
      " 184 - L= 3.0188614 - Gamma=30.4177358 (M=  37) - s=0.0100\n",
      " 185 - L= 3.0188640 - Gamma=30.4037460 (M=  37) - s=0.0100\n",
      " 186 - L= 3.0188659 - Gamma=30.4133185 (M=  37) - s=0.0100\n",
      " 187 - L= 3.0188679 - Gamma=30.4141674 (M=  37) - s=0.0100\n",
      " 188 - L= 3.0188692 - Gamma=30.4141370 (M=  37) - s=0.0100\n",
      " 189 - L= 3.0188705 - Gamma=30.4140743 (M=  37) - s=0.0100\n",
      " 190 - L= 3.0188717 - Gamma=30.4039644 (M=  37) - s=0.0100\n",
      " 191 - L= 3.0188737 - Gamma=30.4121351 (M=  37) - s=0.0100\n",
      " 192 - L= 3.0188749 - Gamma=30.4274641 (M=  37) - s=0.0100\n",
      " 193 - L= 3.0188773 - Gamma=30.4205501 (M=  37) - s=0.0100\n",
      " 194 - L= 3.0188788 - Gamma=30.4189658 (M=  37) - s=0.0100\n",
      " 195 - L= 3.0188803 - Gamma=30.4077633 (M=  37) - s=0.0100\n",
      " 196 - L= 3.0188817 - Gamma=30.4236849 (M=  37) - s=0.0100\n",
      " 197 - L= 3.0188834 - Gamma=30.4312142 (M=  37) - s=0.0100\n",
      " 198 - L= 3.0188849 - Gamma=30.4312827 (M=  37) - s=0.0100\n",
      " 199 - L= 3.0188860 - Gamma=30.4265476 (M=  37) - s=0.0100\n",
      " 200 - L= 3.0188872 - Gamma=30.4162830 (M=  37) - s=0.0100\n",
      "Initial alpha = [[ 0.02907605]]\n",
      "   1 - L=-412.0991692 - Gamma= 1.9999474 (M=   2) - s=0.0100\n",
      "   2 - L=-240.4065093 - Gamma= 2.9998959 (M=   3) - s=0.0100\n",
      "   3 - L=-181.7394880 - Gamma= 3.9997413 (M=   4) - s=0.0100\n",
      "   4 - L=-128.0318158 - Gamma= 4.9995827 (M=   5) - s=0.0100\n",
      "   5 - L=-100.6011406 - Gamma= 5.9992903 (M=   6) - s=0.0100\n",
      "   6 - L=-80.8505149 - Gamma= 6.9988861 (M=   7) - s=0.0100\n",
      "   7 - L=-58.7744373 - Gamma= 7.9985403 (M=   8) - s=0.0100\n",
      "   8 - L=-44.4073399 - Gamma= 8.9979322 (M=   9) - s=0.0100\n",
      "   9 - L=-35.2818697 - Gamma= 9.9970833 (M=  10) - s=0.0100\n",
      "  10 - L=-26.2282063 - Gamma=10.9961541 (M=  11) - s=0.0100\n",
      "  11 - L=-20.2748488 - Gamma=11.9948688 (M=  12) - s=0.0100\n",
      "  12 - L=-14.0565636 - Gamma=12.9935967 (M=  13) - s=0.0100\n",
      "  13 - L=-9.4396418 - Gamma=13.9916267 (M=  14) - s=0.0100\n",
      "  14 - L=-6.2064367 - Gamma=14.9892260 (M=  15) - s=0.0100\n",
      "  15 - L=-3.7994828 - Gamma=15.9859597 (M=  16) - s=0.0100\n",
      "  16 - L=-1.9416188 - Gamma=16.9817608 (M=  17) - s=0.0100\n",
      "  17 - L=-0.5334119 - Gamma=17.9763478 (M=  18) - s=0.0100\n",
      "  18 - L= 0.4484499 - Gamma=18.9679653 (M=  19) - s=0.0100\n",
      "  19 - L= 1.1606165 - Gamma=19.9565608 (M=  20) - s=0.0100\n",
      "  20 - L= 1.7993974 - Gamma=20.9447434 (M=  21) - s=0.0100\n",
      "  21 - L= 2.1845969 - Gamma=21.9253550 (M=  22) - s=0.0100\n",
      "  22 - L= 2.4257901 - Gamma=22.8941978 (M=  23) - s=0.0100\n",
      "  23 - L= 2.6339355 - Gamma=23.8568352 (M=  24) - s=0.0100\n",
      "  24 - L= 2.7399260 - Gamma=24.7978071 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8270170 - Gamma=25.7294981 (M=  26) - s=0.0100\n",
      "  26 - L= 2.8662690 - Gamma=26.6033998 (M=  27) - s=0.0100\n",
      "  27 - L= 2.8959220 - Gamma=27.4507763 (M=  28) - s=0.0100\n",
      "  28 - L= 2.9110896 - Gamma=28.2197226 (M=  29) - s=0.0100\n",
      "  29 - L= 2.9200296 - Gamma=28.2195092 (M=  29) - s=0.0100\n",
      "  30 - L= 2.9271911 - Gamma=28.2433705 (M=  29) - s=0.0100\n",
      "  31 - L= 2.9349558 - Gamma=28.9202351 (M=  30) - s=0.0100\n",
      "  32 - L= 2.9418692 - Gamma=28.9216017 (M=  30) - s=0.0100\n",
      "  33 - L= 2.9470285 - Gamma=28.9224639 (M=  30) - s=0.0100\n",
      "  34 - L= 2.9509911 - Gamma=28.9262248 (M=  30) - s=0.0100\n",
      "  35 - L= 2.9549196 - Gamma=28.9080969 (M=  30) - s=0.0100\n",
      "  36 - L= 2.9587834 - Gamma=28.9097858 (M=  30) - s=0.0100\n",
      "  37 - L= 2.9624873 - Gamma=29.4727281 (M=  31) - s=0.0100\n",
      "  38 - L= 2.9659189 - Gamma=29.4736288 (M=  31) - s=0.0100\n",
      "  39 - L= 2.9691448 - Gamma=29.4741258 (M=  31) - s=0.0100\n",
      "  40 - L= 2.9720758 - Gamma=29.4744466 (M=  31) - s=0.0100\n",
      "  41 - L= 2.9749360 - Gamma=29.4728020 (M=  31) - s=0.0100\n",
      "  42 - L= 2.9770792 - Gamma=29.4723282 (M=  31) - s=0.0100\n",
      "  43 - L= 2.9783473 - Gamma=29.4757456 (M=  31) - s=0.0100\n",
      "  44 - L= 2.9793974 - Gamma=29.4985925 (M=  31) - s=0.0100\n",
      "  45 - L= 2.9804605 - Gamma=29.5119191 (M=  31) - s=0.0100\n",
      "  46 - L= 2.9813027 - Gamma=29.8503666 (M=  32) - s=0.0100\n",
      "  47 - L= 2.9817915 - Gamma=29.8396756 (M=  32) - s=0.0100\n",
      "  48 - L= 2.9822416 - Gamma=29.8397206 (M=  32) - s=0.0100\n",
      "  49 - L= 2.9826288 - Gamma=30.0860128 (M=  33) - s=0.0100\n",
      "  50 - L= 2.9830156 - Gamma=30.0586164 (M=  33) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  51 - L= 2.9833026 - Gamma=30.2366566 (M=  34) - s=0.0100\n",
      "  52 - L= 2.9835426 - Gamma=30.2646567 (M=  34) - s=0.0100\n",
      "  53 - L= 2.9837616 - Gamma=30.2646819 (M=  34) - s=0.0100\n",
      "  54 - L= 2.9839404 - Gamma=30.2615407 (M=  34) - s=0.0100\n",
      "  55 - L= 2.9841120 - Gamma=30.4318191 (M=  35) - s=0.0100\n",
      "  56 - L= 2.9844645 - Gamma=30.2003097 (M=  35) - s=0.0100\n",
      "  57 - L= 2.9846472 - Gamma=30.2007397 (M=  35) - s=0.0100\n",
      "  58 - L= 2.9847779 - Gamma=30.2007774 (M=  35) - s=0.0100\n",
      "  59 - L= 2.9848869 - Gamma=30.2030721 (M=  35) - s=0.0100\n",
      "  60 - L= 2.9849923 - Gamma=30.2038261 (M=  35) - s=0.0100\n",
      "  61 - L= 2.9850952 - Gamma=30.2056240 (M=  35) - s=0.0100\n",
      "  62 - L= 2.9851868 - Gamma=30.2056816 (M=  35) - s=0.0100\n",
      "  63 - L= 2.9852771 - Gamma=30.3109558 (M=  35) - s=0.0100\n",
      "  64 - L= 2.9853511 - Gamma=30.3865685 (M=  35) - s=0.0100\n",
      "  65 - L= 2.9854854 - Gamma=30.3216637 (M=  35) - s=0.0100\n",
      "  66 - L= 2.9855611 - Gamma=30.2983001 (M=  35) - s=0.0100\n",
      "  67 - L= 2.9856276 - Gamma=30.2931613 (M=  35) - s=0.0100\n",
      "  68 - L= 2.9857089 - Gamma=30.3599065 (M=  35) - s=0.0100\n",
      "  69 - L= 2.9857765 - Gamma=30.3457010 (M=  35) - s=0.0100\n",
      "  70 - L= 2.9858262 - Gamma=30.2557089 (M=  34) - s=0.0100\n",
      "  71 - L= 2.9859363 - Gamma=30.3544311 (M=  34) - s=0.0100\n",
      "  72 - L= 2.9860120 - Gamma=30.2961524 (M=  34) - s=0.0100\n",
      "  73 - L= 2.9860849 - Gamma=30.2626591 (M=  34) - s=0.0100\n",
      "  74 - L= 2.9861686 - Gamma=30.3199446 (M=  34) - s=0.0100\n",
      "  75 - L= 2.9862513 - Gamma=30.2075088 (M=  34) - s=0.0100\n",
      "  76 - L= 2.9863506 - Gamma=30.2225022 (M=  34) - s=0.0100\n",
      "  77 - L= 2.9864304 - Gamma=30.1514611 (M=  34) - s=0.0100\n",
      "  78 - L= 2.9865208 - Gamma=30.2099525 (M=  34) - s=0.0100\n",
      "  79 - L= 2.9866379 - Gamma=30.2668431 (M=  34) - s=0.0100\n",
      "  80 - L= 2.9867144 - Gamma=30.1842676 (M=  34) - s=0.0100\n",
      "  81 - L= 2.9868063 - Gamma=30.0505207 (M=  33) - s=0.0100\n",
      "  82 - L= 2.9870391 - Gamma=30.2575497 (M=  34) - s=0.0100\n",
      "  83 - L= 2.9872264 - Gamma=30.1909190 (M=  34) - s=0.0100\n",
      "  84 - L= 2.9872979 - Gamma=30.3123168 (M=  35) - s=0.0100\n",
      "  85 - L= 2.9873985 - Gamma=30.2014680 (M=  35) - s=0.0100\n",
      "  86 - L= 2.9875989 - Gamma=30.2619461 (M=  35) - s=0.0100\n",
      "  87 - L= 2.9876930 - Gamma=30.1839094 (M=  34) - s=0.0100\n",
      "  88 - L= 2.9877711 - Gamma=30.1767078 (M=  34) - s=0.0100\n",
      "  89 - L= 2.9878480 - Gamma=30.1489300 (M=  34) - s=0.0100\n",
      "  90 - L= 2.9879251 - Gamma=30.2596487 (M=  34) - s=0.0100\n",
      "  91 - L= 2.9879837 - Gamma=30.2699033 (M=  34) - s=0.0100\n",
      "  92 - L= 2.9880273 - Gamma=30.3060714 (M=  34) - s=0.0100\n",
      "  93 - L= 2.9880786 - Gamma=30.3328028 (M=  34) - s=0.0100\n",
      "  94 - L= 2.9881159 - Gamma=30.3289685 (M=  34) - s=0.0100\n",
      "  95 - L= 2.9881429 - Gamma=30.3188019 (M=  34) - s=0.0100\n",
      "  96 - L= 2.9881641 - Gamma=30.2932164 (M=  34) - s=0.0100\n",
      "  97 - L= 2.9881762 - Gamma=30.2480930 (M=  34) - s=0.0100\n",
      "  98 - L= 2.9881941 - Gamma=30.3075691 (M=  35) - s=0.0100\n",
      "  99 - L= 2.9882015 - Gamma=30.3109616 (M=  35) - s=0.0100\n",
      " 100 - L= 2.9882085 - Gamma=30.3114054 (M=  35) - s=0.0100\n",
      " 101 - L= 2.9882152 - Gamma=30.3114835 (M=  35) - s=0.0100\n",
      " 102 - L= 2.9882213 - Gamma=30.3241673 (M=  35) - s=0.0100\n",
      " 103 - L= 2.9882280 - Gamma=30.3008598 (M=  35) - s=0.0100\n",
      " 104 - L= 2.9882339 - Gamma=30.3093594 (M=  35) - s=0.0100\n",
      " 105 - L= 2.9882387 - Gamma=30.3351221 (M=  35) - s=0.0100\n",
      " 106 - L= 2.9882446 - Gamma=30.3329493 (M=  35) - s=0.0100\n",
      " 107 - L= 2.9882502 - Gamma=30.3647479 (M=  35) - s=0.0100\n",
      " 108 - L= 2.9882575 - Gamma=30.3281804 (M=  35) - s=0.0100\n",
      " 109 - L= 2.9882622 - Gamma=30.3280828 (M=  35) - s=0.0100\n",
      " 110 - L= 2.9882661 - Gamma=30.3279471 (M=  35) - s=0.0100\n",
      " 111 - L= 2.9882685 - Gamma=30.3279148 (M=  35) - s=0.0100\n",
      " 112 - L= 2.9882708 - Gamma=30.3280399 (M=  35) - s=0.0100\n",
      " 113 - L= 2.9882730 - Gamma=30.3275210 (M=  35) - s=0.0100\n",
      " 114 - L= 2.9882752 - Gamma=30.3265457 (M=  35) - s=0.0100\n",
      " 115 - L= 2.9882773 - Gamma=30.3259781 (M=  35) - s=0.0100\n",
      " 116 - L= 2.9882792 - Gamma=30.3418153 (M=  35) - s=0.0100\n",
      " 117 - L= 2.9882813 - Gamma=30.3285966 (M=  35) - s=0.0100\n",
      " 118 - L= 2.9882858 - Gamma=30.3559801 (M=  35) - s=0.0100\n",
      " 119 - L= 2.9882888 - Gamma=30.3458796 (M=  35) - s=0.0100\n",
      " 120 - L= 2.9882920 - Gamma=30.3480444 (M=  35) - s=0.0100\n",
      " 121 - L= 2.9882950 - Gamma=30.3539204 (M=  35) - s=0.0100\n",
      " 122 - L= 2.9882975 - Gamma=30.3390794 (M=  35) - s=0.0100\n",
      " 123 - L= 2.9883006 - Gamma=30.3478722 (M=  35) - s=0.0100\n",
      " 124 - L= 2.9883032 - Gamma=30.3680218 (M=  35) - s=0.0100\n",
      " 125 - L= 2.9883058 - Gamma=30.3712176 (M=  35) - s=0.0100\n",
      " 126 - L= 2.9883080 - Gamma=30.3568295 (M=  35) - s=0.0100\n",
      " 127 - L= 2.9883094 - Gamma=30.3716659 (M=  35) - s=0.0100\n",
      " 128 - L= 2.9883110 - Gamma=30.3542612 (M=  35) - s=0.0100\n",
      " 129 - L= 2.9883129 - Gamma=30.3695247 (M=  35) - s=0.0100\n",
      " 130 - L= 2.9883140 - Gamma=30.3631290 (M=  35) - s=0.0100\n",
      " 131 - L= 2.9883151 - Gamma=30.3631377 (M=  35) - s=0.0100\n",
      " 132 - L= 2.9883161 - Gamma=30.3631579 (M=  35) - s=0.0100\n",
      " 133 - L= 2.9883171 - Gamma=30.3643451 (M=  35) - s=0.0100\n",
      " 134 - L= 2.9883182 - Gamma=30.3639292 (M=  35) - s=0.0100\n",
      " 135 - L= 2.9883191 - Gamma=30.3639179 (M=  35) - s=0.0100\n",
      " 136 - L= 2.9883200 - Gamma=30.3639136 (M=  35) - s=0.0100\n",
      " 137 - L= 2.9883208 - Gamma=30.3639190 (M=  35) - s=0.0100\n",
      " 138 - L= 2.9883216 - Gamma=30.3551849 (M=  35) - s=0.0100\n",
      " 139 - L= 2.9883233 - Gamma=30.3708067 (M=  35) - s=0.0100\n",
      " 140 - L= 2.9883243 - Gamma=30.3701228 (M=  35) - s=0.0100\n",
      " 141 - L= 2.9883251 - Gamma=30.3730500 (M=  35) - s=0.0100\n",
      " 142 - L= 2.9883258 - Gamma=30.3722716 (M=  35) - s=0.0100\n",
      " 143 - L= 2.9883264 - Gamma=30.3646688 (M=  35) - s=0.0100\n",
      " 144 - L= 2.9883272 - Gamma=30.3782092 (M=  36) - s=0.0100\n",
      " 145 - L= 2.9883286 - Gamma=30.3839331 (M=  36) - s=0.0100\n",
      " 146 - L= 2.9883293 - Gamma=30.3723046 (M=  36) - s=0.0100\n",
      " 147 - L= 2.9883301 - Gamma=30.3828925 (M=  36) - s=0.0100\n",
      " 148 - L= 2.9883309 - Gamma=30.3738764 (M=  36) - s=0.0100\n",
      " 149 - L= 2.9883316 - Gamma=30.3860341 (M=  36) - s=0.0100\n",
      " 150 - L= 2.9883325 - Gamma=30.3803080 (M=  36) - s=0.0100\n",
      " 151 - L= 2.9883332 - Gamma=30.3803423 (M=  36) - s=0.0100\n",
      " 152 - L= 2.9883337 - Gamma=30.3817508 (M=  36) - s=0.0100\n",
      " 153 - L= 2.9883342 - Gamma=30.3899771 (M=  36) - s=0.0100\n",
      " 154 - L= 2.9883349 - Gamma=30.3812991 (M=  36) - s=0.0100\n",
      " 155 - L= 2.9883356 - Gamma=30.3851389 (M=  36) - s=0.0100\n",
      " 156 - L= 2.9883361 - Gamma=30.3874527 (M=  36) - s=0.0100\n",
      " 157 - L= 2.9883365 - Gamma=30.3974895 (M=  36) - s=0.0100\n",
      " 158 - L= 2.9883370 - Gamma=30.3976605 (M=  36) - s=0.0100\n",
      " 159 - L= 2.9883375 - Gamma=30.3976633 (M=  36) - s=0.0100\n",
      " 160 - L= 2.9883379 - Gamma=30.3976343 (M=  36) - s=0.0100\n",
      " 161 - L= 2.9883382 - Gamma=30.3976325 (M=  36) - s=0.0100\n",
      " 162 - L= 2.9883384 - Gamma=30.3982584 (M=  36) - s=0.0100\n",
      " 163 - L= 2.9883388 - Gamma=30.4047652 (M=  36) - s=0.0100\n",
      " 164 - L= 2.9883394 - Gamma=30.3966321 (M=  36) - s=0.0100\n",
      " 165 - L= 2.9883398 - Gamma=30.3926215 (M=  36) - s=0.0100\n",
      " 166 - L= 2.9883402 - Gamma=30.3955490 (M=  36) - s=0.0100\n",
      " 167 - L= 2.9883406 - Gamma=30.4026133 (M=  36) - s=0.0100\n",
      " 168 - L= 2.9883409 - Gamma=30.3969851 (M=  36) - s=0.0100\n",
      " 169 - L= 2.9883412 - Gamma=30.4050889 (M=  36) - s=0.0100\n",
      " 170 - L= 2.9883415 - Gamma=30.4049917 (M=  36) - s=0.0100\n",
      " 171 - L= 2.9883418 - Gamma=30.4046196 (M=  36) - s=0.0100\n",
      " 172 - L= 2.9883421 - Gamma=30.3964719 (M=  36) - s=0.0100\n",
      " 173 - L= 2.9883424 - Gamma=30.4025134 (M=  36) - s=0.0100\n",
      " 174 - L= 2.9883427 - Gamma=30.4023158 (M=  36) - s=0.0100\n",
      " 175 - L= 2.9883429 - Gamma=30.4039549 (M=  36) - s=0.0100\n",
      " 176 - L= 2.9883431 - Gamma=30.4039485 (M=  36) - s=0.0100\n",
      " 177 - L= 2.9883434 - Gamma=30.4089639 (M=  36) - s=0.0100\n",
      " 178 - L= 2.9883436 - Gamma=30.4034889 (M=  36) - s=0.0100\n",
      " 179 - L= 2.9883439 - Gamma=30.4057172 (M=  36) - s=0.0100\n",
      " 180 - L= 2.9883441 - Gamma=30.4028393 (M=  36) - s=0.0100\n",
      " 181 - L= 2.9883443 - Gamma=30.4034067 (M=  36) - s=0.0100\n",
      " 182 - L= 2.9883446 - Gamma=30.4091755 (M=  36) - s=0.0100\n",
      " 183 - L= 2.9883448 - Gamma=30.4041185 (M=  36) - s=0.0100\n",
      " 184 - L= 2.9883450 - Gamma=30.4040866 (M=  36) - s=0.0100\n",
      " 185 - L= 2.9883452 - Gamma=30.4049230 (M=  36) - s=0.0100\n",
      " 186 - L= 2.9883453 - Gamma=30.4062146 (M=  36) - s=0.0100\n",
      " 187 - L= 2.9883455 - Gamma=30.4062139 (M=  36) - s=0.0100\n",
      " 188 - L= 2.9883456 - Gamma=30.4062178 (M=  36) - s=0.0100\n",
      " 189 - L= 2.9883457 - Gamma=30.4099056 (M=  36) - s=0.0100\n",
      " 190 - L= 2.9883459 - Gamma=30.4041067 (M=  36) - s=0.0100\n",
      " 191 - L= 2.9883460 - Gamma=30.4089152 (M=  36) - s=0.0100\n",
      " 192 - L= 2.9883462 - Gamma=30.4046128 (M=  36) - s=0.0100\n",
      " 193 - L= 2.9883463 - Gamma=30.4063729 (M=  36) - s=0.0100\n",
      " 194 - L= 2.9883464 - Gamma=30.4101246 (M=  36) - s=0.0100\n",
      " 195 - L= 2.9883465 - Gamma=30.4112353 (M=  36) - s=0.0100\n",
      " 196 - L= 2.9883467 - Gamma=30.4089573 (M=  36) - s=0.0100\n",
      " 197 - L= 2.9883468 - Gamma=30.4056303 (M=  36) - s=0.0100\n",
      " 198 - L= 2.9883469 - Gamma=30.4115844 (M=  36) - s=0.0100\n",
      " 199 - L= 2.9883470 - Gamma=30.4113640 (M=  36) - s=0.0100\n",
      " 200 - L= 2.9883471 - Gamma=30.4127297 (M=  36) - s=0.0100\n",
      "Initial alpha = [[ 0.02863823]]\n",
      "   1 - L=-361.6706974 - Gamma= 1.9999435 (M=   2) - s=0.0100\n",
      "   2 - L=-220.4136706 - Gamma= 2.9998896 (M=   3) - s=0.0100\n",
      "   3 - L=-169.6370343 - Gamma= 3.9997335 (M=   4) - s=0.0100\n",
      "   4 - L=-128.7756958 - Gamma= 4.9994769 (M=   5) - s=0.0100\n",
      "   5 - L=-85.4377554 - Gamma= 5.9992756 (M=   6) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6 - L=-68.0388460 - Gamma= 6.9988012 (M=   7) - s=0.0100\n",
      "   7 - L=-55.0434086 - Gamma= 7.9981930 (M=   8) - s=0.0100\n",
      "   8 - L=-43.9062631 - Gamma= 8.9974938 (M=   9) - s=0.0100\n",
      "   9 - L=-30.0686675 - Gamma= 9.9968330 (M=  10) - s=0.0100\n",
      "  10 - L=-23.3801276 - Gamma=10.9956317 (M=  11) - s=0.0100\n",
      "  11 - L=-17.9487107 - Gamma=11.9940590 (M=  12) - s=0.0100\n",
      "  12 - L=-13.0531783 - Gamma=12.9924731 (M=  13) - s=0.0100\n",
      "  13 - L=-8.5331744 - Gamma=13.9907153 (M=  14) - s=0.0100\n",
      "  14 - L=-5.5419812 - Gamma=14.9881335 (M=  15) - s=0.0100\n",
      "  15 - L=-2.9649073 - Gamma=15.9843547 (M=  16) - s=0.0100\n",
      "  16 - L=-1.0980871 - Gamma=16.9800461 (M=  17) - s=0.0100\n",
      "  17 - L= 0.0497685 - Gamma=17.9734399 (M=  18) - s=0.0100\n",
      "  18 - L= 0.8987812 - Gamma=18.9643689 (M=  19) - s=0.0100\n",
      "  19 - L= 1.6004262 - Gamma=19.9533550 (M=  20) - s=0.0100\n",
      "  20 - L= 1.9726012 - Gamma=20.9332944 (M=  21) - s=0.0100\n",
      "  21 - L= 2.3413328 - Gamma=21.9131129 (M=  22) - s=0.0100\n",
      "  22 - L= 2.5537400 - Gamma=22.8805160 (M=  23) - s=0.0100\n",
      "  23 - L= 2.7069345 - Gamma=23.8346713 (M=  24) - s=0.0100\n",
      "  24 - L= 2.8195625 - Gamma=24.7779865 (M=  25) - s=0.0100\n",
      "  25 - L= 2.8927725 - Gamma=25.6948145 (M=  26) - s=0.0100\n",
      "  26 - L= 2.9285511 - Gamma=26.5568518 (M=  27) - s=0.0100\n",
      "  27 - L= 2.9635536 - Gamma=27.4185391 (M=  28) - s=0.0100\n",
      "  28 - L= 2.9814295 - Gamma=27.4134019 (M=  28) - s=0.0100\n",
      "  29 - L= 2.9944074 - Gamma=28.1687307 (M=  29) - s=0.0100\n",
      "  30 - L= 3.0054065 - Gamma=28.1683903 (M=  29) - s=0.0100\n",
      "  31 - L= 3.0139978 - Gamma=28.1687645 (M=  29) - s=0.0100\n",
      "  32 - L= 3.0220696 - Gamma=28.1713632 (M=  29) - s=0.0100\n",
      "  33 - L= 3.0295731 - Gamma=28.8353123 (M=  30) - s=0.0100\n",
      "  34 - L= 3.0366991 - Gamma=28.8367961 (M=  30) - s=0.0100\n",
      "  35 - L= 3.0423513 - Gamma=28.8338503 (M=  30) - s=0.0100\n",
      "  36 - L= 3.0458639 - Gamma=29.3911778 (M=  31) - s=0.0100\n",
      "  37 - L= 3.0479005 - Gamma=29.8655929 (M=  32) - s=0.0100\n",
      "  38 - L= 3.0497771 - Gamma=29.8759479 (M=  32) - s=0.0100\n",
      "  39 - L= 3.0513921 - Gamma=29.8761637 (M=  32) - s=0.0100\n",
      "  40 - L= 3.0528254 - Gamma=29.8757083 (M=  32) - s=0.0100\n",
      "  41 - L= 3.0538925 - Gamma=29.8760572 (M=  32) - s=0.0100\n",
      "  42 - L= 3.0549128 - Gamma=29.9067317 (M=  32) - s=0.0100\n",
      "  43 - L= 3.0558140 - Gamma=29.9058056 (M=  32) - s=0.0100\n",
      "  44 - L= 3.0566531 - Gamma=29.9067094 (M=  32) - s=0.0100\n",
      "  45 - L= 3.0573338 - Gamma=29.9009288 (M=  32) - s=0.0100\n",
      "  46 - L= 3.0579753 - Gamma=30.2091011 (M=  33) - s=0.0100\n",
      "  47 - L= 3.0585846 - Gamma=30.5047120 (M=  34) - s=0.0100\n",
      "  48 - L= 3.0591142 - Gamma=30.5037440 (M=  34) - s=0.0100\n",
      "  49 - L= 3.0595329 - Gamma=30.5073709 (M=  34) - s=0.0100\n",
      "  50 - L= 3.0599058 - Gamma=30.5070609 (M=  34) - s=0.0100\n",
      "  51 - L= 3.0601804 - Gamma=30.5070020 (M=  34) - s=0.0100\n",
      "  52 - L= 3.0604069 - Gamma=30.3828913 (M=  34) - s=0.0100\n",
      "  53 - L= 3.0605842 - Gamma=30.4075131 (M=  34) - s=0.0100\n",
      "  54 - L= 3.0606836 - Gamma=30.4149529 (M=  34) - s=0.0100\n",
      "  55 - L= 3.0607789 - Gamma=30.5080989 (M=  34) - s=0.0100\n",
      "  56 - L= 3.0608533 - Gamma=30.5086989 (M=  34) - s=0.0100\n",
      "  57 - L= 3.0609165 - Gamma=30.5102892 (M=  34) - s=0.0100\n",
      "  58 - L= 3.0609738 - Gamma=30.4683536 (M=  34) - s=0.0100\n",
      "  59 - L= 3.0610287 - Gamma=30.4676760 (M=  34) - s=0.0100\n",
      "  60 - L= 3.0610761 - Gamma=30.4608315 (M=  34) - s=0.0100\n",
      "  61 - L= 3.0611169 - Gamma=30.4461643 (M=  34) - s=0.0100\n",
      "  62 - L= 3.0611650 - Gamma=30.5136269 (M=  34) - s=0.0100\n",
      "  63 - L= 3.0612141 - Gamma=30.4457242 (M=  34) - s=0.0100\n",
      "  64 - L= 3.0612546 - Gamma=30.4458370 (M=  34) - s=0.0100\n",
      "  65 - L= 3.0612813 - Gamma=30.4900116 (M=  34) - s=0.0100\n",
      "  66 - L= 3.0613032 - Gamma=30.4706680 (M=  34) - s=0.0100\n",
      "  67 - L= 3.0613153 - Gamma=30.4704306 (M=  34) - s=0.0100\n",
      "  68 - L= 3.0613270 - Gamma=30.4726130 (M=  34) - s=0.0100\n",
      "  69 - L= 3.0613364 - Gamma=30.4733801 (M=  34) - s=0.0100\n",
      "  70 - L= 3.0613463 - Gamma=30.5017758 (M=  34) - s=0.0100\n",
      "  71 - L= 3.0613561 - Gamma=30.4830633 (M=  34) - s=0.0100\n",
      "  72 - L= 3.0613669 - Gamma=30.4487651 (M=  34) - s=0.0100\n",
      "  73 - L= 3.0613766 - Gamma=30.4410260 (M=  34) - s=0.0100\n",
      "  74 - L= 3.0613829 - Gamma=30.4411211 (M=  34) - s=0.0100\n",
      "  75 - L= 3.0613888 - Gamma=30.4606488 (M=  34) - s=0.0100\n",
      "  76 - L= 3.0613952 - Gamma=30.4976800 (M=  35) - s=0.0100\n",
      "  77 - L= 3.0614000 - Gamma=30.4938108 (M=  35) - s=0.0100\n",
      "  78 - L= 3.0614037 - Gamma=30.4944855 (M=  35) - s=0.0100\n",
      "  79 - L= 3.0614074 - Gamma=30.4928784 (M=  35) - s=0.0100\n",
      "  80 - L= 3.0614110 - Gamma=30.5093309 (M=  35) - s=0.0100\n",
      "  81 - L= 3.0614153 - Gamma=30.4865830 (M=  35) - s=0.0100\n",
      "  82 - L= 3.0614189 - Gamma=30.4864012 (M=  35) - s=0.0100\n",
      "  83 - L= 3.0614222 - Gamma=30.4845047 (M=  35) - s=0.0100\n",
      "  84 - L= 3.0614248 - Gamma=30.4833748 (M=  35) - s=0.0100\n",
      "  85 - L= 3.0614282 - Gamma=30.4719348 (M=  35) - s=0.0100\n",
      "  86 - L= 3.0614303 - Gamma=30.4722097 (M=  35) - s=0.0100\n",
      "  87 - L= 3.0614323 - Gamma=30.4722377 (M=  35) - s=0.0100\n",
      "  88 - L= 3.0614339 - Gamma=30.4689669 (M=  35) - s=0.0100\n",
      "  89 - L= 3.0614360 - Gamma=30.4802866 (M=  35) - s=0.0100\n",
      "  90 - L= 3.0614385 - Gamma=30.4937262 (M=  35) - s=0.0100\n",
      "  91 - L= 3.0614406 - Gamma=30.4773545 (M=  35) - s=0.0100\n",
      "  92 - L= 3.0614420 - Gamma=30.4772960 (M=  35) - s=0.0100\n",
      "  93 - L= 3.0614427 - Gamma=30.4888601 (M=  35) - s=0.0100\n",
      "  94 - L= 3.0614432 - Gamma=30.4842261 (M=  35) - s=0.0100\n",
      "  95 - L= 3.0614439 - Gamma=30.4904059 (M=  35) - s=0.0100\n",
      "  96 - L= 3.0614445 - Gamma=30.4883856 (M=  35) - s=0.0100\n",
      "  97 - L= 3.0614450 - Gamma=30.4854464 (M=  35) - s=0.0100\n",
      "  98 - L= 3.0614454 - Gamma=30.4779597 (M=  35) - s=0.0100\n",
      "  99 - L= 3.0614460 - Gamma=30.4842562 (M=  35) - s=0.0100\n",
      " 100 - L= 3.0614464 - Gamma=30.4844175 (M=  35) - s=0.0100\n",
      " 101 - L= 3.0614468 - Gamma=30.4843719 (M=  35) - s=0.0100\n",
      " 102 - L= 3.0614471 - Gamma=30.4843695 (M=  35) - s=0.0100\n",
      " 103 - L= 3.0614474 - Gamma=30.4843646 (M=  35) - s=0.0100\n",
      " 104 - L= 3.0614476 - Gamma=30.4839672 (M=  35) - s=0.0100\n",
      " 105 - L= 3.0614479 - Gamma=30.4836335 (M=  35) - s=0.0100\n",
      " 106 - L= 3.0614481 - Gamma=30.4836035 (M=  35) - s=0.0100\n",
      " 107 - L= 3.0614483 - Gamma=30.4806630 (M=  35) - s=0.0100\n",
      " 108 - L= 3.0614485 - Gamma=30.4845484 (M=  35) - s=0.0100\n",
      " 109 - L= 3.0614488 - Gamma=30.4789318 (M=  35) - s=0.0100\n",
      " 110 - L= 3.0614490 - Gamma=30.4825363 (M=  35) - s=0.0100\n",
      " 111 - L= 3.0614492 - Gamma=30.4817277 (M=  35) - s=0.0100\n",
      " 112 - L= 3.0614493 - Gamma=30.4812900 (M=  35) - s=0.0100\n",
      " 113 - L= 3.0614495 - Gamma=30.4802048 (M=  35) - s=0.0100\n",
      " 114 - L= 3.0614497 - Gamma=30.4859339 (M=  35) - s=0.0100\n",
      " 115 - L= 3.0614500 - Gamma=30.4813688 (M=  35) - s=0.0100\n",
      " 116 - L= 3.0614501 - Gamma=30.4813825 (M=  35) - s=0.0100\n",
      " 117 - L= 3.0614502 - Gamma=30.4813850 (M=  35) - s=0.0100\n",
      " 118 - L= 3.0614503 - Gamma=30.4813908 (M=  35) - s=0.0100\n",
      " 119 - L= 3.0614504 - Gamma=30.4813320 (M=  35) - s=0.0100\n",
      " 120 - L= 3.0614505 - Gamma=30.4778511 (M=  35) - s=0.0100\n",
      " 121 - L= 3.0614507 - Gamma=30.4807327 (M=  35) - s=0.0100\n",
      " 122 - L= 3.0614508 - Gamma=30.4855782 (M=  35) - s=0.0100\n",
      " 123 - L= 3.0614509 - Gamma=30.4838845 (M=  35) - s=0.0100\n",
      " 124 - L= 3.0614509 - Gamma=30.4808074 (M=  35) - s=0.0100\n",
      " 125 - L= 3.0614510 - Gamma=30.4825766 (M=  35) - s=0.0100\n",
      " 126 - L= 3.0614510 - Gamma=30.4819988 (M=  35) - s=0.0100\n",
      " 127 - L= 3.0614511 - Gamma=30.4835088 (M=  35) - s=0.0100\n",
      " 128 - L= 3.0614511 - Gamma=30.4835062 (M=  35) - s=0.0100\n",
      " 129 - L= 3.0614511 - Gamma=30.4835067 (M=  35) - s=0.0100\n",
      " 130 - L= 3.0614511 - Gamma=30.4835094 (M=  35) - s=0.0100\n",
      " 131 - L= 3.0614512 - Gamma=30.4833386 (M=  35) - s=0.0100\n",
      " 132 - L= 3.0614512 - Gamma=30.4833368 (M=  35) - s=0.0100\n",
      " 133 - L= 3.0614512 - Gamma=30.4820494 (M=  35) - s=0.0100\n",
      " 134 - L= 3.0614512 - Gamma=30.4802527 (M=  35) - s=0.0100\n",
      " 135 - L= 3.0614513 - Gamma=30.4825886 (M=  35) - s=0.0100\n",
      " 136 - L= 3.0614513 - Gamma=30.4822954 (M=  35) - s=0.0100\n",
      " 137 - L= 3.0614513 - Gamma=30.4822883 (M=  35) - s=0.0100\n",
      " 138 - L= 3.0614513 - Gamma=30.4821713 (M=  35) - s=0.0100\n",
      " 139 - L= 3.0614514 - Gamma=30.4813283 (M=  35) - s=0.0100\n",
      " 140 - L= 3.0614514 - Gamma=30.4813481 (M=  35) - s=0.0100\n",
      " 141 - L= 3.0614514 - Gamma=30.4813895 (M=  35) - s=0.0100\n",
      " 142 - L= 3.0614514 - Gamma=30.4813873 (M=  35) - s=0.0100\n",
      " 143 - L= 3.0614514 - Gamma=30.4813081 (M=  35) - s=0.0100\n",
      " 144 - L= 3.0614514 - Gamma=30.4822703 (M=  35) - s=0.0100\n",
      " 145 - L= 3.0614514 - Gamma=30.4822969 (M=  35) - s=0.0100\n",
      " 146 - L= 3.0614514 - Gamma=30.4810159 (M=  35) - s=0.0100\n",
      " 147 - L= 3.0614515 - Gamma=30.4819440 (M=  35) - s=0.0100\n",
      " 148 - L= 3.0614515 - Gamma=30.4815943 (M=  35) - s=0.0100\n",
      " 149 - L= 3.0614515 - Gamma=30.4815330 (M=  35) - s=0.0100\n",
      " 150 - L= 3.0614515 - Gamma=30.4815304 (M=  35) - s=0.0100\n",
      " 151 - L= 3.0614515 - Gamma=30.4811404 (M=  35) - s=0.0100\n",
      " 152 - L= 3.0614515 - Gamma=30.4811561 (M=  35) - s=0.0100\n",
      " 153 - L= 3.0614515 - Gamma=30.4806306 (M=  35) - s=0.0100\n",
      " 154 - L= 3.0614515 - Gamma=30.4806383 (M=  35) - s=0.0100\n",
      " 155 - L= 3.0614515 - Gamma=30.4806386 (M=  35) - s=0.0100\n",
      " 156 - L= 3.0614515 - Gamma=30.4797813 (M=  35) - s=0.0100\n",
      " 157 - L= 3.0614515 - Gamma=30.4805514 (M=  35) - s=0.0100\n",
      " 158 - L= 3.0614516 - Gamma=30.4799280 (M=  35) - s=0.0100\n",
      " 159 - L= 3.0614516 - Gamma=30.4811855 (M=  35) - s=0.0100\n",
      " 160 - L= 3.0614516 - Gamma=30.4811802 (M=  35) - s=0.0100\n",
      " 161 - L= 3.0614516 - Gamma=30.4817347 (M=  35) - s=0.0100\n",
      " 162 - L= 3.0614516 - Gamma=30.4807832 (M=  35) - s=0.0100\n",
      " 163 - L= 3.0614516 - Gamma=30.4807899 (M=  35) - s=0.0100\n",
      " 164 - L= 3.0614516 - Gamma=30.4807247 (M=  35) - s=0.0100\n",
      " 165 - L= 3.0614516 - Gamma=30.4805883 (M=  35) - s=0.0100\n",
      " 166 - L= 3.0614516 - Gamma=30.4802717 (M=  35) - s=0.0100\n",
      " 167 - L= 3.0614516 - Gamma=30.4806027 (M=  35) - s=0.0100\n",
      " 168 - L= 3.0614516 - Gamma=30.4806027 (M=  35) - s=0.0100\n",
      "Stopping at iteration 168 - max_delta_ml=1.2662355251054792e-07\n",
      "L=3.061451595542213 - Gamma=30.480602656962823 (M=35) - s=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alpha = [[ 0.02967984]]\n",
      "   1 - L=-440.0027237 - Gamma= 1.9999516 (M=   2) - s=0.0100\n",
      "   2 - L=-242.1600900 - Gamma= 2.9999127 (M=   3) - s=0.0100\n",
      "   3 - L=-178.7680600 - Gamma= 3.9997714 (M=   4) - s=0.0100\n",
      "   4 - L=-136.5609996 - Gamma= 4.9995626 (M=   5) - s=0.0100\n",
      "   5 - L=-108.9337577 - Gamma= 5.9992851 (M=   6) - s=0.0100\n",
      "   6 - L=-81.4387663 - Gamma= 6.9990076 (M=   7) - s=0.0100\n",
      "   7 - L=-61.3024072 - Gamma= 7.9985828 (M=   8) - s=0.0100\n",
      "   8 - L=-47.1007120 - Gamma= 8.9980313 (M=   9) - s=0.0100\n",
      "   9 - L=-34.9864936 - Gamma= 9.9973794 (M=  10) - s=0.0100\n",
      "  10 - L=-25.6355473 - Gamma=10.9965190 (M=  11) - s=0.0100\n",
      "  11 - L=-19.4837866 - Gamma=11.9952301 (M=  12) - s=0.0100\n",
      "  12 - L=-12.2524960 - Gamma=12.9939785 (M=  13) - s=0.0100\n",
      "  13 - L=-8.9296024 - Gamma=13.9916182 (M=  14) - s=0.0100\n",
      "  14 - L=-6.2652346 - Gamma=14.9887325 (M=  15) - s=0.0100\n",
      "  15 - L=-4.1545445 - Gamma=15.9845366 (M=  16) - s=0.0100\n",
      "  16 - L=-2.7428045 - Gamma=16.9791109 (M=  17) - s=0.0100\n",
      "  17 - L=-1.4949233 - Gamma=17.9726252 (M=  18) - s=0.0100\n",
      "  18 - L=-0.1957800 - Gamma=18.9665404 (M=  19) - s=0.0100\n",
      "  19 - L= 0.6573673 - Gamma=19.9573233 (M=  20) - s=0.0100\n",
      "  20 - L= 1.3770410 - Gamma=20.9467305 (M=  21) - s=0.0100\n",
      "  21 - L= 1.7698003 - Gamma=21.9283273 (M=  22) - s=0.0100\n",
      "  22 - L= 2.0797169 - Gamma=22.9055872 (M=  23) - s=0.0100\n",
      "  23 - L= 2.3513479 - Gamma=23.8799650 (M=  24) - s=0.0100\n",
      "  24 - L= 2.5541655 - Gamma=24.8450389 (M=  25) - s=0.0100\n",
      "  25 - L= 2.7141015 - Gamma=25.8024954 (M=  26) - s=0.0100\n",
      "  26 - L= 2.7891025 - Gamma=26.7188935 (M=  27) - s=0.0100\n",
      "  27 - L= 2.8399760 - Gamma=27.6157959 (M=  28) - s=0.0100\n",
      "  28 - L= 2.8726494 - Gamma=28.4719528 (M=  29) - s=0.0100\n",
      "  29 - L= 2.8855543 - Gamma=29.2239691 (M=  30) - s=0.0100\n",
      "  30 - L= 2.8939546 - Gamma=29.9167432 (M=  31) - s=0.0100\n",
      "  31 - L= 2.8994149 - Gamma=29.9165248 (M=  31) - s=0.0100\n",
      "  32 - L= 2.9046586 - Gamma=29.9166876 (M=  31) - s=0.0100\n",
      "  33 - L= 2.9093134 - Gamma=29.9163236 (M=  31) - s=0.0100\n",
      "  34 - L= 2.9139066 - Gamma=29.9123469 (M=  31) - s=0.0100\n",
      "  35 - L= 2.9184506 - Gamma=30.5082413 (M=  32) - s=0.0100\n",
      "  36 - L= 2.9214797 - Gamma=30.5091622 (M=  32) - s=0.0100\n",
      "  37 - L= 2.9241247 - Gamma=30.5101758 (M=  32) - s=0.0100\n",
      "  38 - L= 2.9267677 - Gamma=30.5123398 (M=  32) - s=0.0100\n",
      "  39 - L= 2.9290456 - Gamma=30.5160315 (M=  32) - s=0.0100\n",
      "  40 - L= 2.9309635 - Gamma=30.5113932 (M=  32) - s=0.0100\n",
      "  41 - L= 2.9328891 - Gamma=30.5349862 (M=  32) - s=0.0100\n",
      "  42 - L= 2.9347006 - Gamma=30.5355724 (M=  32) - s=0.0100\n",
      "  43 - L= 2.9363508 - Gamma=30.5358086 (M=  32) - s=0.0100\n",
      "  44 - L= 2.9378793 - Gamma=30.9682223 (M=  33) - s=0.0100\n",
      "  45 - L= 2.9393036 - Gamma=30.9685563 (M=  33) - s=0.0100\n",
      "  46 - L= 2.9404102 - Gamma=30.9824320 (M=  33) - s=0.0100\n",
      "  47 - L= 2.9414596 - Gamma=30.9863144 (M=  33) - s=0.0100\n",
      "  48 - L= 2.9421199 - Gamma=30.9864884 (M=  33) - s=0.0100\n",
      "  49 - L= 2.9427711 - Gamma=30.9882233 (M=  33) - s=0.0100\n",
      "  50 - L= 2.9434227 - Gamma=31.3040308 (M=  34) - s=0.0100\n",
      "  51 - L= 2.9438361 - Gamma=31.5565851 (M=  35) - s=0.0100\n",
      "  52 - L= 2.9442162 - Gamma=31.5565345 (M=  35) - s=0.0100\n",
      "  53 - L= 2.9445226 - Gamma=31.4722310 (M=  35) - s=0.0100\n",
      "  54 - L= 2.9448197 - Gamma=31.4725491 (M=  35) - s=0.0100\n",
      "  55 - L= 2.9450403 - Gamma=31.4938465 (M=  35) - s=0.0100\n",
      "  56 - L= 2.9451484 - Gamma=31.4967153 (M=  35) - s=0.0100\n",
      "  57 - L= 2.9452418 - Gamma=31.4833770 (M=  35) - s=0.0100\n",
      "  58 - L= 2.9453166 - Gamma=31.6061047 (M=  36) - s=0.0100\n",
      "  59 - L= 2.9453895 - Gamma=31.6093207 (M=  36) - s=0.0100\n",
      "  60 - L= 2.9454471 - Gamma=31.6100575 (M=  36) - s=0.0100\n",
      "  61 - L= 2.9454924 - Gamma=31.6108998 (M=  36) - s=0.0100\n",
      "  62 - L= 2.9455125 - Gamma=31.6088685 (M=  36) - s=0.0100\n",
      "  63 - L= 2.9455281 - Gamma=31.6507378 (M=  36) - s=0.0100\n",
      "  64 - L= 2.9455420 - Gamma=31.6157531 (M=  36) - s=0.0100\n",
      "  65 - L= 2.9455541 - Gamma=31.6232151 (M=  36) - s=0.0100\n",
      "  66 - L= 2.9455652 - Gamma=31.6014305 (M=  36) - s=0.0100\n",
      "  67 - L= 2.9455724 - Gamma=31.6014427 (M=  36) - s=0.0100\n",
      "  68 - L= 2.9455780 - Gamma=31.6009362 (M=  36) - s=0.0100\n",
      "  69 - L= 2.9455820 - Gamma=31.6007281 (M=  36) - s=0.0100\n",
      "  70 - L= 2.9455845 - Gamma=31.6241558 (M=  37) - s=0.0100\n",
      "  71 - L= 2.9455871 - Gamma=31.6219797 (M=  37) - s=0.0100\n",
      "  72 - L= 2.9455894 - Gamma=31.6214302 (M=  37) - s=0.0100\n",
      "  73 - L= 2.9455911 - Gamma=31.6208028 (M=  37) - s=0.0100\n",
      "  74 - L= 2.9455928 - Gamma=31.6380364 (M=  37) - s=0.0100\n",
      "  75 - L= 2.9455950 - Gamma=31.6235537 (M=  37) - s=0.0100\n",
      "  76 - L= 2.9455966 - Gamma=31.6237272 (M=  37) - s=0.0100\n",
      "  77 - L= 2.9455979 - Gamma=31.6408966 (M=  38) - s=0.0100\n",
      "  78 - L= 2.9455993 - Gamma=31.6330319 (M=  38) - s=0.0100\n",
      "  79 - L= 2.9456004 - Gamma=31.6489549 (M=  39) - s=0.0100\n",
      "  80 - L= 2.9456015 - Gamma=31.6438781 (M=  39) - s=0.0100\n",
      "  81 - L= 2.9456022 - Gamma=31.6356838 (M=  39) - s=0.0100\n",
      "  82 - L= 2.9456029 - Gamma=31.6354556 (M=  39) - s=0.0100\n",
      "  83 - L= 2.9456036 - Gamma=31.6459861 (M=  39) - s=0.0100\n",
      "  84 - L= 2.9456045 - Gamma=31.6595407 (M=  40) - s=0.0100\n",
      "  85 - L= 2.9456051 - Gamma=31.6594947 (M=  40) - s=0.0100\n",
      "  86 - L= 2.9456056 - Gamma=31.6598371 (M=  40) - s=0.0100\n",
      "  87 - L= 2.9456062 - Gamma=31.6548265 (M=  40) - s=0.0100\n",
      "  88 - L= 2.9456065 - Gamma=31.6551219 (M=  40) - s=0.0100\n",
      "  89 - L= 2.9456069 - Gamma=31.6612048 (M=  40) - s=0.0100\n",
      "  90 - L= 2.9456073 - Gamma=31.6548404 (M=  40) - s=0.0100\n",
      "  91 - L= 2.9456078 - Gamma=31.6637163 (M=  40) - s=0.0100\n",
      "  92 - L= 2.9456081 - Gamma=31.6725277 (M=  40) - s=0.0100\n",
      "  93 - L= 2.9456086 - Gamma=31.6687487 (M=  40) - s=0.0100\n",
      "  94 - L= 2.9456091 - Gamma=31.6790983 (M=  40) - s=0.0100\n",
      "  95 - L= 2.9456096 - Gamma=31.6714412 (M=  40) - s=0.0100\n",
      "  96 - L= 2.9456104 - Gamma=31.6582787 (M=  40) - s=0.0100\n",
      "  97 - L= 2.9456113 - Gamma=31.6716676 (M=  40) - s=0.0100\n",
      "  98 - L= 2.9456119 - Gamma=31.6705125 (M=  40) - s=0.0100\n",
      "  99 - L= 2.9456124 - Gamma=31.6669490 (M=  40) - s=0.0100\n",
      " 100 - L= 2.9456129 - Gamma=31.6569519 (M=  39) - s=0.0100\n",
      " 101 - L= 2.9456139 - Gamma=31.6705072 (M=  39) - s=0.0100\n",
      " 102 - L= 2.9456149 - Gamma=31.6851900 (M=  39) - s=0.0100\n",
      " 103 - L= 2.9456161 - Gamma=31.6732279 (M=  39) - s=0.0100\n",
      " 104 - L= 2.9456166 - Gamma=31.6657608 (M=  39) - s=0.0100\n",
      " 105 - L= 2.9456176 - Gamma=31.6799547 (M=  39) - s=0.0100\n",
      " 106 - L= 2.9456185 - Gamma=31.6921007 (M=  39) - s=0.0100\n",
      " 107 - L= 2.9456191 - Gamma=31.6877700 (M=  39) - s=0.0100\n",
      " 108 - L= 2.9456197 - Gamma=31.6827092 (M=  39) - s=0.0100\n",
      " 109 - L= 2.9456202 - Gamma=31.6827958 (M=  39) - s=0.0100\n",
      " 110 - L= 2.9456207 - Gamma=31.6752873 (M=  39) - s=0.0100\n",
      " 111 - L= 2.9456214 - Gamma=31.6838698 (M=  39) - s=0.0100\n",
      " 112 - L= 2.9456220 - Gamma=31.6949257 (M=  39) - s=0.0100\n",
      " 113 - L= 2.9456226 - Gamma=31.6948527 (M=  39) - s=0.0100\n",
      " 114 - L= 2.9456232 - Gamma=31.6864658 (M=  39) - s=0.0100\n",
      " 115 - L= 2.9456241 - Gamma=31.7001211 (M=  39) - s=0.0100\n",
      " 116 - L= 2.9456249 - Gamma=31.6909928 (M=  39) - s=0.0100\n",
      " 117 - L= 2.9456254 - Gamma=31.6907978 (M=  39) - s=0.0100\n",
      " 118 - L= 2.9456259 - Gamma=31.6869491 (M=  39) - s=0.0100\n",
      " 119 - L= 2.9456266 - Gamma=31.6984070 (M=  39) - s=0.0100\n",
      " 120 - L= 2.9456271 - Gamma=31.6987543 (M=  39) - s=0.0100\n",
      " 121 - L= 2.9456277 - Gamma=31.6976544 (M=  39) - s=0.0100\n",
      " 122 - L= 2.9456284 - Gamma=31.7089974 (M=  39) - s=0.0100\n",
      " 123 - L= 2.9456293 - Gamma=31.7040798 (M=  39) - s=0.0100\n",
      " 124 - L= 2.9456298 - Gamma=31.7040382 (M=  39) - s=0.0100\n",
      " 125 - L= 2.9456302 - Gamma=31.7118617 (M=  39) - s=0.0100\n",
      " 126 - L= 2.9456308 - Gamma=31.7065049 (M=  39) - s=0.0100\n",
      " 127 - L= 2.9456313 - Gamma=31.7163461 (M=  39) - s=0.0100\n",
      " 128 - L= 2.9456320 - Gamma=31.7072362 (M=  39) - s=0.0100\n",
      " 129 - L= 2.9456326 - Gamma=31.6991698 (M=  39) - s=0.0100\n",
      " 130 - L= 2.9456334 - Gamma=31.7123609 (M=  39) - s=0.0100\n",
      " 131 - L= 2.9456339 - Gamma=31.7126067 (M=  39) - s=0.0100\n",
      " 132 - L= 2.9456344 - Gamma=31.7088826 (M=  39) - s=0.0100\n",
      " 133 - L= 2.9456350 - Gamma=31.7198112 (M=  39) - s=0.0100\n",
      " 134 - L= 2.9456355 - Gamma=31.7119756 (M=  39) - s=0.0100\n",
      " 135 - L= 2.9456359 - Gamma=31.7045732 (M=  39) - s=0.0100\n",
      " 136 - L= 2.9456367 - Gamma=31.7151666 (M=  39) - s=0.0100\n",
      " 137 - L= 2.9456372 - Gamma=31.7250423 (M=  39) - s=0.0100\n",
      " 138 - L= 2.9456376 - Gamma=31.7202542 (M=  39) - s=0.0100\n",
      " 139 - L= 2.9456380 - Gamma=31.7193734 (M=  39) - s=0.0100\n",
      " 140 - L= 2.9456383 - Gamma=31.7192976 (M=  39) - s=0.0100\n",
      " 141 - L= 2.9456386 - Gamma=31.7134287 (M=  39) - s=0.0100\n",
      " 142 - L= 2.9456390 - Gamma=31.7225440 (M=  39) - s=0.0100\n",
      " 143 - L= 2.9456395 - Gamma=31.7144372 (M=  39) - s=0.0100\n",
      " 144 - L= 2.9456400 - Gamma=31.7239934 (M=  39) - s=0.0100\n",
      " 145 - L= 2.9456406 - Gamma=31.7201441 (M=  39) - s=0.0100\n",
      " 146 - L= 2.9456409 - Gamma=31.7201627 (M=  39) - s=0.0100\n",
      " 147 - L= 2.9456412 - Gamma=31.7268965 (M=  39) - s=0.0100\n",
      " 148 - L= 2.9456415 - Gamma=31.7271412 (M=  39) - s=0.0100\n",
      " 149 - L= 2.9456418 - Gamma=31.7271962 (M=  39) - s=0.0100\n",
      " 150 - L= 2.9456421 - Gamma=31.7270569 (M=  39) - s=0.0100\n",
      " 151 - L= 2.9456424 - Gamma=31.7344722 (M=  39) - s=0.0100\n",
      " 152 - L= 2.9456428 - Gamma=31.7274259 (M=  39) - s=0.0100\n",
      " 153 - L= 2.9456433 - Gamma=31.7226571 (M=  39) - s=0.0100\n",
      " 154 - L= 2.9456437 - Gamma=31.7319522 (M=  39) - s=0.0100\n",
      " 155 - L= 2.9456443 - Gamma=31.7277833 (M=  39) - s=0.0100\n",
      " 156 - L= 2.9456446 - Gamma=31.7354000 (M=  39) - s=0.0100\n",
      " 157 - L= 2.9456450 - Gamma=31.7278875 (M=  39) - s=0.0100\n",
      " 158 - L= 2.9456453 - Gamma=31.7218863 (M=  39) - s=0.0100\n",
      " 159 - L= 2.9456457 - Gamma=31.7303735 (M=  39) - s=0.0100\n",
      " 160 - L= 2.9456460 - Gamma=31.7304401 (M=  39) - s=0.0100\n",
      " 161 - L= 2.9456463 - Gamma=31.7304493 (M=  39) - s=0.0100\n",
      " 162 - L= 2.9456466 - Gamma=31.7296098 (M=  39) - s=0.0100\n",
      " 163 - L= 2.9456470 - Gamma=31.7374543 (M=  39) - s=0.0100\n",
      " 164 - L= 2.9456475 - Gamma=31.7339179 (M=  39) - s=0.0100\n",
      " 165 - L= 2.9456478 - Gamma=31.7338649 (M=  39) - s=0.0100\n",
      " 166 - L= 2.9456481 - Gamma=31.7406344 (M=  39) - s=0.0100\n",
      " 167 - L= 2.9456484 - Gamma=31.7408146 (M=  39) - s=0.0100\n",
      " 168 - L= 2.9456486 - Gamma=31.7408588 (M=  39) - s=0.0100\n",
      " 169 - L= 2.9456489 - Gamma=31.7408284 (M=  39) - s=0.0100\n",
      " 170 - L= 2.9456491 - Gamma=31.7472468 (M=  39) - s=0.0100\n",
      " 171 - L= 2.9456495 - Gamma=31.7403867 (M=  39) - s=0.0100\n",
      " 172 - L= 2.9456498 - Gamma=31.7333592 (M=  39) - s=0.0100\n",
      " 173 - L= 2.9456502 - Gamma=31.7409259 (M=  39) - s=0.0100\n",
      " 174 - L= 2.9456505 - Gamma=31.7375546 (M=  39) - s=0.0100\n",
      " 175 - L= 2.9456509 - Gamma=31.7455146 (M=  39) - s=0.0100\n",
      " 176 - L= 2.9456512 - Gamma=31.7453011 (M=  39) - s=0.0100\n",
      " 177 - L= 2.9456515 - Gamma=31.7411457 (M=  39) - s=0.0100\n",
      " 178 - L= 2.9456518 - Gamma=31.7412625 (M=  39) - s=0.0100\n",
      " 179 - L= 2.9456521 - Gamma=31.7415046 (M=  39) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 180 - L= 2.9456524 - Gamma=31.7354439 (M=  39) - s=0.0100\n",
      " 181 - L= 2.9456528 - Gamma=31.7427482 (M=  39) - s=0.0100\n",
      " 182 - L= 2.9456531 - Gamma=31.7498089 (M=  39) - s=0.0100\n",
      " 183 - L= 2.9456535 - Gamma=31.7415701 (M=  39) - s=0.0100\n",
      " 184 - L= 2.9456538 - Gamma=31.7417912 (M=  39) - s=0.0100\n",
      " 185 - L= 2.9456540 - Gamma=31.7365318 (M=  39) - s=0.0100\n",
      " 186 - L= 2.9456543 - Gamma=31.7443715 (M=  39) - s=0.0100\n",
      " 187 - L= 2.9456546 - Gamma=31.7409304 (M=  39) - s=0.0100\n",
      " 188 - L= 2.9456549 - Gamma=31.7477716 (M=  39) - s=0.0100\n",
      " 189 - L= 2.9456551 - Gamma=31.7476388 (M=  39) - s=0.0100\n",
      " 190 - L= 2.9456553 - Gamma=31.7468807 (M=  39) - s=0.0100\n",
      " 191 - L= 2.9456555 - Gamma=31.7445831 (M=  39) - s=0.0100\n",
      " 192 - L= 2.9456557 - Gamma=31.7495123 (M=  39) - s=0.0100\n",
      " 193 - L= 2.9456560 - Gamma=31.7557739 (M=  39) - s=0.0100\n",
      " 194 - L= 2.9456562 - Gamma=31.7503640 (M=  39) - s=0.0100\n",
      " 195 - L= 2.9456564 - Gamma=31.7447998 (M=  39) - s=0.0100\n",
      " 196 - L= 2.9456566 - Gamma=31.7510846 (M=  39) - s=0.0100\n",
      " 197 - L= 2.9456570 - Gamma=31.7476772 (M=  39) - s=0.0100\n",
      " 198 - L= 2.9456572 - Gamma=31.7537820 (M=  39) - s=0.0100\n",
      " 199 - L= 2.9456574 - Gamma=31.7505030 (M=  39) - s=0.0100\n",
      " 200 - L= 2.9456576 - Gamma=31.7504762 (M=  39) - s=0.0100\n",
      "MODEL: RVM accuracy:  0.771084337349 +/-: 0.00487082988225\n",
      "Initial alpha = [[ 0.02358065]]\n",
      "   1 - L=-417.8044950 - Gamma= 1.9999581 (M=   2) - s=0.0100\n",
      "   2 - L=-247.8326549 - Gamma= 2.9999154 (M=   3) - s=0.0100\n",
      "   3 - L=-207.9998705 - Gamma= 3.9997591 (M=   4) - s=0.0100\n",
      "   4 - L=-172.6273341 - Gamma= 4.9995612 (M=   5) - s=0.0100\n",
      "   5 - L=-137.1635220 - Gamma= 5.9993804 (M=   6) - s=0.0100\n",
      "   6 - L=-111.6903459 - Gamma= 6.9991179 (M=   7) - s=0.0100\n",
      "   7 - L=-91.4036104 - Gamma= 7.9988007 (M=   8) - s=0.0100\n",
      "   8 - L=-72.1083001 - Gamma= 8.9984804 (M=   9) - s=0.0100\n",
      "   9 - L=-56.4100458 - Gamma= 9.9980328 (M=  10) - s=0.0100\n",
      "  10 - L=-43.7536692 - Gamma=10.9974904 (M=  11) - s=0.0100\n",
      "  11 - L=-34.8565873 - Gamma=11.9967415 (M=  12) - s=0.0100\n",
      "  12 - L=-28.7495713 - Gamma=12.9955799 (M=  13) - s=0.0100\n",
      "  13 - L=-22.7015313 - Gamma=13.9944863 (M=  14) - s=0.0100\n",
      "  14 - L=-18.3125930 - Gamma=14.9930570 (M=  15) - s=0.0100\n",
      "  15 - L=-13.9312777 - Gamma=15.9915631 (M=  16) - s=0.0100\n",
      "  16 - L=-11.3605541 - Gamma=16.9891476 (M=  17) - s=0.0100\n",
      "  17 - L=-8.8955713 - Gamma=17.9865585 (M=  18) - s=0.0100\n",
      "  18 - L=-6.7775206 - Gamma=18.9835038 (M=  19) - s=0.0100\n",
      "  19 - L=-4.4708707 - Gamma=19.9805790 (M=  20) - s=0.0100\n",
      "  20 - L=-2.8547028 - Gamma=20.9768175 (M=  21) - s=0.0100\n",
      "  21 - L=-1.5486732 - Gamma=21.9718312 (M=  22) - s=0.0100\n",
      "  22 - L=-0.5967144 - Gamma=22.9653690 (M=  23) - s=0.0100\n",
      "  23 - L= 0.3384057 - Gamma=23.9588068 (M=  24) - s=0.0100\n",
      "  24 - L= 0.9389708 - Gamma=24.9485240 (M=  25) - s=0.0100\n",
      "  25 - L= 1.4716965 - Gamma=25.9372448 (M=  26) - s=0.0100\n",
      "  26 - L= 1.8721882 - Gamma=26.9223016 (M=  27) - s=0.0100\n",
      "  27 - L= 2.2494144 - Gamma=27.9061914 (M=  28) - s=0.0100\n",
      "  28 - L= 2.4384107 - Gamma=28.8769934 (M=  29) - s=0.0100\n",
      "  29 - L= 2.5795406 - Gamma=29.8380678 (M=  30) - s=0.0100\n",
      "  30 - L= 2.6743860 - Gamma=30.7844563 (M=  31) - s=0.0100\n",
      "  31 - L= 2.7452092 - Gamma=31.7179649 (M=  32) - s=0.0100\n",
      "  32 - L= 2.7964335 - Gamma=32.6250977 (M=  33) - s=0.0100\n",
      "  33 - L= 2.8379276 - Gamma=33.5185157 (M=  34) - s=0.0100\n",
      "  34 - L= 2.8725628 - Gamma=34.4005875 (M=  35) - s=0.0100\n",
      "  35 - L= 2.9066801 - Gamma=35.2675310 (M=  36) - s=0.0100\n",
      "  36 - L= 2.9199567 - Gamma=36.0508609 (M=  37) - s=0.0100\n",
      "  37 - L= 2.9296575 - Gamma=36.7928649 (M=  38) - s=0.0100\n",
      "  38 - L= 2.9356463 - Gamma=37.4635828 (M=  39) - s=0.0100\n",
      "  39 - L= 2.9412266 - Gamma=37.4628617 (M=  39) - s=0.0100\n",
      "  40 - L= 2.9455718 - Gamma=37.4633734 (M=  39) - s=0.0100\n",
      "  41 - L= 2.9491033 - Gamma=37.4625359 (M=  39) - s=0.0100\n",
      "  42 - L= 2.9519784 - Gamma=38.0211322 (M=  40) - s=0.0100\n",
      "  43 - L= 2.9541229 - Gamma=38.0787745 (M=  40) - s=0.0100\n",
      "  44 - L= 2.9560412 - Gamma=38.0789053 (M=  40) - s=0.0100\n",
      "  45 - L= 2.9579499 - Gamma=38.0781854 (M=  40) - s=0.0100\n",
      "  46 - L= 2.9598504 - Gamma=38.0789548 (M=  40) - s=0.0100\n",
      "  47 - L= 2.9617495 - Gamma=38.0788991 (M=  40) - s=0.0100\n",
      "  48 - L= 2.9635117 - Gamma=38.0797082 (M=  40) - s=0.0100\n",
      "  49 - L= 2.9645671 - Gamma=38.0798355 (M=  40) - s=0.0100\n",
      "  50 - L= 2.9654664 - Gamma=38.4519122 (M=  41) - s=0.0100\n",
      "  51 - L= 2.9663739 - Gamma=38.8306091 (M=  42) - s=0.0100\n",
      "  52 - L= 2.9672478 - Gamma=38.8321495 (M=  42) - s=0.0100\n",
      "  53 - L= 2.9680675 - Gamma=38.8326841 (M=  42) - s=0.0100\n",
      "  54 - L= 2.9687184 - Gamma=38.8368768 (M=  42) - s=0.0100\n",
      "  55 - L= 2.9693200 - Gamma=38.8016715 (M=  42) - s=0.0100\n",
      "  56 - L= 2.9699511 - Gamma=39.1233814 (M=  43) - s=0.0100\n",
      "  57 - L= 2.9705444 - Gamma=39.1337248 (M=  43) - s=0.0100\n",
      "  58 - L= 2.9709858 - Gamma=39.1253314 (M=  43) - s=0.0100\n",
      "  59 - L= 2.9713436 - Gamma=39.1266576 (M=  43) - s=0.0100\n",
      "  60 - L= 2.9716775 - Gamma=39.1257344 (M=  43) - s=0.0100\n",
      "  61 - L= 2.9719708 - Gamma=39.1308801 (M=  43) - s=0.0100\n",
      "  62 - L= 2.9722464 - Gamma=39.1307694 (M=  43) - s=0.0100\n",
      "  63 - L= 2.9724521 - Gamma=39.1308975 (M=  43) - s=0.0100\n",
      "  64 - L= 2.9726183 - Gamma=39.3208773 (M=  44) - s=0.0100\n",
      "  65 - L= 2.9727999 - Gamma=39.2481136 (M=  44) - s=0.0100\n",
      "  66 - L= 2.9729531 - Gamma=39.2482171 (M=  44) - s=0.0100\n",
      "  67 - L= 2.9731004 - Gamma=39.2494361 (M=  44) - s=0.0100\n",
      "  68 - L= 2.9732462 - Gamma=39.2501061 (M=  44) - s=0.0100\n",
      "  69 - L= 2.9733634 - Gamma=39.2496544 (M=  44) - s=0.0100\n",
      "  70 - L= 2.9734230 - Gamma=39.2505956 (M=  44) - s=0.0100\n",
      "  71 - L= 2.9734821 - Gamma=39.2506828 (M=  44) - s=0.0100\n",
      "  72 - L= 2.9735357 - Gamma=39.2496399 (M=  44) - s=0.0100\n",
      "  73 - L= 2.9735839 - Gamma=39.2596364 (M=  44) - s=0.0100\n",
      "  74 - L= 2.9736206 - Gamma=39.2600770 (M=  44) - s=0.0100\n",
      "  75 - L= 2.9736554 - Gamma=39.1946185 (M=  44) - s=0.0100\n",
      "  76 - L= 2.9736828 - Gamma=39.2788803 (M=  45) - s=0.0100\n",
      "  77 - L= 2.9737215 - Gamma=39.2271851 (M=  45) - s=0.0100\n",
      "  78 - L= 2.9737647 - Gamma=39.3315399 (M=  46) - s=0.0100\n",
      "  79 - L= 2.9738005 - Gamma=39.2949075 (M=  46) - s=0.0100\n",
      "  80 - L= 2.9738278 - Gamma=39.2831009 (M=  46) - s=0.0100\n",
      "  81 - L= 2.9738466 - Gamma=39.2865058 (M=  46) - s=0.0100\n",
      "  82 - L= 2.9738704 - Gamma=39.2270945 (M=  46) - s=0.0100\n",
      "  83 - L= 2.9738894 - Gamma=39.2833892 (M=  46) - s=0.0100\n",
      "  84 - L= 2.9739027 - Gamma=39.2769824 (M=  46) - s=0.0100\n",
      "  85 - L= 2.9739162 - Gamma=39.3137699 (M=  46) - s=0.0100\n",
      "  86 - L= 2.9739285 - Gamma=39.2822582 (M=  46) - s=0.0100\n",
      "  87 - L= 2.9739522 - Gamma=39.3572649 (M=  47) - s=0.0100\n",
      "  88 - L= 2.9739656 - Gamma=39.3555036 (M=  47) - s=0.0100\n",
      "  89 - L= 2.9739782 - Gamma=39.3414438 (M=  47) - s=0.0100\n",
      "  90 - L= 2.9739943 - Gamma=39.2888926 (M=  47) - s=0.0100\n",
      "  91 - L= 2.9740086 - Gamma=39.2637510 (M=  47) - s=0.0100\n",
      "  92 - L= 2.9740214 - Gamma=39.3013642 (M=  47) - s=0.0100\n",
      "  93 - L= 2.9740332 - Gamma=39.2686163 (M=  47) - s=0.0100\n",
      "  94 - L= 2.9740503 - Gamma=39.3334272 (M=  48) - s=0.0100\n",
      "  95 - L= 2.9740602 - Gamma=39.3291668 (M=  48) - s=0.0100\n",
      "  96 - L= 2.9740726 - Gamma=39.2798521 (M=  48) - s=0.0100\n",
      "  97 - L= 2.9740918 - Gamma=39.3493876 (M=  49) - s=0.0100\n",
      "  98 - L= 2.9741067 - Gamma=39.4047922 (M=  49) - s=0.0100\n",
      "  99 - L= 2.9741320 - Gamma=39.3531350 (M=  49) - s=0.0100\n",
      " 100 - L= 2.9741538 - Gamma=39.2833023 (M=  49) - s=0.0100\n",
      " 101 - L= 2.9741886 - Gamma=39.3731923 (M=  50) - s=0.0100\n",
      " 102 - L= 2.9742023 - Gamma=39.3193481 (M=  49) - s=0.0100\n",
      " 103 - L= 2.9742528 - Gamma=39.4012691 (M=  49) - s=0.0100\n",
      " 104 - L= 2.9742957 - Gamma=39.4962412 (M=  49) - s=0.0100\n",
      " 105 - L= 2.9743301 - Gamma=39.4294438 (M=  49) - s=0.0100\n",
      " 106 - L= 2.9743718 - Gamma=39.3820012 (M=  49) - s=0.0100\n",
      " 107 - L= 2.9744057 - Gamma=39.3733791 (M=  49) - s=0.0100\n",
      " 108 - L= 2.9744497 - Gamma=39.4763664 (M=  50) - s=0.0100\n",
      " 109 - L= 2.9744777 - Gamma=39.5309899 (M=  50) - s=0.0100\n",
      " 110 - L= 2.9745042 - Gamma=39.5346937 (M=  50) - s=0.0100\n",
      " 111 - L= 2.9745242 - Gamma=39.4789448 (M=  50) - s=0.0100\n",
      " 112 - L= 2.9745531 - Gamma=39.5503416 (M=  50) - s=0.0100\n",
      " 113 - L= 2.9745814 - Gamma=39.4662148 (M=  50) - s=0.0100\n",
      " 114 - L= 2.9746033 - Gamma=39.5320070 (M=  50) - s=0.0100\n",
      " 115 - L= 2.9746071 - Gamma=39.5184843 (M=  49) - s=0.0100\n",
      " 116 - L= 2.9746361 - Gamma=39.4848273 (M=  49) - s=0.0100\n",
      " 117 - L= 2.9746562 - Gamma=39.4487240 (M=  49) - s=0.0100\n",
      " 118 - L= 2.9746779 - Gamma=39.5148117 (M=  49) - s=0.0100\n",
      " 119 - L= 2.9747067 - Gamma=39.4419009 (M=  49) - s=0.0100\n",
      " 120 - L= 2.9747357 - Gamma=39.5122356 (M=  49) - s=0.0100\n",
      " 121 - L= 2.9747801 - Gamma=39.5739591 (M=  49) - s=0.0100\n",
      " 122 - L= 2.9748142 - Gamma=39.4918693 (M=  48) - s=0.0100\n",
      " 123 - L= 2.9748342 - Gamma=39.4928696 (M=  48) - s=0.0100\n",
      " 124 - L= 2.9748529 - Gamma=39.4985071 (M=  48) - s=0.0100\n",
      " 125 - L= 2.9748713 - Gamma=39.4962197 (M=  48) - s=0.0100\n",
      " 126 - L= 2.9748883 - Gamma=39.4884431 (M=  48) - s=0.0100\n",
      " 127 - L= 2.9749046 - Gamma=39.4712250 (M=  48) - s=0.0100\n",
      " 128 - L= 2.9749209 - Gamma=39.5210952 (M=  48) - s=0.0100\n",
      " 129 - L= 2.9749423 - Gamma=39.4566931 (M=  47) - s=0.0100\n",
      " 130 - L= 2.9749699 - Gamma=39.5251260 (M=  47) - s=0.0100\n",
      " 131 - L= 2.9749939 - Gamma=39.4820914 (M=  47) - s=0.0100\n",
      " 132 - L= 2.9750203 - Gamma=39.4049856 (M=  47) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 133 - L= 2.9750462 - Gamma=39.4845255 (M=  48) - s=0.0100\n",
      " 134 - L= 2.9750661 - Gamma=39.5358484 (M=  48) - s=0.0100\n",
      " 135 - L= 2.9750903 - Gamma=39.4632014 (M=  47) - s=0.0100\n",
      " 136 - L= 2.9751176 - Gamma=39.5251347 (M=  47) - s=0.0100\n",
      " 137 - L= 2.9751503 - Gamma=39.4982343 (M=  47) - s=0.0100\n",
      " 138 - L= 2.9751812 - Gamma=39.4597593 (M=  47) - s=0.0100\n",
      " 139 - L= 2.9752343 - Gamma=39.5616506 (M=  47) - s=0.0100\n",
      " 140 - L= 2.9752717 - Gamma=39.5017486 (M=  47) - s=0.0100\n",
      " 141 - L= 2.9753064 - Gamma=39.5645439 (M=  47) - s=0.0100\n",
      " 142 - L= 2.9753346 - Gamma=39.6149057 (M=  47) - s=0.0100\n",
      " 143 - L= 2.9753662 - Gamma=39.5719567 (M=  47) - s=0.0100\n",
      " 144 - L= 2.9754023 - Gamma=39.6262832 (M=  47) - s=0.0100\n",
      " 145 - L= 2.9754307 - Gamma=39.6929822 (M=  47) - s=0.0100\n",
      " 146 - L= 2.9754598 - Gamma=39.6343051 (M=  47) - s=0.0100\n",
      " 147 - L= 2.9754895 - Gamma=39.6449043 (M=  47) - s=0.0100\n",
      " 148 - L= 2.9755165 - Gamma=39.6009412 (M=  47) - s=0.0100\n",
      " 149 - L= 2.9755528 - Gamma=39.6523318 (M=  47) - s=0.0100\n",
      " 150 - L= 2.9755788 - Gamma=39.6397443 (M=  47) - s=0.0100\n",
      " 151 - L= 2.9756014 - Gamma=39.6858641 (M=  47) - s=0.0100\n",
      " 152 - L= 2.9756309 - Gamma=39.7473934 (M=  47) - s=0.0100\n",
      " 153 - L= 2.9756668 - Gamma=39.7158386 (M=  47) - s=0.0100\n",
      " 154 - L= 2.9756968 - Gamma=39.6498257 (M=  47) - s=0.0100\n",
      " 155 - L= 2.9757306 - Gamma=39.5952747 (M=  47) - s=0.0100\n",
      " 156 - L= 2.9757590 - Gamma=39.6364027 (M=  47) - s=0.0100\n",
      " 157 - L= 2.9758060 - Gamma=39.5425161 (M=  47) - s=0.0100\n",
      " 158 - L= 2.9758464 - Gamma=39.6072212 (M=  47) - s=0.0100\n",
      " 159 - L= 2.9758870 - Gamma=39.6628356 (M=  47) - s=0.0100\n",
      " 160 - L= 2.9759223 - Gamma=39.5829755 (M=  47) - s=0.0100\n",
      " 161 - L= 2.9759619 - Gamma=39.5940250 (M=  47) - s=0.0100\n",
      " 162 - L= 2.9759972 - Gamma=39.6355170 (M=  47) - s=0.0100\n",
      " 163 - L= 2.9760493 - Gamma=39.5584338 (M=  47) - s=0.0100\n",
      " 164 - L= 2.9760854 - Gamma=39.6131244 (M=  47) - s=0.0100\n",
      " 165 - L= 2.9761258 - Gamma=39.5147258 (M=  47) - s=0.0100\n",
      " 166 - L= 2.9761571 - Gamma=39.4307246 (M=  47) - s=0.0100\n",
      " 167 - L= 2.9761954 - Gamma=39.4791519 (M=  47) - s=0.0100\n",
      " 168 - L= 2.9762316 - Gamma=39.5170871 (M=  47) - s=0.0100\n",
      " 169 - L= 2.9762415 - Gamma=39.4786249 (M=  46) - s=0.0100\n",
      " 170 - L= 2.9762831 - Gamma=39.4401570 (M=  46) - s=0.0100\n",
      " 171 - L= 2.9763043 - Gamma=39.3681148 (M=  45) - s=0.0100\n",
      " 172 - L= 2.9763448 - Gamma=39.2908519 (M=  45) - s=0.0100\n",
      " 173 - L= 2.9764126 - Gamma=39.3569078 (M=  45) - s=0.0100\n",
      " 174 - L= 2.9764602 - Gamma=39.4122864 (M=  45) - s=0.0100\n",
      " 175 - L= 2.9764985 - Gamma=39.3952573 (M=  45) - s=0.0100\n",
      " 176 - L= 2.9765432 - Gamma=39.3031636 (M=  45) - s=0.0100\n",
      " 177 - L= 2.9765903 - Gamma=39.3417219 (M=  45) - s=0.0100\n",
      " 178 - L= 2.9766412 - Gamma=39.3529390 (M=  45) - s=0.0100\n",
      " 179 - L= 2.9766832 - Gamma=39.3513818 (M=  45) - s=0.0100\n",
      " 180 - L= 2.9767197 - Gamma=39.3428456 (M=  45) - s=0.0100\n",
      " 181 - L= 2.9767541 - Gamma=39.3382763 (M=  45) - s=0.0100\n",
      " 182 - L= 2.9767950 - Gamma=39.2760632 (M=  45) - s=0.0100\n",
      " 183 - L= 2.9768336 - Gamma=39.3712735 (M=  46) - s=0.0100\n",
      " 184 - L= 2.9768613 - Gamma=39.3691849 (M=  46) - s=0.0100\n",
      " 185 - L= 2.9768892 - Gamma=39.2885234 (M=  46) - s=0.0100\n",
      " 186 - L= 2.9769239 - Gamma=39.3308427 (M=  46) - s=0.0100\n",
      " 187 - L= 2.9769314 - Gamma=39.2960932 (M=  45) - s=0.0100\n",
      " 188 - L= 2.9769641 - Gamma=39.3364895 (M=  45) - s=0.0100\n",
      " 189 - L= 2.9769982 - Gamma=39.2973979 (M=  45) - s=0.0100\n",
      " 190 - L= 2.9770546 - Gamma=39.4039876 (M=  46) - s=0.0100\n",
      " 191 - L= 2.9771002 - Gamma=39.4375950 (M=  46) - s=0.0100\n",
      " 192 - L= 2.9771474 - Gamma=39.3359474 (M=  46) - s=0.0100\n",
      " 193 - L= 2.9772011 - Gamma=39.2559162 (M=  46) - s=0.0100\n",
      " 194 - L= 2.9772603 - Gamma=39.1973154 (M=  46) - s=0.0100\n",
      " 195 - L= 2.9772747 - Gamma=39.1403702 (M=  45) - s=0.0100\n",
      " 196 - L= 2.9773541 - Gamma=39.2314674 (M=  45) - s=0.0100\n",
      " 197 - L= 2.9774174 - Gamma=39.3305941 (M=  45) - s=0.0100\n",
      " 198 - L= 2.9774579 - Gamma=39.2394496 (M=  44) - s=0.0100\n",
      " 199 - L= 2.9775661 - Gamma=39.3021781 (M=  44) - s=0.0100\n",
      " 200 - L= 2.9776906 - Gamma=39.3701543 (M=  44) - s=0.0100\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 0s - loss: 0.7805 - acc: 0.6308 - val_loss: 0.6691 - val_acc: 0.6111\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 0s - loss: 0.6912 - acc: 0.6308 - val_loss: 0.6684 - val_acc: 0.6111\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 0s - loss: 0.6716 - acc: 0.6308 - val_loss: 0.6682 - val_acc: 0.6111\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 0s - loss: 0.7058 - acc: 0.6308 - val_loss: 0.6691 - val_acc: 0.6111\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 0s - loss: 0.6690 - acc: 0.6308 - val_loss: 0.6689 - val_acc: 0.6111\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s - loss: 0.6569 - acc: 0.6212 - val_loss: 0.6645 - val_acc: 0.6471\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s - loss: 0.6990 - acc: 0.6212 - val_loss: 0.6640 - val_acc: 0.6471\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s - loss: 0.6749 - acc: 0.6212 - val_loss: 0.6522 - val_acc: 0.6471\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s - loss: 0.6801 - acc: 0.6212 - val_loss: 0.6520 - val_acc: 0.6471\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s - loss: 0.6747 - acc: 0.6212 - val_loss: 0.6516 - val_acc: 0.6471\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.6674 - acc: 0.6269 - val_loss: 0.6598 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.6658 - acc: 0.6269 - val_loss: 0.6597 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.6759 - acc: 0.6269 - val_loss: 0.6576 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.6751 - acc: 0.6269 - val_loss: 0.6620 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.6685 - acc: 0.6269 - val_loss: 0.6543 - val_acc: 0.6250\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.6533 - acc: 0.6269 - val_loss: 0.6723 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.6734 - acc: 0.6269 - val_loss: 0.6665 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.6642 - acc: 0.6269 - val_loss: 0.6615 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.6691 - acc: 0.6269 - val_loss: 0.6615 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.6757 - acc: 0.6269 - val_loss: 0.6650 - val_acc: 0.6250\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.7152 - acc: 0.6269 - val_loss: 0.6574 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.6758 - acc: 0.6269 - val_loss: 0.6627 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.6633 - acc: 0.6269 - val_loss: 0.6536 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.6586 - acc: 0.6269 - val_loss: 0.6533 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.6563 - acc: 0.6269 - val_loss: 0.6380 - val_acc: 0.6250\n",
      "MODEL: DNN accuracy:  0.626506024096 +/-: 0.000139229253418\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 22215, 1) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 2s - loss: 1.9467 - acc: 0.6000 - val_loss: 0.7258 - val_acc: 0.6111\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s - loss: 0.7119 - acc: 0.6154 - val_loss: 0.6330 - val_acc: 0.6111\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 2s - loss: 0.5346 - acc: 0.8308 - val_loss: 2.5953 - val_acc: 0.6111\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 2s - loss: 0.6853 - acc: 0.7692 - val_loss: 0.4700 - val_acc: 0.6111\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 1s - loss: 0.2773 - acc: 0.9231 - val_loss: 0.4525 - val_acc: 0.6111\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 2s - loss: 0.2356 - acc: 0.9242 - val_loss: 0.0467 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 2s - loss: 0.1900 - acc: 0.9394 - val_loss: 0.0349 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 2s - loss: 0.1371 - acc: 0.9545 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 2s - loss: 0.1221 - acc: 0.9545 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 2s - loss: 0.0454 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 2s - loss: 0.0770 - acc: 0.9701 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s - loss: 0.0327 - acc: 0.9851 - val_loss: 2.1472 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s - loss: 0.1942 - acc: 0.9701 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 2s - loss: 0.0334 - acc: 0.9851 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 2s - loss: 0.0132 - acc: 1.0000 - val_loss: 4.2713e-04 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 2s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.2311e-04 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s - loss: 0.0427 - acc: 0.9851 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s - loss: 0.0162 - acc: 1.0000 - val_loss: 8.4550e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 2s - loss: 0.0048 - acc: 1.0000 - val_loss: 6.6527e-05 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 2s - loss: 0.0034 - acc: 1.0000 - val_loss: 1.3030e-04 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 2s - loss: 3.3299e-04 - acc: 1.0000 - val_loss: 1.3947e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s - loss: 5.6738e-04 - acc: 1.0000 - val_loss: 2.1698e-05 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s - loss: 0.0470 - acc: 0.9701 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 2s - loss: 0.0136 - acc: 1.0000 - val_loss: 1.3412e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 2s - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5333e-04 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.915662650602 +/-: 0.0256850695957\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "METHOD_LIST = ['ExtraTrees', 'RandomForest', 'GBM', 'AdaBoost', 'LR', 'SVM', 'MLNN', 'XGB'] # XGB\n",
    "Runs = []\n",
    "nruns = 2\n",
    "SCALER = \"minmax\"\n",
    "GROUPING = \"mean\"\n",
    "DIM_TYPE = None # \"LDA\" # \"PCA\" # \"PLS\"\n",
    "DIM_NUM = 1000\n",
    "Results = None\n",
    "ACC = pd.DataFrame()\n",
    "Rocket.VIZ = False\n",
    "for i in range(0, nruns):\n",
    "    Rocket.SEED = np.random.randint(0,10000)\n",
    "    MODELS  = []\n",
    "    for idx, METHOD in enumerate(METHOD_LIST):\n",
    "        preds, class_model, accuracy = Rocket.classify_treatment(model_type = METHOD, \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "        MODELS.append({'method': METHOD, 'model': class_model})\n",
    "        ACC = ACC.append(accuracy, ignore_index= True)\n",
    "        preds = [pred_[1]for pred_ in preds]\n",
    "        #len(Rocket.DATA_merged[Rocket.DATA_merged[\"array-batch\"].isin([\"cohort 1\", \"cohort 2\", \"JB\", \"IA\", \"ALL-10\"])])\n",
    "        if Results is None:\n",
    "            Results = Rocket.DATA_merged_processed.copy()\n",
    "        Results['pred'] = preds\n",
    "        Results['method'] = METHOD\n",
    "        if idx == 0:\n",
    "            AllResults = Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]]\n",
    "        else:\n",
    "            AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], \n",
    "                                                    'pred', \n",
    "                                                    'method', \n",
    "                                                    Rocket.MODEL_PARAMETERS['target']]], \n",
    "                                      ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"RVM\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': METHOD, 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"RVM\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]], ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"DNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': METHOD, 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"DNN\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]],\n",
    "                                   ignore_index = True)\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"CNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': METHOD, 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"CNN\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]],\n",
    "                                   ignore_index = True)\n",
    "    \n",
    "    \n",
    "    AllResults[Rocket.MODEL_PARAMETERS['ID']] = AllResults[Rocket.MODEL_PARAMETERS['ID']].astype('str')\n",
    "    AllResults = AllResults.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "    #AllResults[AllResults['Treatment_risk_group_in_ALL10'].notnull()]\n",
    "    ####\n",
    "    ####\n",
    "    Runs.append(AllResults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on average: 0.8806133625410731 +- 0.004423644581547632, median: 0.9156626506024096+-0.002201458800000379\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "         acc model       var\n",
      "0   0.915663    ET  0.000909\n",
      "1   0.891566    RF  0.002421\n",
      "2   0.915663   GBM  0.000909\n",
      "3   0.927711   ADA  0.003412\n",
      "4   0.939759    LR  0.001465\n",
      "5   0.939759   SVM  0.001465\n",
      "6   0.879518  MLNN  0.015516\n",
      "7   0.927711   XGB  0.002127\n",
      "8   0.771084   RVM  0.004871\n",
      "9   0.626506   DNN  0.000139\n",
      "10  0.951807   CNN  0.003190\n",
      "11  0.939759    ET  0.003148\n",
      "12  0.915663    RF  0.000791\n",
      "13  0.903614   GBM  0.002276\n",
      "14  0.927711   ADA  0.003412\n",
      "15  0.939759    LR  0.001465\n",
      "16  0.939759   SVM  0.001465\n",
      "17  0.879518  MLNN  0.015516\n",
      "18  0.927711   XGB  0.002127\n",
      "19  0.771084   RVM  0.004871\n",
      "20  0.626506   DNN  0.000139\n",
      "21  0.915663   CNN  0.025685\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on average: {} +- {}, median: {}+-{}\".format(ACC.mean()[0], ACC.mean()[1], ACC.median()[0], ACC.median()[1]))\n",
    "print(\"+\"*40)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "###########\n",
    "##Runs.append(AllResults)\n",
    "final_df = pandas.DataFrame()\n",
    "for idx, df in enumerate(Runs):\n",
    "    df['run'] = idx\n",
    "    final_df = final_df.append(df, ignore_index = True)\n",
    "#final_df = final_df.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "final_df['pred']= pandas.to_numeric(final_df['pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df_agg = final_df.groupby([Rocket.MODEL_PARAMETERS['ID']], as_index=True).agg({'pred': [numpy.mean, numpy.median, numpy.std]})['pred']\n",
    "\n",
    "final_df.to_csv(\"out/patient_results_\"+Rocket.SET_NAME+\".csv\")\n",
    "final_df_agg.to_csv(\"out/patient_results_agg_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop through models..\n",
    "### Tree weights\n",
    "top_genomes_weights = pandas.DataFrame()\n",
    "#top_genomes.index = Rocket.DATA_merged_processed\n",
    "for mod in MODELS:\n",
    "    if(mod['method'] in ['RandomForest', 'GBM', 'AdaBoost', 'ExtraTrees']): # RF, ET, GBM, ADA\n",
    "        top_genomes_weights[mod['method']]=mod['model'].feature_importances_\n",
    "        # column normalise\n",
    "        top_genomes_weights[mod['method']] = top_genomes_weights[mod['method']]/top_genomes_weights[mod['method']].max()\n",
    "        \n",
    "top_genomes_weights.index = Rocket.DATA_merged_processed.drop(['target', 'ID'], axis=1).columns\n",
    "#top_genomes['ALL'] = top_genomes.sum(axis=1)\n",
    "top_genomes_weights['MED'] = top_genomes_weights.median(axis=1)\n",
    "top_genomes_weights = top_genomes_weights.sort_values(by='MED', ascending=False)\n",
    "       \n",
    "### Coefficients\n",
    "top_genomes_coeffs = pandas.DataFrame()\n",
    "for mod in MODELS:\n",
    "    if(mod['method'] in ['LR', 'SVM']):\n",
    "        top_genomes_coeffs[mod['method']] = mod['model'].coef_[0,:]\n",
    "        top_genomes_coeffs[mod['method']] = top_genomes_coeffs[mod['method']]/top_genomes_coeffs[mod['method']].max() #\\\n",
    "                                                               #  -top_genomes[mod['method']].min())\n",
    "                                                                 #+numpy.abs(top_genomes[mod['method']].min())\n",
    "top_genomes_coeffs.index = Rocket.DATA_merged_processed.drop(['target', 'ID'], axis=1).columns\n",
    "#top_genomes['ALL'] = top_genomes.sum(axis=1)\n",
    "top_genomes_coeffs['MEAN'] = top_genomes_coeffs.mean(axis=1)\n",
    "top_genomes_coeffs = top_genomes_coeffs.sort_values(by='MEAN', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genomes_coeffs.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/coeffs_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genomes_weights.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/weights_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF9 = top_genomes_weights['RandomForest'].quantile(q=0.9)\n",
    "GBM9 = top_genomes_weights['GBM'].quantile(q=0.9)\n",
    "ADA9 = top_genomes_weights['AdaBoost'].quantile(q=0.9)\n",
    "ET9 = top_genomes_weights['ExtraTrees'].quantile(q=0.9)\n",
    "Overlapping_genomes = set(top_genomes_weights.loc[top_genomes_weights['RandomForest']>RF9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['GBM']>GBM9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['AdaBoost']>ADA9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['ExtraTrees']>ET9].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import*\n",
    "#from scipy.dspatial.distance import cosine\n",
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import cdist\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TransPosed = Rocket.DATA_all_samples.T # all microarrays, may be multiple per patient versus all probesets, may be multiple per genome\n",
    "Normal = Rocket.DATA_merged_processed.loc[:, (Rocket.DATA_merged_processed.columns !='target') & \n",
    "                                             (Rocket.DATA_merged_processed.columns !='ID')]\n",
    "#AllNormal = Rocket.DATA_merged\n",
    "#probeset_weights = Rocket.get_probeset_weights(method = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 9827_corr2.CEL, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'cosine', normalised = True, inflation = 2, minkowski_dim=1)\n",
    "##### apply Markov clustering\n",
    "#######################\n",
    "# non-distributed, non-sparse version, only for small-sized problems (N is order 1000)\n",
    "e = 2\n",
    "r = 2 \n",
    "epsilon = 1e-7\n",
    "convergence = 0.001\n",
    "num_iter = 10\n",
    "Orientation = 'col' # columnwise or rowwise\n",
    "\n",
    "# add loop\n",
    "def add_loop(df_matrix, value=0): \n",
    "    for i in df_matrix.index:\n",
    "        df_matrix.loc[i, i] = value\n",
    "    return df_matrix\n",
    "patient_sim = add_loop(patient_sim, 1)\n",
    "patient_sim = patient_sim - epsilon\n",
    "\n",
    "def normalise(sim, type = 'col'):\n",
    "    if(type == 'col'):\n",
    "        # column normalisation\n",
    "        for variable in sim.keys():\n",
    "            col_vec = sim[variable]\n",
    "            sum_val = sum([p for p in col_vec])\n",
    "            sim[variable] = sim[variable]/sum_val\n",
    "    elif (type == 'row'):\n",
    "        # row normalisation\n",
    "        for variable in sim.keys():\n",
    "            row_vec = sim.loc[variable, :]\n",
    "            sum_val = sum([p for p in row_vec])\n",
    "            sim.loc[variable,:] = sim.loc[variable,:]/sum_val\n",
    "    return sim\n",
    "\n",
    "# step E: expansion, get the nth power of the matrix\n",
    "def expansion(sim):\n",
    "    X = numpy.array(sim)\n",
    "    VarList = sim.keys()\n",
    "    if e == 1:\n",
    "        return sim\n",
    "    elif e > 1:        \n",
    "        return pandas.DataFrame(numpy.linalg.matrix_power(X, e), index = VarList, columns = VarList)\n",
    "     \n",
    "# step I: inflation, per column raise by rth power and column normalise\n",
    "def inflation(sim, type = 'col'):    \n",
    "    if type == 'col':\n",
    "        Axis = 0\n",
    "    elif type == 'row':\n",
    "        Axis = 1\n",
    "    return sim.apply(lambda x: x**r/sum(x**r), axis = Axis)\n",
    "\n",
    "# remove weak connections, values < epsilon\n",
    "def clean(sim):\n",
    "    return sim.applymap(lambda x:0 if x<epsilon else x)\n",
    "    \n",
    "def difference(old, new):\n",
    "    # relative zeroes over entire array\n",
    "    #return (new.apply(lambda x: numpy.ceil(x-epsilon)) - old.apply(lambda x: numpy.ceil(x-epsilon))).sum().sum()/len(old)**2    \n",
    "    return abs(new - old).sum().sum()/len(old)**2    \n",
    "\n",
    "#patient_sim = normalise(patient_sim, type = Orientation)\n",
    "_sim_a = patient_sim\n",
    "for i in range(0,num_iter):\n",
    "    # repeat E and I until convergence, the row-wise elements form the clusters.\n",
    "    _sim_b = clean(inflation(expansion(_sim_a), type = Orientation))\n",
    "    _sim_a = normalise(_sim_a, type = Orientation)\n",
    "    #if ((difference(_sim_a, _sim_b)) < convergence) & (i>0):\n",
    "    #    print(difference(_sim_a, _sim_b))\n",
    "    #    print(\"CONVERGED after \", i, \" iterations\")\n",
    "    #    break;\n",
    "    _sim_a = _sim_b\n",
    "\n",
    "result_mcl = clean(_sim_b)\n",
    "result_mcl.loc[result_mcl.loc['9827_corr2.CEL',:]>epsilon, '9827_corr2.CEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 patient clusters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'pearson', normalised = False, inflation=1, minkowski_dim=1)\n",
    "##### apply Affinity Propagation\n",
    "#######################\n",
    "X = numpy.array(patient_sim)\n",
    "af = AffinityPropagation(preference=-10).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "patient_clusters = patient_sim.keys()[cluster_centers_indices].values\n",
    "patient_cluster_members = af.labels_\n",
    "print(\"There are {} patient clusters\".format(n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AggResults = Rocket.DATA_merged\n",
    "AggResults = _helpers._preprocess(AggResults, Rclass = Rocket)\n",
    "#AggResults = _helpers._group_patients(AggResults, method = 'mean')\n",
    "AggResults['cluster_ap'] = patient_cluster_members\n",
    "\n",
    "#AggResults.groupby(['Treatment risk group in ALL10', 'cluster_ap']).agg({'Microarray file': pandas.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "AggResults['FU_RFS'] = pandas.to_numeric(AggResults['FU_RFS'])\n",
    "AggResults['FU_EFS'] = pandas.to_numeric(AggResults['FU_EFS'])\n",
    "AggResults['FU_OS'] = pandas.to_numeric(AggResults['FU_OS'])\n",
    "AggResults['WhiteBloodCellcount'] = pandas.to_numeric(AggResults['WhiteBloodCellcount'])\n",
    "AggResults['Age'] = pandas.to_numeric(AggResults['Age'])\n",
    "AggResults['Gender'] = pandas.to_numeric(AggResults['Gender'])\n",
    "AggResults['code_RFS']= pandas.to_numeric(AggResults['code_RFS'])\n",
    "AggResults['code_EFS']= pandas.to_numeric(AggResults['code_EFS'])\n",
    "AggResults['code_OS']= pandas.to_numeric(AggResults['code_OS'])\n",
    "\n",
    "AggResults['mutations_NOTCH_pathway'] = pandas.to_numeric(AggResults['mutations_NOTCH_pathway'])\n",
    "AggResults['mutations_PTEN_AKT_pathway'] = pandas.to_numeric(AggResults['mutations_PTEN_AKT_pathway'])\n",
    "AggResults['mutations_IL7R_pathway'] = pandas.to_numeric(AggResults['mutations_IL7R_pathway'])\n",
    "#AggResults.replace(to_replace=9999, value=0.5, inplace=True)\n",
    "AggResults[['mutations_NOTCH_pathway', \n",
    "            'mutations_PTEN_AKT_pathway', \n",
    "            'mutations_IL7R_pathway']] = AggResults[['mutations_NOTCH_pathway', \n",
    "                                                    'mutations_PTEN_AKT_pathway', \n",
    "                                                    'mutations_IL7R_pathway']].replace([9999],[numpy.nan],\n",
    "                                                                                       inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "AggResults['comb_mutations_NOTCH_IL7R'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_NOTCH_PTEN'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_PTEN_AKT_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN'] =  AggResults['mutations_PTEN_AKT_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN_NOTCH'] =  AggResults['mutations_PTEN_AKT_pathway']\\\n",
    "                                                + AggResults['mutations_IL7R_pathway']\\\n",
    "                                                + AggResults['mutations_NOTCH_pathway']\n",
    "\n",
    "\n",
    "patient_count = AggResults.groupby(['cluster_ap']).agg({'labnr_patient': pandas.Series.nunique})\n",
    "Clustered_by_patients_whitebloodcells = AggResults[AggResults['WhiteBloodCellcount'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'WhiteBloodCellcount': numpy.mean,\n",
    "    'Age': numpy.mean, \n",
    "    'Gender': numpy.mean})\n",
    "\n",
    "# Cancer_gene\n",
    "# Treatment_protocol\n",
    "# Treatment_risk_group_in_ALL_10\n",
    "\n",
    "Clustered_by_patients_CODE = AggResults.groupby(['cluster_ap']).agg(\n",
    "    {'code_RFS': numpy.mean, \n",
    "     'code_EFS': numpy.mean,\n",
    "     'code_OS': numpy.mean})\n",
    "\n",
    "Clustered_by_patients_FU_RFS = AggResults[AggResults['FU_RFS'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'FU_RFS': numpy.median, \n",
    "     'FU_EFS': numpy.median,\n",
    "     'FU_OS': numpy.median})\n",
    "Clustered_by_patients_NotchPath = AggResults[AggResults['mutations_NOTCH_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_NOTCH_pathway': numpy.mean})\n",
    "Clustered_by_patients_IL7RPath = AggResults[AggResults['mutations_IL7R_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_IL7R_pathway': numpy.mean})\n",
    "Clustered_by_patients_PTENAKTPath = AggResults[AggResults['mutations_PTEN_AKT_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_PTEN_AKT_pathway': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_IL7R = AggResults[AggResults['comb_mutations_NOTCH_IL7R'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_IL7R': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_PTEN = AggResults[AggResults['comb_mutations_NOTCH_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN = AggResults[AggResults['comb_mutations_IL7R_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN_NOTCH = AggResults[AggResults['comb_mutations_IL7R_PTEN_NOTCH'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN_NOTCH': numpy.mean})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_agg = pandas.merge(Clustered_by_patients_whitebloodcells, Clustered_by_patients_CODE, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN_NOTCH, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_IL7R, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_PTEN, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_FU_RFS, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_IL7RPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_NotchPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_PTENAKTPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, patient_count, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Cluster centers:\",patient_sim.keys()[cluster_centers_indices].values)\n",
    "print(patient_cluster_members)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    class_members = patient_cluster_members == k\n",
    "    cluster_center = X[cluster_centers_indices[k]]\n",
    "    plt.plot(X[class_members, 0], X[class_members, 1], col + '.', \n",
    "             label = patient_sim.keys()[cluster_centers_indices[k]])\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in X[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.title('Estimated number of clusters from Affinity Propagation: %d' % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### CREATE graph from similarity matrix\n",
    "##################\n",
    "# nodes\n",
    "VarList = TransPosed.keys()\n",
    "nodes = []\n",
    "node_index = 0\n",
    "for patient_name in VarList:\n",
    "    nodes.append((node_index, {'name': patient_name}))\n",
    "    node_index = node_index + 1\n",
    "\n",
    "edges = []\n",
    "# edges\n",
    "patient_sim = patient_similarity(Normal, sim_type = 'pearson', normalised = True, inflation=2)\n",
    "node_index_x = 0\n",
    "node_index_y = 0\n",
    "for patient_name_x in VarList:\n",
    "    for patient_name_y in VarList:        \n",
    "        edges.append((node_index_x, node_index_y, patient_sim.iloc[node_index_x, node_index_y]))\n",
    "        node_index_y = node_index_y + 1\n",
    "    node_index_x = node_index_x + 1\n",
    "    node_index_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(edges, weight = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:138: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  plt.hold(b)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.\n",
      "  warnings.warn(self.msg_depr_set % key)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0\n",
      "  warnings.warn(\"axes.hold is deprecated, will be removed in 3.0\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAFCCAYAAABSJMy8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f31beac128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### apply Spring-force\n",
    "#######################\n",
    "pos = nx.spring_layout(G, k = None, dim = 3, scale = 1.0)\n",
    "nx.draw_spring(G, k = 30, dim = 2, scale = 1.0, iterations =1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### APPLY community detector\n",
    "# maximize betweenness and modularity\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### LOAD IN DATA\n",
    "###################\n",
    "# https://stackoverflow.com/questions/14529838/apply-multiple-functions-to-multiple-groupby-columns\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
