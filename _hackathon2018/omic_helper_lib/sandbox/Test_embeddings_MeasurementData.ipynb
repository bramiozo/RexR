{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings to test\n",
    "\n",
    "* UMAP\n",
    "* t-SNE\n",
    "* Parametric UMAP (part of UMAP)\n",
    "* DenseMap (part of UMAP)\n",
    "* [PacMap](https://github.com/YingfanWang/PaCMAP)\n",
    "* [TriMap](https://github.com/eamid/trimap)\n",
    "* PCA\n",
    "* Laplacian eigenmaps\n",
    "* MDS\n",
    "* Isomap\n",
    "* [MDE](https://github.com/cvxgrp/pymde)\n",
    "* [PHATE](https://github.com/KrishnaswamyLab/PHATE)\n",
    "* ForceAtlas2\n",
    "* dbMAP\n",
    "\n",
    "\n",
    "# Experiments\n",
    "\n",
    "* distance/distance-rank preservation with varying ```n_neighbors```, ```n_components``` and ```min_dist```, measured with Pearson's corr.\n",
    "* hierarchical embedding: original -> 1000d -> 100d -> 2d\n",
    "* negative test: does it magically create clusters? Test using a high dimensional Gaussian\n",
    "\n",
    "\n",
    "Metrics:\n",
    "* Spearman rank correlation between samples\n",
    "* Pearson correlation of distances\n",
    "* Distance correlation of distances\n",
    "* Average Jaccard distance\n",
    "* kNN accuracy and recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport omic_helpers\n",
    "%matplotlib inline\n",
    "\n",
    "from omic_helpers.graph import embedding as graph_embedding\n",
    "from omic_helpers.graph import clustering as graph_clustering\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, RobustScaler, MinMaxScaler, FunctionTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare, chi2_contingency, pearsonr\n",
    "from scipy.stats import kendalltau,spearmanr, weightedtau, theilslopes, wilcoxon, ttest_rel\n",
    "from scipy.spatial import distance\n",
    "import dcor\n",
    "\n",
    "import umap\n",
    "import pacmap\n",
    "import trimap\n",
    "import pymde\n",
    "import dbmap\n",
    "import numba\n",
    "import ugtm\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skfuzzy as  fuzz\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, NMF, FactorAnalysis\n",
    "from sklearn.manifold import Isomap, MDS, SpectralEmbedding\n",
    "from sklearn.manifold import LocallyLinearEmbedding as LLE, TSNE, smacof, trustworthiness\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection as GRP\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim as min_dim\n",
    "\n",
    "from sklearn.kernel_approximation import Nystroem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import rand_score, adjusted_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN, NeighborhoodComponentsAnalysis as NCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intra_sample_distances(X, how='euclidean'):\n",
    "    if how == 'euclidean':  \n",
    "        return distance.pdist(X)\n",
    "\n",
    "# from trimap paper \n",
    "def global_score(X, Y):\n",
    "    \"\"\"\n",
    "    Global score, wrt PCA\n",
    "    Input\n",
    "    ------\n",
    "    X: Instance matrix\n",
    "    Y: Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def global_loss_(X, Y):\n",
    "        # least squares loss of embedding\n",
    "        X = X - np.mean(X, axis=0)\n",
    "        Y = Y - np.mean(Y, axis=0)\n",
    "        A = X.T @ (Y @ np.linalg.inv(Y.T @ Y))\n",
    "        return np.mean(np.power(X.T - A @ Y.T, 2))\n",
    "\n",
    "    n_dims = Y.shape[1]\n",
    "    Y_pca = PCA(n_components=n_dims).fit_transform(X)\n",
    "    gs_pca = global_loss_(X, Y_pca)\n",
    "    gs_emb = global_loss_(X, Y)\n",
    "    return np.exp(-(gs_emb - gs_pca) / gs_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] \n",
    " * [Sammon mapping](https://arxiv.org/pdf/2009.08136.pdf): \n",
    " * landmark maximum variance unfolding \n",
    " * Landmark MDS\n",
    " * [GSOM](https://github.com/CDAC-lab/pygsom/tree/master/gsom):  -> never mind this is a clustering method..\n",
    " * SMACOF\n",
    " * KernelPCA, PCA, SparsePCA\n",
    " * Factor Analysis\n",
    " * Isomap\n",
    " * Spectral Embedding/Laplacian eigenmap\n",
    " * UMAP\n",
    " * PacMap\n",
    " * t-SNE\n",
    " * dbMAP\n",
    " * Sammon\n",
    " * LLE\n",
    " * NMF\n",
    " * MDS\n",
    " * Trimap\n",
    " * NCA with k-means/medoids as labels\n",
    " \n",
    "- [ ]\n",
    " * [Generative Topographic Mapping (GTM)](https://ugtm.readthedocs.io/en/latest/eGTM_transformer.html)\n",
    " * [IVIS](https://github.com/beringresearch/ivis): [paper](https://www.nature.com/articles/s41598-019-45301-0)\n",
    " * [FactorizedEmbeddings](https://github.com/TrofimovAssya/FactorizedEmbeddings): [paper](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i417/5870511)\n",
    " * [Diffeomap](): diffeomorphic dimensionality reduction Diffeomap\n",
    " * HOPE: karateclub\n",
    "    * custom autoencoder \n",
    "    * RankVisu\n",
    "    * FastMap MDS: https://github.com/shawn-davis/FastMapy\n",
    "    * MetricMap\n",
    "    * SparseMap: https://github.com/vene/sparsemap\n",
    "    * growing curvilinear component analysis\n",
    "    * curvilinear distance analysis\n",
    "    * autoencoder NeuroScale\n",
    "    * PHATE\n",
    "    * GPLVM\n",
    "    * FA\n",
    "    * Nonlinear PCA\n",
    "    * SDNE \n",
    "    * GCN\n",
    "    * Graph Factorisation\n",
    "    * [opt-SNE](https://github.com/omiq-ai/Multicore-opt-SNE): \n",
    "    *  Poincare embedding : https://github.com/facebookresearch/poincare-embeddings\n",
    "    * NN-graph/Parametric UMAP -> GraphSage/Node2Vec/etc.. see NetworkX and karateclub!\n",
    "    * https://github.com/benedekrozemberczki/karateclub\n",
    "    * [GEM benchmark](https://github.com/palash1992/GEM-Benchmark), [GEM git](https://github.com/palash1992/GEM), [GEM paper](https://www.sciencedirect.com/science/article/pii/S0950705118301540)\n",
    "\n",
    "\n",
    "\n",
    "# testsuite\n",
    "* distance preservation, \n",
    "* trustworthiness, \n",
    "* topology preservation (https://github.com/scikit-tda, https://github.com/giotto-ai/giotto-tda)\n",
    "\n",
    "\n",
    "# Ideas\n",
    "\n",
    "* Use Bolt to accelerate NN-search: https://github.com/dblalock/bolt\n",
    "* benchmarks: https://www.nature.com/articles/s41598-019-45301-0\n",
    "* add custom encoder: https://discuss.pytorch.org/t/extracting-reduced-dimension-data-from-autoencoder-in-pytorch/56581\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on genomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA expression data from ~1000 lung cancer patients\n",
    "RNAex = pd.read_feather(\"/media/bramiozo/DATA-FAST/genetic_expression/lung_cancer_2021/TCGA/Lung/Lung_RNAex.feather\")\n",
    "RNAex.set_index('index', inplace=True)\n",
    "RNAex = RNAex.loc[:, RNAex.columns[RNAex.var(axis=0)>0].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_dim(RNAex.shape[0], eps=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "eps_range = np.arange(1, 100, 1)/100\n",
    "min_dims = [min_dim(RNAex.shape[0], eps=_eps) for _eps in eps_range]\n",
    "sns.lineplot(eps_range, min_dims, ax=ax)\n",
    "ax.axhline(1000, color='black')\n",
    "ax.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIMAP(n_inliers=10, n_outliers=5, n_random=5, distance=euclidean, lr=0.015, n_iters=5000, weight_adj=500.0, apply_pca=True, opt_method=dbd, verbose=True, return_seq=False)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "sample_size = 250\n",
    "sample_selection = np.random.randint(0,num_samples, sample_size)\n",
    "n_landmarks = 75\n",
    "\n",
    "n_n = 47\n",
    "reduce_dim = 25\n",
    "scaler = StandardScaler\n",
    "embedder_type = 'dbmap'\n",
    "\n",
    "\n",
    "embedder = {}\n",
    "embedder['nystrom'] = Nystroem(kernel='rbf', n_components=reduce_dim, random_state=1234)\n",
    "embedder['umap'] = umap.UMAP(n_components=reduce_dim, densmap=False, metric='euclidean',\n",
    "                             n_neighbors=n_n, min_dist=0., disconnection_distance=None)\n",
    "embedder['trimap'] = trimap.TRIMAP(n_dims=reduce_dim, n_iters=5000, lr=0.015);\n",
    "embedder['pacmap'] = pacmap.PaCMAP(n_dims=reduce_dim, n_neighbors=n_n)\n",
    "embedder['SpectralEmbedding'] = SpectralEmbedding(n_components=reduce_dim, n_neighbors=n_n)\n",
    "embedder['Isomap'] = Isomap(n_components=reduce_dim, n_neighbors=n_n)\n",
    "embedder['MDS'] = MDS(n_components=reduce_dim, metric='euclidean')\n",
    "embedder['KernelPCA'] = KernelPCA(n_components=reduce_dim, kernel='sigmoid')\n",
    "embedder['PCA'] = PCA(n_components=reduce_dim)\n",
    "embedder['SparsePCA'] = SparsePCA(n_components=reduce_dim, alpha=0.0001, n_jobs=8)\n",
    "embedder['FA'] = FactorAnalysis(n_components=reduce_dim, max_iter=1000)\n",
    "embedder['dbmap'] = dbmap.diffusion.Diffusor(n_components=120, ann_dist='euclidean')\n",
    "embedder['LLE'] = LLE(n_components=reduce_dim, n_neighbors=n_n, method='ltsa')\n",
    "embedder['NMF'] = NMF(n_components=reduce_dim, max_iter=10000)\n",
    "embedder['TSNE'] = TSNE(n_components=3, perplexity=50)\n",
    "embedder['Sammon'] = graph_embedding.Sammon(n_components=reduce_dim, n_neighbors=n_n,\n",
    "                                            max_iterations=250, learning_rate=0.1, init_type='PCA')\n",
    "embedder['MVU'] = graph_embedding.MaximumVarianceUnfolding(n_components=2, n_neighbors=n_n)\n",
    "embedder['LMVU'] = graph_embedding.LandmarkMaximumVarianceUnfolding(n_components=reduce_dim, \n",
    "                                                                     n_neighbors=n_n, \n",
    "                                                                     n_landmarks=n_landmarks)\n",
    "embedder['LMDS'] = graph_embedding.LandmarkMultiDimensionalScaling(n_components=reduce_dim,\n",
    "                                                                     n_landmarks=n_landmarks)\n",
    "embedder['GPR'] = GRP(n_components=reduce_dim, random_state=3231, eps=0.8)\n",
    "embedder['NCA'] = NCA(n_components=reduce_dim, random_state=3231)\n",
    "embedder['GTM'] = ugtm.ugtm_sklearn.eGTM(k=16, m=4, s=0.3, regul=0.1, \n",
    "                                        random_state=1234, niter=200, model='means')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse input. Proceding without converting...\n",
      "Index-time parameters M: 30 n_threads: 10 efConstruction: 100 post:0\n",
      "Indexing time = 23.198467 (sec)\n",
      "Query-time parameter efSearch: 100\n",
      "kNN time total=13.231073 (sec), per query=0.011657 (sec), per query adjusted for thread number=0.116573 (sec)\n",
      "Automatically selected and multiscaled 93 diffusion components.\n",
      "Diffusion time = 38.859558 (sec), per sample=0.034237 (sec), per sample adjusted for thread number=0.342375 (sec)\n",
      "Input data is <class 'numpy.ndarray'> .Converting input to sparse...\n",
      "Index-time parameters M: 30 n_threads: 10 efConstruction: 100 post:0\n",
      "Indexing time = 0.101618 (sec)\n",
      "Query-time parameter efSearch: 100\n",
      "kNN time total=0.016962 (sec), per query=0.000015 (sec), per query adjusted for thread number=0.000149 (sec)\n",
      "Automatically selected and multiscaled 128 diffusion components.\n",
      "Diffusion time = 2.199420 (sec), per sample=0.001938 (sec), per sample adjusted for thread number=0.019378 (sec)\n"
     ]
    }
   ],
   "source": [
    "if embedder_type == 'dbmap':\n",
    "    pipe = Pipeline([('scaler', scaler()), \n",
    "                     ('prepmap', embedder['dbmap']), \n",
    "                     ('reducer', embedder['umap'])])\n",
    "    tts = embedder['dbmap'].fit_transform(csr_matrix(RNAex.values))\n",
    "    RNAembedded =np.array(pipe.fit_transform(tts))\n",
    "elif embedder_type == 'NMF':    \n",
    "    nonnegger = lambda x: x + 2*np.abs(np.min(x, axis=0))\n",
    "    nonnegger_F = FunctionTransformer(func=nonnegger)\n",
    "\n",
    "    pipe = Pipeline([('scaler', scaler()), \n",
    "                     ('nngr', nonnegger_F), \n",
    "                     ('reducer', embedder['NMF'])])\n",
    "    RNAembedded = pipe.fit_transform(RNAex)\n",
    "elif embedder_type == 'SMACOF':\n",
    "    try:\n",
    "        dissimilarities;\n",
    "    except NameError:\n",
    "        # np.abs(np.log(similarities))\n",
    "        #dissimilarities = 1 - spearmanr(RNAex.values, axis=1)[0]\n",
    "        dissimilarities = distance.squareform(distance.pdist(RNAex.values, metric='seuclidean'))\n",
    "    RNAembedded = smacof(dissimilarities, n_components=reduce_dim, max_iter=300, eps=1e-3, n_jobs=4)[0]\n",
    "elif embedder_type == 'NCA':\n",
    "    pipe = Pipeline([('scaler', scaler()), \n",
    "                     ('reducer', embedder[embedder_type])]) \n",
    "    km = KMeans(n_clusters=25).fit(StandardScaler().fit_transform(RNAex))\n",
    "    y = km.labels_\n",
    "    RNAembedded = pipe.fit_transform(RNAex, y)\n",
    "else:\n",
    "    pipe = Pipeline([('scaler', scaler()), \n",
    "                     ('reducer', embedder[embedder_type])])\n",
    "    RNAembedded = pipe.fit_transform(RNAex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RNAex distance preservation')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_or = get_intra_sample_distances(RNAex.iloc[sample_selection,:])\n",
    "dist_emb = get_intra_sample_distances(RNAembedded[sample_selection,:])\n",
    "\n",
    "dists = {'d_or': dist_or, 'd_emb': dist_emb}\n",
    "dist_preservation_overall = {'dataset': 'RNAex', \n",
    "                          'corr':dcor.distance_correlation(dist_or, dist_emb)}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "ax.scatter(x=dists['d_or'], y=dists['d_emb'], color='black', alpha=0.01)\n",
    "mx,my = max(dists['d_or']), max(dists['d_emb'])\n",
    "ax.plot([0,mx], [0, my], ls='--', c='blue')\n",
    "ax.set_title('RNAex distance preservation')\n",
    "\n",
    "# topology preservation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rand/MI clustering\n",
    "kclusterer1 = KMeans(n_clusters=20)\n",
    "kclusterer1.fit(scaler().fit_transform(RNAex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance preservation overall {'dataset': 'RNAex', 'corr': 0.1885600657905727}\n",
      "Intra-distance trustworthiness 0.9472908857088133\n",
      "Rand score 0.8865192022313901\n",
      "Adjusted Rand score 0.2470692282908527\n",
      "Adjusted MI score 0.4410178729711857\n",
      "Calinski-Harabasz ratio, lower than 1 means better clustering for embedding 0.21422651029418335\n",
      "David-Bouldin ratio, higher than 1 means better clustering for embedding 1.86323426622765\n",
      "Relative L2-loss 0.4852598554762117\n"
     ]
    }
   ],
   "source": [
    "# ADD kNN accuracy/recall \n",
    "# ADD add Fuzzy Partitioning Coefficient (with decreasing dimensionality FPC should decay)\n",
    "\n",
    "kclusterer2 = KMeans(n_clusters=20)\n",
    "kclusterer2.fit(RNAembedded)\n",
    "\n",
    "r_score =rand_score(kclusterer1.labels_, kclusterer2.labels_)\n",
    "ar_score = adjusted_rand_score(kclusterer1.labels_, kclusterer2.labels_)\n",
    "mi_score = adjusted_mutual_info_score(kclusterer1.labels_, kclusterer2.labels_)\n",
    "ch_score1 = calinski_harabasz_score(RNAex, kclusterer1.labels_)\n",
    "ch_score2 = calinski_harabasz_score(RNAembedded, kclusterer2.labels_)\n",
    "\n",
    "db_score1 = davies_bouldin_score(RNAex, kclusterer1.labels_)\n",
    "db_score2 = davies_bouldin_score(RNAembedded, kclusterer2.labels_)\n",
    "\n",
    "print(\"Distance preservation overall\", dist_preservation_overall)\n",
    "print(\"Intra-distance trustworthiness\", trustworthiness(RNAex, RNAembedded))\n",
    "print(\"Rand score\", r_score)\n",
    "print(\"Adjusted Rand score\", ar_score)\n",
    "print(\"Adjusted MI score\", mi_score)\n",
    "print(\"Calinski-Harabasz ratio, lower than 1 means better clustering for embedding\", ch_score1/ch_score2)\n",
    "print(\"David-Bouldin ratio, higher than 1 means better clustering for embedding\", db_score1/db_score2)\n",
    "print(\"Relative L2-loss\", global_score(RNAex.values, RNAembedded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(data=RNAembedded, columns=['d'+'_'+str(i) for i in range(reduce_dim)], index=RNAex.index)\n",
    "meta = pd.read_feather(\"/media/bramiozo/DATA-FAST/genetic_expression/lung_cancer_2021/TCGA/Lung/Lung_meta.feather\")\n",
    "meta.set_index('SampleID', inplace=True)\n",
    "plot_df = plot_df.join(meta[['Diagnosis', 'Response']], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_dim_ = min([6, reduce_dim])\n",
    "if reduce_dim_>2:\n",
    "    num_rows = int(np.ceil((reduce_dim_)**2/3))\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=num_rows, figsize=(18, 5*num_rows))\n",
    "    k = 0\n",
    "    for ki in range(reduce_dim_):\n",
    "        for kj in range(reduce_dim_): \n",
    "            i = int(k/3)\n",
    "            j = k%3\n",
    "            if num_rows > 1:\n",
    "                sns.scatterplot(data=plot_df, x='d_'+str(ki), y='d_'+str(kj), ax=ax[i,j], hue='Diagnosis', alpha=0.25)\n",
    "            else:\n",
    "                sns.scatterplot(data=plot_df, x='d_'+str(ki), y='d_'+str(kj), ax=ax[k], hue='Diagnosis', alpha=0.25)\n",
    "            k += 1\n",
    "else:\n",
    "    sns.scatterplot(data=plot_df, x='d_0', y='d_1', hue='Diagnosis', alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 39.28it/s]\n"
     ]
    }
   ],
   "source": [
    "fpcs_embedded = []\n",
    "for ncenters in tqdm(range(2, 20)):\n",
    "    _, _, _, _, _, _, fpc = fuzz.cluster.cmeans(RNAembedded, ncenters, 3, error=0.005, maxiter=1000, init=None)\n",
    "    fpcs_embedded.append({'fpc': fpc, 'n_clusters': ncenters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:07<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "fpcs_full = []\n",
    "for ncenters in tqdm(range(2, 20)):    \n",
    "    _, _, _, _, _, _, fpc = fuzz.cluster.cmeans(RNAex, \n",
    "                                                ncenters, 3, \n",
    "                                                error=0.005, \n",
    "                                                maxiter=1500,)\n",
    "    fpcs_full.append({'fpc': fpc, 'n_clusters': ncenters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=pd.DataFrame(fpcs_full), y='fpc', x='n_clusters', label='full data')\n",
    "sns.lineplot(data=pd.DataFrame(fpcs_embedded), y='fpc', x='n_clusters', label='embedded data')\n",
    "plt.legend()\n",
    "plt.title(\"Fuzzy partitioning coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "* dimensionality versus scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.arange(2, 20, 1) # reduced dimensions\n",
    "km = 10 # k-means clusters\n",
    "_eps = 0.1\n",
    "distance_metric = 'pearson' # pearson, spearmanr, dcor\n",
    "n_neighbors = np.arange(7, 117 ,11)\n",
    "\n",
    "num_samples = 1000\n",
    "sample_size = 250\n",
    "sample_selection = np.random.randint(0,num_samples, sample_size)\n",
    "dist_or = get_intra_sample_distances(RNAex.iloc[sample_selection,:])\n",
    "    \n",
    "embedder_type = 'pacmap'\n",
    "\n",
    "clusterer_base = KMeans(n_clusters=km)\n",
    "clusterer_base.fit(scaler().fit_transform(RNAex))\n",
    "ch_score1 = calinski_harabasz_score(RNAex, clusterer_base.labels_)\n",
    "db_score1 = davies_bouldin_score(RNAex, clusterer_base.labels_)\n",
    "\n",
    "scores = []\n",
    "if embedder_type in ['PCA', 'KernelPCA']:\n",
    "    n_neighbors = [1]\n",
    "for nn in tqdm(n_neighbors):\n",
    "    for dim in tqdm(dims):    \n",
    "        _embedder = embedder[embedder_type]\n",
    "        if embedder_type in ['trimap', 'pacmap']:\n",
    "            _embedder.n_dims = dim\n",
    "        else:\n",
    "            _embedder.n_components = dim\n",
    "\n",
    "        _embedder.n_neighbors = nn\n",
    "\n",
    "        ref_embedder = GRP(n_components=dim, random_state=None, eps=_eps) # _eps\n",
    "\n",
    "        pipe = Pipeline([('scaler', scaler()), \n",
    "                         ('reducer', _embedder)])\n",
    "\n",
    "        ref_pipe = Pipeline([('scaler', scaler()), \n",
    "                         ('reducer', ref_embedder)])\n",
    "\n",
    "        embedding = pipe.fit_transform(RNAex)\n",
    "        ref_embedding = ref_pipe.fit_transform(RNAex)\n",
    "\n",
    "        clusterer = KMeans(n_clusters=km)\n",
    "        clusterer.fit(embedding)\n",
    "\n",
    "        ref_clusterer = KMeans(n_clusters=km)\n",
    "        ref_clusterer.fit(ref_embedding)\n",
    "\n",
    "        ####################\n",
    "        # get metrics ######\n",
    "        ####################\n",
    "\n",
    "        dist_emb = get_intra_sample_distances(embedding[sample_selection,:])\n",
    "        if distance_metric=='dcor':\n",
    "            dist_cor = dcor.distance_correlation(dist_or, dist_emb)\n",
    "        elif distance_metric=='pearson':\n",
    "            dist_cor = pearsonr(dist_or, dist_emb)[0]\n",
    "        elif distance_metric=='spearman':\n",
    "            dist_cor = spearmanr(dist_or, dist_emb)[0]\n",
    "        \n",
    "        trust = trustworthiness(RNAex, embedding)\n",
    "\n",
    "        r_score =rand_score(clusterer_base.labels_, clusterer.labels_)\n",
    "        ar_score = adjusted_rand_score(clusterer_base.labels_, clusterer.labels_)\n",
    "        mi_score = adjusted_mutual_info_score(clusterer_base.labels_, clusterer.labels_)\n",
    "\n",
    "        ch_score2 = calinski_harabasz_score(embedding, clusterer.labels_)\n",
    "        db_score2 = davies_bouldin_score(embedding, clusterer.labels_)\n",
    "\n",
    "        rel_ch_score = ch_score1/ch_score2\n",
    "        rel_db_score = db_score1/db_score2\n",
    "\n",
    "        scores.append({'dim':dim, 'dist_cor': dist_cor, 'trust': trust,\n",
    "                       'rand': r_score, 'adj_rand': ar_score, 'adj_mi': mi_score,\n",
    "                       'ch_score': ch_score2, 'db_score': db_score2, \n",
    "                       'rel_ch_score': rel_ch_score , 'rel_db_score': rel_db_score,   \n",
    "                       'neighbors': nn, 'embedder': embedder_type})\n",
    "\n",
    "\n",
    "        dist_emb = get_intra_sample_distances(ref_embedding[sample_selection,:])\n",
    "        dist_cor = dcor.distance_correlation(dist_or, dist_emb)\n",
    "\n",
    "        trust = trustworthiness(RNAex, ref_embedding)\n",
    "\n",
    "        r_score =rand_score(clusterer_base.labels_, ref_clusterer.labels_)\n",
    "        ar_score = adjusted_rand_score(clusterer_base.labels_, ref_clusterer.labels_)\n",
    "        mi_score = adjusted_mutual_info_score(clusterer_base.labels_, ref_clusterer.labels_)\n",
    "\n",
    "        ch_score2 = calinski_harabasz_score(ref_embedding, ref_clusterer.labels_)\n",
    "        db_score2 = davies_bouldin_score(ref_embedding, ref_clusterer.labels_)\n",
    "\n",
    "        rel_ch_score = ch_score1/ch_score2\n",
    "        rel_db_score = db_score1/db_score2\n",
    "\n",
    "        scores.append({'dim':dim, 'dist_cor': dist_cor, 'trust': trust,\n",
    "                       'rand': r_score, 'adj_rand': ar_score, 'adj_mi': mi_score,\n",
    "                       'ch_score': ch_score2, 'db_score': db_score2,                    \n",
    "                       'rel_ch_score': rel_ch_score , 'rel_db_score': rel_db_score,   \n",
    "                       'neighbors': nn, 'embedder': 'GRP'})\n",
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(17,18))\n",
    "sns.lineplot(data=scores_df, x='dim', y='dist_cor', hue='embedder', ax=ax[0,0])\n",
    "sns.lineplot(data=scores_df, x='dim', y='trust', hue='embedder', ax=ax[0,1])\n",
    "sns.lineplot(data=scores_df, x='dim', y='rand', hue='embedder', ax=ax[0,2])\n",
    "\n",
    "sns.lineplot(data=scores_df, x='dim', y='adj_rand', hue='embedder', ax=ax[1,0])\n",
    "sns.lineplot(data=scores_df, x='dim', y='adj_mi', hue='embedder', ax=ax[1,1])\n",
    "sns.lineplot(data=scores_df, x='dim', y='ch_score', hue='embedder', ax=ax[1,2])\n",
    "\n",
    "sns.lineplot(data=scores_df, x='dim', y='db_score', hue='embedder', ax=ax[2,0])\n",
    "sns.lineplot(data=scores_df, x='dim', y='rel_ch_score', hue='embedder', ax=ax[2,1])\n",
    "sns.lineplot(data=scores_df, x='dim', y='rel_db_score', hue='embedder', ax=ax[2,2])\n",
    "\n",
    "fig.suptitle(f\"Embedder type: {embedder_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Neural networks for embeddings\n",
    "\n",
    "work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import Tensor\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "# utility functions\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, layer_sizes, dropout_ratio=0.25):\n",
    "        super(DenseEncoder, self).__init__()\n",
    "        \n",
    "        layer_sizes = [in_features] + layer_sizes\n",
    "        \n",
    "        self.seq= nn.Sequential()       \n",
    "        for idx in range(0, len(layer_sizes)-1):\n",
    "            self.seq.add_module('ENC_fc_'+str(idx), nn.Linear(in_features=layer_sizes[idx], \n",
    "                                                              out_features=layer_sizes[idx+1]))\n",
    "            self.seq.add_module('ENC_relu_'+str(idx), nn.ReLU())\n",
    "            self.seq.add_module('ENC_dropout'+str(idx), nn.Dropout(dropout_ratio))\n",
    "        self.seq.add_module('ENC_fcF', nn.Linear(in_features=layer_sizes[-1], out_features=out_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "class DenseDecoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, layer_sizes):\n",
    "        super(DenseDecoder, self).__init__()\n",
    "        \n",
    "        layer_sizes = list(reversed(layer_sizes))\n",
    "        layer_sizes = [out_features] + layer_sizes\n",
    "        \n",
    "        self.seq= nn.Sequential()\n",
    "        for idx in range(0, len(layer_sizes)-1):\n",
    "            self.seq.add_module('DEC_fc_'+str(idx), nn.Linear(in_features=layer_sizes[idx], \n",
    "                                                              out_features=layer_sizes[idx+1]))\n",
    "            self.seq.add_module('DEC_relu_'+str(idx), nn.ReLU())\n",
    "        self.seq.add_module('DEC_fcF', nn.Linear(in_features=layer_sizes[-1], out_features=in_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "    \n",
    "class DenseAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(DenseAE, self).__init__()\n",
    "        self.encoder = DenseEncoder(in_features=kwargs['in_features'], \n",
    "                                    out_features=kwargs['out_features'],\n",
    "                                    layer_sizes=kwargs['layer_sizes'])\n",
    "        self.decoder = DenseDecoder(in_features=kwargs['in_features'], \n",
    "                                    out_features=kwargs['out_features'],\n",
    "                                    layer_sizes=kwargs['layer_sizes'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, layer_sizes):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=8, stride=4, padding=0, \n",
    "                      bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=0, \n",
    "                      bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=out_features, kernel_size=3, stride=1, padding=0, \n",
    "                      bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.seq(x) \n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, layer_sizes):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=out_features, out_channels=64, kernel_size=3, stride=1, padding=0, \n",
    "                               bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=0, \n",
    "                               bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=32, out_channels=1, kernel_size=8, stride=4, padding=0, \n",
    "                               bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.seq(x) \n",
    "    \n",
    "class ConvAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConvAE, self).__init__()\n",
    "        self.encoder = ConvEncoder(in_features=kwargs['in_features'], \n",
    "                                    out_features=kwargs['out_features'],\n",
    "                                    layer_sizes=kwargs['layer_sizes'])\n",
    "        self.decoder = ConvDecoder(in_features=kwargs['in_features'], \n",
    "                                    out_features=kwargs['out_features'],\n",
    "                                    layer_sizes=kwargs['layer_sizes'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedColumnarDataset(Dataset):\n",
    "    \"\"\"Dataset class for column dataset.\n",
    "    Args:\n",
    "       cats (list of str): List of the name of columns contain\n",
    "                           categorical variables.\n",
    "       conts (list of str): List of the name of columns which \n",
    "                           contain continuous variables.\n",
    "       y (Tensor, optional): Target variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, cat_flds):       \n",
    "        conts = [c.values for n,c in df.items()]\n",
    "        \n",
    "        n = len(conts[0])\n",
    "        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n",
    "        self.len = len(df)\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.len   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.conts[idx]\n",
    "    \n",
    "outputs = None\n",
    "def get_embeddings(model, x, ntype = 'dense'):\n",
    "    if ntype == 'dense':\n",
    "        return model.encoder.forward(Tensor(x).cuda()).cpu().detach().numpy()\n",
    "    elif ntype == 'conv':\n",
    "        return model.encoder.forward(Tensor(x).unsqueeze(1).cuda()).cpu().detach().numpy()\n",
    "\n",
    "def train(net, trainloader, optimizer, NUM_EPOCHS, ntype='conv'):\n",
    "    train_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            if ntype=='conv':\n",
    "                dataTensor = Tensor(data).unsqueeze(1)\n",
    "                optimizer.zero_grad()            \n",
    "                outputs = n_net(dataTensor.cuda())\n",
    "                loss = criterion(outputs, dataTensor.cuda())\n",
    "            else:\n",
    "                optimizer.zero_grad()            \n",
    "                outputs = n_net(Tensor(data).cuda())\n",
    "                loss = criterion(outputs, data.cuda())                \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        loss = running_loss / len(trainloader)\n",
    "        train_loss.append(loss)\n",
    "        print(f\"-------------Train loss: {loss}, epoch: {epoch}\")\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNAex_normalised = pd.DataFrame(data=MinMaxScaler().fit_transform(np.log(RNAex.values+1)), \n",
    "                                columns=RNAex.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nntype='dense'\n",
    "if nntype == 'dense':\n",
    "    n_net = DenseAE(in_features=RNAex.shape[1], out_features=8, layer_sizes=[48,32,32])\n",
    "    n_net.to(device)\n",
    "elif nntype == 'conv':\n",
    "    n_net = ConvAE(in_features=RNAex.shape[1], out_features=8, layer_sizes=[64,32,32,16])\n",
    "    n_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "net_optimizer = optim.Adam(n_net.parameters(), lr=LEARNING_RATE, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(MixedColumnarDataset(RNAex_normalised, []), batch_size=96, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = train(n_net, train_dl, net_optimizer, NUM_EPOCHS, ntype=nntype)\n",
    "torch.cuda.empty_cache()\n",
    "ae_embs = get_embeddings(n_net, RNAex_normalised.values, ntype=nntype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='d_1', ylabel='d_2'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame(data=ae_embs, columns=['d_'+str(i) for i in range(8)], index=RNAex.index)\n",
    "meta = pd.read_feather(\"/media/bramiozo/DATA-FAST/genetic_expression/lung_cancer_2021/TCGA/Lung/Lung_meta.feather\")\n",
    "meta.set_index('SampleID', inplace=True)\n",
    "plot_df = plot_df.join(meta[['Diagnosis', 'Response']], how='left')\n",
    "sns.scatterplot(data=plot_df, x='d_1', y='d_2', hue='Diagnosis', alpha=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance preservation overall {'dataset': 'RNAex', 'corr': 0.37245995146171595}\n",
      "Intra-distance trustworthiness 0.7368883121147329\n",
      "Rand score 0.694367915219604\n",
      "Adjusted Rand score 0.27375788180239347\n",
      "Adjusted MI score 0.40015047305337825\n",
      "Calinski-Harabasz ratio, lower than 1 means better clustering for embedding 0.02884254649759499\n",
      "David-Bouldin ratio, higher than 1 means better clustering for embedding 3.8883397543568066\n",
      "Relative L2-loss 0.5207016863928956\n"
     ]
    }
   ],
   "source": [
    "kclusterer2 = KMeans(n_clusters=10)\n",
    "kclusterer2.fit(ae_embs)\n",
    "\n",
    "dist_or = get_intra_sample_distances(RNAex.iloc[sample_selection,:])\n",
    "dist_emb = get_intra_sample_distances(ae_embs[sample_selection,:])\n",
    "\n",
    "dists = {'d_or': dist_or, 'd_emb': dist_emb}\n",
    "dist_preservation_overall = {'dataset': 'RNAex', \n",
    "                          'corr':dcor.distance_correlation(dist_or, dist_emb)}\n",
    "\n",
    "r_score =rand_score(kclusterer1.labels_, kclusterer2.labels_)\n",
    "ar_score = adjusted_rand_score(kclusterer1.labels_, kclusterer2.labels_)\n",
    "mi_score = adjusted_mutual_info_score(kclusterer1.labels_, kclusterer2.labels_)\n",
    "ch_score1 = calinski_harabasz_score(RNAex, kclusterer1.labels_)\n",
    "ch_score2 = calinski_harabasz_score(ae_embs, kclusterer2.labels_)\n",
    "\n",
    "db_score1 = davies_bouldin_score(RNAex, kclusterer1.labels_)\n",
    "db_score2 = davies_bouldin_score(ae_embs, kclusterer2.labels_)\n",
    "\n",
    "print(\"Distance preservation overall\", dist_preservation_overall)\n",
    "print(\"Intra-distance trustworthiness\", trustworthiness(RNAex, ae_embs))\n",
    "print(\"Rand score\", r_score)\n",
    "print(\"Adjusted Rand score\", ar_score)\n",
    "print(\"Adjusted MI score\", mi_score)\n",
    "print(\"Calinski-Harabasz ratio, lower than 1 means better clustering for embedding\", ch_score1/ch_score2)\n",
    "print(\"David-Bouldin ratio, higher than 1 means better clustering for embedding\", db_score1/db_score2)\n",
    "print(\"Relative L2-loss\", global_score(RNAex.values, ae_embs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance correlation/preservation and the trustworthiness metrics are not suitable metrics to qualify embeddings as they cannot distinguish between neighborhoods in the original space. Even if points are projected randomly they can have similar distances in lower dimensional space, in fact the higher the dimensionality of the embeddeds space the more possibilities there are to randomly obtain similar intra-point distances.\n",
    "\n",
    "We would expect that if we increase the embedded dimensions we get closer to the performance of random projections in terms of intra-distance preservations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on CELLDYN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised UMAP\n",
    "\n",
    "The main flavor is to add labels for the different clusters we know we want to \n",
    "see. This can be based on a clustering on a sample set of the original data (perhaps also a selection of features).\n",
    "\n",
    "Possible methods:\n",
    "* SS-UMAP\n",
    "* NCA\n",
    "* knn-based SSL, or fuzzy-c based SSL with multi-label\n",
    "* SSL-trained neural network\n",
    "* SS-WDA (Wasserstein discriminant analysis)\n",
    "\n",
    "Labels can be:\n",
    "* k-means/medoids clusters on the original dataset\n",
    "* phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric UMAP\n",
    "\n",
    "* Create nearest-neighbor graph with fuzzy simplicials\n",
    "* Apply graph embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anchored embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance preserving embedding\n",
    "\n",
    "* Siamese twins networks\n",
    "* distance as outcome\n",
    "* pairs as input\n",
    "\n",
    "The method IVIS seems to use this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking based embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-patch UMAP\n",
    "\n",
    "The core assumption of UMAP is that all points lie on the same manifold. What if we split our data in dense patches prior to the creation of the fuzzy simplicials? \n",
    "\n",
    "To make this tractable this split should be computationally in-expensive. One way to go about is to treat overlapping regions with a sufficient number of samples as patches. The embeddings associated with these patches can later be combined.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-sample UMAP\n",
    "\n",
    "\n",
    "* $N$ sampled UMAP embedders with/without minimal perturbations\n",
    "* aligned using Procrustes\n",
    "* uniform scaling\n",
    "* concensus distance determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmarkbased embeddings coupled to sparse exemplar finders\n",
    "\n",
    "Instead of random landmarks we can use exemplars based on \n",
    "* points closest to centroids\n",
    "* exemplars based on e.g. affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5a14f050fb035b48dd4bb6477ca57635d0b683745fc30c1f601aba2e74fe38c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('long': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd0d5a14f050fb035b48dd4bb6477ca57635d0b683745fc30c1f601aba2e74fe38c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
