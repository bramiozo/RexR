{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++ Firing up RexR! ++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from RexR import *\n",
    "import _helpers\n",
    "Rocket = RexR(datalocation = None, #'_data/genomic_data/data.pkl', \n",
    "              seed = 3123, \n",
    "              debug = False, \n",
    "              write_out=True,\n",
    "              set_name = 'ALL_10') # data to read in ALL_10, or MELA\n",
    "Rocket.load_probeset_data();\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD_LIST = ['RF','XGB', 'LGBM', 'ExtraTrees','SVM', 'LR', 'MLNN', 'RVM', 'DNN', 'CNN'] #, 'NaiveBayes','MLNN', 'XGB'] # \n",
    "Runs = []\n",
    "nruns = 2\n",
    "SCALER = \"minmax\" # minmax, standard, normaliser\n",
    "GROUPING = \"mean\"\n",
    "FEAT_SELECTOR = \"low_variance\" # \"low_variance\"\n",
    "SELECTOR_METHOD = \"FDR\" # mannwhitney, FDR\n",
    "SELECTOR_ALPHA = 0.025 # see this as the maximum p-value to classify \n",
    "DIM_TYPE =  None #\"LDA\", \"PCA\", \"PLS\" \n",
    "DIM_NUM = 1000\n",
    "Results = None\n",
    "ACC = pd.DataFrame()\n",
    "Rocket.VIZ = False\n",
    "Rocket.DATA_merged_processed = None\n",
    "PREPROC_DICT = {\"patient_grouping\": GROUPING, \"bias_removal\": False, \"noise\": True}\n",
    "FSELECT_DICT = {\"type\": FEAT_SELECTOR, \"pvalue\": SELECTOR_ALPHA, \"method\": SELECTOR_METHOD}\n",
    "DIMRED_DICT = {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Prepping data, this may take a while..\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Grouping probesets\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Selecting features using a low_variance filter\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Kept 78 of 54613 features using FDR with p = 0.025\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: RF accuracy:  0.7931034482758621 +/-: 0.030339062443699775\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: XGB accuracy:  0.7413793103448276 +/-: 0.006783050481029083\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: LGBM accuracy:  0.8275862068965517 +/-: 0.0231731704680575\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: ET accuracy:  0.8103448275862069 +/-: 0.03286581630814686\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: SVM accuracy:  0.8793103448275861 +/-: 0.007638813821929159\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: MLNN accuracy:  0.8448275862068966 +/-: 0.0038734551219687936\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "Initial alpha = [[0.0717407]]\n",
      "   1 - L=-599.6339408 - Gamma= 1.9997787 (M=   2) - s=0.0100\n",
      "   2 - L=-452.0356023 - Gamma= 2.9996254 (M=   3) - s=0.0100\n",
      "   3 - L=-408.6748364 - Gamma= 3.9992889 (M=   4) - s=0.0100\n",
      "   4 - L=-360.8392627 - Gamma= 4.9989667 (M=   5) - s=0.0100\n",
      "   5 - L=-331.6403233 - Gamma= 5.9984905 (M=   6) - s=0.0100\n",
      "   6 - L=-306.4401185 - Gamma= 6.9979574 (M=   7) - s=0.0100\n",
      "   7 - L=-237.3794370 - Gamma= 7.9975328 (M=   8) - s=0.0100\n",
      "   8 - L=-179.0216169 - Gamma= 8.9971020 (M=   9) - s=0.0100\n",
      "   9 - L=-151.1716242 - Gamma= 9.9964061 (M=  10) - s=0.0100\n",
      "  10 - L=-131.5122983 - Gamma=10.9957093 (M=  11) - s=0.0100\n",
      "  11 - L=-113.4604702 - Gamma=11.9950102 (M=  12) - s=0.0100\n",
      "  12 - L=-99.7837617 - Gamma=12.9940062 (M=  13) - s=0.0100\n",
      "  13 - L=-84.7426904 - Gamma=13.9925834 (M=  14) - s=0.0100\n",
      "  14 - L=-68.1729473 - Gamma=14.9916925 (M=  15) - s=0.0100\n",
      "  15 - L=-58.4007767 - Gamma=15.9893894 (M=  16) - s=0.0100\n",
      "  16 - L=-51.3176605 - Gamma=16.9877696 (M=  17) - s=0.0100\n",
      "  17 - L=-36.7163838 - Gamma=17.9849957 (M=  18) - s=0.0100\n",
      "  18 - L=-33.3309739 - Gamma=18.9811048 (M=  19) - s=0.0100\n",
      "  19 - L=-33.2663241 - Gamma=17.9841647 (M=  18) - s=0.0100\n",
      "  20 - L=-29.6786693 - Gamma=18.9780746 (M=  19) - s=0.0100\n",
      "  21 - L=-25.7250584 - Gamma=19.9737711 (M=  20) - s=0.0100\n",
      "  22 - L=-25.6472459 - Gamma=18.9764863 (M=  19) - s=0.0100\n",
      "  23 - L=-22.5106303 - Gamma=19.9721755 (M=  20) - s=0.0100\n",
      "  24 - L=-19.1621414 - Gamma=20.9642083 (M=  21) - s=0.0100\n",
      "  25 - L=-15.0884298 - Gamma=21.9603260 (M=  22) - s=0.0100\n",
      "  26 - L=-13.3035609 - Gamma=22.9529914 (M=  23) - s=0.0100\n",
      "  27 - L=-11.1050024 - Gamma=23.9454143 (M=  24) - s=0.0100\n",
      "  28 - L=-8.6533192 - Gamma=24.9382277 (M=  25) - s=0.0100\n",
      "  29 - L=-7.3919785 - Gamma=25.9258439 (M=  26) - s=0.0100\n",
      "  30 - L=-5.9454081 - Gamma=26.9143512 (M=  27) - s=0.0100\n",
      "  31 - L=-3.6753055 - Gamma=27.9037553 (M=  28) - s=0.0100\n",
      "  32 - L=-2.3855293 - Gamma=28.8834820 (M=  29) - s=0.0100\n",
      "  33 - L=-1.4846796 - Gamma=29.8692185 (M=  30) - s=0.0100\n",
      "  34 - L=-0.7604337 - Gamma=30.8492117 (M=  31) - s=0.0100\n",
      "  35 - L=-0.3851962 - Gamma=31.8072029 (M=  32) - s=0.0100\n",
      "  36 - L=-0.0924528 - Gamma=32.7527103 (M=  33) - s=0.0100\n",
      "  37 - L= 0.2643414 - Gamma=33.7104864 (M=  34) - s=0.0100\n",
      "  38 - L= 0.4216837 - Gamma=33.7152372 (M=  34) - s=0.0100\n",
      "  39 - L= 0.5469373 - Gamma=33.7173171 (M=  34) - s=0.0100\n",
      "  40 - L= 0.6384667 - Gamma=33.7188513 (M=  34) - s=0.0100\n",
      "  41 - L= 0.7206086 - Gamma=34.6039969 (M=  35) - s=0.0100\n",
      "  42 - L= 0.7780026 - Gamma=34.6052069 (M=  35) - s=0.0100\n",
      "  43 - L= 0.8251484 - Gamma=34.6164648 (M=  35) - s=0.0100\n",
      "  44 - L= 0.8672939 - Gamma=34.6287447 (M=  35) - s=0.0100\n",
      "  45 - L= 0.9098724 - Gamma=34.6359414 (M=  35) - s=0.0100\n",
      "  46 - L= 0.9532313 - Gamma=35.4771698 (M=  36) - s=0.0100\n",
      "  47 - L= 0.9997994 - Gamma=36.3206340 (M=  37) - s=0.0100\n",
      "  48 - L= 1.0493362 - Gamma=36.9608437 (M=  38) - s=0.0100\n",
      "  49 - L= 1.0905789 - Gamma=36.9675535 (M=  38) - s=0.0100\n",
      "  50 - L= 1.1314951 - Gamma=36.9713912 (M=  38) - s=0.0100\n",
      "  51 - L= 1.1697351 - Gamma=36.9871802 (M=  38) - s=0.0100\n",
      "  52 - L= 1.2021946 - Gamma=36.9879439 (M=  38) - s=0.0100\n",
      "  53 - L= 1.2270142 - Gamma=36.9929787 (M=  38) - s=0.0100\n",
      "  54 - L= 1.2480525 - Gamma=37.0001130 (M=  38) - s=0.0100\n",
      "  55 - L= 1.2664757 - Gamma=37.1552245 (M=  38) - s=0.0100\n",
      "  56 - L= 1.2817964 - Gamma=37.1635732 (M=  38) - s=0.0100\n",
      "  57 - L= 1.2953339 - Gamma=37.1758467 (M=  38) - s=0.0100\n",
      "  58 - L= 1.3084161 - Gamma=37.1783382 (M=  38) - s=0.0100\n",
      "  59 - L= 1.3203748 - Gamma=37.1761801 (M=  38) - s=0.0100\n",
      "  60 - L= 1.3296470 - Gamma=37.1699943 (M=  38) - s=0.0100\n",
      "  61 - L= 1.3385090 - Gamma=37.7708566 (M=  39) - s=0.0100\n",
      "  62 - L= 1.3476935 - Gamma=37.0806911 (M=  38) - s=0.0100\n",
      "  63 - L= 1.3571678 - Gamma=36.8847338 (M=  38) - s=0.0100\n",
      "  64 - L= 1.3637109 - Gamma=36.9065787 (M=  38) - s=0.0100\n",
      "  65 - L= 1.3697139 - Gamma=36.8115006 (M=  38) - s=0.0100\n",
      "  66 - L= 1.3752893 - Gamma=36.8666417 (M=  38) - s=0.0100\n",
      "  67 - L= 1.3807946 - Gamma=36.8719092 (M=  38) - s=0.0100\n",
      "  68 - L= 1.3860469 - Gamma=36.8761572 (M=  38) - s=0.0100\n",
      "  69 - L= 1.3904110 - Gamma=36.8423970 (M=  38) - s=0.0100\n",
      "  70 - L= 1.3948330 - Gamma=36.7655810 (M=  38) - s=0.0100\n",
      "  71 - L= 1.3986849 - Gamma=36.7635541 (M=  38) - s=0.0100\n",
      "  72 - L= 1.4020608 - Gamma=36.7529068 (M=  38) - s=0.0100\n",
      "  73 - L= 1.4054437 - Gamma=36.7767429 (M=  38) - s=0.0100\n",
      "  74 - L= 1.4082809 - Gamma=36.7828573 (M=  38) - s=0.0100\n",
      "  75 - L= 1.4108055 - Gamma=36.8192589 (M=  38) - s=0.0100\n",
      "  76 - L= 1.4129981 - Gamma=36.9490857 (M=  38) - s=0.0100\n",
      "  77 - L= 1.4147300 - Gamma=36.7269275 (M=  38) - s=0.0100\n",
      "  78 - L= 1.4154717 - Gamma=36.7230974 (M=  38) - s=0.0100\n",
      "  79 - L= 1.4160711 - Gamma=36.6666704 (M=  38) - s=0.0100\n",
      "  80 - L= 1.4166674 - Gamma=36.6657845 (M=  38) - s=0.0100\n",
      "  81 - L= 1.4172532 - Gamma=36.6170787 (M=  38) - s=0.0100\n",
      "  82 - L= 1.4176739 - Gamma=36.6202793 (M=  38) - s=0.0100\n",
      "  83 - L= 1.4180623 - Gamma=36.6281768 (M=  38) - s=0.0100\n",
      "  84 - L= 1.4184504 - Gamma=36.6277907 (M=  38) - s=0.0100\n",
      "  85 - L= 1.4187861 - Gamma=36.6271164 (M=  38) - s=0.0100\n",
      "  86 - L= 1.4190073 - Gamma=36.6156395 (M=  38) - s=0.0100\n",
      "  87 - L= 1.4192069 - Gamma=36.6150988 (M=  38) - s=0.0100\n",
      "  88 - L= 1.4194011 - Gamma=36.6161669 (M=  38) - s=0.0100\n",
      "  89 - L= 1.4195868 - Gamma=36.6417104 (M=  38) - s=0.0100\n",
      "  90 - L= 1.4198792 - Gamma=36.5110714 (M=  38) - s=0.0100\n",
      "  91 - L= 1.4202997 - Gamma=36.6669309 (M=  39) - s=0.0100\n",
      "  92 - L= 1.4208556 - Gamma=36.4859302 (M=  38) - s=0.0100\n",
      "  93 - L= 1.4211590 - Gamma=36.6151560 (M=  38) - s=0.0100\n",
      "  94 - L= 1.4213687 - Gamma=36.6212286 (M=  38) - s=0.0100\n",
      "  95 - L= 1.4215227 - Gamma=36.6245867 (M=  38) - s=0.0100\n",
      "  96 - L= 1.4216476 - Gamma=36.6241623 (M=  38) - s=0.0100\n",
      "  97 - L= 1.4217604 - Gamma=36.6244545 (M=  38) - s=0.0100\n",
      "  98 - L= 1.4218613 - Gamma=36.5962379 (M=  38) - s=0.0100\n",
      "  99 - L= 1.4219857 - Gamma=36.5684216 (M=  38) - s=0.0100\n",
      " 100 - L= 1.4220938 - Gamma=36.5690361 (M=  38) - s=0.0100\n",
      " 101 - L= 1.4222001 - Gamma=36.5683787 (M=  38) - s=0.0100\n",
      " 102 - L= 1.4223020 - Gamma=36.5681897 (M=  38) - s=0.0100\n",
      " 103 - L= 1.4223519 - Gamma=36.5682079 (M=  38) - s=0.0100\n",
      " 104 - L= 1.4223953 - Gamma=36.5693573 (M=  38) - s=0.0100\n",
      " 105 - L= 1.4224332 - Gamma=36.5693175 (M=  38) - s=0.0100\n",
      " 106 - L= 1.4224648 - Gamma=36.5693329 (M=  38) - s=0.0100\n",
      " 107 - L= 1.4224956 - Gamma=36.5688176 (M=  38) - s=0.0100\n",
      " 108 - L= 1.4225212 - Gamma=36.5324068 (M=  38) - s=0.0100\n",
      " 109 - L= 1.4225481 - Gamma=36.5914517 (M=  39) - s=0.0100\n",
      " 110 - L= 1.4225814 - Gamma=36.5933856 (M=  39) - s=0.0100\n",
      " 111 - L= 1.4226102 - Gamma=36.5887863 (M=  39) - s=0.0100\n",
      " 112 - L= 1.4226358 - Gamma=36.5749918 (M=  39) - s=0.0100\n",
      " 113 - L= 1.4226746 - Gamma=36.5559028 (M=  39) - s=0.0100\n",
      " 114 - L= 1.4227005 - Gamma=36.5550745 (M=  39) - s=0.0100\n",
      " 115 - L= 1.4227296 - Gamma=36.6122824 (M=  39) - s=0.0100\n",
      " 116 - L= 1.4227811 - Gamma=36.5569046 (M=  39) - s=0.0100\n",
      " 117 - L= 1.4228191 - Gamma=36.5582713 (M=  39) - s=0.0100\n",
      " 118 - L= 1.4228552 - Gamma=36.5407857 (M=  39) - s=0.0100\n",
      " 119 - L= 1.4228907 - Gamma=36.5995595 (M=  39) - s=0.0100\n",
      " 120 - L= 1.4229400 - Gamma=36.6108779 (M=  39) - s=0.0100\n",
      " 121 - L= 1.4229998 - Gamma=36.5448159 (M=  39) - s=0.0100\n",
      " 122 - L= 1.4230272 - Gamma=36.5400596 (M=  39) - s=0.0100\n",
      " 123 - L= 1.4230615 - Gamma=36.5937617 (M=  39) - s=0.0100\n",
      " 124 - L= 1.4231110 - Gamma=36.5714948 (M=  39) - s=0.0100\n",
      " 125 - L= 1.4231623 - Gamma=36.5477783 (M=  39) - s=0.0100\n",
      " 126 - L= 1.4232089 - Gamma=36.5497241 (M=  39) - s=0.0100\n",
      " 127 - L= 1.4232377 - Gamma=36.5002119 (M=  39) - s=0.0100\n",
      " 128 - L= 1.4232857 - Gamma=36.5586561 (M=  39) - s=0.0100\n",
      " 129 - L= 1.4233363 - Gamma=36.5689070 (M=  39) - s=0.0100\n",
      " 130 - L= 1.4233893 - Gamma=36.5436268 (M=  39) - s=0.0100\n",
      " 131 - L= 1.4234671 - Gamma=36.4533354 (M=  39) - s=0.0100\n",
      " 132 - L= 1.4235390 - Gamma=36.4548941 (M=  39) - s=0.0100\n",
      " 133 - L= 1.4236100 - Gamma=36.4534399 (M=  39) - s=0.0100\n",
      " 134 - L= 1.4236820 - Gamma=36.5185734 (M=  39) - s=0.0100\n",
      " 135 - L= 1.4237420 - Gamma=36.5108867 (M=  39) - s=0.0100\n",
      " 136 - L= 1.4237988 - Gamma=36.4323404 (M=  38) - s=0.0100\n",
      " 137 - L= 1.4239291 - Gamma=36.3861830 (M=  38) - s=0.0100\n",
      " 138 - L= 1.4240273 - Gamma=36.3498477 (M=  38) - s=0.0100\n",
      " 139 - L= 1.4241068 - Gamma=36.4112090 (M=  38) - s=0.0100\n",
      " 140 - L= 1.4241957 - Gamma=36.4233680 (M=  38) - s=0.0100\n",
      " 141 - L= 1.4242711 - Gamma=36.4229250 (M=  38) - s=0.0100\n",
      " 142 - L= 1.4243430 - Gamma=36.4257803 (M=  38) - s=0.0100\n",
      " 143 - L= 1.4243992 - Gamma=36.4276069 (M=  38) - s=0.0100\n",
      " 144 - L= 1.4244547 - Gamma=36.3938541 (M=  38) - s=0.0100\n",
      " 145 - L= 1.4245094 - Gamma=36.3920458 (M=  38) - s=0.0100\n",
      " 146 - L= 1.4245582 - Gamma=36.3923948 (M=  38) - s=0.0100\n",
      " 147 - L= 1.4245978 - Gamma=36.3922740 (M=  38) - s=0.0100\n",
      " 148 - L= 1.4246377 - Gamma=36.3854742 (M=  38) - s=0.0100\n",
      " 149 - L= 1.4246812 - Gamma=36.3587549 (M=  38) - s=0.0100\n",
      " 150 - L= 1.4247403 - Gamma=36.4061608 (M=  38) - s=0.0100\n",
      " 151 - L= 1.4247939 - Gamma=36.4072852 (M=  38) - s=0.0100\n",
      " 152 - L= 1.4248578 - Gamma=36.3672406 (M=  38) - s=0.0100\n",
      " 153 - L= 1.4249010 - Gamma=36.3668159 (M=  38) - s=0.0100\n",
      " 154 - L= 1.4249437 - Gamma=36.3663667 (M=  38) - s=0.0100\n",
      " 155 - L= 1.4249851 - Gamma=36.3657576 (M=  38) - s=0.0100\n",
      " 156 - L= 1.4250209 - Gamma=36.3659945 (M=  38) - s=0.0100\n",
      " 157 - L= 1.4250578 - Gamma=36.3394034 (M=  38) - s=0.0100\n",
      " 158 - L= 1.4250959 - Gamma=36.3391679 (M=  38) - s=0.0100\n",
      " 159 - L= 1.4251324 - Gamma=36.3380186 (M=  38) - s=0.0100\n",
      " 160 - L= 1.4251617 - Gamma=36.3378108 (M=  38) - s=0.0100\n",
      " 161 - L= 1.4251887 - Gamma=36.3378870 (M=  38) - s=0.0100\n",
      " 162 - L= 1.4252147 - Gamma=36.3389575 (M=  38) - s=0.0100\n",
      " 163 - L= 1.4252444 - Gamma=36.3093389 (M=  38) - s=0.0100\n",
      " 164 - L= 1.4252835 - Gamma=36.3445414 (M=  38) - s=0.0100\n",
      " 165 - L= 1.4253153 - Gamma=36.3380265 (M=  38) - s=0.0100\n",
      " 166 - L= 1.4253430 - Gamma=36.3388441 (M=  38) - s=0.0100\n",
      " 167 - L= 1.4253697 - Gamma=36.3146119 (M=  38) - s=0.0100\n",
      " 168 - L= 1.4254009 - Gamma=36.3705688 (M=  39) - s=0.0100\n",
      " 169 - L= 1.4254918 - Gamma=36.3146772 (M=  39) - s=0.0100\n",
      " 170 - L= 1.4255523 - Gamma=36.3539678 (M=  39) - s=0.0100\n",
      " 171 - L= 1.4256727 - Gamma=36.4527321 (M=  39) - s=0.0100\n",
      " 172 - L= 1.4258409 - Gamma=36.3845848 (M=  39) - s=0.0100\n",
      " 173 - L= 1.4261958 - Gamma=36.2541290 (M=  39) - s=0.0100\n",
      " 174 - L= 1.4264689 - Gamma=36.3838036 (M=  39) - s=0.0100\n",
      " 175 - L= 1.4269029 - Gamma=36.4678770 (M=  39) - s=0.0100\n",
      " 176 - L= 1.4274192 - Gamma=36.3105591 (M=  39) - s=0.0100\n",
      " 177 - L= 1.4286686 - Gamma=36.1195707 (M=  38) - s=0.0100\n",
      " 178 - L= 1.4294159 - Gamma=36.0779824 (M=  38) - s=0.0100\n",
      " 179 - L= 1.4301831 - Gamma=36.2514622 (M=  38) - s=0.0100\n",
      " 180 - L= 1.4309365 - Gamma=35.9568496 (M=  38) - s=0.0100\n",
      " 181 - L= 1.4314464 - Gamma=36.0275758 (M=  38) - s=0.0100\n",
      " 182 - L= 1.4318936 - Gamma=36.0306983 (M=  38) - s=0.0100\n",
      " 183 - L= 1.4319285 - Gamma=35.9595861 (M=  37) - s=0.0100\n",
      " 184 - L= 1.4322547 - Gamma=35.9539523 (M=  37) - s=0.0100\n",
      " 185 - L= 1.4325148 - Gamma=35.9546770 (M=  37) - s=0.0100\n",
      " 186 - L= 1.4327518 - Gamma=35.9561686 (M=  37) - s=0.0100\n",
      " 187 - L= 1.4329850 - Gamma=35.9526674 (M=  37) - s=0.0100\n",
      " 188 - L= 1.4331516 - Gamma=36.0171638 (M=  37) - s=0.0100\n",
      " 189 - L= 1.4333674 - Gamma=36.1830705 (M=  38) - s=0.0100\n",
      " 190 - L= 1.4335265 - Gamma=36.1848281 (M=  38) - s=0.0100\n",
      " 191 - L= 1.4336436 - Gamma=36.1636683 (M=  38) - s=0.0100\n",
      " 192 - L= 1.4337821 - Gamma=36.1937457 (M=  38) - s=0.0100\n",
      " 193 - L= 1.4339086 - Gamma=36.1928975 (M=  38) - s=0.0100\n",
      " 194 - L= 1.4340081 - Gamma=36.1924593 (M=  38) - s=0.0100\n",
      " 195 - L= 1.4340924 - Gamma=36.2323199 (M=  38) - s=0.0100\n",
      " 196 - L= 1.4341759 - Gamma=36.2319370 (M=  38) - s=0.0100\n",
      " 197 - L= 1.4342442 - Gamma=36.2314180 (M=  38) - s=0.0100\n",
      " 198 - L= 1.4342910 - Gamma=36.2314064 (M=  38) - s=0.0100\n",
      " 199 - L= 1.4343322 - Gamma=36.2307673 (M=  38) - s=0.0100\n",
      " 200 - L= 1.4343638 - Gamma=36.2874049 (M=  38) - s=0.0100\n",
      "Initial alpha = [[0.07343726]]\n",
      "   1 - L=-555.9657989 - Gamma= 1.9998983 (M=   2) - s=0.0100\n",
      "   2 - L=-441.1005533 - Gamma= 2.9997953 (M=   3) - s=0.0100\n",
      "   3 - L=-353.5262239 - Gamma= 3.9996054 (M=   4) - s=0.0100\n",
      "   4 - L=-314.6451216 - Gamma= 4.9993058 (M=   5) - s=0.0100\n",
      "   5 - L=-251.7064139 - Gamma= 5.9988886 (M=   6) - s=0.0100\n",
      "   6 - L=-231.0563054 - Gamma= 6.9981263 (M=   7) - s=0.0100\n",
      "   7 - L=-213.0122525 - Gamma= 7.9973576 (M=   8) - s=0.0100\n",
      "   8 - L=-191.2205780 - Gamma= 8.9967421 (M=   9) - s=0.0100\n",
      "   9 - L=-172.6231092 - Gamma= 9.9960341 (M=  10) - s=0.0100\n",
      "  10 - L=-159.4065934 - Gamma=10.9946877 (M=  11) - s=0.0100\n",
      "  11 - L=-142.9240793 - Gamma=11.9938446 (M=  12) - s=0.0100\n",
      "  12 - L=-128.7045436 - Gamma=12.9926109 (M=  13) - s=0.0100\n",
      "  13 - L=-117.2271709 - Gamma=13.9914374 (M=  14) - s=0.0100\n",
      "  14 - L=-108.8780946 - Gamma=14.9898205 (M=  15) - s=0.0100\n",
      "  15 - L=-94.5207279 - Gamma=15.9886415 (M=  16) - s=0.0100\n",
      "  16 - L=-84.4066771 - Gamma=16.9865003 (M=  17) - s=0.0100\n",
      "  17 - L=-73.3728699 - Gamma=17.9850300 (M=  18) - s=0.0100\n",
      "  18 - L=-65.2557606 - Gamma=18.9801777 (M=  19) - s=0.0100\n",
      "  19 - L=-58.6715597 - Gamma=19.9771348 (M=  20) - s=0.0100\n",
      "  20 - L=-51.4484914 - Gamma=20.9743892 (M=  21) - s=0.0100\n",
      "  21 - L=-46.5186407 - Gamma=21.9710769 (M=  22) - s=0.0100\n",
      "  22 - L=-41.8505224 - Gamma=22.9670368 (M=  23) - s=0.0100\n",
      "  23 - L=-41.7625481 - Gamma=21.9698227 (M=  22) - s=0.0100\n",
      "  24 - L=-37.0359871 - Gamma=22.9669293 (M=  23) - s=0.0100\n",
      "  25 - L=-34.6534184 - Gamma=23.9613237 (M=  24) - s=0.0100\n",
      "  26 - L=-29.9362371 - Gamma=24.9565862 (M=  25) - s=0.0100\n",
      "  27 - L=-26.2608984 - Gamma=25.9458642 (M=  26) - s=0.0100\n",
      "  28 - L=-22.6122677 - Gamma=26.9418709 (M=  27) - s=0.0100\n",
      "  29 - L=-17.9294892 - Gamma=27.9357309 (M=  28) - s=0.0100\n",
      "  30 - L=-14.4092723 - Gamma=28.9307188 (M=  29) - s=0.0100\n",
      "  31 - L=-8.6854790 - Gamma=29.9141871 (M=  30) - s=0.0100\n",
      "  32 - L=-6.6232060 - Gamma=30.9037682 (M=  31) - s=0.0100\n",
      "  33 - L=-4.7901888 - Gamma=31.8921174 (M=  32) - s=0.0100\n",
      "  34 - L=-4.0627889 - Gamma=32.8712394 (M=  33) - s=0.0100\n",
      "  35 - L=-3.2411824 - Gamma=33.8450462 (M=  34) - s=0.0100\n",
      "  36 - L=-2.4036826 - Gamma=34.8127036 (M=  35) - s=0.0100\n",
      "  37 - L=-2.3462392 - Gamma=33.8411485 (M=  34) - s=0.0100\n",
      "  38 - L=-1.6797516 - Gamma=34.7997338 (M=  35) - s=0.0100\n",
      "  39 - L=-0.9633854 - Gamma=35.7681105 (M=  36) - s=0.0100\n",
      "  40 - L=-0.9072042 - Gamma=34.7978505 (M=  35) - s=0.0100\n",
      "  41 - L=-0.3267802 - Gamma=35.7611573 (M=  36) - s=0.0100\n",
      "  42 - L=-0.0161068 - Gamma=35.7670815 (M=  36) - s=0.0100\n",
      "  43 - L= 0.1268559 - Gamma=36.6701743 (M=  37) - s=0.0100\n",
      "  44 - L= 0.2162711 - Gamma=36.6883746 (M=  37) - s=0.0100\n",
      "  45 - L= 0.2812104 - Gamma=37.5618165 (M=  38) - s=0.0100\n",
      "  46 - L= 0.3630798 - Gamma=38.4076326 (M=  39) - s=0.0100\n",
      "  47 - L= 0.4420033 - Gamma=39.2984928 (M=  40) - s=0.0100\n",
      "  48 - L= 0.5107595 - Gamma=39.3299001 (M=  40) - s=0.0100\n",
      "  49 - L= 0.5720385 - Gamma=39.3326623 (M=  40) - s=0.0100\n",
      "  50 - L= 0.6259615 - Gamma=39.3390020 (M=  40) - s=0.0100\n",
      "  51 - L= 0.6696290 - Gamma=39.3438860 (M=  40) - s=0.0100\n",
      "  52 - L= 0.7101052 - Gamma=39.3552662 (M=  40) - s=0.0100\n",
      "  53 - L= 0.7431746 - Gamma=39.3570077 (M=  40) - s=0.0100\n",
      "  54 - L= 0.7763451 - Gamma=39.1913161 (M=  40) - s=0.0100\n",
      "  55 - L= 0.8079723 - Gamma=39.8501282 (M=  41) - s=0.0100\n",
      "  56 - L= 0.8300059 - Gamma=39.2065912 (M=  40) - s=0.0100\n",
      "  57 - L= 0.8559790 - Gamma=39.2086015 (M=  40) - s=0.0100\n",
      "  58 - L= 0.8761871 - Gamma=39.2137544 (M=  40) - s=0.0100\n",
      "  59 - L= 0.8932380 - Gamma=39.2159145 (M=  40) - s=0.0100\n",
      "  60 - L= 0.9073996 - Gamma=39.2218852 (M=  40) - s=0.0100\n",
      "  61 - L= 0.9214089 - Gamma=39.2729754 (M=  40) - s=0.0100\n",
      "  62 - L= 0.9353370 - Gamma=39.2744740 (M=  40) - s=0.0100\n",
      "  63 - L= 0.9489522 - Gamma=39.2788724 (M=  40) - s=0.0100\n",
      "  64 - L= 0.9624255 - Gamma=39.2804221 (M=  40) - s=0.0100\n",
      "  65 - L= 0.9755442 - Gamma=39.2884792 (M=  40) - s=0.0100\n",
      "  66 - L= 0.9885795 - Gamma=39.2924142 (M=  40) - s=0.0100\n",
      "  67 - L= 0.9999563 - Gamma=39.2951198 (M=  40) - s=0.0100\n",
      "  68 - L= 1.0091929 - Gamma=38.7216996 (M=  40) - s=0.0100\n",
      "  69 - L= 1.0181059 - Gamma=38.7228987 (M=  40) - s=0.0100\n",
      "  70 - L= 1.0261002 - Gamma=38.7086904 (M=  40) - s=0.0100\n",
      "  71 - L= 1.0333883 - Gamma=38.7780797 (M=  40) - s=0.0100\n",
      "  72 - L= 1.0394030 - Gamma=38.7853780 (M=  40) - s=0.0100\n",
      "  73 - L= 1.0451975 - Gamma=38.7874894 (M=  40) - s=0.0100\n",
      "  74 - L= 1.0500309 - Gamma=38.7985599 (M=  40) - s=0.0100\n",
      "  75 - L= 1.0545253 - Gamma=38.8045538 (M=  40) - s=0.0100\n",
      "  76 - L= 1.0584713 - Gamma=38.8148295 (M=  40) - s=0.0100\n",
      "  77 - L= 1.0613222 - Gamma=38.8159471 (M=  40) - s=0.0100\n",
      "  78 - L= 1.0635954 - Gamma=38.8166750 (M=  40) - s=0.0100\n",
      "  79 - L= 1.0657255 - Gamma=39.2369651 (M=  41) - s=0.0100\n",
      "  80 - L= 1.0677703 - Gamma=39.2377065 (M=  41) - s=0.0100\n",
      "  81 - L= 1.0696379 - Gamma=39.2751496 (M=  41) - s=0.0100\n",
      "  82 - L= 1.0702211 - Gamma=39.0388922 (M=  40) - s=0.0100\n",
      "  83 - L= 1.0715542 - Gamma=39.0623721 (M=  40) - s=0.0100\n",
      "  84 - L= 1.0725388 - Gamma=39.3830147 (M=  41) - s=0.0100\n",
      "  85 - L= 1.0731966 - Gamma=39.3842135 (M=  41) - s=0.0100\n",
      "  86 - L= 1.0736129 - Gamma=39.3861714 (M=  41) - s=0.0100\n",
      "  87 - L= 1.0738495 - Gamma=39.3833837 (M=  41) - s=0.0100\n",
      "  88 - L= 1.0740716 - Gamma=39.3834940 (M=  41) - s=0.0100\n",
      "  89 - L= 1.0741760 - Gamma=39.3837961 (M=  41) - s=0.0100\n",
      "  90 - L= 1.0742402 - Gamma=39.3835926 (M=  41) - s=0.0100\n",
      "  91 - L= 1.0742843 - Gamma=39.3835042 (M=  41) - s=0.0100\n",
      "  92 - L= 1.0743237 - Gamma=39.3751901 (M=  41) - s=0.0100\n",
      "  93 - L= 1.0743479 - Gamma=39.3753749 (M=  41) - s=0.0100\n",
      "  94 - L= 1.0743719 - Gamma=39.3787408 (M=  41) - s=0.0100\n",
      "  95 - L= 1.0743951 - Gamma=39.3787552 (M=  41) - s=0.0100\n",
      "  96 - L= 1.0744138 - Gamma=39.3788711 (M=  41) - s=0.0100\n",
      "  97 - L= 1.0744310 - Gamma=39.3793844 (M=  41) - s=0.0100\n",
      "  98 - L= 1.0744472 - Gamma=39.3793422 (M=  41) - s=0.0100\n",
      "  99 - L= 1.0744588 - Gamma=39.3794985 (M=  41) - s=0.0100\n",
      " 100 - L= 1.0744694 - Gamma=39.3802983 (M=  41) - s=0.0100\n",
      " 101 - L= 1.0744774 - Gamma=39.3803493 (M=  41) - s=0.0100\n",
      " 102 - L= 1.0744830 - Gamma=39.3806363 (M=  41) - s=0.0100\n",
      " 103 - L= 1.0744884 - Gamma=39.3807931 (M=  41) - s=0.0100\n",
      " 104 - L= 1.0744933 - Gamma=39.4000468 (M=  41) - s=0.0100\n",
      " 105 - L= 1.0744986 - Gamma=39.3986651 (M=  41) - s=0.0100\n",
      " 106 - L= 1.0745040 - Gamma=39.3973632 (M=  41) - s=0.0100\n",
      " 107 - L= 1.0745089 - Gamma=39.3967361 (M=  41) - s=0.0100\n",
      " 108 - L= 1.0745129 - Gamma=39.3966864 (M=  41) - s=0.0100\n",
      " 109 - L= 1.0745162 - Gamma=39.3966923 (M=  41) - s=0.0100\n",
      " 110 - L= 1.0745193 - Gamma=39.3965670 (M=  41) - s=0.0100\n",
      " 111 - L= 1.0745222 - Gamma=39.3965815 (M=  41) - s=0.0100\n",
      " 112 - L= 1.0745248 - Gamma=39.3842714 (M=  41) - s=0.0100\n",
      " 113 - L= 1.0745270 - Gamma=39.3842958 (M=  41) - s=0.0100\n",
      " 114 - L= 1.0745290 - Gamma=39.3843411 (M=  41) - s=0.0100\n",
      " 115 - L= 1.0745306 - Gamma=39.3843477 (M=  41) - s=0.0100\n",
      " 116 - L= 1.0745321 - Gamma=39.3843206 (M=  41) - s=0.0100\n",
      " 117 - L= 1.0745331 - Gamma=39.3843034 (M=  41) - s=0.0100\n",
      " 118 - L= 1.0745338 - Gamma=39.3843094 (M=  41) - s=0.0100\n",
      " 119 - L= 1.0745343 - Gamma=39.3904475 (M=  41) - s=0.0100\n",
      " 120 - L= 1.0745346 - Gamma=39.3904396 (M=  41) - s=0.0100\n",
      " 121 - L= 1.0745349 - Gamma=39.3904454 (M=  41) - s=0.0100\n",
      " 122 - L= 1.0745352 - Gamma=39.3911388 (M=  41) - s=0.0100\n",
      " 123 - L= 1.0745355 - Gamma=39.3911283 (M=  41) - s=0.0100\n",
      " 124 - L= 1.0745357 - Gamma=39.3911240 (M=  41) - s=0.0100\n",
      " 125 - L= 1.0745358 - Gamma=39.3910835 (M=  41) - s=0.0100\n",
      " 126 - L= 1.0745359 - Gamma=39.3910929 (M=  41) - s=0.0100\n",
      " 127 - L= 1.0745360 - Gamma=39.3910888 (M=  41) - s=0.0100\n",
      " 128 - L= 1.0745361 - Gamma=39.3912610 (M=  41) - s=0.0100\n",
      " 129 - L= 1.0745361 - Gamma=39.3895105 (M=  41) - s=0.0100\n",
      " 130 - L= 1.0745362 - Gamma=39.3894671 (M=  41) - s=0.0100\n",
      " 131 - L= 1.0745362 - Gamma=39.3894718 (M=  41) - s=0.0100\n",
      " 132 - L= 1.0745362 - Gamma=39.3894685 (M=  41) - s=0.0100\n",
      " 133 - L= 1.0745362 - Gamma=39.3894629 (M=  41) - s=0.0100\n",
      " 134 - L= 1.0745362 - Gamma=39.3894400 (M=  41) - s=0.0100\n",
      " 135 - L= 1.0745363 - Gamma=39.3904547 (M=  41) - s=0.0100\n",
      " 136 - L= 1.0745363 - Gamma=39.3903897 (M=  41) - s=0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in log\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 137 - L= 1.0745363 - Gamma=39.3903287 (M=  41) - s=0.0100\n",
      " 138 - L= 1.0745363 - Gamma=39.3903259 (M=  41) - s=0.0100\n",
      " 139 - L= 1.0745363 - Gamma=39.3904506 (M=  41) - s=0.0100\n",
      " 140 - L= 1.0745363 - Gamma=39.3904607 (M=  41) - s=0.0100\n",
      " 141 - L= 1.0745363 - Gamma=39.3904640 (M=  41) - s=0.0100\n",
      " 142 - L= 1.0745363 - Gamma=39.3904631 (M=  41) - s=0.0100\n",
      " 143 - L= 1.0745363 - Gamma=39.3904686 (M=  41) - s=0.0100\n",
      " 144 - L= 1.0745363 - Gamma=39.3904686 (M=  41) - s=0.0100\n",
      "Stopping at iteration 144 - max_delta_ml=2.3286951638512967e-07\n",
      "L=1.0745363221870379 - Gamma=39.39046858468963 (M=41) - s=0.01\n",
      "Initial alpha = [[0.07497704]]\n",
      "   1 - L=-577.6855769 - Gamma= 1.9999130 (M=   2) - s=0.0100\n",
      "   2 - L=-494.3435539 - Gamma= 2.9997521 (M=   3) - s=0.0100\n",
      "   3 - L=-442.5026611 - Gamma= 3.9994503 (M=   4) - s=0.0100\n",
      "   4 - L=-398.7133525 - Gamma= 4.9989683 (M=   5) - s=0.0100\n",
      "   5 - L=-341.1181294 - Gamma= 5.9984319 (M=   6) - s=0.0100\n",
      "   6 - L=-310.9214620 - Gamma= 6.9979652 (M=   7) - s=0.0100\n",
      "   7 - L=-272.9617872 - Gamma= 7.9975216 (M=   8) - s=0.0100\n",
      "   8 - L=-241.2077586 - Gamma= 8.9970612 (M=   9) - s=0.0100\n",
      "   9 - L=-241.1277411 - Gamma= 7.9976355 (M=   8) - s=0.0100\n",
      "  10 - L=-198.2760583 - Gamma= 8.9971788 (M=   9) - s=0.0100\n",
      "  11 - L=-170.8996527 - Gamma= 9.9965556 (M=  10) - s=0.0100\n",
      "  12 - L=-158.2633007 - Gamma=10.9954525 (M=  11) - s=0.0100\n",
      "  13 - L=-145.3380564 - Gamma=11.9943976 (M=  12) - s=0.0100\n",
      "  14 - L=-131.1991841 - Gamma=12.9934796 (M=  13) - s=0.0100\n",
      "  15 - L=-119.1397106 - Gamma=13.9824729 (M=  14) - s=0.0100\n",
      "  16 - L=-107.0453977 - Gamma=14.9809199 (M=  15) - s=0.0100\n",
      "  17 - L=-93.3909732 - Gamma=15.9797199 (M=  16) - s=0.0100\n",
      "  18 - L=-85.0418398 - Gamma=16.9767666 (M=  17) - s=0.0100\n",
      "  19 - L=-78.0776702 - Gamma=17.9749064 (M=  18) - s=0.0100\n",
      "  20 - L=-63.3203797 - Gamma=18.9729639 (M=  19) - s=0.0100\n",
      "  21 - L=-63.2467471 - Gamma=17.9741033 (M=  18) - s=0.0100\n",
      "  22 - L=-54.2895308 - Gamma=18.9716740 (M=  19) - s=0.0100\n",
      "  23 - L=-42.7558157 - Gamma=19.9691781 (M=  20) - s=0.0100\n",
      "  24 - L=-35.5386940 - Gamma=20.9673427 (M=  21) - s=0.0100\n",
      "  25 - L=-30.3881761 - Gamma=21.9630747 (M=  22) - s=0.0100\n",
      "  26 - L=-26.2188661 - Gamma=22.9566152 (M=  23) - s=0.0100\n",
      "  27 - L=-22.4612071 - Gamma=23.9522953 (M=  24) - s=0.0100\n",
      "  28 - L=-18.3240604 - Gamma=24.9481500 (M=  25) - s=0.0100\n",
      "  29 - L=-14.5608932 - Gamma=25.9439757 (M=  26) - s=0.0100\n",
      "  30 - L=-12.3032608 - Gamma=26.9324398 (M=  27) - s=0.0100\n",
      "  31 - L=-10.0615431 - Gamma=27.9116202 (M=  28) - s=0.0100\n",
      "  32 - L=-8.5681835 - Gamma=28.8985800 (M=  29) - s=0.0100\n",
      "  33 - L=-6.7219150 - Gamma=29.8828460 (M=  30) - s=0.0100\n",
      "  34 - L=-5.5686737 - Gamma=30.8689962 (M=  31) - s=0.0100\n",
      "  35 - L=-4.4758876 - Gamma=31.8550552 (M=  32) - s=0.0100\n",
      "  36 - L=-4.4302678 - Gamma=30.8800081 (M=  31) - s=0.0100\n",
      "  37 - L=-3.3504486 - Gamma=31.8669620 (M=  32) - s=0.0100\n",
      "  38 - L=-2.3428462 - Gamma=31.8944634 (M=  32) - s=0.0100\n",
      "  39 - L=-1.5813590 - Gamma=32.8766863 (M=  33) - s=0.0100\n",
      "  40 - L=-1.5257333 - Gamma=31.8881178 (M=  32) - s=0.0100\n",
      "  41 - L=-1.0714790 - Gamma=32.8627409 (M=  33) - s=0.0100\n",
      "  42 - L=-0.7519836 - Gamma=33.8247259 (M=  34) - s=0.0100\n",
      "  43 - L=-0.4951739 - Gamma=34.7696411 (M=  35) - s=0.0100\n",
      "  44 - L=-0.2038885 - Gamma=35.6879253 (M=  36) - s=0.0100\n",
      "  45 - L= 0.0048324 - Gamma=36.6181922 (M=  37) - s=0.0100\n",
      "  46 - L= 0.3278536 - Gamma=37.5694877 (M=  38) - s=0.0100\n",
      "  47 - L= 0.4823979 - Gamma=38.4801873 (M=  39) - s=0.0100\n",
      "  48 - L= 0.6100719 - Gamma=39.3625287 (M=  40) - s=0.0100\n",
      "  49 - L= 0.7114630 - Gamma=39.3669674 (M=  40) - s=0.0100\n",
      "  50 - L= 0.7935774 - Gamma=40.2005988 (M=  41) - s=0.0100\n",
      "  51 - L= 0.8673544 - Gamma=40.2089538 (M=  41) - s=0.0100\n",
      "  52 - L= 0.8982373 - Gamma=40.2160086 (M=  41) - s=0.0100\n",
      "  53 - L= 0.9259563 - Gamma=40.9539437 (M=  42) - s=0.0100\n",
      "  54 - L= 0.9542356 - Gamma=40.4422195 (M=  42) - s=0.0100\n",
      "  55 - L= 0.9706773 - Gamma=40.4473563 (M=  42) - s=0.0100\n",
      "  56 - L= 0.9871228 - Gamma=40.4493944 (M=  42) - s=0.0100\n",
      "  57 - L= 1.0016309 - Gamma=40.4712404 (M=  42) - s=0.0100\n",
      "  58 - L= 1.0195809 - Gamma=41.0240521 (M=  43) - s=0.0100\n",
      "  59 - L= 1.0220804 - Gamma=40.7113937 (M=  42) - s=0.0100\n",
      "  60 - L= 1.0483858 - Gamma=40.7925842 (M=  42) - s=0.0100\n",
      "  61 - L= 1.0666703 - Gamma=40.8230307 (M=  42) - s=0.0100\n",
      "  62 - L= 1.0804072 - Gamma=40.8240447 (M=  42) - s=0.0100\n",
      "  63 - L= 1.0901966 - Gamma=40.8249744 (M=  42) - s=0.0100\n",
      "  64 - L= 1.0999465 - Gamma=40.8385384 (M=  42) - s=0.0100\n",
      "  65 - L= 1.1102054 - Gamma=40.8687113 (M=  42) - s=0.0100\n",
      "  66 - L= 1.1168224 - Gamma=40.8771662 (M=  42) - s=0.0100\n",
      "  67 - L= 1.1222515 - Gamma=40.8671501 (M=  42) - s=0.0100\n",
      "  68 - L= 1.1270850 - Gamma=40.8681228 (M=  42) - s=0.0100\n",
      "  69 - L= 1.1313037 - Gamma=40.8618703 (M=  42) - s=0.0100\n",
      "  70 - L= 1.1351203 - Gamma=40.8576744 (M=  42) - s=0.0100\n",
      "  71 - L= 1.1387530 - Gamma=40.8587769 (M=  42) - s=0.0100\n",
      "  72 - L= 1.1423266 - Gamma=40.7851998 (M=  42) - s=0.0100\n",
      "  73 - L= 1.1458642 - Gamma=40.7972346 (M=  42) - s=0.0100\n",
      "  74 - L= 1.1492310 - Gamma=40.7984645 (M=  42) - s=0.0100\n",
      "  75 - L= 1.1522671 - Gamma=40.8006624 (M=  42) - s=0.0100\n",
      "  76 - L= 1.1546463 - Gamma=40.8042909 (M=  42) - s=0.0100\n",
      "  77 - L= 1.1568863 - Gamma=40.7176923 (M=  42) - s=0.0100\n",
      "  78 - L= 1.1599645 - Gamma=40.8052121 (M=  42) - s=0.0100\n",
      "  79 - L= 1.1624788 - Gamma=40.8125629 (M=  42) - s=0.0100\n",
      "  80 - L= 1.1648418 - Gamma=40.6160075 (M=  42) - s=0.0100\n",
      "  81 - L= 1.1668931 - Gamma=40.6102892 (M=  42) - s=0.0100\n",
      "  82 - L= 1.1682790 - Gamma=40.6314629 (M=  42) - s=0.0100\n",
      "  83 - L= 1.1691153 - Gamma=40.6401496 (M=  42) - s=0.0100\n",
      "  84 - L= 1.1697666 - Gamma=40.6432006 (M=  42) - s=0.0100\n",
      "  85 - L= 1.1702870 - Gamma=40.6487043 (M=  42) - s=0.0100\n",
      "  86 - L= 1.1708692 - Gamma=40.5701536 (M=  42) - s=0.0100\n",
      "  87 - L= 1.1713893 - Gamma=40.5790514 (M=  42) - s=0.0100\n",
      "  88 - L= 1.1717624 - Gamma=40.5793282 (M=  42) - s=0.0100\n",
      "  89 - L= 1.1720951 - Gamma=40.5803777 (M=  42) - s=0.0100\n",
      "  90 - L= 1.1723784 - Gamma=40.5805366 (M=  42) - s=0.0100\n",
      "  91 - L= 1.1726156 - Gamma=40.5963825 (M=  42) - s=0.0100\n",
      "  92 - L= 1.1728479 - Gamma=40.5964827 (M=  42) - s=0.0100\n",
      "  93 - L= 1.1730424 - Gamma=40.5963935 (M=  42) - s=0.0100\n",
      "  94 - L= 1.1732376 - Gamma=40.5934461 (M=  42) - s=0.0100\n",
      "  95 - L= 1.1734166 - Gamma=40.5902669 (M=  42) - s=0.0100\n",
      "  96 - L= 1.1735822 - Gamma=40.5899287 (M=  42) - s=0.0100\n",
      "  97 - L= 1.1737293 - Gamma=40.5891889 (M=  42) - s=0.0100\n",
      "  98 - L= 1.1738749 - Gamma=40.5867348 (M=  42) - s=0.0100\n",
      "  99 - L= 1.1740087 - Gamma=40.5870061 (M=  42) - s=0.0100\n",
      " 100 - L= 1.1741357 - Gamma=40.5829336 (M=  42) - s=0.0100\n",
      " 101 - L= 1.1742333 - Gamma=40.5814678 (M=  42) - s=0.0100\n",
      " 102 - L= 1.1743075 - Gamma=40.5794499 (M=  42) - s=0.0100\n",
      " 103 - L= 1.1743812 - Gamma=40.5811047 (M=  42) - s=0.0100\n",
      " 104 - L= 1.1744454 - Gamma=40.5490814 (M=  42) - s=0.0100\n",
      " 105 - L= 1.1745176 - Gamma=40.5608626 (M=  42) - s=0.0100\n",
      " 106 - L= 1.1745763 - Gamma=40.5603747 (M=  42) - s=0.0100\n",
      " 107 - L= 1.1746280 - Gamma=40.5607095 (M=  42) - s=0.0100\n",
      " 108 - L= 1.1746788 - Gamma=40.5588698 (M=  42) - s=0.0100\n",
      " 109 - L= 1.1747289 - Gamma=40.5595939 (M=  42) - s=0.0100\n",
      " 110 - L= 1.1747670 - Gamma=40.5649902 (M=  42) - s=0.0100\n",
      " 111 - L= 1.1748047 - Gamma=40.5579458 (M=  42) - s=0.0100\n",
      " 112 - L= 1.1748498 - Gamma=40.5216577 (M=  42) - s=0.0100\n",
      " 113 - L= 1.1748948 - Gamma=40.4918164 (M=  42) - s=0.0100\n",
      " 114 - L= 1.1749363 - Gamma=40.4931096 (M=  42) - s=0.0100\n",
      " 115 - L= 1.1749711 - Gamma=40.4936055 (M=  42) - s=0.0100\n",
      " 116 - L= 1.1749967 - Gamma=40.4945122 (M=  42) - s=0.0100\n",
      " 117 - L= 1.1750159 - Gamma=40.4949036 (M=  42) - s=0.0100\n",
      " 118 - L= 1.1750330 - Gamma=40.4968281 (M=  42) - s=0.0100\n",
      " 119 - L= 1.1750500 - Gamma=40.5309004 (M=  43) - s=0.0100\n",
      " 120 - L= 1.1750676 - Gamma=40.5318644 (M=  43) - s=0.0100\n",
      " 121 - L= 1.1750835 - Gamma=40.5318000 (M=  43) - s=0.0100\n",
      " 122 - L= 1.1750976 - Gamma=40.5272571 (M=  43) - s=0.0100\n",
      " 123 - L= 1.1751139 - Gamma=40.5039946 (M=  43) - s=0.0100\n",
      " 124 - L= 1.1751338 - Gamma=40.5030386 (M=  43) - s=0.0100\n",
      " 125 - L= 1.1751584 - Gamma=40.5415558 (M=  43) - s=0.0100\n",
      " 126 - L= 1.1751787 - Gamma=40.5435094 (M=  43) - s=0.0100\n",
      " 127 - L= 1.1751995 - Gamma=40.5417043 (M=  43) - s=0.0100\n",
      " 128 - L= 1.1752180 - Gamma=40.5451213 (M=  43) - s=0.0100\n",
      " 129 - L= 1.1752373 - Gamma=40.5441040 (M=  43) - s=0.0100\n",
      " 130 - L= 1.1752555 - Gamma=40.5455477 (M=  43) - s=0.0100\n",
      " 131 - L= 1.1752729 - Gamma=40.5444138 (M=  43) - s=0.0100\n",
      " 132 - L= 1.1752915 - Gamma=40.5389298 (M=  43) - s=0.0100\n",
      " 133 - L= 1.1753262 - Gamma=40.5813112 (M=  43) - s=0.0100\n",
      " 134 - L= 1.1753620 - Gamma=40.5803274 (M=  43) - s=0.0100\n",
      " 135 - L= 1.1753973 - Gamma=40.5439017 (M=  43) - s=0.0100\n",
      " 136 - L= 1.1754204 - Gamma=40.5443533 (M=  43) - s=0.0100\n",
      " 137 - L= 1.1754424 - Gamma=40.5758212 (M=  43) - s=0.0100\n",
      " 138 - L= 1.1754835 - Gamma=40.5670109 (M=  43) - s=0.0100\n",
      " 139 - L= 1.1755233 - Gamma=40.5940823 (M=  43) - s=0.0100\n",
      " 140 - L= 1.1755654 - Gamma=40.6341427 (M=  43) - s=0.0100\n",
      " 141 - L= 1.1756387 - Gamma=40.6375740 (M=  43) - s=0.0100\n",
      " 142 - L= 1.1756867 - Gamma=40.6280828 (M=  43) - s=0.0100\n",
      " 143 - L= 1.1757362 - Gamma=40.6262520 (M=  43) - s=0.0100\n",
      " 144 - L= 1.1757807 - Gamma=40.6275370 (M=  43) - s=0.0100\n",
      " 145 - L= 1.1758347 - Gamma=40.5783472 (M=  43) - s=0.0100\n",
      " 146 - L= 1.1759207 - Gamma=40.6298889 (M=  43) - s=0.0100\n",
      " 147 - L= 1.1760194 - Gamma=40.6276531 (M=  43) - s=0.0100\n",
      " 148 - L= 1.1761302 - Gamma=40.6107804 (M=  43) - s=0.0100\n",
      " 149 - L= 1.1762324 - Gamma=40.6491426 (M=  43) - s=0.0100\n",
      " 150 - L= 1.1763904 - Gamma=40.7079967 (M=  43) - s=0.0100\n",
      " 151 - L= 1.1765279 - Gamma=40.7052674 (M=  43) - s=0.0100\n",
      " 152 - L= 1.1766447 - Gamma=40.7046170 (M=  43) - s=0.0100\n",
      " 153 - L= 1.1767899 - Gamma=40.6124108 (M=  43) - s=0.0100\n",
      " 154 - L= 1.1769579 - Gamma=40.5919758 (M=  43) - s=0.0100\n",
      " 155 - L= 1.1770653 - Gamma=40.5908754 (M=  43) - s=0.0100\n",
      " 156 - L= 1.1771791 - Gamma=40.5705345 (M=  43) - s=0.0100\n",
      " 157 - L= 1.1773769 - Gamma=40.6248440 (M=  43) - s=0.0100\n",
      " 158 - L= 1.1776052 - Gamma=40.6304776 (M=  43) - s=0.0100\n",
      " 159 - L= 1.1778337 - Gamma=40.6250163 (M=  43) - s=0.0100\n",
      " 160 - L= 1.1780689 - Gamma=40.6735081 (M=  43) - s=0.0100\n",
      " 161 - L= 1.1783204 - Gamma=40.6678040 (M=  43) - s=0.0100\n",
      " 162 - L= 1.1785920 - Gamma=40.7190384 (M=  43) - s=0.0100\n",
      " 163 - L= 1.1789675 - Gamma=40.6684572 (M=  43) - s=0.0100\n",
      " 164 - L= 1.1794874 - Gamma=40.4420035 (M=  43) - s=0.0100\n",
      " 165 - L= 1.1798658 - Gamma=40.4023328 (M=  43) - s=0.0100\n",
      " 166 - L= 1.1799193 - Gamma=40.3553859 (M=  42) - s=0.0100\n",
      " 167 - L= 1.1802726 - Gamma=40.5474995 (M=  43) - s=0.0100\n",
      " 168 - L= 1.1806103 - Gamma=40.5444896 (M=  43) - s=0.0100\n",
      " 169 - L= 1.1809562 - Gamma=40.5343974 (M=  43) - s=0.0100\n",
      " 170 - L= 1.1814726 - Gamma=40.5857826 (M=  43) - s=0.0100\n",
      " 171 - L= 1.1818903 - Gamma=40.6354152 (M=  43) - s=0.0100\n",
      " 172 - L= 1.1822946 - Gamma=40.6295929 (M=  43) - s=0.0100\n",
      " 173 - L= 1.1827174 - Gamma=40.6187800 (M=  43) - s=0.0100\n",
      " 174 - L= 1.1831777 - Gamma=40.5386323 (M=  43) - s=0.0100\n",
      " 175 - L= 1.1837219 - Gamma=40.5452390 (M=  43) - s=0.0100\n",
      " 176 - L= 1.1842140 - Gamma=40.5479646 (M=  43) - s=0.0100\n",
      " 177 - L= 1.1847070 - Gamma=40.5374565 (M=  43) - s=0.0100\n",
      " 178 - L= 1.1852008 - Gamma=40.5728564 (M=  43) - s=0.0100\n",
      " 179 - L= 1.1859009 - Gamma=40.5479983 (M=  43) - s=0.0100\n",
      " 180 - L= 1.1867387 - Gamma=40.7705680 (M=  44) - s=0.0100\n",
      " 181 - L= 1.1880117 - Gamma=40.6569254 (M=  44) - s=0.0100\n",
      " 182 - L= 1.1889570 - Gamma=40.6848089 (M=  44) - s=0.0100\n",
      " 183 - L= 1.1904194 - Gamma=40.4424228 (M=  44) - s=0.0100\n",
      " 184 - L= 1.1925461 - Gamma=40.3681747 (M=  44) - s=0.0100\n",
      " 185 - L= 1.1931716 - Gamma=40.1758802 (M=  43) - s=0.0100\n",
      " 186 - L= 1.1955239 - Gamma=40.1361583 (M=  43) - s=0.0100\n",
      " 187 - L= 1.1983900 - Gamma=40.3722438 (M=  43) - s=0.0100\n",
      " 188 - L= 1.2016482 - Gamma=40.1428306 (M=  43) - s=0.0100\n",
      " 189 - L= 1.2068838 - Gamma=39.6007908 (M=  42) - s=0.0100\n",
      " 190 - L= 1.2092018 - Gamma=39.3296425 (M=  41) - s=0.0100\n",
      " 191 - L= 1.2157326 - Gamma=39.3457626 (M=  41) - s=0.0100\n",
      " 192 - L= 1.2200348 - Gamma=39.2397967 (M=  41) - s=0.0100\n",
      " 193 - L= 1.2243079 - Gamma=39.2098950 (M=  41) - s=0.0100\n",
      " 194 - L= 1.2283174 - Gamma=39.2827549 (M=  41) - s=0.0100\n",
      " 195 - L= 1.2316113 - Gamma=39.2501361 (M=  41) - s=0.0100\n",
      " 196 - L= 1.2342711 - Gamma=39.5681829 (M=  41) - s=0.0100\n",
      " 197 - L= 1.2368887 - Gamma=39.5741487 (M=  41) - s=0.0100\n",
      " 198 - L= 1.2392354 - Gamma=39.5797514 (M=  41) - s=0.0100\n",
      " 199 - L= 1.2412697 - Gamma=39.6822521 (M=  41) - s=0.0100\n",
      " 200 - L= 1.2428804 - Gamma=39.6761263 (M=  41) - s=0.0100\n",
      "Initial alpha = [[0.07577691]]\n",
      "   1 - L=-504.1519113 - Gamma= 1.9999338 (M=   2) - s=0.0100\n",
      "   2 - L=-329.6202484 - Gamma= 2.9997670 (M=   3) - s=0.0100\n",
      "   3 - L=-287.6123969 - Gamma= 3.9994699 (M=   4) - s=0.0100\n",
      "   4 - L=-252.3183179 - Gamma= 4.9990739 (M=   5) - s=0.0100\n",
      "   5 - L=-218.7428486 - Gamma= 5.9987290 (M=   6) - s=0.0100\n",
      "   6 - L=-166.3661269 - Gamma= 6.9984143 (M=   7) - s=0.0100\n",
      "   7 - L=-130.6315309 - Gamma= 7.9980502 (M=   8) - s=0.0100\n",
      "   8 - L=-119.4532312 - Gamma= 8.9968915 (M=   9) - s=0.0100\n",
      "   9 - L=-103.6668075 - Gamma= 9.9957315 (M=  10) - s=0.0100\n",
      "  10 - L=-92.6909469 - Gamma=10.9945003 (M=  11) - s=0.0100\n",
      "  11 - L=-85.2669122 - Gamma=11.9929527 (M=  12) - s=0.0100\n",
      "  12 - L=-78.1840380 - Gamma=12.9912378 (M=  13) - s=0.0100\n",
      "  13 - L=-73.2921530 - Gamma=13.9884853 (M=  14) - s=0.0100\n",
      "  14 - L=-68.5208505 - Gamma=14.9858304 (M=  15) - s=0.0100\n",
      "  15 - L=-62.4481926 - Gamma=15.9834652 (M=  16) - s=0.0100\n",
      "  16 - L=-57.0769848 - Gamma=16.9806275 (M=  17) - s=0.0100\n",
      "  17 - L=-52.0921494 - Gamma=17.9780616 (M=  18) - s=0.0100\n",
      "  18 - L=-47.7283636 - Gamma=18.9746908 (M=  19) - s=0.0100\n",
      "  19 - L=-44.2775532 - Gamma=19.9710781 (M=  20) - s=0.0100\n",
      "  20 - L=-44.1915956 - Gamma=18.9730724 (M=  19) - s=0.0100\n",
      "  21 - L=-41.5731749 - Gamma=19.9673710 (M=  20) - s=0.0100\n",
      "  22 - L=-39.0544553 - Gamma=20.9617620 (M=  21) - s=0.0100\n",
      "  23 - L=-35.1104774 - Gamma=21.9566215 (M=  22) - s=0.0100\n",
      "  24 - L=-31.0180247 - Gamma=22.9500661 (M=  23) - s=0.0100\n",
      "  25 - L=-27.5344779 - Gamma=23.9437397 (M=  24) - s=0.0100\n",
      "  26 - L=-27.4577067 - Gamma=22.9499246 (M=  23) - s=0.0100\n",
      "  27 - L=-27.4014004 - Gamma=21.9552227 (M=  22) - s=0.0100\n",
      "  28 - L=-25.0213714 - Gamma=22.9480226 (M=  23) - s=0.0100\n",
      "  29 - L=-22.3767447 - Gamma=23.9403898 (M=  24) - s=0.0100\n",
      "  30 - L=-19.4835194 - Gamma=24.9329477 (M=  25) - s=0.0100\n",
      "  31 - L=-18.1121862 - Gamma=25.9211554 (M=  26) - s=0.0100\n",
      "  32 - L=-16.7057429 - Gamma=26.9094165 (M=  27) - s=0.0100\n",
      "  33 - L=-14.9218838 - Gamma=27.8939026 (M=  28) - s=0.0100\n",
      "  34 - L=-13.2857690 - Gamma=28.8833605 (M=  29) - s=0.0100\n",
      "  35 - L=-12.5127539 - Gamma=29.8642002 (M=  30) - s=0.0100\n",
      "  36 - L=-11.6288837 - Gamma=30.8410025 (M=  31) - s=0.0100\n",
      "  37 - L=-10.7492599 - Gamma=31.8173075 (M=  32) - s=0.0100\n",
      "  38 - L=-9.2285994 - Gamma=32.7988277 (M=  33) - s=0.0100\n",
      "  39 - L=-7.0747011 - Gamma=33.7678062 (M=  34) - s=0.0100\n",
      "  40 - L=-7.0235328 - Gamma=32.7907943 (M=  33) - s=0.0100\n",
      "  41 - L=-6.0973402 - Gamma=33.7683438 (M=  34) - s=0.0100\n",
      "  42 - L=-5.4760224 - Gamma=34.7349762 (M=  35) - s=0.0100\n",
      "  43 - L=-4.5621473 - Gamma=35.7113737 (M=  36) - s=0.0100\n",
      "  44 - L=-3.9932107 - Gamma=36.6491392 (M=  37) - s=0.0100\n",
      "  45 - L=-3.4723125 - Gamma=37.5784526 (M=  38) - s=0.0100\n",
      "  46 - L=-2.4493504 - Gamma=38.5237048 (M=  39) - s=0.0100\n",
      "  47 - L=-1.6910806 - Gamma=39.4549758 (M=  40) - s=0.0100\n",
      "  48 - L=-0.9543465 - Gamma=40.2234502 (M=  41) - s=0.0100\n",
      "  49 - L=-0.9089093 - Gamma=39.2902310 (M=  40) - s=0.0100\n",
      "  50 - L=-0.8773343 - Gamma=38.4762765 (M=  39) - s=0.0100\n",
      "  51 - L=-0.6451718 - Gamma=38.4954698 (M=  39) - s=0.0100\n",
      "  52 - L=-0.4215233 - Gamma=39.4352720 (M=  40) - s=0.0100\n",
      "  53 - L=-0.1979394 - Gamma=40.2936686 (M=  41) - s=0.0100\n",
      "  54 - L=-0.0498575 - Gamma=40.3064459 (M=  41) - s=0.0100\n",
      "  55 - L= 0.0600823 - Gamma=40.3402912 (M=  41) - s=0.0100\n",
      "  56 - L= 0.1672554 - Gamma=40.3460395 (M=  41) - s=0.0100\n",
      "  57 - L= 0.2682263 - Gamma=41.1711341 (M=  42) - s=0.0100\n",
      "  58 - L= 0.3785302 - Gamma=41.1837432 (M=  42) - s=0.0100\n",
      "  59 - L= 0.4668226 - Gamma=41.1939190 (M=  42) - s=0.0100\n",
      "  60 - L= 0.5541582 - Gamma=41.2012887 (M=  42) - s=0.0100\n",
      "  61 - L= 0.6072570 - Gamma=41.2214987 (M=  42) - s=0.0100\n",
      "  62 - L= 0.6596694 - Gamma=41.2343919 (M=  42) - s=0.0100\n",
      "  63 - L= 0.7015008 - Gamma=41.2709914 (M=  42) - s=0.0100\n",
      "  64 - L= 0.7338322 - Gamma=41.2933698 (M=  42) - s=0.0100\n",
      "  65 - L= 0.7635226 - Gamma=41.3069576 (M=  42) - s=0.0100\n",
      "  66 - L= 0.7925455 - Gamma=41.3209444 (M=  42) - s=0.0100\n",
      "  67 - L= 0.8188917 - Gamma=41.3407350 (M=  42) - s=0.0100\n",
      "  68 - L= 0.8426116 - Gamma=41.3606226 (M=  42) - s=0.0100\n",
      "  69 - L= 0.8658665 - Gamma=41.3923881 (M=  42) - s=0.0100\n",
      "  70 - L= 0.8826647 - Gamma=41.4083329 (M=  42) - s=0.0100\n",
      "  71 - L= 0.8988091 - Gamma=41.4209222 (M=  42) - s=0.0100\n",
      "  72 - L= 0.9148892 - Gamma=41.3391810 (M=  42) - s=0.0100\n",
      "  73 - L= 0.9335118 - Gamma=41.9849657 (M=  43) - s=0.0100\n",
      "  74 - L= 0.9468202 - Gamma=41.9692724 (M=  43) - s=0.0100\n",
      "  75 - L= 0.9573267 - Gamma=41.9706445 (M=  43) - s=0.0100\n",
      "  76 - L= 0.9670255 - Gamma=41.9744415 (M=  43) - s=0.0100\n",
      "  77 - L= 0.9764251 - Gamma=41.9759031 (M=  43) - s=0.0100\n",
      "  78 - L= 0.9854379 - Gamma=41.9891724 (M=  43) - s=0.0100\n",
      "  79 - L= 0.9937391 - Gamma=42.0069063 (M=  43) - s=0.0100\n",
      "  80 - L= 1.0019923 - Gamma=42.0313300 (M=  43) - s=0.0100\n",
      "  81 - L= 1.0103370 - Gamma=42.0085430 (M=  43) - s=0.0100\n",
      "  82 - L= 1.0181305 - Gamma=42.0127027 (M=  43) - s=0.0100\n",
      "  83 - L= 1.0253147 - Gamma=42.0436943 (M=  43) - s=0.0100\n",
      "  84 - L= 1.0306899 - Gamma=42.0016357 (M=  43) - s=0.0100\n",
      "  85 - L= 1.0362769 - Gamma=42.0060655 (M=  43) - s=0.0100\n",
      "  86 - L= 1.0406079 - Gamma=42.0068368 (M=  43) - s=0.0100\n",
      "  87 - L= 1.0445918 - Gamma=42.4712728 (M=  44) - s=0.0100\n",
      "  88 - L= 1.0504081 - Gamma=42.2213393 (M=  44) - s=0.0100\n",
      "  89 - L= 1.0566804 - Gamma=42.5856463 (M=  45) - s=0.0100\n",
      "  90 - L= 1.0597609 - Gamma=42.3253450 (M=  44) - s=0.0100\n",
      "  91 - L= 1.0745105 - Gamma=41.8518349 (M=  44) - s=0.0100\n",
      "  92 - L= 1.0880417 - Gamma=41.7226530 (M=  44) - s=0.0100\n",
      "  93 - L= 1.0897367 - Gamma=41.5293400 (M=  43) - s=0.0100\n",
      "  94 - L= 1.1010083 - Gamma=41.2457708 (M=  43) - s=0.0100\n",
      "  95 - L= 1.1100446 - Gamma=41.1913762 (M=  43) - s=0.0100\n",
      "  96 - L= 1.1166703 - Gamma=41.3206216 (M=  43) - s=0.0100\n",
      "  97 - L= 1.1248735 - Gamma=41.0777235 (M=  43) - s=0.0100\n",
      "  98 - L= 1.1369135 - Gamma=41.5672008 (M=  44) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  99 - L= 1.1476472 - Gamma=40.9321683 (M=  43) - s=0.0100\n",
      " 100 - L= 1.1566635 - Gamma=40.5043060 (M=  42) - s=0.0100\n",
      " 101 - L= 1.1602546 - Gamma=40.5086217 (M=  42) - s=0.0100\n",
      " 102 - L= 1.1634852 - Gamma=40.5268074 (M=  42) - s=0.0100\n",
      " 103 - L= 1.1669122 - Gamma=40.1069849 (M=  42) - s=0.0100\n",
      " 104 - L= 1.1696466 - Gamma=40.1054551 (M=  42) - s=0.0100\n",
      " 105 - L= 1.1722910 - Gamma=40.0933879 (M=  42) - s=0.0100\n",
      " 106 - L= 1.1750253 - Gamma=40.0242337 (M=  42) - s=0.0100\n",
      " 107 - L= 1.1753933 - Gamma=39.8778989 (M=  41) - s=0.0100\n",
      " 108 - L= 1.1797694 - Gamma=39.2899556 (M=  41) - s=0.0100\n",
      " 109 - L= 1.1828450 - Gamma=39.3206809 (M=  41) - s=0.0100\n",
      " 110 - L= 1.1851116 - Gamma=39.3211587 (M=  41) - s=0.0100\n",
      " 111 - L= 1.1851534 - Gamma=39.2517727 (M=  40) - s=0.0100\n",
      " 112 - L= 1.1869633 - Gamma=39.2351816 (M=  40) - s=0.0100\n",
      " 113 - L= 1.1888759 - Gamma=39.3181411 (M=  40) - s=0.0100\n",
      " 114 - L= 1.1903732 - Gamma=39.3151197 (M=  40) - s=0.0100\n",
      " 115 - L= 1.1918642 - Gamma=39.3203391 (M=  40) - s=0.0100\n",
      " 116 - L= 1.1933262 - Gamma=39.3216293 (M=  40) - s=0.0100\n",
      " 117 - L= 1.1942991 - Gamma=39.3197203 (M=  40) - s=0.0100\n",
      " 118 - L= 1.1952688 - Gamma=39.3203490 (M=  40) - s=0.0100\n",
      " 119 - L= 1.1962211 - Gamma=39.3255330 (M=  40) - s=0.0100\n",
      " 120 - L= 1.1970685 - Gamma=39.2401976 (M=  40) - s=0.0100\n",
      " 121 - L= 1.1976275 - Gamma=39.2398860 (M=  40) - s=0.0100\n",
      " 122 - L= 1.1980625 - Gamma=39.2406503 (M=  40) - s=0.0100\n",
      " 123 - L= 1.1983659 - Gamma=39.2400393 (M=  40) - s=0.0100\n",
      " 124 - L= 1.1986642 - Gamma=39.2388703 (M=  40) - s=0.0100\n",
      " 125 - L= 1.1989260 - Gamma=39.2394299 (M=  40) - s=0.0100\n",
      " 126 - L= 1.1990657 - Gamma=39.2359457 (M=  40) - s=0.0100\n",
      " 127 - L= 1.1991929 - Gamma=39.2362239 (M=  40) - s=0.0100\n",
      " 128 - L= 1.1993100 - Gamma=39.2334741 (M=  40) - s=0.0100\n",
      " 129 - L= 1.1994234 - Gamma=39.2339732 (M=  40) - s=0.0100\n",
      " 130 - L= 1.1995192 - Gamma=39.2163443 (M=  40) - s=0.0100\n",
      " 131 - L= 1.1996046 - Gamma=39.2988658 (M=  41) - s=0.0100\n",
      " 132 - L= 1.1996875 - Gamma=39.2969318 (M=  41) - s=0.0100\n",
      " 133 - L= 1.1997405 - Gamma=39.2968548 (M=  41) - s=0.0100\n",
      " 134 - L= 1.1997923 - Gamma=39.2970236 (M=  41) - s=0.0100\n",
      " 135 - L= 1.1998413 - Gamma=39.2969612 (M=  41) - s=0.0100\n",
      " 136 - L= 1.1998902 - Gamma=39.2970164 (M=  41) - s=0.0100\n",
      " 137 - L= 1.1999369 - Gamma=39.2969120 (M=  41) - s=0.0100\n",
      " 138 - L= 1.1999830 - Gamma=39.2968225 (M=  41) - s=0.0100\n",
      " 139 - L= 1.2000242 - Gamma=39.3060989 (M=  41) - s=0.0100\n",
      " 140 - L= 1.2000609 - Gamma=39.3050796 (M=  41) - s=0.0100\n",
      " 141 - L= 1.2000923 - Gamma=39.2860022 (M=  41) - s=0.0100\n",
      " 142 - L= 1.2001220 - Gamma=39.2861726 (M=  41) - s=0.0100\n",
      " 143 - L= 1.2001465 - Gamma=39.2862131 (M=  41) - s=0.0100\n",
      " 144 - L= 1.2001694 - Gamma=39.2838133 (M=  41) - s=0.0100\n",
      " 145 - L= 1.2001891 - Gamma=39.2840760 (M=  41) - s=0.0100\n",
      " 146 - L= 1.2002025 - Gamma=39.2842442 (M=  41) - s=0.0100\n",
      " 147 - L= 1.2002146 - Gamma=39.3128005 (M=  41) - s=0.0100\n",
      " 148 - L= 1.2002220 - Gamma=39.3128220 (M=  41) - s=0.0100\n",
      " 149 - L= 1.2002290 - Gamma=39.3034029 (M=  41) - s=0.0100\n",
      " 150 - L= 1.2002356 - Gamma=39.3036576 (M=  41) - s=0.0100\n",
      " 151 - L= 1.2002421 - Gamma=39.3047415 (M=  41) - s=0.0100\n",
      " 152 - L= 1.2002471 - Gamma=39.3223065 (M=  41) - s=0.0100\n",
      " 153 - L= 1.2002520 - Gamma=39.3142168 (M=  41) - s=0.0100\n",
      " 154 - L= 1.2002572 - Gamma=39.3136653 (M=  41) - s=0.0100\n",
      " 155 - L= 1.2002608 - Gamma=39.3281276 (M=  41) - s=0.0100\n",
      " 156 - L= 1.2002642 - Gamma=39.3286818 (M=  41) - s=0.0100\n",
      " 157 - L= 1.2002678 - Gamma=39.3215228 (M=  41) - s=0.0100\n",
      " 158 - L= 1.2002712 - Gamma=39.3248939 (M=  41) - s=0.0100\n",
      " 159 - L= 1.2002744 - Gamma=39.3249546 (M=  41) - s=0.0100\n",
      " 160 - L= 1.2002771 - Gamma=39.3371911 (M=  41) - s=0.0100\n",
      " 161 - L= 1.2002804 - Gamma=39.3301964 (M=  41) - s=0.0100\n",
      " 162 - L= 1.2002827 - Gamma=39.3411743 (M=  41) - s=0.0100\n",
      " 163 - L= 1.2002843 - Gamma=39.3360940 (M=  41) - s=0.0100\n",
      " 164 - L= 1.2002859 - Gamma=39.3378258 (M=  41) - s=0.0100\n",
      " 165 - L= 1.2002875 - Gamma=39.3377744 (M=  41) - s=0.0100\n",
      " 166 - L= 1.2002885 - Gamma=39.3379204 (M=  41) - s=0.0100\n",
      " 167 - L= 1.2002895 - Gamma=39.3378783 (M=  41) - s=0.0100\n",
      " 168 - L= 1.2002904 - Gamma=39.3378091 (M=  41) - s=0.0100\n",
      " 169 - L= 1.2002914 - Gamma=39.3447017 (M=  41) - s=0.0100\n",
      " 170 - L= 1.2002926 - Gamma=39.3401843 (M=  41) - s=0.0100\n",
      " 171 - L= 1.2002935 - Gamma=39.3468166 (M=  41) - s=0.0100\n",
      " 172 - L= 1.2002944 - Gamma=39.3466124 (M=  41) - s=0.0100\n",
      " 173 - L= 1.2002952 - Gamma=39.3468702 (M=  41) - s=0.0100\n",
      " 174 - L= 1.2002960 - Gamma=39.3431156 (M=  41) - s=0.0100\n",
      " 175 - L= 1.2002969 - Gamma=39.3448251 (M=  41) - s=0.0100\n",
      " 176 - L= 1.2002977 - Gamma=39.3445866 (M=  41) - s=0.0100\n",
      " 177 - L= 1.2002984 - Gamma=39.3504298 (M=  41) - s=0.0100\n",
      " 178 - L= 1.2002992 - Gamma=39.3466869 (M=  41) - s=0.0100\n",
      " 179 - L= 1.2003000 - Gamma=39.3466627 (M=  41) - s=0.0100\n",
      " 180 - L= 1.2003006 - Gamma=39.3467392 (M=  41) - s=0.0100\n",
      " 181 - L= 1.2003013 - Gamma=39.3466617 (M=  41) - s=0.0100\n",
      " 182 - L= 1.2003019 - Gamma=39.3467170 (M=  41) - s=0.0100\n",
      " 183 - L= 1.2003024 - Gamma=39.3517538 (M=  41) - s=0.0100\n",
      " 184 - L= 1.2003030 - Gamma=39.3515705 (M=  41) - s=0.0100\n",
      " 185 - L= 1.2003036 - Gamma=39.3483185 (M=  41) - s=0.0100\n",
      " 186 - L= 1.2003041 - Gamma=39.3528387 (M=  41) - s=0.0100\n",
      " 187 - L= 1.2003045 - Gamma=39.3528085 (M=  41) - s=0.0100\n",
      " 188 - L= 1.2003049 - Gamma=39.3531454 (M=  41) - s=0.0100\n",
      " 189 - L= 1.2003053 - Gamma=39.3534048 (M=  41) - s=0.0100\n",
      " 190 - L= 1.2003057 - Gamma=39.3507802 (M=  41) - s=0.0100\n",
      " 191 - L= 1.2003061 - Gamma=39.3508018 (M=  41) - s=0.0100\n",
      " 192 - L= 1.2003065 - Gamma=39.3508096 (M=  41) - s=0.0100\n",
      " 193 - L= 1.2003068 - Gamma=39.3508326 (M=  41) - s=0.0100\n",
      " 194 - L= 1.2003072 - Gamma=39.3508136 (M=  41) - s=0.0100\n",
      " 195 - L= 1.2003075 - Gamma=39.3546385 (M=  41) - s=0.0100\n",
      " 196 - L= 1.2003078 - Gamma=39.3547364 (M=  41) - s=0.0100\n",
      " 197 - L= 1.2003081 - Gamma=39.3547055 (M=  41) - s=0.0100\n",
      " 198 - L= 1.2003084 - Gamma=39.3523792 (M=  41) - s=0.0100\n",
      " 199 - L= 1.2003087 - Gamma=39.3525428 (M=  41) - s=0.0100\n",
      " 200 - L= 1.2003090 - Gamma=39.3535322 (M=  41) - s=0.0100\n",
      "Initial alpha = [[0.07762299]]\n",
      "   1 - L=-644.5640768 - Gamma= 1.9998908 (M=   2) - s=0.0100\n",
      "   2 - L=-470.0141036 - Gamma= 2.9997997 (M=   3) - s=0.0100\n",
      "   3 - L=-387.8471838 - Gamma= 3.9994700 (M=   4) - s=0.0100\n",
      "   4 - L=-337.8466725 - Gamma= 4.9992381 (M=   5) - s=0.0100\n",
      "   5 - L=-294.5002142 - Gamma= 5.9989015 (M=   6) - s=0.0100\n",
      "   6 - L=-264.7850195 - Gamma= 6.9984793 (M=   7) - s=0.0100\n",
      "   7 - L=-230.0539946 - Gamma= 7.9981045 (M=   8) - s=0.0100\n",
      "   8 - L=-188.5559521 - Gamma= 8.9977096 (M=   9) - s=0.0100\n",
      "   9 - L=-173.4945323 - Gamma= 9.9967967 (M=  10) - s=0.0100\n",
      "  10 - L=-153.7086947 - Gamma=10.9960172 (M=  11) - s=0.0100\n",
      "  11 - L=-140.4205739 - Gamma=11.9938095 (M=  12) - s=0.0100\n",
      "  12 - L=-128.5363487 - Gamma=12.9924063 (M=  13) - s=0.0100\n",
      "  13 - L=-119.3297007 - Gamma=13.9906135 (M=  14) - s=0.0100\n",
      "  14 - L=-109.7630512 - Gamma=14.9890180 (M=  15) - s=0.0100\n",
      "  15 - L=-97.2821175 - Gamma=15.9875873 (M=  16) - s=0.0100\n",
      "  16 - L=-82.9100051 - Gamma=16.9861763 (M=  17) - s=0.0100\n",
      "  17 - L=-74.4896763 - Gamma=17.9842038 (M=  18) - s=0.0100\n",
      "  18 - L=-65.0491541 - Gamma=18.9824979 (M=  19) - s=0.0100\n",
      "  19 - L=-60.3097117 - Gamma=19.9753074 (M=  20) - s=0.0100\n",
      "  20 - L=-60.2365235 - Gamma=18.9776586 (M=  19) - s=0.0100\n",
      "  21 - L=-60.1875970 - Gamma=17.9840670 (M=  18) - s=0.0100\n",
      "  22 - L=-55.3081591 - Gamma=18.9802638 (M=  19) - s=0.0100\n",
      "  23 - L=-55.2214750 - Gamma=17.9815270 (M=  18) - s=0.0100\n",
      "  24 - L=-49.5905539 - Gamma=18.9783463 (M=  19) - s=0.0100\n",
      "  25 - L=-40.6324886 - Gamma=19.9758609 (M=  20) - s=0.0100\n",
      "  26 - L=-36.6215849 - Gamma=20.9717599 (M=  21) - s=0.0100\n",
      "  27 - L=-34.2591799 - Gamma=21.9665346 (M=  22) - s=0.0100\n",
      "  28 - L=-31.8261876 - Gamma=22.9593817 (M=  23) - s=0.0100\n",
      "  29 - L=-29.6167811 - Gamma=23.9536590 (M=  24) - s=0.0100\n",
      "  30 - L=-27.3488744 - Gamma=24.9472515 (M=  25) - s=0.0100\n",
      "  31 - L=-25.3486611 - Gamma=25.9382087 (M=  26) - s=0.0100\n",
      "  32 - L=-23.0118251 - Gamma=26.9284927 (M=  27) - s=0.0100\n",
      "  33 - L=-19.7112917 - Gamma=27.9182322 (M=  28) - s=0.0100\n",
      "  34 - L=-19.6560643 - Gamma=26.9283171 (M=  27) - s=0.0100\n",
      "  35 - L=-17.1245247 - Gamma=27.9212695 (M=  28) - s=0.0100\n",
      "  36 - L=-12.7028070 - Gamma=28.9114236 (M=  29) - s=0.0100\n",
      "  37 - L=-10.5132469 - Gamma=29.8993389 (M=  30) - s=0.0100\n",
      "  38 - L=-7.7655665 - Gamma=30.8899508 (M=  31) - s=0.0100\n",
      "  39 - L=-6.1392365 - Gamma=31.8796092 (M=  32) - s=0.0100\n",
      "  40 - L=-4.5513855 - Gamma=32.8683632 (M=  33) - s=0.0100\n",
      "  41 - L=-3.3925563 - Gamma=33.8540263 (M=  34) - s=0.0100\n",
      "  42 - L=-2.5397194 - Gamma=34.8316120 (M=  35) - s=0.0100\n",
      "  43 - L=-2.0893247 - Gamma=35.7655457 (M=  36) - s=0.0100\n",
      "  44 - L=-1.5449000 - Gamma=36.7161426 (M=  37) - s=0.0100\n",
      "  45 - L=-0.7554947 - Gamma=37.6808507 (M=  38) - s=0.0100\n",
      "  46 - L=-0.1527037 - Gamma=38.6348224 (M=  39) - s=0.0100\n",
      "  47 - L=-0.1007795 - Gamma=37.6704079 (M=  38) - s=0.0100\n",
      "  48 - L= 0.0765371 - Gamma=38.5861571 (M=  39) - s=0.0100\n",
      "  49 - L= 0.2340929 - Gamma=39.5080676 (M=  40) - s=0.0100\n",
      "  50 - L= 0.3325081 - Gamma=39.5120068 (M=  40) - s=0.0100\n",
      "  51 - L= 0.4126168 - Gamma=39.5591002 (M=  40) - s=0.0100\n",
      "  52 - L= 0.4794915 - Gamma=39.5679382 (M=  40) - s=0.0100\n",
      "  53 - L= 0.5356524 - Gamma=39.5713314 (M=  40) - s=0.0100\n",
      "  54 - L= 0.5913803 - Gamma=39.5846749 (M=  40) - s=0.0100\n",
      "  55 - L= 0.6439107 - Gamma=39.6170815 (M=  40) - s=0.0100\n",
      "  56 - L= 0.6803723 - Gamma=38.6658540 (M=  39) - s=0.0100\n",
      "  57 - L= 0.7295197 - Gamma=38.6711844 (M=  39) - s=0.0100\n",
      "  58 - L= 0.7698795 - Gamma=38.6731668 (M=  39) - s=0.0100\n",
      "  59 - L= 0.8079855 - Gamma=38.5345550 (M=  39) - s=0.0100\n",
      "  60 - L= 0.8416604 - Gamma=38.5457941 (M=  39) - s=0.0100\n",
      "  61 - L= 0.8744838 - Gamma=38.5488754 (M=  39) - s=0.0100\n",
      "  62 - L= 0.9061759 - Gamma=38.5553878 (M=  39) - s=0.0100\n",
      "  63 - L= 0.9368397 - Gamma=38.5657413 (M=  39) - s=0.0100\n",
      "  64 - L= 0.9670246 - Gamma=38.5675802 (M=  39) - s=0.0100\n",
      "  65 - L= 0.9952665 - Gamma=38.4684224 (M=  39) - s=0.0100\n",
      "  66 - L= 1.0223058 - Gamma=38.4705861 (M=  39) - s=0.0100\n",
      "  67 - L= 1.0482473 - Gamma=38.4851458 (M=  39) - s=0.0100\n",
      "  68 - L= 1.0724016 - Gamma=38.4921452 (M=  39) - s=0.0100\n",
      "  69 - L= 1.0936461 - Gamma=38.4980321 (M=  39) - s=0.0100\n",
      "  70 - L= 1.1123518 - Gamma=38.4946580 (M=  39) - s=0.0100\n",
      "  71 - L= 1.1294590 - Gamma=38.4972681 (M=  39) - s=0.0100\n",
      "  72 - L= 1.1465748 - Gamma=38.5081600 (M=  39) - s=0.0100\n",
      "  73 - L= 1.1615954 - Gamma=38.5157639 (M=  39) - s=0.0100\n",
      "  74 - L= 1.1749894 - Gamma=38.5166857 (M=  39) - s=0.0100\n",
      "  75 - L= 1.1834301 - Gamma=38.4987436 (M=  39) - s=0.0100\n",
      "  76 - L= 1.1894927 - Gamma=38.5054703 (M=  39) - s=0.0100\n",
      "  77 - L= 1.1954472 - Gamma=38.5073345 (M=  39) - s=0.0100\n",
      "  78 - L= 1.2002811 - Gamma=38.5155805 (M=  39) - s=0.0100\n",
      "  79 - L= 1.2049810 - Gamma=38.5121493 (M=  39) - s=0.0100\n",
      "  80 - L= 1.2089147 - Gamma=38.5028215 (M=  39) - s=0.0100\n",
      "  81 - L= 1.2137835 - Gamma=38.9753229 (M=  40) - s=0.0100\n",
      "  82 - L= 1.2155885 - Gamma=38.9924539 (M=  40) - s=0.0100\n",
      "  83 - L= 1.2175670 - Gamma=38.8445803 (M=  40) - s=0.0100\n",
      "  84 - L= 1.2182473 - Gamma=38.8469107 (M=  40) - s=0.0100\n",
      "  85 - L= 1.2189039 - Gamma=38.8383126 (M=  40) - s=0.0100\n",
      "  86 - L= 1.2193946 - Gamma=38.9249390 (M=  40) - s=0.0100\n",
      "  87 - L= 1.2200083 - Gamma=38.8750054 (M=  40) - s=0.0100\n",
      "  88 - L= 1.2205627 - Gamma=38.8659969 (M=  40) - s=0.0100\n",
      "  89 - L= 1.2210163 - Gamma=38.8725065 (M=  40) - s=0.0100\n",
      "  90 - L= 1.2213986 - Gamma=38.8735613 (M=  40) - s=0.0100\n",
      "  91 - L= 1.2217336 - Gamma=38.8731661 (M=  40) - s=0.0100\n",
      "  92 - L= 1.2219817 - Gamma=38.8736975 (M=  40) - s=0.0100\n",
      "  93 - L= 1.2221475 - Gamma=38.9131775 (M=  40) - s=0.0100\n",
      "  94 - L= 1.2223731 - Gamma=38.8385275 (M=  40) - s=0.0100\n",
      "  95 - L= 1.2225832 - Gamma=38.8273983 (M=  40) - s=0.0100\n",
      "  96 - L= 1.2227756 - Gamma=38.8283117 (M=  40) - s=0.0100\n",
      "  97 - L= 1.2229590 - Gamma=38.9507971 (M=  41) - s=0.0100\n",
      "  98 - L= 1.2231548 - Gamma=38.8715844 (M=  41) - s=0.0100\n",
      "  99 - L= 1.2233218 - Gamma=38.8707230 (M=  41) - s=0.0100\n",
      " 100 - L= 1.2234857 - Gamma=38.9020478 (M=  41) - s=0.0100\n",
      " 101 - L= 1.2236868 - Gamma=38.8948254 (M=  41) - s=0.0100\n",
      " 102 - L= 1.2238713 - Gamma=38.9985776 (M=  41) - s=0.0100\n",
      " 103 - L= 1.2242066 - Gamma=38.8707302 (M=  41) - s=0.0100\n",
      " 104 - L= 1.2244422 - Gamma=38.8624124 (M=  41) - s=0.0100\n",
      " 105 - L= 1.2247006 - Gamma=38.9666168 (M=  41) - s=0.0100\n",
      " 106 - L= 1.2249917 - Gamma=38.8218547 (M=  40) - s=0.0100\n",
      " 107 - L= 1.2254661 - Gamma=39.0594785 (M=  41) - s=0.0100\n",
      " 108 - L= 1.2257324 - Gamma=39.0636402 (M=  41) - s=0.0100\n",
      " 109 - L= 1.2259804 - Gamma=39.0489592 (M=  41) - s=0.0100\n",
      " 110 - L= 1.2262091 - Gamma=39.1347285 (M=  41) - s=0.0100\n",
      " 111 - L= 1.2263942 - Gamma=39.1384419 (M=  41) - s=0.0100\n",
      " 112 - L= 1.2265620 - Gamma=39.1643691 (M=  41) - s=0.0100\n",
      " 113 - L= 1.2267771 - Gamma=39.1237706 (M=  41) - s=0.0100\n",
      " 114 - L= 1.2269387 - Gamma=39.1228865 (M=  41) - s=0.0100\n",
      " 115 - L= 1.2270562 - Gamma=39.1237479 (M=  41) - s=0.0100\n",
      " 116 - L= 1.2271772 - Gamma=39.1168573 (M=  41) - s=0.0100\n",
      " 117 - L= 1.2272685 - Gamma=39.1164770 (M=  41) - s=0.0100\n",
      " 118 - L= 1.2273506 - Gamma=39.1172304 (M=  41) - s=0.0100\n",
      " 119 - L= 1.2274211 - Gamma=39.1183105 (M=  41) - s=0.0100\n",
      " 120 - L= 1.2274808 - Gamma=39.1131350 (M=  41) - s=0.0100\n",
      " 121 - L= 1.2275406 - Gamma=39.1131783 (M=  41) - s=0.0100\n",
      " 122 - L= 1.2275968 - Gamma=39.1122948 (M=  41) - s=0.0100\n",
      " 123 - L= 1.2276425 - Gamma=39.1122307 (M=  41) - s=0.0100\n",
      " 124 - L= 1.2276857 - Gamma=39.1124440 (M=  41) - s=0.0100\n",
      " 125 - L= 1.2277254 - Gamma=39.1233113 (M=  41) - s=0.0100\n",
      " 126 - L= 1.2277597 - Gamma=39.1236012 (M=  41) - s=0.0100\n",
      " 127 - L= 1.2277928 - Gamma=39.1234607 (M=  41) - s=0.0100\n",
      " 128 - L= 1.2278217 - Gamma=39.1236133 (M=  41) - s=0.0100\n",
      " 129 - L= 1.2278503 - Gamma=39.1236651 (M=  41) - s=0.0100\n",
      " 130 - L= 1.2278767 - Gamma=39.1236922 (M=  41) - s=0.0100\n",
      " 131 - L= 1.2278990 - Gamma=39.1238202 (M=  41) - s=0.0100\n",
      " 132 - L= 1.2279158 - Gamma=39.1240794 (M=  41) - s=0.0100\n",
      " 133 - L= 1.2279289 - Gamma=39.1249790 (M=  41) - s=0.0100\n",
      " 134 - L= 1.2279406 - Gamma=39.1247294 (M=  41) - s=0.0100\n",
      " 135 - L= 1.2279509 - Gamma=39.1247127 (M=  41) - s=0.0100\n",
      " 136 - L= 1.2279603 - Gamma=39.1247870 (M=  41) - s=0.0100\n",
      " 137 - L= 1.2279667 - Gamma=39.1170386 (M=  41) - s=0.0100\n",
      " 138 - L= 1.2279736 - Gamma=39.1152557 (M=  41) - s=0.0100\n",
      " 139 - L= 1.2279800 - Gamma=39.1153258 (M=  41) - s=0.0100\n",
      " 140 - L= 1.2279848 - Gamma=39.1152588 (M=  41) - s=0.0100\n",
      " 141 - L= 1.2279887 - Gamma=39.1138369 (M=  41) - s=0.0100\n",
      " 142 - L= 1.2279934 - Gamma=39.1173595 (M=  41) - s=0.0100\n",
      " 143 - L= 1.2279960 - Gamma=39.1173866 (M=  41) - s=0.0100\n",
      " 144 - L= 1.2279984 - Gamma=39.1172921 (M=  41) - s=0.0100\n",
      " 145 - L= 1.2280005 - Gamma=39.1026240 (M=  41) - s=0.0100\n",
      " 146 - L= 1.2280025 - Gamma=39.1023395 (M=  41) - s=0.0100\n",
      " 147 - L= 1.2280038 - Gamma=39.1022557 (M=  41) - s=0.0100\n",
      " 148 - L= 1.2280048 - Gamma=39.1023304 (M=  41) - s=0.0100\n",
      " 149 - L= 1.2280057 - Gamma=39.1022090 (M=  41) - s=0.0100\n",
      " 150 - L= 1.2280066 - Gamma=39.1024307 (M=  41) - s=0.0100\n",
      " 151 - L= 1.2280075 - Gamma=39.1024761 (M=  41) - s=0.0100\n",
      " 152 - L= 1.2280084 - Gamma=39.1024872 (M=  41) - s=0.0100\n",
      " 153 - L= 1.2280092 - Gamma=39.1024995 (M=  41) - s=0.0100\n",
      " 154 - L= 1.2280100 - Gamma=39.1024893 (M=  41) - s=0.0100\n",
      " 155 - L= 1.2280106 - Gamma=39.1025090 (M=  41) - s=0.0100\n",
      " 156 - L= 1.2280112 - Gamma=39.1024760 (M=  41) - s=0.0100\n",
      " 157 - L= 1.2280119 - Gamma=39.1016871 (M=  41) - s=0.0100\n",
      " 158 - L= 1.2280124 - Gamma=39.1017365 (M=  41) - s=0.0100\n",
      " 159 - L= 1.2280128 - Gamma=39.1012750 (M=  41) - s=0.0100\n",
      " 160 - L= 1.2280133 - Gamma=39.1008305 (M=  41) - s=0.0100\n",
      " 161 - L= 1.2280137 - Gamma=39.1019146 (M=  41) - s=0.0100\n",
      " 162 - L= 1.2280143 - Gamma=39.0995373 (M=  41) - s=0.0100\n",
      " 163 - L= 1.2280149 - Gamma=39.0997174 (M=  41) - s=0.0100\n",
      " 164 - L= 1.2280151 - Gamma=39.0997463 (M=  41) - s=0.0100\n",
      " 165 - L= 1.2280152 - Gamma=39.0997656 (M=  41) - s=0.0100\n",
      " 166 - L= 1.2280154 - Gamma=39.0997639 (M=  41) - s=0.0100\n",
      " 167 - L= 1.2280155 - Gamma=39.1015698 (M=  41) - s=0.0100\n",
      " 168 - L= 1.2280156 - Gamma=39.1015952 (M=  41) - s=0.0100\n",
      " 169 - L= 1.2280157 - Gamma=39.1015873 (M=  41) - s=0.0100\n",
      " 170 - L= 1.2280158 - Gamma=39.1015887 (M=  41) - s=0.0100\n",
      " 171 - L= 1.2280158 - Gamma=39.1015859 (M=  41) - s=0.0100\n",
      " 172 - L= 1.2280159 - Gamma=39.1013866 (M=  41) - s=0.0100\n",
      " 173 - L= 1.2280160 - Gamma=39.1011909 (M=  41) - s=0.0100\n",
      " 174 - L= 1.2280161 - Gamma=39.1016525 (M=  41) - s=0.0100\n",
      " 175 - L= 1.2280162 - Gamma=39.0984743 (M=  41) - s=0.0100\n",
      " 176 - L= 1.2280162 - Gamma=39.0984816 (M=  41) - s=0.0100\n",
      " 177 - L= 1.2280163 - Gamma=39.0984877 (M=  41) - s=0.0100\n",
      " 178 - L= 1.2280164 - Gamma=39.0984932 (M=  41) - s=0.0100\n",
      " 179 - L= 1.2280164 - Gamma=39.0984715 (M=  41) - s=0.0100\n",
      " 180 - L= 1.2280164 - Gamma=39.0984722 (M=  41) - s=0.0100\n",
      " 181 - L= 1.2280164 - Gamma=39.0984735 (M=  41) - s=0.0100\n",
      " 182 - L= 1.2280164 - Gamma=39.0984572 (M=  41) - s=0.0100\n",
      " 183 - L= 1.2280165 - Gamma=39.0983663 (M=  41) - s=0.0100\n",
      " 184 - L= 1.2280165 - Gamma=39.0983568 (M=  41) - s=0.0100\n",
      " 185 - L= 1.2280165 - Gamma=39.0985369 (M=  41) - s=0.0100\n",
      " 186 - L= 1.2280165 - Gamma=39.0985322 (M=  41) - s=0.0100\n",
      " 187 - L= 1.2280165 - Gamma=39.0985404 (M=  41) - s=0.0100\n",
      " 188 - L= 1.2280165 - Gamma=39.0982006 (M=  41) - s=0.0100\n",
      " 189 - L= 1.2280165 - Gamma=39.0982252 (M=  41) - s=0.0100\n",
      " 190 - L= 1.2280165 - Gamma=39.0981526 (M=  41) - s=0.0100\n",
      " 191 - L= 1.2280165 - Gamma=39.0981592 (M=  41) - s=0.0100\n",
      " 192 - L= 1.2280166 - Gamma=39.0981622 (M=  41) - s=0.0100\n",
      " 193 - L= 1.2280166 - Gamma=39.0981627 (M=  41) - s=0.0100\n",
      " 194 - L= 1.2280166 - Gamma=39.0981627 (M=  41) - s=0.0100\n",
      "Stopping at iteration 194 - max_delta_ml=2.1160661276491783e-07\n",
      "L=1.2280165667889653 - Gamma=39.098162701108436 (M=41) - s=0.01\n",
      "MODEL: RVM accuracy:  0.5517241379310345 +/-: 0.0199212697726372\n",
      "Initial alpha = [[0.06048543]]\n",
      "   1 - L=-613.7125014 - Gamma= 1.9999147 (M=   2) - s=0.0100\n",
      "   2 - L=-469.7526288 - Gamma= 2.9998368 (M=   3) - s=0.0100\n",
      "   3 - L=-427.2378615 - Gamma= 3.9995672 (M=   4) - s=0.0100\n",
      "   4 - L=-364.8982254 - Gamma= 4.9993499 (M=   5) - s=0.0100\n",
      "   5 - L=-325.2043398 - Gamma= 5.9990297 (M=   6) - s=0.0100\n",
      "   6 - L=-296.3939378 - Gamma= 6.9986384 (M=   7) - s=0.0100\n",
      "   7 - L=-277.4404645 - Gamma= 7.9980271 (M=   8) - s=0.0100\n",
      "   8 - L=-265.6158442 - Gamma= 8.9972275 (M=   9) - s=0.0100\n",
      "   9 - L=-251.8615765 - Gamma= 9.9964544 (M=  10) - s=0.0100\n",
      "  10 - L=-232.0476671 - Gamma=10.9957952 (M=  11) - s=0.0100\n",
      "  11 - L=-214.0385525 - Gamma=11.9952428 (M=  12) - s=0.0100\n",
      "  12 - L=-198.0457962 - Gamma=12.9944163 (M=  13) - s=0.0100\n",
      "  13 - L=-187.5479929 - Gamma=13.9934513 (M=  14) - s=0.0100\n",
      "  14 - L=-177.6792900 - Gamma=14.9922902 (M=  15) - s=0.0100\n",
      "  15 - L=-160.9992963 - Gamma=15.9913652 (M=  16) - s=0.0100\n",
      "  16 - L=-147.2781892 - Gamma=16.9904670 (M=  17) - s=0.0100\n",
      "  17 - L=-133.5813026 - Gamma=17.9894864 (M=  18) - s=0.0100\n",
      "  18 - L=-122.8056572 - Gamma=18.9878174 (M=  19) - s=0.0100\n",
      "  19 - L=-110.4018603 - Gamma=19.9864089 (M=  20) - s=0.0100\n",
      "  20 - L=-102.7426028 - Gamma=20.9849004 (M=  21) - s=0.0100\n",
      "  21 - L=-94.6257256 - Gamma=21.9833697 (M=  22) - s=0.0100\n",
      "  22 - L=-87.8514437 - Gamma=22.9810399 (M=  23) - s=0.0100\n",
      "  23 - L=-82.8896000 - Gamma=23.9775474 (M=  24) - s=0.0100\n",
      "  24 - L=-79.3958740 - Gamma=24.9736925 (M=  25) - s=0.0100\n",
      "  25 - L=-75.2245114 - Gamma=25.9704536 (M=  26) - s=0.0100\n",
      "  26 - L=-70.5952947 - Gamma=26.9677727 (M=  27) - s=0.0100\n",
      "  27 - L=-66.8897917 - Gamma=27.9646683 (M=  28) - s=0.0100\n",
      "  28 - L=-63.6868647 - Gamma=28.9606620 (M=  29) - s=0.0100\n",
      "  29 - L=-61.3651600 - Gamma=29.9565626 (M=  30) - s=0.0100\n",
      "  30 - L=-57.4632277 - Gamma=30.9529036 (M=  31) - s=0.0100\n",
      "  31 - L=-54.5663081 - Gamma=31.9480782 (M=  32) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  32 - L=-51.6271000 - Gamma=32.9372423 (M=  33) - s=0.0100\n",
      "  33 - L=-48.9623969 - Gamma=33.9307030 (M=  34) - s=0.0100\n",
      "  34 - L=-45.9828103 - Gamma=34.9233740 (M=  35) - s=0.0100\n",
      "  35 - L=-42.9019260 - Gamma=35.9092382 (M=  36) - s=0.0100\n",
      "  36 - L=-42.8521850 - Gamma=34.9245395 (M=  35) - s=0.0100\n",
      "  37 - L=-39.5034979 - Gamma=35.9182948 (M=  36) - s=0.0100\n",
      "  38 - L=-37.3402960 - Gamma=36.9102733 (M=  37) - s=0.0100\n",
      "  39 - L=-34.2847518 - Gamma=37.8982318 (M=  38) - s=0.0100\n",
      "  40 - L=-32.3688420 - Gamma=38.8766215 (M=  39) - s=0.0100\n",
      "  41 - L=-32.3274694 - Gamma=37.8917343 (M=  38) - s=0.0100\n",
      "  42 - L=-30.7600306 - Gamma=38.8752122 (M=  39) - s=0.0100\n",
      "  43 - L=-29.2509904 - Gamma=39.8615112 (M=  40) - s=0.0100\n",
      "  44 - L=-27.0350627 - Gamma=40.8321262 (M=  41) - s=0.0100\n",
      "  45 - L=-26.9981420 - Gamma=39.8478904 (M=  40) - s=0.0100\n",
      "  46 - L=-23.8525602 - Gamma=40.8194948 (M=  41) - s=0.0100\n",
      "  47 - L=-20.4007643 - Gamma=41.7976424 (M=  42) - s=0.0100\n",
      "  48 - L=-20.3487401 - Gamma=40.8296317 (M=  41) - s=0.0100\n",
      "  49 - L=-18.5616980 - Gamma=41.8198067 (M=  42) - s=0.0100\n",
      "  50 - L=-16.9022937 - Gamma=42.7842783 (M=  43) - s=0.0100\n",
      "  51 - L=-15.0806585 - Gamma=43.7411818 (M=  44) - s=0.0100\n",
      "  52 - L=-13.7353669 - Gamma=43.7657961 (M=  44) - s=0.0100\n",
      "  53 - L=-12.4495861 - Gamma=44.7451137 (M=  45) - s=0.0100\n",
      "  54 - L=-11.6109548 - Gamma=45.7210778 (M=  46) - s=0.0100\n",
      "  55 - L=-10.4910091 - Gamma=46.6923581 (M=  47) - s=0.0100\n",
      "  56 - L=-10.4469531 - Gamma=45.7219839 (M=  46) - s=0.0100\n",
      "  57 - L=-8.5341485 - Gamma=46.6883464 (M=  47) - s=0.0100\n",
      "  58 - L=-7.3984444 - Gamma=47.5650163 (M=  48) - s=0.0100\n",
      "  59 - L=-7.3306106 - Gamma=46.5823320 (M=  47) - s=0.0100\n",
      "  60 - L=-6.4292341 - Gamma=47.5016763 (M=  48) - s=0.0100\n",
      "  61 - L=-6.3805609 - Gamma=46.5742789 (M=  47) - s=0.0100\n",
      "  62 - L=-6.3360230 - Gamma=45.6242072 (M=  46) - s=0.0100\n",
      "  63 - L=-6.2985471 - Gamma=44.6793758 (M=  45) - s=0.0100\n",
      "  64 - L=-6.2641534 - Gamma=43.7278149 (M=  44) - s=0.0100\n",
      "  65 - L=-5.2366268 - Gamma=44.7000227 (M=  45) - s=0.0100\n",
      "  66 - L=-4.5562648 - Gamma=44.7431887 (M=  45) - s=0.0100\n",
      "  67 - L=-4.0405759 - Gamma=44.7541347 (M=  45) - s=0.0100\n",
      "  68 - L=-3.5372993 - Gamma=44.7646404 (M=  45) - s=0.0100\n",
      "  69 - L=-3.1243575 - Gamma=45.7091526 (M=  46) - s=0.0100\n",
      "  70 - L=-2.7895548 - Gamma=45.7517014 (M=  46) - s=0.0100\n",
      "  71 - L=-2.4691206 - Gamma=46.7143844 (M=  47) - s=0.0100\n",
      "  72 - L=-2.1420342 - Gamma=47.6662306 (M=  48) - s=0.0100\n",
      "  73 - L=-1.8717943 - Gamma=48.6199392 (M=  49) - s=0.0100\n",
      "  74 - L=-1.6765193 - Gamma=48.6284389 (M=  49) - s=0.0100\n",
      "  75 - L=-1.4915296 - Gamma=48.6316553 (M=  49) - s=0.0100\n",
      "  76 - L=-1.3070762 - Gamma=48.6609038 (M=  49) - s=0.0100\n",
      "  77 - L=-1.1272622 - Gamma=49.6024743 (M=  50) - s=0.0100\n",
      "  78 - L=-0.9618376 - Gamma=49.6099642 (M=  50) - s=0.0100\n",
      "  79 - L=-0.7999745 - Gamma=49.6156369 (M=  50) - s=0.0100\n",
      "  80 - L=-0.6398854 - Gamma=49.6251747 (M=  50) - s=0.0100\n",
      "  81 - L=-0.4982978 - Gamma=49.6330398 (M=  50) - s=0.0100\n",
      "  82 - L=-0.3648440 - Gamma=49.6360425 (M=  50) - s=0.0100\n",
      "  83 - L=-0.2328532 - Gamma=49.6472037 (M=  50) - s=0.0100\n",
      "  84 - L=-0.1550061 - Gamma=49.6485280 (M=  50) - s=0.0100\n",
      "  85 - L=-0.0797000 - Gamma=49.6541922 (M=  50) - s=0.0100\n",
      "  86 - L=-0.0075533 - Gamma=49.6652809 (M=  50) - s=0.0100\n",
      "  87 - L= 0.0623030 - Gamma=49.6736207 (M=  50) - s=0.0100\n",
      "  88 - L= 0.1188778 - Gamma=49.6817292 (M=  50) - s=0.0100\n",
      "  89 - L= 0.1696869 - Gamma=49.6854493 (M=  50) - s=0.0100\n",
      "  90 - L= 0.2124675 - Gamma=49.6922616 (M=  50) - s=0.0100\n",
      "  91 - L= 0.2537280 - Gamma=50.5428822 (M=  51) - s=0.0100\n",
      "  92 - L= 0.2905490 - Gamma=50.5469617 (M=  51) - s=0.0100\n",
      "  93 - L= 0.3179408 - Gamma=50.5517612 (M=  51) - s=0.0100\n",
      "  94 - L= 0.3431222 - Gamma=50.5572911 (M=  51) - s=0.0100\n",
      "  95 - L= 0.3655606 - Gamma=50.5698636 (M=  51) - s=0.0100\n",
      "  96 - L= 0.3877420 - Gamma=50.5723894 (M=  51) - s=0.0100\n",
      "  97 - L= 0.4095325 - Gamma=50.5759609 (M=  51) - s=0.0100\n",
      "  98 - L= 0.4309243 - Gamma=51.2875107 (M=  52) - s=0.0100\n",
      "  99 - L= 0.4551674 - Gamma=51.1019846 (M=  52) - s=0.0100\n",
      " 100 - L= 0.4745425 - Gamma=51.1250986 (M=  52) - s=0.0100\n",
      " 101 - L= 0.4897864 - Gamma=51.1300031 (M=  52) - s=0.0100\n",
      " 102 - L= 0.5018181 - Gamma=51.1406712 (M=  52) - s=0.0100\n",
      " 103 - L= 0.5138352 - Gamma=51.1459689 (M=  52) - s=0.0100\n",
      " 104 - L= 0.5236246 - Gamma=51.1762751 (M=  52) - s=0.0100\n",
      " 105 - L= 0.5314269 - Gamma=51.1806835 (M=  52) - s=0.0100\n",
      " 106 - L= 0.5378473 - Gamma=51.1892285 (M=  52) - s=0.0100\n",
      " 107 - L= 0.5421627 - Gamma=51.1915819 (M=  52) - s=0.0100\n",
      " 108 - L= 0.5463937 - Gamma=51.1985055 (M=  52) - s=0.0100\n",
      " 109 - L= 0.5487329 - Gamma=51.1994315 (M=  52) - s=0.0100\n",
      " 110 - L= 0.5510659 - Gamma=51.2011573 (M=  52) - s=0.0100\n",
      " 111 - L= 0.5529354 - Gamma=51.2031721 (M=  52) - s=0.0100\n",
      " 112 - L= 0.5545777 - Gamma=51.2143060 (M=  52) - s=0.0100\n",
      " 113 - L= 0.5562174 - Gamma=51.2089329 (M=  52) - s=0.0100\n",
      " 114 - L= 0.5571078 - Gamma=51.2069049 (M=  52) - s=0.0100\n",
      " 115 - L= 0.5579095 - Gamma=51.2084223 (M=  52) - s=0.0100\n",
      " 116 - L= 0.5586004 - Gamma=51.2223708 (M=  52) - s=0.0100\n",
      " 117 - L= 0.5591902 - Gamma=51.2227927 (M=  52) - s=0.0100\n",
      " 118 - L= 0.5597663 - Gamma=51.2230226 (M=  52) - s=0.0100\n",
      " 119 - L= 0.5602229 - Gamma=51.2204876 (M=  52) - s=0.0100\n",
      " 120 - L= 0.5606985 - Gamma=51.2641329 (M=  52) - s=0.0100\n",
      " 121 - L= 0.5612274 - Gamma=51.2507448 (M=  52) - s=0.0100\n",
      " 122 - L= 0.5616771 - Gamma=51.2508022 (M=  52) - s=0.0100\n",
      " 123 - L= 0.5620318 - Gamma=51.2057957 (M=  52) - s=0.0100\n",
      " 124 - L= 0.5622494 - Gamma=51.2066315 (M=  52) - s=0.0100\n",
      " 125 - L= 0.5624401 - Gamma=51.2068784 (M=  52) - s=0.0100\n",
      " 126 - L= 0.5625312 - Gamma=51.2070793 (M=  52) - s=0.0100\n",
      " 127 - L= 0.5626201 - Gamma=51.1751670 (M=  52) - s=0.0100\n",
      " 128 - L= 0.5626853 - Gamma=51.1751971 (M=  52) - s=0.0100\n",
      " 129 - L= 0.5627410 - Gamma=51.1752829 (M=  52) - s=0.0100\n",
      " 130 - L= 0.5627936 - Gamma=51.1748643 (M=  52) - s=0.0100\n",
      " 131 - L= 0.5628370 - Gamma=51.1749399 (M=  52) - s=0.0100\n",
      " 132 - L= 0.5628768 - Gamma=51.1750555 (M=  52) - s=0.0100\n",
      " 133 - L= 0.5629140 - Gamma=51.2598783 (M=  53) - s=0.0100\n",
      " 134 - L= 0.5629421 - Gamma=51.2571924 (M=  53) - s=0.0100\n",
      " 135 - L= 0.5629698 - Gamma=51.2572186 (M=  53) - s=0.0100\n",
      " 136 - L= 0.5629964 - Gamma=51.2572310 (M=  53) - s=0.0100\n",
      " 137 - L= 0.5630184 - Gamma=51.2650357 (M=  53) - s=0.0100\n",
      " 138 - L= 0.5630355 - Gamma=51.2650510 (M=  53) - s=0.0100\n",
      " 139 - L= 0.5630505 - Gamma=51.2649799 (M=  53) - s=0.0100\n",
      " 140 - L= 0.5630651 - Gamma=51.2650262 (M=  53) - s=0.0100\n",
      " 141 - L= 0.5630776 - Gamma=51.2650508 (M=  53) - s=0.0100\n",
      " 142 - L= 0.5630897 - Gamma=51.2627150 (M=  53) - s=0.0100\n",
      " 143 - L= 0.5631005 - Gamma=51.2627388 (M=  53) - s=0.0100\n",
      " 144 - L= 0.5631106 - Gamma=51.2622942 (M=  53) - s=0.0100\n",
      " 145 - L= 0.5631191 - Gamma=51.2625580 (M=  53) - s=0.0100\n",
      " 146 - L= 0.5631266 - Gamma=51.2619155 (M=  53) - s=0.0100\n",
      " 147 - L= 0.5631323 - Gamma=51.2620623 (M=  53) - s=0.0100\n",
      " 148 - L= 0.5631381 - Gamma=51.2625421 (M=  53) - s=0.0100\n",
      " 149 - L= 0.5631433 - Gamma=51.2624839 (M=  53) - s=0.0100\n",
      " 150 - L= 0.5631485 - Gamma=51.2624772 (M=  53) - s=0.0100\n",
      " 151 - L= 0.5631532 - Gamma=51.2628338 (M=  53) - s=0.0100\n",
      " 152 - L= 0.5631568 - Gamma=51.2628391 (M=  53) - s=0.0100\n",
      " 153 - L= 0.5631603 - Gamma=51.2628213 (M=  53) - s=0.0100\n",
      " 154 - L= 0.5631631 - Gamma=51.2627963 (M=  53) - s=0.0100\n",
      " 155 - L= 0.5631657 - Gamma=51.2627844 (M=  53) - s=0.0100\n",
      " 156 - L= 0.5631681 - Gamma=51.2628426 (M=  53) - s=0.0100\n",
      " 157 - L= 0.5631705 - Gamma=51.2618322 (M=  53) - s=0.0100\n",
      " 158 - L= 0.5631720 - Gamma=51.2573216 (M=  53) - s=0.0100\n",
      " 159 - L= 0.5631737 - Gamma=51.2572194 (M=  53) - s=0.0100\n",
      " 160 - L= 0.5631755 - Gamma=51.2593527 (M=  53) - s=0.0100\n",
      " 161 - L= 0.5631772 - Gamma=51.2586652 (M=  53) - s=0.0100\n",
      " 162 - L= 0.5631785 - Gamma=51.2586998 (M=  53) - s=0.0100\n",
      " 163 - L= 0.5631795 - Gamma=51.2587506 (M=  53) - s=0.0100\n",
      " 164 - L= 0.5631804 - Gamma=51.2587626 (M=  53) - s=0.0100\n",
      " 165 - L= 0.5631811 - Gamma=51.2564980 (M=  53) - s=0.0100\n",
      " 166 - L= 0.5631818 - Gamma=51.2449282 (M=  53) - s=0.0100\n",
      " 167 - L= 0.5631825 - Gamma=51.2449327 (M=  53) - s=0.0100\n",
      " 168 - L= 0.5631832 - Gamma=51.2448699 (M=  53) - s=0.0100\n",
      " 169 - L= 0.5631838 - Gamma=51.2418732 (M=  53) - s=0.0100\n",
      " 170 - L= 0.5631845 - Gamma=51.2419205 (M=  53) - s=0.0100\n",
      " 171 - L= 0.5631850 - Gamma=51.2419137 (M=  53) - s=0.0100\n",
      " 172 - L= 0.5631855 - Gamma=51.2419631 (M=  53) - s=0.0100\n",
      " 173 - L= 0.5631858 - Gamma=51.2419678 (M=  53) - s=0.0100\n",
      " 174 - L= 0.5631862 - Gamma=51.2428438 (M=  53) - s=0.0100\n",
      " 175 - L= 0.5631865 - Gamma=51.2428356 (M=  53) - s=0.0100\n",
      " 176 - L= 0.5631867 - Gamma=51.2428440 (M=  53) - s=0.0100\n",
      " 177 - L= 0.5631870 - Gamma=51.2427693 (M=  53) - s=0.0100\n",
      " 178 - L= 0.5631873 - Gamma=51.2426547 (M=  53) - s=0.0100\n",
      " 179 - L= 0.5631874 - Gamma=51.2426635 (M=  53) - s=0.0100\n",
      " 180 - L= 0.5631876 - Gamma=51.2426697 (M=  53) - s=0.0100\n",
      " 181 - L= 0.5631877 - Gamma=51.2424795 (M=  53) - s=0.0100\n",
      " 182 - L= 0.5631878 - Gamma=51.2377766 (M=  53) - s=0.0100\n",
      " 183 - L= 0.5631880 - Gamma=51.2363452 (M=  53) - s=0.0100\n",
      " 184 - L= 0.5631881 - Gamma=51.2364117 (M=  53) - s=0.0100\n",
      " 185 - L= 0.5631882 - Gamma=51.2364171 (M=  53) - s=0.0100\n",
      " 186 - L= 0.5631883 - Gamma=51.2364226 (M=  53) - s=0.0100\n",
      " 187 - L= 0.5631884 - Gamma=51.2364259 (M=  53) - s=0.0100\n",
      " 188 - L= 0.5631885 - Gamma=51.2364426 (M=  53) - s=0.0100\n",
      " 189 - L= 0.5631886 - Gamma=51.2368752 (M=  53) - s=0.0100\n",
      " 190 - L= 0.5631886 - Gamma=51.2368781 (M=  53) - s=0.0100\n",
      " 191 - L= 0.5631887 - Gamma=51.2367119 (M=  53) - s=0.0100\n",
      " 192 - L= 0.5631887 - Gamma=51.2367496 (M=  53) - s=0.0100\n",
      " 193 - L= 0.5631888 - Gamma=51.2366097 (M=  53) - s=0.0100\n",
      " 194 - L= 0.5631888 - Gamma=51.2366149 (M=  53) - s=0.0100\n",
      " 195 - L= 0.5631889 - Gamma=51.2366211 (M=  53) - s=0.0100\n",
      " 196 - L= 0.5631889 - Gamma=51.2366143 (M=  53) - s=0.0100\n",
      " 197 - L= 0.5631889 - Gamma=51.2366011 (M=  53) - s=0.0100\n",
      " 198 - L= 0.5631889 - Gamma=51.2366015 (M=  53) - s=0.0100\n",
      " 199 - L= 0.5631890 - Gamma=51.2365214 (M=  53) - s=0.0100\n",
      " 200 - L= 0.5631890 - Gamma=51.2359713 (M=  53) - s=0.0100\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6928 - acc: 0.6087 - val_loss: 0.6651 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6382 - acc: 0.7391 - val_loss: 0.6659 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5948 - acc: 0.6739 - val_loss: 0.3829 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4896 - acc: 0.8043 - val_loss: 0.1808 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.3625 - acc: 0.8261 - val_loss: 1.3396 - val_acc: 0.4167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6757 - acc: 0.8043 - val_loss: 0.4222 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.2496 - acc: 0.8913 - val_loss: 0.6113 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2631 - acc: 0.9130 - val_loss: 0.4846 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.2535 - acc: 0.9130 - val_loss: 0.4623 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.1477 - acc: 0.9565 - val_loss: 0.5291 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.2689 - acc: 0.8913 - val_loss: 0.1038 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.2174 - acc: 0.8696 - val_loss: 0.2822 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2394 - acc: 0.8696 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.1681 - acc: 0.9130 - val_loss: 0.1097 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.2147 - acc: 0.8913 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1095 - acc: 0.9574 - val_loss: 0.2139 - val_acc: 0.9091\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0599 - acc: 0.9787 - val_loss: 0.1243 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0514 - acc: 0.9787 - val_loss: 0.1601 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0542 - acc: 0.9787 - val_loss: 0.3411 - val_acc: 0.8182\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.1022 - acc: 0.9362 - val_loss: 0.1709 - val_acc: 0.9091\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.2218 - acc: 0.9149 - val_loss: 0.0682 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0366 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0242 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7061 - val_acc: 0.8182\n",
      "MODEL: DNN accuracy:  0.7758620689655173 +/-: 0.04093251180052607\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78, 1) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6789 - acc: 0.6087 - val_loss: 0.6889 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.7072 - acc: 0.6087 - val_loss: 0.6701 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6879 - acc: 0.5652 - val_loss: 0.6531 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6668 - acc: 0.5435 - val_loss: 0.6347 - val_acc: 0.5833\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6507 - acc: 0.6304 - val_loss: 0.6060 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6259 - acc: 0.6304 - val_loss: 0.6147 - val_acc: 0.6667\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5736 - acc: 0.6304 - val_loss: 0.5979 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5363 - acc: 0.7609 - val_loss: 0.5832 - val_acc: 0.6667\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4705 - acc: 0.7609 - val_loss: 0.5633 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4467 - acc: 0.8913 - val_loss: 0.6962 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.4834 - acc: 0.7391 - val_loss: 0.4408 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.4967 - acc: 0.8043 - val_loss: 0.3305 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.3869 - acc: 0.8696 - val_loss: 0.3258 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.3907 - acc: 0.8478 - val_loss: 0.5264 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4317 - acc: 0.7609 - val_loss: 0.2904 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.3806 - acc: 0.8298 - val_loss: 0.3613 - val_acc: 0.9091\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.3113 - acc: 0.9149 - val_loss: 0.3298 - val_acc: 0.9091\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4221 - acc: 0.7872 - val_loss: 0.3413 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.2819 - acc: 0.8936 - val_loss: 0.3323 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.2600 - acc: 0.8936 - val_loss: 0.3732 - val_acc: 0.8182\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.3212 - acc: 0.8723 - val_loss: 0.2042 - val_acc: 0.9091\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.3234 - acc: 0.8511 - val_loss: 0.2080 - val_acc: 0.9091\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.2624 - acc: 0.9149 - val_loss: 0.2238 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.3086 - acc: 0.8723 - val_loss: 0.2804 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.2905 - acc: 0.8936 - val_loss: 0.2020 - val_acc: 0.9091\n",
      "MODEL: CNN accuracy:  0.7413793103448276 +/-: 0.018538536374446003\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: RF accuracy:  0.8103448275862069 +/-: 0.03286581630814686\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: XGB accuracy:  0.7413793103448276 +/-: 0.01030969624905416\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: LGBM accuracy:  0.8448275862068966 +/-: 0.016020790545166287\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: ET accuracy:  0.7931034482758621 +/-: 0.030339062443699775\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: SVM accuracy:  0.896551724137931 +/-: 0.004319352862753574\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "MODEL: MLNN accuracy:  0.8620689655172413 +/-: 0.007490181241667566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "Initial alpha = [[0.07195591]]\n",
      "   1 - L=-602.8559486 - Gamma= 1.9997818 (M=   2) - s=0.0100\n",
      "   2 - L=-449.5794884 - Gamma= 2.9996372 (M=   3) - s=0.0100\n",
      "   3 - L=-409.1881149 - Gamma= 3.9992795 (M=   4) - s=0.0100\n",
      "   4 - L=-360.8526185 - Gamma= 4.9989688 (M=   5) - s=0.0100\n",
      "   5 - L=-330.3274912 - Gamma= 5.9984605 (M=   6) - s=0.0100\n",
      "   6 - L=-299.6128394 - Gamma= 6.9978969 (M=   7) - s=0.0100\n",
      "   7 - L=-270.7440848 - Gamma= 7.9973866 (M=   8) - s=0.0100\n",
      "   8 - L=-252.7997755 - Gamma= 8.9967130 (M=   9) - s=0.0100\n",
      "   9 - L=-236.0625878 - Gamma= 9.9958487 (M=  10) - s=0.0100\n",
      "  10 - L=-212.4827134 - Gamma=10.9951404 (M=  11) - s=0.0100\n",
      "  11 - L=-191.3827772 - Gamma=11.9944277 (M=  12) - s=0.0100\n",
      "  12 - L=-162.4593215 - Gamma=12.9935037 (M=  13) - s=0.0100\n",
      "  13 - L=-135.4491138 - Gamma=13.9907086 (M=  14) - s=0.0100\n",
      "  14 - L=-115.3884130 - Gamma=14.9897803 (M=  15) - s=0.0100\n",
      "  15 - L=-102.4516443 - Gamma=15.9882129 (M=  16) - s=0.0100\n",
      "  16 - L=-86.2645184 - Gamma=16.9869907 (M=  17) - s=0.0100\n",
      "  17 - L=-79.2125962 - Gamma=17.9847301 (M=  18) - s=0.0100\n",
      "  18 - L=-71.6635238 - Gamma=18.9815801 (M=  19) - s=0.0100\n",
      "  19 - L=-64.1366904 - Gamma=19.9791266 (M=  20) - s=0.0100\n",
      "  20 - L=-60.3758369 - Gamma=20.9753294 (M=  21) - s=0.0100\n",
      "  21 - L=-55.3738990 - Gamma=21.9721181 (M=  22) - s=0.0100\n",
      "  22 - L=-49.9404646 - Gamma=22.9677943 (M=  23) - s=0.0100\n",
      "  23 - L=-45.1647422 - Gamma=23.9588124 (M=  24) - s=0.0100\n",
      "  24 - L=-41.1530678 - Gamma=24.9532513 (M=  25) - s=0.0100\n",
      "  25 - L=-36.0778036 - Gamma=25.9432983 (M=  26) - s=0.0100\n",
      "  26 - L=-29.9595496 - Gamma=26.9391687 (M=  27) - s=0.0100\n",
      "  27 - L=-29.8939017 - Gamma=25.9453004 (M=  26) - s=0.0100\n",
      "  28 - L=-23.5738683 - Gamma=26.9348033 (M=  27) - s=0.0100\n",
      "  29 - L=-23.4985589 - Gamma=25.9441167 (M=  26) - s=0.0100\n",
      "  30 - L=-18.1455747 - Gamma=26.9410363 (M=  27) - s=0.0100\n",
      "  31 - L=-11.8484059 - Gamma=27.9329183 (M=  28) - s=0.0100\n",
      "  32 - L=-8.2744674 - Gamma=28.9239542 (M=  29) - s=0.0100\n",
      "  33 - L=-6.8975228 - Gamma=29.9067779 (M=  30) - s=0.0100\n",
      "  34 - L=-4.3407391 - Gamma=30.8770709 (M=  31) - s=0.0100\n",
      "  35 - L=-2.9028384 - Gamma=31.8616926 (M=  32) - s=0.0100\n",
      "  36 - L=-2.0514123 - Gamma=32.8422738 (M=  33) - s=0.0100\n",
      "  37 - L=-1.5385949 - Gamma=33.8153261 (M=  34) - s=0.0100\n",
      "  38 - L=-1.4839189 - Gamma=32.8349680 (M=  33) - s=0.0100\n",
      "  39 - L=-1.1488001 - Gamma=33.7903643 (M=  34) - s=0.0100\n",
      "  40 - L=-0.9391784 - Gamma=33.7980561 (M=  34) - s=0.0100\n",
      "  41 - L=-0.7394718 - Gamma=33.8016874 (M=  34) - s=0.0100\n",
      "  42 - L=-0.5395420 - Gamma=34.7488251 (M=  35) - s=0.0100\n",
      "  43 - L=-0.3706555 - Gamma=34.7527874 (M=  35) - s=0.0100\n",
      "  44 - L=-0.2011397 - Gamma=34.7628061 (M=  35) - s=0.0100\n",
      "  45 - L=-0.0534444 - Gamma=34.7697837 (M=  35) - s=0.0100\n",
      "  46 - L= 0.0242274 - Gamma=33.7823419 (M=  34) - s=0.0100\n",
      "  47 - L= 0.1590387 - Gamma=33.7882348 (M=  34) - s=0.0100\n",
      "  48 - L= 0.2954414 - Gamma=34.7161468 (M=  35) - s=0.0100\n",
      "  49 - L= 0.4444689 - Gamma=35.6337625 (M=  36) - s=0.0100\n",
      "  50 - L= 0.5490199 - Gamma=35.6372438 (M=  36) - s=0.0100\n",
      "  51 - L= 0.6021687 - Gamma=35.6464608 (M=  36) - s=0.0100\n",
      "  52 - L= 0.6555027 - Gamma=35.6503144 (M=  36) - s=0.0100\n",
      "  53 - L= 0.7001284 - Gamma=36.4736387 (M=  37) - s=0.0100\n",
      "  54 - L= 0.7461394 - Gamma=36.4773092 (M=  37) - s=0.0100\n",
      "  55 - L= 0.7783892 - Gamma=36.4807067 (M=  37) - s=0.0100\n",
      "  56 - L= 0.8101393 - Gamma=36.4921525 (M=  37) - s=0.0100\n",
      "  57 - L= 0.8405100 - Gamma=36.4936969 (M=  37) - s=0.0100\n",
      "  58 - L= 0.8697000 - Gamma=36.5012575 (M=  37) - s=0.0100\n",
      "  59 - L= 0.8985400 - Gamma=36.5048262 (M=  37) - s=0.0100\n",
      "  60 - L= 0.9234468 - Gamma=36.5080258 (M=  37) - s=0.0100\n",
      "  61 - L= 0.9443455 - Gamma=37.2602867 (M=  38) - s=0.0100\n",
      "  62 - L= 0.9688023 - Gamma=37.9696335 (M=  39) - s=0.0100\n",
      "  63 - L= 0.9838673 - Gamma=37.9803353 (M=  39) - s=0.0100\n",
      "  64 - L= 0.9965989 - Gamma=37.9831818 (M=  39) - s=0.0100\n",
      "  65 - L= 1.0068720 - Gamma=37.9858077 (M=  39) - s=0.0100\n",
      "  66 - L= 1.0167212 - Gamma=37.9783821 (M=  39) - s=0.0100\n",
      "  67 - L= 1.0245754 - Gamma=38.4754906 (M=  40) - s=0.0100\n",
      "  68 - L= 1.0298537 - Gamma=38.4950990 (M=  40) - s=0.0100\n",
      "  69 - L= 1.0334872 - Gamma=38.4965008 (M=  40) - s=0.0100\n",
      "  70 - L= 1.0371056 - Gamma=38.4935114 (M=  40) - s=0.0100\n",
      "  71 - L= 1.0399824 - Gamma=38.5900803 (M=  40) - s=0.0100\n",
      "  72 - L= 1.0430066 - Gamma=39.0246095 (M=  41) - s=0.0100\n",
      "  73 - L= 1.0461766 - Gamma=39.0666168 (M=  41) - s=0.0100\n",
      "  74 - L= 1.0493674 - Gamma=39.5143466 (M=  42) - s=0.0100\n",
      "  75 - L= 1.0512660 - Gamma=39.5279953 (M=  42) - s=0.0100\n",
      "  76 - L= 1.0526587 - Gamma=39.6969664 (M=  42) - s=0.0100\n",
      "  77 - L= 1.0539160 - Gamma=39.7235033 (M=  42) - s=0.0100\n",
      "  78 - L= 1.0550912 - Gamma=39.7126400 (M=  42) - s=0.0100\n",
      "  79 - L= 1.0560048 - Gamma=39.7136335 (M=  42) - s=0.0100\n",
      "  80 - L= 1.0568440 - Gamma=39.7312867 (M=  42) - s=0.0100\n",
      "  81 - L= 1.0576279 - Gamma=39.5889593 (M=  42) - s=0.0100\n",
      "  82 - L= 1.0584256 - Gamma=39.6366633 (M=  42) - s=0.0100\n",
      "  83 - L= 1.0592036 - Gamma=39.6454019 (M=  42) - s=0.0100\n",
      "  84 - L= 1.0599315 - Gamma=39.6415585 (M=  42) - s=0.0100\n",
      "  85 - L= 1.0604680 - Gamma=39.6410790 (M=  42) - s=0.0100\n",
      "  86 - L= 1.0608212 - Gamma=39.6398993 (M=  42) - s=0.0100\n",
      "  87 - L= 1.0611595 - Gamma=39.8378602 (M=  43) - s=0.0100\n",
      "  88 - L= 1.0613865 - Gamma=39.8370022 (M=  43) - s=0.0100\n",
      "  89 - L= 1.0615815 - Gamma=39.8409407 (M=  43) - s=0.0100\n",
      "  90 - L= 1.0617634 - Gamma=39.8406017 (M=  43) - s=0.0100\n",
      "  91 - L= 1.0619024 - Gamma=39.8471303 (M=  43) - s=0.0100\n",
      "  92 - L= 1.0620474 - Gamma=39.8642256 (M=  43) - s=0.0100\n",
      "  93 - L= 1.0621687 - Gamma=39.8642633 (M=  43) - s=0.0100\n",
      "  94 - L= 1.0622748 - Gamma=39.9233072 (M=  43) - s=0.0100\n",
      "  95 - L= 1.0624082 - Gamma=39.9623252 (M=  43) - s=0.0100\n",
      "  96 - L= 1.0625072 - Gamma=39.9621416 (M=  43) - s=0.0100\n",
      "  97 - L= 1.0625942 - Gamma=39.9622435 (M=  43) - s=0.0100\n",
      "  98 - L= 1.0626809 - Gamma=39.9619355 (M=  43) - s=0.0100\n",
      "  99 - L= 1.0627602 - Gamma=39.9619620 (M=  43) - s=0.0100\n",
      " 100 - L= 1.0628310 - Gamma=39.9084806 (M=  43) - s=0.0100\n",
      " 101 - L= 1.0628987 - Gamma=39.9075415 (M=  43) - s=0.0100\n",
      " 102 - L= 1.0629642 - Gamma=39.9076929 (M=  43) - s=0.0100\n",
      " 103 - L= 1.0630239 - Gamma=39.9077421 (M=  43) - s=0.0100\n",
      " 104 - L= 1.0630704 - Gamma=39.9091813 (M=  43) - s=0.0100\n",
      " 105 - L= 1.0631136 - Gamma=39.8395890 (M=  43) - s=0.0100\n",
      " 106 - L= 1.0631823 - Gamma=39.8818905 (M=  43) - s=0.0100\n",
      " 107 - L= 1.0632252 - Gamma=39.8817666 (M=  43) - s=0.0100\n",
      " 108 - L= 1.0632626 - Gamma=39.8799216 (M=  43) - s=0.0100\n",
      " 109 - L= 1.0632905 - Gamma=39.8826643 (M=  43) - s=0.0100\n",
      " 110 - L= 1.0633210 - Gamma=39.8993753 (M=  43) - s=0.0100\n",
      " 111 - L= 1.0633484 - Gamma=39.8629023 (M=  43) - s=0.0100\n",
      " 112 - L= 1.0633797 - Gamma=39.8854252 (M=  43) - s=0.0100\n",
      " 113 - L= 1.0634094 - Gamma=39.8858131 (M=  43) - s=0.0100\n",
      " 114 - L= 1.0634338 - Gamma=39.8922529 (M=  43) - s=0.0100\n",
      " 115 - L= 1.0634570 - Gamma=39.8908831 (M=  43) - s=0.0100\n",
      " 116 - L= 1.0634731 - Gamma=39.8454228 (M=  43) - s=0.0100\n",
      " 117 - L= 1.0634924 - Gamma=39.8469488 (M=  43) - s=0.0100\n",
      " 118 - L= 1.0635111 - Gamma=39.8492341 (M=  43) - s=0.0100\n",
      " 119 - L= 1.0635278 - Gamma=39.8686873 (M=  43) - s=0.0100\n",
      " 120 - L= 1.0635514 - Gamma=39.8321781 (M=  43) - s=0.0100\n",
      " 121 - L= 1.0635695 - Gamma=39.8319543 (M=  43) - s=0.0100\n",
      " 122 - L= 1.0635876 - Gamma=39.8439770 (M=  43) - s=0.0100\n",
      " 123 - L= 1.0635992 - Gamma=39.8429445 (M=  43) - s=0.0100\n",
      " 124 - L= 1.0636070 - Gamma=39.8098590 (M=  43) - s=0.0100\n",
      " 125 - L= 1.0636189 - Gamma=39.8254935 (M=  43) - s=0.0100\n",
      " 126 - L= 1.0636276 - Gamma=39.8257325 (M=  43) - s=0.0100\n",
      " 127 - L= 1.0636384 - Gamma=39.7996282 (M=  43) - s=0.0100\n",
      " 128 - L= 1.0636497 - Gamma=39.8124336 (M=  43) - s=0.0100\n",
      " 129 - L= 1.0636596 - Gamma=39.8130613 (M=  43) - s=0.0100\n",
      " 130 - L= 1.0636675 - Gamma=39.8129800 (M=  43) - s=0.0100\n",
      " 131 - L= 1.0636745 - Gamma=39.8129666 (M=  43) - s=0.0100\n",
      " 132 - L= 1.0636812 - Gamma=39.8162011 (M=  43) - s=0.0100\n",
      " 133 - L= 1.0636886 - Gamma=39.8157197 (M=  43) - s=0.0100\n",
      " 134 - L= 1.0636959 - Gamma=39.8148516 (M=  43) - s=0.0100\n",
      " 135 - L= 1.0637044 - Gamma=39.8191570 (M=  43) - s=0.0100\n",
      " 136 - L= 1.0637120 - Gamma=39.8183226 (M=  43) - s=0.0100\n",
      " 137 - L= 1.0637188 - Gamma=39.8196377 (M=  43) - s=0.0100\n",
      " 138 - L= 1.0637251 - Gamma=39.8196518 (M=  43) - s=0.0100\n",
      " 139 - L= 1.0637311 - Gamma=39.8196706 (M=  43) - s=0.0100\n",
      " 140 - L= 1.0637367 - Gamma=39.8208817 (M=  43) - s=0.0100\n",
      " 141 - L= 1.0637433 - Gamma=39.7891285 (M=  43) - s=0.0100\n",
      " 142 - L= 1.0637480 - Gamma=39.7892506 (M=  43) - s=0.0100\n",
      " 143 - L= 1.0637536 - Gamma=39.7697907 (M=  43) - s=0.0100\n",
      " 144 - L= 1.0637626 - Gamma=39.7807110 (M=  43) - s=0.0100\n",
      " 145 - L= 1.0637679 - Gamma=39.7806563 (M=  43) - s=0.0100\n",
      " 146 - L= 1.0637729 - Gamma=39.7813940 (M=  43) - s=0.0100\n",
      " 147 - L= 1.0637769 - Gamma=39.7901439 (M=  43) - s=0.0100\n",
      " 148 - L= 1.0637823 - Gamma=39.7965103 (M=  43) - s=0.0100\n",
      " 149 - L= 1.0637923 - Gamma=39.7691888 (M=  43) - s=0.0100\n",
      " 150 - L= 1.0637959 - Gamma=39.7714894 (M=  43) - s=0.0100\n",
      " 151 - L= 1.0637993 - Gamma=39.7712568 (M=  43) - s=0.0100\n",
      " 152 - L= 1.0638023 - Gamma=39.7707041 (M=  43) - s=0.0100\n",
      " 153 - L= 1.0638040 - Gamma=39.7543567 (M=  42) - s=0.0100\n",
      " 154 - L= 1.0638077 - Gamma=39.7626607 (M=  42) - s=0.0100\n",
      " 155 - L= 1.0638111 - Gamma=39.7635963 (M=  42) - s=0.0100\n",
      " 156 - L= 1.0638140 - Gamma=39.7630630 (M=  42) - s=0.0100\n",
      " 157 - L= 1.0638170 - Gamma=39.7676059 (M=  42) - s=0.0100\n",
      " 158 - L= 1.0638197 - Gamma=39.7676422 (M=  42) - s=0.0100\n",
      " 159 - L= 1.0638221 - Gamma=39.7538406 (M=  42) - s=0.0100\n",
      " 160 - L= 1.0638247 - Gamma=39.7595927 (M=  42) - s=0.0100\n",
      " 161 - L= 1.0638273 - Gamma=39.7590528 (M=  42) - s=0.0100\n",
      " 162 - L= 1.0638297 - Gamma=39.7593538 (M=  42) - s=0.0100\n",
      " 163 - L= 1.0638318 - Gamma=39.7593254 (M=  42) - s=0.0100\n",
      " 164 - L= 1.0638339 - Gamma=39.7594353 (M=  42) - s=0.0100\n",
      " 165 - L= 1.0638358 - Gamma=39.7594083 (M=  42) - s=0.0100\n",
      " 166 - L= 1.0638377 - Gamma=39.7594245 (M=  42) - s=0.0100\n",
      " 167 - L= 1.0638394 - Gamma=39.7593548 (M=  42) - s=0.0100\n",
      " 168 - L= 1.0638411 - Gamma=39.7591131 (M=  42) - s=0.0100\n",
      " 169 - L= 1.0638428 - Gamma=39.7591229 (M=  42) - s=0.0100\n",
      " 170 - L= 1.0638444 - Gamma=39.7476632 (M=  42) - s=0.0100\n",
      " 171 - L= 1.0638460 - Gamma=39.7476866 (M=  42) - s=0.0100\n",
      " 172 - L= 1.0638474 - Gamma=39.7526908 (M=  42) - s=0.0100\n",
      " 173 - L= 1.0638488 - Gamma=39.7532862 (M=  42) - s=0.0100\n",
      " 174 - L= 1.0638503 - Gamma=39.7564167 (M=  42) - s=0.0100\n",
      " 175 - L= 1.0638515 - Gamma=39.7577259 (M=  42) - s=0.0100\n",
      " 176 - L= 1.0638526 - Gamma=39.7576879 (M=  42) - s=0.0100\n",
      " 177 - L= 1.0638537 - Gamma=39.7576744 (M=  42) - s=0.0100\n",
      " 178 - L= 1.0638546 - Gamma=39.7576461 (M=  42) - s=0.0100\n",
      " 179 - L= 1.0638554 - Gamma=39.7579312 (M=  42) - s=0.0100\n",
      " 180 - L= 1.0638563 - Gamma=39.7489065 (M=  42) - s=0.0100\n",
      " 181 - L= 1.0638573 - Gamma=39.7523348 (M=  42) - s=0.0100\n",
      " 182 - L= 1.0638583 - Gamma=39.7520197 (M=  42) - s=0.0100\n",
      " 183 - L= 1.0638591 - Gamma=39.7524889 (M=  42) - s=0.0100\n",
      " 184 - L= 1.0638598 - Gamma=39.7525461 (M=  42) - s=0.0100\n",
      " 185 - L= 1.0638605 - Gamma=39.7525909 (M=  42) - s=0.0100\n",
      " 186 - L= 1.0638612 - Gamma=39.7523307 (M=  42) - s=0.0100\n",
      " 187 - L= 1.0638617 - Gamma=39.7454366 (M=  42) - s=0.0100\n",
      " 188 - L= 1.0638624 - Gamma=39.7489200 (M=  42) - s=0.0100\n",
      " 189 - L= 1.0638631 - Gamma=39.7489005 (M=  42) - s=0.0100\n",
      " 190 - L= 1.0638637 - Gamma=39.7509378 (M=  42) - s=0.0100\n",
      " 191 - L= 1.0638641 - Gamma=39.7509495 (M=  42) - s=0.0100\n",
      " 192 - L= 1.0638645 - Gamma=39.7448573 (M=  42) - s=0.0100\n",
      " 193 - L= 1.0638649 - Gamma=39.7446389 (M=  42) - s=0.0100\n",
      " 194 - L= 1.0638653 - Gamma=39.7446877 (M=  42) - s=0.0100\n",
      " 195 - L= 1.0638657 - Gamma=39.7455962 (M=  42) - s=0.0100\n",
      " 196 - L= 1.0638662 - Gamma=39.7478745 (M=  42) - s=0.0100\n",
      " 197 - L= 1.0638665 - Gamma=39.7482207 (M=  42) - s=0.0100\n",
      " 198 - L= 1.0638668 - Gamma=39.7481507 (M=  42) - s=0.0100\n",
      " 199 - L= 1.0638670 - Gamma=39.7433899 (M=  42) - s=0.0100\n",
      " 200 - L= 1.0638672 - Gamma=39.7433866 (M=  42) - s=0.0100\n",
      "Initial alpha = [[0.07397588]]\n",
      "   1 - L=-549.6256059 - Gamma= 1.9999064 (M=   2) - s=0.0100\n",
      "   2 - L=-425.4495067 - Gamma= 2.9998124 (M=   3) - s=0.0100\n",
      "   3 - L=-349.9548466 - Gamma= 3.9996086 (M=   4) - s=0.0100\n",
      "   4 - L=-316.7962341 - Gamma= 4.9992036 (M=   5) - s=0.0100\n",
      "   5 - L=-279.9418059 - Gamma= 5.9988892 (M=   6) - s=0.0100\n",
      "   6 - L=-245.0544480 - Gamma= 6.9982768 (M=   7) - s=0.0100\n",
      "   7 - L=-202.8963361 - Gamma= 7.9978433 (M=   8) - s=0.0100\n",
      "   8 - L=-184.3131138 - Gamma= 8.9965588 (M=   9) - s=0.0100\n",
      "   9 - L=-184.2312015 - Gamma= 7.9977074 (M=   8) - s=0.0100\n",
      "  10 - L=-165.1822399 - Gamma= 8.9969022 (M=   9) - s=0.0100\n",
      "  11 - L=-147.6366222 - Gamma= 9.9962123 (M=  10) - s=0.0100\n",
      "  12 - L=-129.3533109 - Gamma=10.9954699 (M=  11) - s=0.0100\n",
      "  13 - L=-119.0027494 - Gamma=11.9940325 (M=  12) - s=0.0100\n",
      "  14 - L=-110.5606463 - Gamma=12.9924555 (M=  13) - s=0.0100\n",
      "  15 - L=-102.9870905 - Gamma=13.9897992 (M=  14) - s=0.0100\n",
      "  16 - L=-97.1539024 - Gamma=14.9877317 (M=  15) - s=0.0100\n",
      "  17 - L=-89.0746208 - Gamma=15.9862212 (M=  16) - s=0.0100\n",
      "  18 - L=-73.2693314 - Gamma=16.9835675 (M=  17) - s=0.0100\n",
      "  19 - L=-65.9965958 - Gamma=17.9804940 (M=  18) - s=0.0100\n",
      "  20 - L=-55.2951370 - Gamma=18.9774283 (M=  19) - s=0.0100\n",
      "  21 - L=-51.6165080 - Gamma=19.9722736 (M=  20) - s=0.0100\n",
      "  22 - L=-46.3959956 - Gamma=20.9685605 (M=  21) - s=0.0100\n",
      "  23 - L=-43.6238437 - Gamma=21.9599027 (M=  22) - s=0.0100\n",
      "  24 - L=-40.9229991 - Gamma=22.9538748 (M=  23) - s=0.0100\n",
      "  25 - L=-40.8580301 - Gamma=21.9606361 (M=  22) - s=0.0100\n",
      "  26 - L=-35.7777935 - Gamma=22.9501942 (M=  23) - s=0.0100\n",
      "  27 - L=-35.7216135 - Gamma=21.9571974 (M=  22) - s=0.0100\n",
      "  28 - L=-29.9322825 - Gamma=22.9514333 (M=  23) - s=0.0100\n",
      "  29 - L=-29.8622159 - Gamma=21.9551543 (M=  22) - s=0.0100\n",
      "  30 - L=-26.1136148 - Gamma=22.9499551 (M=  23) - s=0.0100\n",
      "  31 - L=-22.3917733 - Gamma=23.9437058 (M=  24) - s=0.0100\n",
      "  32 - L=-18.6923773 - Gamma=24.9338439 (M=  25) - s=0.0100\n",
      "  33 - L=-16.1548438 - Gamma=25.9255297 (M=  26) - s=0.0100\n",
      "  34 - L=-12.9593714 - Gamma=26.9161496 (M=  27) - s=0.0100\n",
      "  35 - L=-8.9515449 - Gamma=27.9088839 (M=  28) - s=0.0100\n",
      "  36 - L=-4.6250871 - Gamma=28.9024465 (M=  29) - s=0.0100\n",
      "  37 - L=-3.3033752 - Gamma=29.8872745 (M=  30) - s=0.0100\n",
      "  38 - L=-2.0811361 - Gamma=30.8772813 (M=  31) - s=0.0100\n",
      "  39 - L=-1.5784120 - Gamma=31.8441546 (M=  32) - s=0.0100\n",
      "  40 - L=-1.5031655 - Gamma=30.8597761 (M=  31) - s=0.0100\n",
      "  41 - L=-1.4448028 - Gamma=29.8700975 (M=  30) - s=0.0100\n",
      "  42 - L=-0.8478723 - Gamma=30.8453836 (M=  31) - s=0.0100\n",
      "  43 - L=-0.5010267 - Gamma=31.7947111 (M=  32) - s=0.0100\n",
      "  44 - L=-0.1649298 - Gamma=31.8104890 (M=  32) - s=0.0100\n",
      "  45 - L= 0.1553362 - Gamma=32.7664697 (M=  33) - s=0.0100\n",
      "  46 - L= 0.3209064 - Gamma=33.6773362 (M=  34) - s=0.0100\n",
      "  47 - L= 0.3516263 - Gamma=32.7655116 (M=  33) - s=0.0100\n",
      "  48 - L= 0.4773915 - Gamma=32.7695912 (M=  33) - s=0.0100\n",
      "  49 - L= 0.5748995 - Gamma=32.7729992 (M=  33) - s=0.0100\n",
      "  50 - L= 0.6541876 - Gamma=32.7761293 (M=  33) - s=0.0100\n",
      "  51 - L= 0.7263141 - Gamma=32.8040914 (M=  33) - s=0.0100\n",
      "  52 - L= 0.7924552 - Gamma=32.8078475 (M=  33) - s=0.0100\n",
      "  53 - L= 0.8547566 - Gamma=33.6816704 (M=  34) - s=0.0100\n",
      "  54 - L= 0.9101964 - Gamma=33.6025227 (M=  34) - s=0.0100\n",
      "  55 - L= 0.9611309 - Gamma=34.4534195 (M=  35) - s=0.0100\n",
      "  56 - L= 1.0146247 - Gamma=34.4575829 (M=  35) - s=0.0100\n",
      "  57 - L= 1.0595119 - Gamma=34.4604811 (M=  35) - s=0.0100\n",
      "  58 - L= 1.1037688 - Gamma=34.4634945 (M=  35) - s=0.0100\n",
      "  59 - L= 1.1439813 - Gamma=35.2123248 (M=  36) - s=0.0100\n",
      "  60 - L= 1.1851990 - Gamma=35.2147241 (M=  36) - s=0.0100\n",
      "  61 - L= 1.2192206 - Gamma=35.2194327 (M=  36) - s=0.0100\n",
      "  62 - L= 1.2507749 - Gamma=35.2214437 (M=  36) - s=0.0100\n",
      "  63 - L= 1.2666456 - Gamma=35.9454814 (M=  37) - s=0.0100\n",
      "  64 - L= 1.2829685 - Gamma=35.9508606 (M=  37) - s=0.0100\n",
      "  65 - L= 1.2985251 - Gamma=35.9555014 (M=  37) - s=0.0100\n",
      "  66 - L= 1.3125510 - Gamma=35.9567173 (M=  37) - s=0.0100\n",
      "  67 - L= 1.3261407 - Gamma=35.9741350 (M=  37) - s=0.0100\n",
      "  68 - L= 1.3369765 - Gamma=35.9754726 (M=  37) - s=0.0100\n",
      "  69 - L= 1.3460304 - Gamma=35.9759487 (M=  37) - s=0.0100\n",
      "  70 - L= 1.3538987 - Gamma=36.0810448 (M=  37) - s=0.0100\n",
      "  71 - L= 1.3596829 - Gamma=36.0841179 (M=  37) - s=0.0100\n",
      "  72 - L= 1.3647775 - Gamma=35.8735541 (M=  37) - s=0.0100\n",
      "  73 - L= 1.3696782 - Gamma=35.8451445 (M=  37) - s=0.0100\n",
      "  74 - L= 1.3742064 - Gamma=36.3546204 (M=  38) - s=0.0100\n",
      "  75 - L= 1.3777941 - Gamma=36.3575872 (M=  38) - s=0.0100\n",
      "  76 - L= 1.3812271 - Gamma=36.3626505 (M=  38) - s=0.0100\n",
      "  77 - L= 1.3836650 - Gamma=36.3555638 (M=  38) - s=0.0100\n",
      "  78 - L= 1.3857499 - Gamma=36.3591982 (M=  38) - s=0.0100\n",
      "  79 - L= 1.3876464 - Gamma=36.4172309 (M=  38) - s=0.0100\n",
      "  80 - L= 1.3892489 - Gamma=36.4629167 (M=  38) - s=0.0100\n",
      "  81 - L= 1.3910462 - Gamma=36.8297208 (M=  39) - s=0.0100\n",
      "  82 - L= 1.3928300 - Gamma=36.5508786 (M=  39) - s=0.0100\n",
      "  83 - L= 1.3946551 - Gamma=36.5608686 (M=  39) - s=0.0100\n",
      "  84 - L= 1.3964593 - Gamma=36.3333978 (M=  39) - s=0.0100\n",
      "  85 - L= 1.3974535 - Gamma=36.3517380 (M=  39) - s=0.0100\n",
      "  86 - L= 1.3983851 - Gamma=36.3533807 (M=  39) - s=0.0100\n",
      "  87 - L= 1.3992345 - Gamma=36.3543450 (M=  39) - s=0.0100\n",
      "  88 - L= 1.3997838 - Gamma=36.3402797 (M=  39) - s=0.0100\n",
      "  89 - L= 1.4002972 - Gamma=36.4745083 (M=  39) - s=0.0100\n",
      "  90 - L= 1.4009029 - Gamma=36.2227847 (M=  39) - s=0.0100\n",
      "  91 - L= 1.4014688 - Gamma=36.2219712 (M=  39) - s=0.0100\n",
      "  92 - L= 1.4019564 - Gamma=36.2396473 (M=  39) - s=0.0100\n",
      "  93 - L= 1.4024216 - Gamma=36.2338769 (M=  39) - s=0.0100\n",
      "  94 - L= 1.4024536 - Gamma=36.1719571 (M=  38) - s=0.0100\n",
      "  95 - L= 1.4029153 - Gamma=36.1907663 (M=  38) - s=0.0100\n",
      "  96 - L= 1.4033795 - Gamma=36.1927453 (M=  38) - s=0.0100\n",
      "  97 - L= 1.4037510 - Gamma=36.0387088 (M=  38) - s=0.0100\n",
      "  98 - L= 1.4040012 - Gamma=36.0467566 (M=  38) - s=0.0100\n",
      "  99 - L= 1.4042863 - Gamma=36.1248466 (M=  38) - s=0.0100\n",
      " 100 - L= 1.4044883 - Gamma=36.1230074 (M=  38) - s=0.0100\n",
      " 101 - L= 1.4046629 - Gamma=36.1290978 (M=  38) - s=0.0100\n",
      " 102 - L= 1.4048178 - Gamma=36.1296166 (M=  38) - s=0.0100\n",
      " 103 - L= 1.4049630 - Gamma=36.1287295 (M=  38) - s=0.0100\n",
      " 104 - L= 1.4050954 - Gamma=36.1288485 (M=  38) - s=0.0100\n",
      " 105 - L= 1.4052223 - Gamma=36.1289106 (M=  38) - s=0.0100\n",
      " 106 - L= 1.4053141 - Gamma=36.1289837 (M=  38) - s=0.0100\n",
      " 107 - L= 1.4053939 - Gamma=36.1306512 (M=  38) - s=0.0100\n",
      " 108 - L= 1.4054600 - Gamma=36.1313593 (M=  38) - s=0.0100\n",
      " 109 - L= 1.4055144 - Gamma=36.1348482 (M=  38) - s=0.0100\n",
      " 110 - L= 1.4055541 - Gamma=36.0763493 (M=  38) - s=0.0100\n",
      " 111 - L= 1.4055905 - Gamma=36.0743200 (M=  38) - s=0.0100\n",
      " 112 - L= 1.4056210 - Gamma=36.0782090 (M=  38) - s=0.0100\n",
      " 113 - L= 1.4056541 - Gamma=36.1016507 (M=  38) - s=0.0100\n",
      " 114 - L= 1.4057001 - Gamma=36.0605409 (M=  38) - s=0.0100\n",
      " 115 - L= 1.4057363 - Gamma=36.0561596 (M=  38) - s=0.0100\n",
      " 116 - L= 1.4057628 - Gamma=36.0557966 (M=  38) - s=0.0100\n",
      " 117 - L= 1.4057841 - Gamma=36.0557641 (M=  38) - s=0.0100\n",
      " 118 - L= 1.4058019 - Gamma=36.0557928 (M=  38) - s=0.0100\n",
      " 119 - L= 1.4058178 - Gamma=36.0557546 (M=  38) - s=0.0100\n",
      " 120 - L= 1.4058325 - Gamma=36.0575302 (M=  38) - s=0.0100\n",
      " 121 - L= 1.4058454 - Gamma=36.0573906 (M=  38) - s=0.0100\n",
      " 122 - L= 1.4058545 - Gamma=36.0574113 (M=  38) - s=0.0100\n",
      " 123 - L= 1.4058629 - Gamma=36.0685776 (M=  38) - s=0.0100\n",
      " 124 - L= 1.4058707 - Gamma=36.0686172 (M=  38) - s=0.0100\n",
      " 125 - L= 1.4058784 - Gamma=36.0686323 (M=  38) - s=0.0100\n",
      " 126 - L= 1.4058860 - Gamma=36.0686476 (M=  38) - s=0.0100\n",
      " 127 - L= 1.4058924 - Gamma=36.0685689 (M=  38) - s=0.0100\n",
      " 128 - L= 1.4058985 - Gamma=36.0685550 (M=  38) - s=0.0100\n",
      " 129 - L= 1.4059038 - Gamma=36.0701151 (M=  38) - s=0.0100\n",
      " 130 - L= 1.4059092 - Gamma=36.0701245 (M=  38) - s=0.0100\n",
      " 131 - L= 1.4059144 - Gamma=36.0693045 (M=  38) - s=0.0100\n",
      " 132 - L= 1.4059191 - Gamma=36.0710028 (M=  38) - s=0.0100\n",
      " 133 - L= 1.4059236 - Gamma=36.0719160 (M=  38) - s=0.0100\n",
      " 134 - L= 1.4059276 - Gamma=36.0720128 (M=  38) - s=0.0100\n",
      " 135 - L= 1.4059311 - Gamma=36.0600936 (M=  38) - s=0.0100\n",
      " 136 - L= 1.4059336 - Gamma=36.0600303 (M=  38) - s=0.0100\n",
      " 137 - L= 1.4059360 - Gamma=36.0601043 (M=  38) - s=0.0100\n",
      " 138 - L= 1.4059382 - Gamma=36.0602316 (M=  38) - s=0.0100\n",
      " 139 - L= 1.4059404 - Gamma=36.0657700 (M=  38) - s=0.0100\n",
      " 140 - L= 1.4059424 - Gamma=36.0660216 (M=  38) - s=0.0100\n",
      " 141 - L= 1.4059437 - Gamma=36.0659958 (M=  38) - s=0.0100\n",
      " 142 - L= 1.4059450 - Gamma=36.0654686 (M=  38) - s=0.0100\n",
      " 143 - L= 1.4059462 - Gamma=36.0792485 (M=  39) - s=0.0100\n",
      " 144 - L= 1.4059471 - Gamma=36.0702142 (M=  39) - s=0.0100\n",
      " 145 - L= 1.4059480 - Gamma=36.0694763 (M=  39) - s=0.0100\n",
      " 146 - L= 1.4059489 - Gamma=36.0693463 (M=  39) - s=0.0100\n",
      " 147 - L= 1.4059495 - Gamma=36.0692837 (M=  39) - s=0.0100\n",
      " 148 - L= 1.4059500 - Gamma=36.0692235 (M=  39) - s=0.0100\n",
      " 149 - L= 1.4059505 - Gamma=36.0689718 (M=  39) - s=0.0100\n",
      " 150 - L= 1.4059510 - Gamma=36.0643114 (M=  39) - s=0.0100\n",
      " 151 - L= 1.4059515 - Gamma=36.0646264 (M=  39) - s=0.0100\n",
      " 152 - L= 1.4059519 - Gamma=36.0671716 (M=  39) - s=0.0100\n",
      " 153 - L= 1.4059524 - Gamma=36.0671760 (M=  39) - s=0.0100\n",
      " 154 - L= 1.4059528 - Gamma=36.0675974 (M=  39) - s=0.0100\n",
      " 155 - L= 1.4059531 - Gamma=36.0676016 (M=  39) - s=0.0100\n",
      " 156 - L= 1.4059533 - Gamma=36.0680023 (M=  39) - s=0.0100\n",
      " 157 - L= 1.4059536 - Gamma=36.0680070 (M=  39) - s=0.0100\n",
      " 158 - L= 1.4059538 - Gamma=36.0681903 (M=  39) - s=0.0100\n",
      " 159 - L= 1.4059539 - Gamma=36.0681598 (M=  39) - s=0.0100\n",
      " 160 - L= 1.4059541 - Gamma=36.0681619 (M=  39) - s=0.0100\n",
      " 161 - L= 1.4059542 - Gamma=36.0657380 (M=  39) - s=0.0100\n",
      " 162 - L= 1.4059543 - Gamma=36.0657454 (M=  39) - s=0.0100\n",
      " 163 - L= 1.4059544 - Gamma=36.0656371 (M=  39) - s=0.0100\n",
      " 164 - L= 1.4059545 - Gamma=36.0667045 (M=  39) - s=0.0100\n",
      " 165 - L= 1.4059545 - Gamma=36.0667036 (M=  39) - s=0.0100\n",
      " 166 - L= 1.4059546 - Gamma=36.0667049 (M=  39) - s=0.0100\n",
      " 167 - L= 1.4059546 - Gamma=36.0666990 (M=  39) - s=0.0100\n",
      " 168 - L= 1.4059546 - Gamma=36.0665619 (M=  39) - s=0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in log\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 169 - L= 1.4059547 - Gamma=36.0664892 (M=  39) - s=0.0100\n",
      " 170 - L= 1.4059547 - Gamma=36.0665551 (M=  39) - s=0.0100\n",
      " 171 - L= 1.4059547 - Gamma=36.0650907 (M=  39) - s=0.0100\n",
      " 172 - L= 1.4059547 - Gamma=36.0651160 (M=  39) - s=0.0100\n",
      " 173 - L= 1.4059547 - Gamma=36.0651277 (M=  39) - s=0.0100\n",
      " 174 - L= 1.4059548 - Gamma=36.0651224 (M=  39) - s=0.0100\n",
      " 175 - L= 1.4059548 - Gamma=36.0651216 (M=  39) - s=0.0100\n",
      " 176 - L= 1.4059548 - Gamma=36.0652069 (M=  39) - s=0.0100\n",
      " 177 - L= 1.4059548 - Gamma=36.0643389 (M=  39) - s=0.0100\n",
      " 178 - L= 1.4059548 - Gamma=36.0648226 (M=  39) - s=0.0100\n",
      " 179 - L= 1.4059548 - Gamma=36.0647860 (M=  39) - s=0.0100\n",
      " 180 - L= 1.4059548 - Gamma=36.0635401 (M=  39) - s=0.0100\n",
      " 181 - L= 1.4059549 - Gamma=36.0635439 (M=  39) - s=0.0100\n",
      " 182 - L= 1.4059549 - Gamma=36.0635484 (M=  39) - s=0.0100\n",
      " 183 - L= 1.4059549 - Gamma=36.0635864 (M=  39) - s=0.0100\n",
      " 184 - L= 1.4059549 - Gamma=36.0635859 (M=  39) - s=0.0100\n",
      " 185 - L= 1.4059549 - Gamma=36.0635794 (M=  39) - s=0.0100\n",
      " 186 - L= 1.4059549 - Gamma=36.0635800 (M=  39) - s=0.0100\n",
      " 187 - L= 1.4059549 - Gamma=36.0635800 (M=  39) - s=0.0100\n",
      "Stopping at iteration 187 - max_delta_ml=2.3010938896879255e-07\n",
      "L=1.4059548874049599 - Gamma=36.06357996756597 (M=39) - s=0.01\n",
      "Initial alpha = [[0.07488365]]\n",
      "   1 - L=-566.6487636 - Gamma= 1.9999174 (M=   2) - s=0.0100\n",
      "   2 - L=-483.6788415 - Gamma= 2.9997574 (M=   3) - s=0.0100\n",
      "   3 - L=-438.2379214 - Gamma= 3.9994288 (M=   4) - s=0.0100\n",
      "   4 - L=-398.2909259 - Gamma= 4.9990784 (M=   5) - s=0.0100\n",
      "   5 - L=-368.6974777 - Gamma= 5.9986270 (M=   6) - s=0.0100\n",
      "   6 - L=-315.8870130 - Gamma= 6.9978184 (M=   7) - s=0.0100\n",
      "   7 - L=-286.9033202 - Gamma= 7.9971318 (M=   8) - s=0.0100\n",
      "   8 - L=-247.2788580 - Gamma= 8.9965771 (M=   9) - s=0.0100\n",
      "   9 - L=-223.7829019 - Gamma= 9.9960643 (M=  10) - s=0.0100\n",
      "  10 - L=-188.9959235 - Gamma=10.9954644 (M=  11) - s=0.0100\n",
      "  11 - L=-161.2908818 - Gamma=11.9949413 (M=  12) - s=0.0100\n",
      "  12 - L=-161.2128322 - Gamma=10.9953877 (M=  11) - s=0.0100\n",
      "  13 - L=-134.6236354 - Gamma=11.9946931 (M=  12) - s=0.0100\n",
      "  14 - L=-115.0980282 - Gamma=12.9939567 (M=  13) - s=0.0100\n",
      "  15 - L=-101.6781220 - Gamma=13.9929522 (M=  14) - s=0.0100\n",
      "  16 - L=-92.1970356 - Gamma=14.9905078 (M=  15) - s=0.0100\n",
      "  17 - L=-84.4727683 - Gamma=15.9889027 (M=  16) - s=0.0100\n",
      "  18 - L=-77.7922846 - Gamma=16.9867747 (M=  17) - s=0.0100\n",
      "  19 - L=-72.9698062 - Gamma=17.9831391 (M=  18) - s=0.0100\n",
      "  20 - L=-68.2487251 - Gamma=18.9803410 (M=  19) - s=0.0100\n",
      "  21 - L=-61.8501717 - Gamma=19.9767586 (M=  20) - s=0.0100\n",
      "  22 - L=-57.1722166 - Gamma=20.9724376 (M=  21) - s=0.0100\n",
      "  23 - L=-48.8695248 - Gamma=21.9695158 (M=  22) - s=0.0100\n",
      "  24 - L=-41.2691453 - Gamma=22.9668015 (M=  23) - s=0.0100\n",
      "  25 - L=-34.9567464 - Gamma=23.9631766 (M=  24) - s=0.0100\n",
      "  26 - L=-27.6485054 - Gamma=24.9594156 (M=  25) - s=0.0100\n",
      "  27 - L=-23.8379124 - Gamma=25.9550420 (M=  26) - s=0.0100\n",
      "  28 - L=-18.3908330 - Gamma=26.9433157 (M=  27) - s=0.0100\n",
      "  29 - L=-14.3675810 - Gamma=27.9337316 (M=  28) - s=0.0100\n",
      "  30 - L=-14.3034651 - Gamma=26.9445238 (M=  27) - s=0.0100\n",
      "  31 - L=-14.2511727 - Gamma=25.9560602 (M=  26) - s=0.0100\n",
      "  32 - L=-14.1927284 - Gamma=24.9608913 (M=  25) - s=0.0100\n",
      "  33 - L=-12.3983953 - Gamma=25.9529202 (M=  26) - s=0.0100\n",
      "  34 - L=-6.5256290 - Gamma=26.9436641 (M=  27) - s=0.0100\n",
      "  35 - L=-6.4651457 - Gamma=25.9501618 (M=  26) - s=0.0100\n",
      "  36 - L=-5.6497319 - Gamma=26.9357321 (M=  27) - s=0.0100\n",
      "  37 - L=-3.8244985 - Gamma=27.9237487 (M=  28) - s=0.0100\n",
      "  38 - L=-2.6079219 - Gamma=28.9126213 (M=  29) - s=0.0100\n",
      "  39 - L=-2.5515167 - Gamma=27.9265920 (M=  28) - s=0.0100\n",
      "  40 - L=-1.9830851 - Gamma=28.9039732 (M=  29) - s=0.0100\n",
      "  41 - L=-1.4778565 - Gamma=29.8805257 (M=  30) - s=0.0100\n",
      "  42 - L=-1.1219626 - Gamma=30.8326380 (M=  31) - s=0.0100\n",
      "  43 - L=-0.5366094 - Gamma=31.7898964 (M=  32) - s=0.0100\n",
      "  44 - L=-0.2951806 - Gamma=32.7283790 (M=  33) - s=0.0100\n",
      "  45 - L=-0.1271038 - Gamma=32.7316213 (M=  33) - s=0.0100\n",
      "  46 - L=-0.0213718 - Gamma=33.6476922 (M=  34) - s=0.0100\n",
      "  47 - L= 0.1334096 - Gamma=34.5340411 (M=  35) - s=0.0100\n",
      "  48 - L= 0.2398017 - Gamma=35.4278090 (M=  36) - s=0.0100\n",
      "  49 - L= 0.3620638 - Gamma=36.2603523 (M=  37) - s=0.0100\n",
      "  50 - L= 0.4092708 - Gamma=35.3339669 (M=  36) - s=0.0100\n",
      "  51 - L= 0.4315612 - Gamma=34.5234699 (M=  35) - s=0.0100\n",
      "  52 - L= 0.5441323 - Gamma=35.4109960 (M=  36) - s=0.0100\n",
      "  53 - L= 0.6475286 - Gamma=36.2314812 (M=  37) - s=0.0100\n",
      "  54 - L= 0.7035297 - Gamma=35.3719890 (M=  36) - s=0.0100\n",
      "  55 - L= 0.7772836 - Gamma=35.3815341 (M=  36) - s=0.0100\n",
      "  56 - L= 0.8466847 - Gamma=35.3859779 (M=  36) - s=0.0100\n",
      "  57 - L= 0.9021620 - Gamma=35.3899630 (M=  36) - s=0.0100\n",
      "  58 - L= 0.9526234 - Gamma=35.3921884 (M=  36) - s=0.0100\n",
      "  59 - L= 0.9875850 - Gamma=35.4112727 (M=  36) - s=0.0100\n",
      "  60 - L= 1.0176133 - Gamma=36.1718255 (M=  37) - s=0.0100\n",
      "  61 - L= 1.0467673 - Gamma=36.1780499 (M=  37) - s=0.0100\n",
      "  62 - L= 1.0753515 - Gamma=36.1993343 (M=  37) - s=0.0100\n",
      "  63 - L= 1.1012000 - Gamma=36.2560839 (M=  37) - s=0.0100\n",
      "  64 - L= 1.1240291 - Gamma=36.2578300 (M=  37) - s=0.0100\n",
      "  65 - L= 1.1449375 - Gamma=36.2590965 (M=  37) - s=0.0100\n",
      "  66 - L= 1.1647998 - Gamma=36.2678023 (M=  37) - s=0.0100\n",
      "  67 - L= 1.1818868 - Gamma=36.9667018 (M=  38) - s=0.0100\n",
      "  68 - L= 1.1991381 - Gamma=37.0246434 (M=  38) - s=0.0100\n",
      "  69 - L= 1.2133979 - Gamma=37.0834908 (M=  38) - s=0.0100\n",
      "  70 - L= 1.2248033 - Gamma=37.0853637 (M=  38) - s=0.0100\n",
      "  71 - L= 1.2320331 - Gamma=37.1070697 (M=  38) - s=0.0100\n",
      "  72 - L= 1.2392497 - Gamma=37.1085837 (M=  38) - s=0.0100\n",
      "  73 - L= 1.2463155 - Gamma=37.6824597 (M=  39) - s=0.0100\n",
      "  74 - L= 1.2528707 - Gamma=37.6843569 (M=  39) - s=0.0100\n",
      "  75 - L= 1.2581055 - Gamma=37.6856847 (M=  39) - s=0.0100\n",
      "  76 - L= 1.2620773 - Gamma=37.6872907 (M=  39) - s=0.0100\n",
      "  77 - L= 1.2659112 - Gamma=37.6881821 (M=  39) - s=0.0100\n",
      "  78 - L= 1.2689082 - Gamma=37.7791412 (M=  39) - s=0.0100\n",
      "  79 - L= 1.2712514 - Gamma=37.7810652 (M=  39) - s=0.0100\n",
      "  80 - L= 1.2734813 - Gamma=37.7751641 (M=  39) - s=0.0100\n",
      "  81 - L= 1.2752933 - Gamma=37.7766299 (M=  39) - s=0.0100\n",
      "  82 - L= 1.2765330 - Gamma=37.7789677 (M=  39) - s=0.0100\n",
      "  83 - L= 1.2776849 - Gamma=37.7542523 (M=  39) - s=0.0100\n",
      "  84 - L= 1.2784976 - Gamma=37.7597220 (M=  39) - s=0.0100\n",
      "  85 - L= 1.2792133 - Gamma=37.7598458 (M=  39) - s=0.0100\n",
      "  86 - L= 1.2796025 - Gamma=37.7577647 (M=  39) - s=0.0100\n",
      "  87 - L= 1.2799784 - Gamma=37.7572400 (M=  39) - s=0.0100\n",
      "  88 - L= 1.2802820 - Gamma=37.7566763 (M=  39) - s=0.0100\n",
      "  89 - L= 1.2805423 - Gamma=37.7733005 (M=  39) - s=0.0100\n",
      "  90 - L= 1.2808105 - Gamma=37.7812379 (M=  39) - s=0.0100\n",
      "  91 - L= 1.2810112 - Gamma=37.7927517 (M=  39) - s=0.0100\n",
      "  92 - L= 1.2812212 - Gamma=37.8356472 (M=  39) - s=0.0100\n",
      "  93 - L= 1.2813814 - Gamma=37.8355574 (M=  39) - s=0.0100\n",
      "  94 - L= 1.2815338 - Gamma=37.8327543 (M=  39) - s=0.0100\n",
      "  95 - L= 1.2816646 - Gamma=37.9687764 (M=  40) - s=0.0100\n",
      "  96 - L= 1.2818034 - Gamma=37.9722046 (M=  40) - s=0.0100\n",
      "  97 - L= 1.2819459 - Gamma=37.9751560 (M=  40) - s=0.0100\n",
      "  98 - L= 1.2820803 - Gamma=37.9750267 (M=  40) - s=0.0100\n",
      "  99 - L= 1.2821742 - Gamma=37.9744228 (M=  40) - s=0.0100\n",
      " 100 - L= 1.2822555 - Gamma=37.9746442 (M=  40) - s=0.0100\n",
      " 101 - L= 1.2823221 - Gamma=37.9763225 (M=  40) - s=0.0100\n",
      " 102 - L= 1.2823866 - Gamma=37.9759648 (M=  40) - s=0.0100\n",
      " 103 - L= 1.2824257 - Gamma=37.9759181 (M=  40) - s=0.0100\n",
      " 104 - L= 1.2824597 - Gamma=37.9762334 (M=  40) - s=0.0100\n",
      " 105 - L= 1.2824932 - Gamma=37.9762832 (M=  40) - s=0.0100\n",
      " 106 - L= 1.2825234 - Gamma=37.9763762 (M=  40) - s=0.0100\n",
      " 107 - L= 1.2825530 - Gamma=37.9763291 (M=  40) - s=0.0100\n",
      " 108 - L= 1.2825795 - Gamma=37.9732979 (M=  40) - s=0.0100\n",
      " 109 - L= 1.2825938 - Gamma=37.9780055 (M=  40) - s=0.0100\n",
      " 110 - L= 1.2826059 - Gamma=37.9779365 (M=  40) - s=0.0100\n",
      " 111 - L= 1.2826153 - Gamma=37.9775608 (M=  40) - s=0.0100\n",
      " 112 - L= 1.2826242 - Gamma=38.0103612 (M=  40) - s=0.0100\n",
      " 113 - L= 1.2826327 - Gamma=38.0128290 (M=  40) - s=0.0100\n",
      " 114 - L= 1.2826415 - Gamma=38.0120883 (M=  40) - s=0.0100\n",
      " 115 - L= 1.2826496 - Gamma=38.0147575 (M=  40) - s=0.0100\n",
      " 116 - L= 1.2826570 - Gamma=38.0221514 (M=  40) - s=0.0100\n",
      " 117 - L= 1.2826638 - Gamma=38.0221307 (M=  40) - s=0.0100\n",
      " 118 - L= 1.2826695 - Gamma=38.0239171 (M=  40) - s=0.0100\n",
      " 119 - L= 1.2826736 - Gamma=38.0239537 (M=  40) - s=0.0100\n",
      " 120 - L= 1.2826760 - Gamma=38.0242175 (M=  40) - s=0.0100\n",
      " 121 - L= 1.2826783 - Gamma=38.0260526 (M=  40) - s=0.0100\n",
      " 122 - L= 1.2826806 - Gamma=38.0258054 (M=  40) - s=0.0100\n",
      " 123 - L= 1.2826829 - Gamma=38.0258493 (M=  40) - s=0.0100\n",
      " 124 - L= 1.2826852 - Gamma=38.0259364 (M=  40) - s=0.0100\n",
      " 125 - L= 1.2826874 - Gamma=38.0258812 (M=  40) - s=0.0100\n",
      " 126 - L= 1.2826891 - Gamma=38.0262396 (M=  40) - s=0.0100\n",
      " 127 - L= 1.2826910 - Gamma=38.0410018 (M=  40) - s=0.0100\n",
      " 128 - L= 1.2826922 - Gamma=38.0409867 (M=  40) - s=0.0100\n",
      " 129 - L= 1.2826930 - Gamma=38.0411943 (M=  40) - s=0.0100\n",
      " 130 - L= 1.2826938 - Gamma=38.0411768 (M=  40) - s=0.0100\n",
      " 131 - L= 1.2826945 - Gamma=38.0411869 (M=  40) - s=0.0100\n",
      " 132 - L= 1.2826952 - Gamma=38.0410151 (M=  40) - s=0.0100\n",
      " 133 - L= 1.2826958 - Gamma=38.0410049 (M=  40) - s=0.0100\n",
      " 134 - L= 1.2826964 - Gamma=38.0416261 (M=  40) - s=0.0100\n",
      " 135 - L= 1.2826970 - Gamma=38.0415325 (M=  40) - s=0.0100\n",
      " 136 - L= 1.2826975 - Gamma=38.0435586 (M=  40) - s=0.0100\n",
      " 137 - L= 1.2826981 - Gamma=38.0435807 (M=  40) - s=0.0100\n",
      " 138 - L= 1.2826986 - Gamma=38.0435566 (M=  40) - s=0.0100\n",
      " 139 - L= 1.2826991 - Gamma=38.0400439 (M=  40) - s=0.0100\n",
      " 140 - L= 1.2826996 - Gamma=38.0403451 (M=  40) - s=0.0100\n",
      " 141 - L= 1.2827000 - Gamma=38.0403147 (M=  40) - s=0.0100\n",
      " 142 - L= 1.2827004 - Gamma=38.0410405 (M=  40) - s=0.0100\n",
      " 143 - L= 1.2827007 - Gamma=38.0408874 (M=  40) - s=0.0100\n",
      " 144 - L= 1.2827011 - Gamma=38.0408850 (M=  40) - s=0.0100\n",
      " 145 - L= 1.2827014 - Gamma=38.0405440 (M=  40) - s=0.0100\n",
      " 146 - L= 1.2827016 - Gamma=38.0405103 (M=  40) - s=0.0100\n",
      " 147 - L= 1.2827019 - Gamma=38.0409524 (M=  40) - s=0.0100\n",
      " 148 - L= 1.2827021 - Gamma=38.0462575 (M=  40) - s=0.0100\n",
      " 149 - L= 1.2827024 - Gamma=38.0462692 (M=  40) - s=0.0100\n",
      " 150 - L= 1.2827026 - Gamma=38.0462448 (M=  40) - s=0.0100\n",
      " 151 - L= 1.2827027 - Gamma=38.0462399 (M=  40) - s=0.0100\n",
      " 152 - L= 1.2827028 - Gamma=38.0462376 (M=  40) - s=0.0100\n",
      " 153 - L= 1.2827029 - Gamma=38.0462353 (M=  40) - s=0.0100\n",
      " 154 - L= 1.2827030 - Gamma=38.0470269 (M=  40) - s=0.0100\n",
      " 155 - L= 1.2827031 - Gamma=38.0472722 (M=  40) - s=0.0100\n",
      " 156 - L= 1.2827032 - Gamma=38.0472173 (M=  40) - s=0.0100\n",
      " 157 - L= 1.2827032 - Gamma=38.0473931 (M=  40) - s=0.0100\n",
      " 158 - L= 1.2827033 - Gamma=38.0476726 (M=  40) - s=0.0100\n",
      " 159 - L= 1.2827033 - Gamma=38.0477336 (M=  40) - s=0.0100\n",
      " 160 - L= 1.2827034 - Gamma=38.0477317 (M=  40) - s=0.0100\n",
      " 161 - L= 1.2827034 - Gamma=38.0476981 (M=  40) - s=0.0100\n",
      " 162 - L= 1.2827034 - Gamma=38.0476998 (M=  40) - s=0.0100\n",
      " 163 - L= 1.2827035 - Gamma=38.0477110 (M=  40) - s=0.0100\n",
      " 164 - L= 1.2827035 - Gamma=38.0469102 (M=  40) - s=0.0100\n",
      " 165 - L= 1.2827035 - Gamma=38.0469045 (M=  40) - s=0.0100\n",
      " 166 - L= 1.2827036 - Gamma=38.0468697 (M=  40) - s=0.0100\n",
      " 167 - L= 1.2827036 - Gamma=38.0484116 (M=  40) - s=0.0100\n",
      " 168 - L= 1.2827036 - Gamma=38.0483937 (M=  40) - s=0.0100\n",
      " 169 - L= 1.2827036 - Gamma=38.0487510 (M=  40) - s=0.0100\n",
      " 170 - L= 1.2827036 - Gamma=38.0487546 (M=  40) - s=0.0100\n",
      " 171 - L= 1.2827036 - Gamma=38.0487754 (M=  40) - s=0.0100\n",
      " 172 - L= 1.2827037 - Gamma=38.0488832 (M=  40) - s=0.0100\n",
      " 173 - L= 1.2827037 - Gamma=38.0489104 (M=  40) - s=0.0100\n",
      " 174 - L= 1.2827037 - Gamma=38.0489124 (M=  40) - s=0.0100\n",
      " 175 - L= 1.2827037 - Gamma=38.0489103 (M=  40) - s=0.0100\n",
      " 176 - L= 1.2827037 - Gamma=38.0489548 (M=  40) - s=0.0100\n",
      " 177 - L= 1.2827037 - Gamma=38.0489505 (M=  40) - s=0.0100\n",
      " 178 - L= 1.2827037 - Gamma=38.0490218 (M=  40) - s=0.0100\n",
      " 179 - L= 1.2827037 - Gamma=38.0491267 (M=  40) - s=0.0100\n",
      " 180 - L= 1.2827037 - Gamma=38.0491275 (M=  40) - s=0.0100\n",
      " 181 - L= 1.2827037 - Gamma=38.0491275 (M=  40) - s=0.0100\n",
      "Stopping at iteration 181 - max_delta_ml=2.186245041711039e-07\n",
      "L=1.2827037344567969 - Gamma=38.04912753635011 (M=40) - s=0.01\n",
      "Initial alpha = [[0.07492319]]\n",
      "   1 - L=-484.9176766 - Gamma= 1.9999347 (M=   2) - s=0.0100\n",
      "   2 - L=-322.4302564 - Gamma= 2.9997629 (M=   3) - s=0.0100\n",
      "   3 - L=-283.4257929 - Gamma= 3.9993908 (M=   4) - s=0.0100\n",
      "   4 - L=-242.0138356 - Gamma= 4.9991058 (M=   5) - s=0.0100\n",
      "   5 - L=-205.2741549 - Gamma= 5.9985937 (M=   6) - s=0.0100\n",
      "   6 - L=-187.2650986 - Gamma= 6.9979045 (M=   7) - s=0.0100\n",
      "   7 - L=-168.1058759 - Gamma= 7.9972702 (M=   8) - s=0.0100\n",
      "   8 - L=-135.1202800 - Gamma= 8.9967847 (M=   9) - s=0.0100\n",
      "   9 - L=-118.5971239 - Gamma= 9.9960290 (M=  10) - s=0.0100\n",
      "  10 - L=-107.0328416 - Gamma=10.9949025 (M=  11) - s=0.0100\n",
      "  11 - L=-91.3948514 - Gamma=11.9933263 (M=  12) - s=0.0100\n",
      "  12 - L=-82.5805316 - Gamma=12.9917561 (M=  13) - s=0.0100\n",
      "  13 - L=-75.7187576 - Gamma=13.9899242 (M=  14) - s=0.0100\n",
      "  14 - L=-69.9887126 - Gamma=14.9871761 (M=  15) - s=0.0100\n",
      "  15 - L=-64.1076505 - Gamma=15.9844238 (M=  16) - s=0.0100\n",
      "  16 - L=-55.2401144 - Gamma=16.9820362 (M=  17) - s=0.0100\n",
      "  17 - L=-55.1585033 - Gamma=15.9833694 (M=  16) - s=0.0100\n",
      "  18 - L=-50.0459625 - Gamma=16.9806509 (M=  17) - s=0.0100\n",
      "  19 - L=-45.9944562 - Gamma=17.9771800 (M=  18) - s=0.0100\n",
      "  20 - L=-42.3597773 - Gamma=18.9737123 (M=  19) - s=0.0100\n",
      "  21 - L=-42.2852791 - Gamma=17.9758850 (M=  18) - s=0.0100\n",
      "  22 - L=-40.4508702 - Gamma=18.9697976 (M=  19) - s=0.0100\n",
      "  23 - L=-40.3764670 - Gamma=17.9730694 (M=  18) - s=0.0100\n",
      "  24 - L=-39.2615324 - Gamma=18.9627487 (M=  19) - s=0.0100\n",
      "  25 - L=-37.6040042 - Gamma=19.9509686 (M=  20) - s=0.0100\n",
      "  26 - L=-35.4980533 - Gamma=20.9306030 (M=  21) - s=0.0100\n",
      "  27 - L=-33.3017770 - Gamma=21.9106877 (M=  22) - s=0.0100\n",
      "  28 - L=-30.6587389 - Gamma=22.8965214 (M=  23) - s=0.0100\n",
      "  29 - L=-28.7243042 - Gamma=23.8864745 (M=  24) - s=0.0100\n",
      "  30 - L=-28.6662374 - Gamma=22.9017753 (M=  23) - s=0.0100\n",
      "  31 - L=-27.1200233 - Gamma=23.8855831 (M=  24) - s=0.0100\n",
      "  32 - L=-23.8582089 - Gamma=24.8696597 (M=  25) - s=0.0100\n",
      "  33 - L=-22.0177039 - Gamma=25.8564833 (M=  26) - s=0.0100\n",
      "  34 - L=-20.0573592 - Gamma=26.8261792 (M=  27) - s=0.0100\n",
      "  35 - L=-17.2906961 - Gamma=27.8145202 (M=  28) - s=0.0100\n",
      "  36 - L=-14.5101643 - Gamma=28.7979136 (M=  29) - s=0.0100\n",
      "  37 - L=-12.5093502 - Gamma=29.7847250 (M=  30) - s=0.0100\n",
      "  38 - L=-10.8455256 - Gamma=30.7723712 (M=  31) - s=0.0100\n",
      "  39 - L=-9.1871810 - Gamma=31.7484574 (M=  32) - s=0.0100\n",
      "  40 - L=-7.2613742 - Gamma=32.7180554 (M=  33) - s=0.0100\n",
      "  41 - L=-5.6526510 - Gamma=33.6801884 (M=  34) - s=0.0100\n",
      "  42 - L=-4.2021949 - Gamma=33.7618638 (M=  34) - s=0.0100\n",
      "  43 - L=-3.3037603 - Gamma=34.7290639 (M=  35) - s=0.0100\n",
      "  44 - L=-2.3869720 - Gamma=35.6996497 (M=  36) - s=0.0100\n",
      "  45 - L=-2.3178511 - Gamma=34.7200570 (M=  35) - s=0.0100\n",
      "  46 - L=-1.9409161 - Gamma=35.6804558 (M=  36) - s=0.0100\n",
      "  47 - L=-1.6187194 - Gamma=36.6403032 (M=  37) - s=0.0100\n",
      "  48 - L=-1.5750347 - Gamma=35.6757179 (M=  36) - s=0.0100\n",
      "  49 - L=-1.2949162 - Gamma=36.6165004 (M=  37) - s=0.0100\n",
      "  50 - L=-1.0497675 - Gamma=36.6303734 (M=  37) - s=0.0100\n",
      "  51 - L=-0.7993089 - Gamma=37.5600626 (M=  38) - s=0.0100\n",
      "  52 - L=-0.5838820 - Gamma=37.5646053 (M=  38) - s=0.0100\n",
      "  53 - L=-0.3983436 - Gamma=37.5837585 (M=  38) - s=0.0100\n",
      "  54 - L=-0.2243914 - Gamma=37.5895407 (M=  38) - s=0.0100\n",
      "  55 - L=-0.0533746 - Gamma=37.6022084 (M=  38) - s=0.0100\n",
      "  56 - L= 0.1139396 - Gamma=37.6168558 (M=  38) - s=0.0100\n",
      "  57 - L= 0.2465753 - Gamma=38.4451453 (M=  39) - s=0.0100\n",
      "  58 - L= 0.3611032 - Gamma=39.3453627 (M=  40) - s=0.0100\n",
      "  59 - L= 0.3858626 - Gamma=38.5299390 (M=  39) - s=0.0100\n",
      "  60 - L= 0.4736269 - Gamma=38.5394065 (M=  39) - s=0.0100\n",
      "  61 - L= 0.5576369 - Gamma=38.5533908 (M=  39) - s=0.0100\n",
      "  62 - L= 0.6374411 - Gamma=38.5718732 (M=  39) - s=0.0100\n",
      "  63 - L= 0.7059774 - Gamma=38.5822392 (M=  39) - s=0.0100\n",
      "  64 - L= 0.7564959 - Gamma=38.5930366 (M=  39) - s=0.0100\n",
      "  65 - L= 0.8039628 - Gamma=38.6101877 (M=  39) - s=0.0100\n",
      "  66 - L= 0.8563568 - Gamma=39.4536454 (M=  40) - s=0.0100\n",
      "  67 - L= 0.8977446 - Gamma=39.4698454 (M=  40) - s=0.0100\n",
      "  68 - L= 0.9299206 - Gamma=39.4763011 (M=  40) - s=0.0100\n",
      "  69 - L= 0.9613558 - Gamma=39.4993049 (M=  40) - s=0.0100\n",
      "  70 - L= 0.9901128 - Gamma=39.5021967 (M=  40) - s=0.0100\n",
      "  71 - L= 1.0099392 - Gamma=39.4719007 (M=  40) - s=0.0100\n",
      "  72 - L= 1.0267043 - Gamma=39.3549493 (M=  40) - s=0.0100\n",
      "  73 - L= 1.0439079 - Gamma=39.9491504 (M=  41) - s=0.0100\n",
      "  74 - L= 1.0574111 - Gamma=39.9265037 (M=  41) - s=0.0100\n",
      "  75 - L= 1.0698176 - Gamma=40.5536720 (M=  42) - s=0.0100\n",
      "  76 - L= 1.0825261 - Gamma=40.5591431 (M=  42) - s=0.0100\n",
      "  77 - L= 1.0940022 - Gamma=41.0827256 (M=  43) - s=0.0100\n",
      "  78 - L= 1.1063628 - Gamma=41.6304208 (M=  44) - s=0.0100\n",
      "  79 - L= 1.1142982 - Gamma=41.5936403 (M=  44) - s=0.0100\n",
      "  80 - L= 1.1193265 - Gamma=41.5992265 (M=  44) - s=0.0100\n",
      "  81 - L= 1.1237191 - Gamma=41.6131576 (M=  44) - s=0.0100\n",
      "  82 - L= 1.1279033 - Gamma=41.6284377 (M=  44) - s=0.0100\n",
      "  83 - L= 1.1320436 - Gamma=41.6357212 (M=  44) - s=0.0100\n",
      "  84 - L= 1.1353379 - Gamma=41.6675025 (M=  44) - s=0.0100\n",
      "  85 - L= 1.1380302 - Gamma=41.6708591 (M=  44) - s=0.0100\n",
      "  86 - L= 1.1405253 - Gamma=41.6720579 (M=  44) - s=0.0100\n",
      "  87 - L= 1.1427384 - Gamma=41.6262300 (M=  44) - s=0.0100\n",
      "  88 - L= 1.1449907 - Gamma=41.6281473 (M=  44) - s=0.0100\n",
      "  89 - L= 1.1470970 - Gamma=41.4769744 (M=  44) - s=0.0100\n",
      "  90 - L= 1.1494837 - Gamma=41.5308261 (M=  44) - s=0.0100\n",
      "  91 - L= 1.1515356 - Gamma=41.5362240 (M=  44) - s=0.0100\n",
      "  92 - L= 1.1534802 - Gamma=41.5329099 (M=  44) - s=0.0100\n",
      "  93 - L= 1.1543542 - Gamma=41.5332128 (M=  44) - s=0.0100\n",
      "  94 - L= 1.1551766 - Gamma=41.5159748 (M=  44) - s=0.0100\n",
      "  95 - L= 1.1559194 - Gamma=41.5771389 (M=  44) - s=0.0100\n",
      "  96 - L= 1.1567505 - Gamma=41.4077867 (M=  44) - s=0.0100\n",
      "  97 - L= 1.1575415 - Gamma=41.4039022 (M=  44) - s=0.0100\n",
      "  98 - L= 1.1583170 - Gamma=41.3639642 (M=  44) - s=0.0100\n",
      "  99 - L= 1.1590884 - Gamma=41.3623588 (M=  44) - s=0.0100\n",
      " 100 - L= 1.1598095 - Gamma=41.4358757 (M=  44) - s=0.0100\n",
      " 101 - L= 1.1603704 - Gamma=41.4076390 (M=  44) - s=0.0100\n",
      " 102 - L= 1.1608189 - Gamma=41.4401901 (M=  44) - s=0.0100\n",
      " 103 - L= 1.1613215 - Gamma=41.4309037 (M=  44) - s=0.0100\n",
      " 104 - L= 1.1618835 - Gamma=41.2320123 (M=  44) - s=0.0100\n",
      " 105 - L= 1.1624317 - Gamma=41.2326774 (M=  44) - s=0.0100\n",
      " 106 - L= 1.1629557 - Gamma=41.1855547 (M=  44) - s=0.0100\n",
      " 107 - L= 1.1631625 - Gamma=41.0851650 (M=  43) - s=0.0100\n",
      " 108 - L= 1.1636585 - Gamma=41.0855194 (M=  43) - s=0.0100\n",
      " 109 - L= 1.1641142 - Gamma=41.0857036 (M=  43) - s=0.0100\n",
      " 110 - L= 1.1645128 - Gamma=41.0765811 (M=  43) - s=0.0100\n",
      " 111 - L= 1.1648592 - Gamma=41.0768605 (M=  43) - s=0.0100\n",
      " 112 - L= 1.1651742 - Gamma=41.0974117 (M=  43) - s=0.0100\n",
      " 113 - L= 1.1658600 - Gamma=41.2861215 (M=  44) - s=0.0100\n",
      " 114 - L= 1.1661844 - Gamma=41.2577761 (M=  44) - s=0.0100\n",
      " 115 - L= 1.1664939 - Gamma=41.2737782 (M=  44) - s=0.0100\n",
      " 116 - L= 1.1669175 - Gamma=41.4237163 (M=  45) - s=0.0100\n",
      " 117 - L= 1.1673400 - Gamma=41.4127087 (M=  45) - s=0.0100\n",
      " 118 - L= 1.1676953 - Gamma=41.3980300 (M=  45) - s=0.0100\n",
      " 119 - L= 1.1681468 - Gamma=41.5076946 (M=  45) - s=0.0100\n",
      " 120 - L= 1.1687953 - Gamma=41.5253754 (M=  45) - s=0.0100\n",
      " 121 - L= 1.1693670 - Gamma=41.3994329 (M=  45) - s=0.0100\n",
      " 122 - L= 1.1702329 - Gamma=41.5532262 (M=  45) - s=0.0100\n",
      " 123 - L= 1.1709849 - Gamma=41.5258942 (M=  45) - s=0.0100\n",
      " 124 - L= 1.1718981 - Gamma=41.4325480 (M=  45) - s=0.0100\n",
      " 125 - L= 1.1733173 - Gamma=41.6385640 (M=  46) - s=0.0100\n",
      " 126 - L= 1.1749406 - Gamma=41.5225649 (M=  46) - s=0.0100\n",
      " 127 - L= 1.1776407 - Gamma=41.3032524 (M=  46) - s=0.0100\n",
      " 128 - L= 1.1792985 - Gamma=41.3196957 (M=  46) - s=0.0100\n",
      " 129 - L= 1.1813901 - Gamma=41.4585057 (M=  46) - s=0.0100\n",
      " 130 - L= 1.1825510 - Gamma=41.3141074 (M=  45) - s=0.0100\n",
      " 131 - L= 1.1866567 - Gamma=40.8595387 (M=  44) - s=0.0100\n",
      " 132 - L= 1.1887650 - Gamma=40.4864742 (M=  43) - s=0.0100\n",
      " 133 - L= 1.1957126 - Gamma=40.6658160 (M=  43) - s=0.0100\n",
      " 134 - L= 1.2070547 - Gamma=40.3653463 (M=  42) - s=0.0100\n",
      " 135 - L= 1.2179845 - Gamma=39.6817450 (M=  41) - s=0.0100\n",
      " 136 - L= 1.2252322 - Gamma=39.7933112 (M=  41) - s=0.0100\n",
      " 137 - L= 1.2318579 - Gamma=39.1377605 (M=  41) - s=0.0100\n",
      " 138 - L= 1.2382375 - Gamma=39.0047870 (M=  41) - s=0.0100\n",
      " 139 - L= 1.2382844 - Gamma=38.9373395 (M=  40) - s=0.0100\n",
      " 140 - L= 1.2431514 - Gamma=38.9016866 (M=  40) - s=0.0100\n",
      " 141 - L= 1.2477575 - Gamma=38.8688615 (M=  40) - s=0.0100\n",
      " 142 - L= 1.2511273 - Gamma=38.8081827 (M=  40) - s=0.0100\n",
      " 143 - L= 1.2542262 - Gamma=38.8144812 (M=  40) - s=0.0100\n",
      " 144 - L= 1.2567790 - Gamma=38.8182964 (M=  40) - s=0.0100\n",
      " 145 - L= 1.2591555 - Gamma=38.8097879 (M=  40) - s=0.0100\n",
      " 146 - L= 1.2612253 - Gamma=38.8048200 (M=  40) - s=0.0100\n",
      " 147 - L= 1.2629836 - Gamma=38.8072328 (M=  40) - s=0.0100\n",
      " 148 - L= 1.2643448 - Gamma=38.8075521 (M=  40) - s=0.0100\n",
      " 149 - L= 1.2656977 - Gamma=38.8090769 (M=  40) - s=0.0100\n",
      " 150 - L= 1.2670724 - Gamma=39.0735299 (M=  41) - s=0.0100\n",
      " 151 - L= 1.2682471 - Gamma=39.0710423 (M=  41) - s=0.0100\n",
      " 152 - L= 1.2694284 - Gamma=39.0660838 (M=  41) - s=0.0100\n",
      " 153 - L= 1.2705349 - Gamma=39.0711339 (M=  41) - s=0.0100\n",
      " 154 - L= 1.2714592 - Gamma=39.0719371 (M=  41) - s=0.0100\n",
      " 155 - L= 1.2722864 - Gamma=39.0725646 (M=  41) - s=0.0100\n",
      " 156 - L= 1.2730901 - Gamma=39.0728128 (M=  41) - s=0.0100\n",
      " 157 - L= 1.2738788 - Gamma=39.0756906 (M=  41) - s=0.0100\n",
      " 158 - L= 1.2746653 - Gamma=39.0766658 (M=  41) - s=0.0100\n",
      " 159 - L= 1.2754427 - Gamma=39.0963221 (M=  41) - s=0.0100\n",
      " 160 - L= 1.2762152 - Gamma=39.0971094 (M=  41) - s=0.0100\n",
      " 161 - L= 1.2769872 - Gamma=39.3050814 (M=  42) - s=0.0100\n",
      " 162 - L= 1.2783089 - Gamma=39.0821836 (M=  42) - s=0.0100\n",
      " 163 - L= 1.2795001 - Gamma=39.0480069 (M=  42) - s=0.0100\n",
      " 164 - L= 1.2802698 - Gamma=39.0458840 (M=  42) - s=0.0100\n",
      " 165 - L= 1.2809516 - Gamma=39.1797530 (M=  42) - s=0.0100\n",
      " 166 - L= 1.2818299 - Gamma=39.1967559 (M=  42) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 167 - L= 1.2827648 - Gamma=39.0914457 (M=  42) - s=0.0100\n",
      " 168 - L= 1.2833114 - Gamma=39.0838521 (M=  42) - s=0.0100\n",
      " 169 - L= 1.2839129 - Gamma=39.1709283 (M=  42) - s=0.0100\n",
      " 170 - L= 1.2844512 - Gamma=39.1665053 (M=  42) - s=0.0100\n",
      " 171 - L= 1.2851331 - Gamma=38.9334313 (M=  42) - s=0.0100\n",
      " 172 - L= 1.2867855 - Gamma=38.8497807 (M=  42) - s=0.0100\n",
      " 173 - L= 1.2868961 - Gamma=38.8284344 (M=  41) - s=0.0100\n",
      " 174 - L= 1.2875597 - Gamma=38.8031238 (M=  41) - s=0.0100\n",
      " 175 - L= 1.2882789 - Gamma=38.8656630 (M=  41) - s=0.0100\n",
      " 176 - L= 1.2888184 - Gamma=38.8767331 (M=  41) - s=0.0100\n",
      " 177 - L= 1.2893432 - Gamma=38.8795014 (M=  41) - s=0.0100\n",
      " 178 - L= 1.2899224 - Gamma=38.7440144 (M=  41) - s=0.0100\n",
      " 179 - L= 1.2904393 - Gamma=38.7267256 (M=  41) - s=0.0100\n",
      " 180 - L= 1.2909812 - Gamma=38.6489824 (M=  41) - s=0.0100\n",
      " 181 - L= 1.2915550 - Gamma=38.6849474 (M=  41) - s=0.0100\n",
      " 182 - L= 1.2920846 - Gamma=38.6988354 (M=  41) - s=0.0100\n",
      " 183 - L= 1.2925958 - Gamma=38.6985609 (M=  41) - s=0.0100\n",
      " 184 - L= 1.2930347 - Gamma=38.6981184 (M=  41) - s=0.0100\n",
      " 185 - L= 1.2934526 - Gamma=38.7096571 (M=  41) - s=0.0100\n",
      " 186 - L= 1.2938452 - Gamma=38.6816877 (M=  41) - s=0.0100\n",
      " 187 - L= 1.2942215 - Gamma=38.6769121 (M=  41) - s=0.0100\n",
      " 188 - L= 1.2945906 - Gamma=38.6745631 (M=  41) - s=0.0100\n",
      " 189 - L= 1.2949489 - Gamma=38.6743874 (M=  41) - s=0.0100\n",
      " 190 - L= 1.2953163 - Gamma=38.5865840 (M=  41) - s=0.0100\n",
      " 191 - L= 1.2958636 - Gamma=38.3944738 (M=  41) - s=0.0100\n",
      " 192 - L= 1.2962716 - Gamma=38.4144470 (M=  41) - s=0.0100\n",
      " 193 - L= 1.2966563 - Gamma=38.4212835 (M=  41) - s=0.0100\n",
      " 194 - L= 1.2970289 - Gamma=38.4214576 (M=  41) - s=0.0100\n",
      " 195 - L= 1.2973287 - Gamma=38.4215876 (M=  41) - s=0.0100\n",
      " 196 - L= 1.2976229 - Gamma=38.4224876 (M=  41) - s=0.0100\n",
      " 197 - L= 1.2978850 - Gamma=38.3242678 (M=  41) - s=0.0100\n",
      " 198 - L= 1.2982542 - Gamma=38.1411324 (M=  40) - s=0.0100\n",
      " 199 - L= 1.2986095 - Gamma=38.2323564 (M=  40) - s=0.0100\n",
      " 200 - L= 1.2991624 - Gamma=38.2207360 (M=  40) - s=0.0100\n",
      "Initial alpha = [[0.07770735]]\n",
      "   1 - L=-618.2029115 - Gamma= 1.9999041 (M=   2) - s=0.0100\n",
      "   2 - L=-388.2813844 - Gamma= 2.9998127 (M=   3) - s=0.0100\n",
      "   3 - L=-331.3176053 - Gamma= 3.9995382 (M=   4) - s=0.0100\n",
      "   4 - L=-283.0774801 - Gamma= 4.9993017 (M=   5) - s=0.0100\n",
      "   5 - L=-240.6842516 - Gamma= 5.9990195 (M=   6) - s=0.0100\n",
      "   6 - L=-209.8667577 - Gamma= 6.9984958 (M=   7) - s=0.0100\n",
      "   7 - L=-187.2821364 - Gamma= 7.9978795 (M=   8) - s=0.0100\n",
      "   8 - L=-168.3940430 - Gamma= 8.9971639 (M=   9) - s=0.0100\n",
      "   9 - L=-144.9303786 - Gamma= 9.9966004 (M=  10) - s=0.0100\n",
      "  10 - L=-131.0062479 - Gamma=10.9955713 (M=  11) - s=0.0100\n",
      "  11 - L=-123.4757333 - Gamma=11.9939991 (M=  12) - s=0.0100\n",
      "  12 - L=-113.4641600 - Gamma=12.9926852 (M=  13) - s=0.0100\n",
      "  13 - L=-103.9055063 - Gamma=13.9912599 (M=  14) - s=0.0100\n",
      "  14 - L=-82.3824335 - Gamma=14.9897328 (M=  15) - s=0.0100\n",
      "  15 - L=-68.5312988 - Gamma=15.9884240 (M=  16) - s=0.0100\n",
      "  16 - L=-52.2606030 - Gamma=16.9862970 (M=  17) - s=0.0100\n",
      "  17 - L=-48.1879497 - Gamma=17.9831213 (M=  18) - s=0.0100\n",
      "  18 - L=-44.8402486 - Gamma=18.9792077 (M=  19) - s=0.0100\n",
      "  19 - L=-41.9111599 - Gamma=19.9737007 (M=  20) - s=0.0100\n",
      "  20 - L=-37.4886355 - Gamma=20.9683219 (M=  21) - s=0.0100\n",
      "  21 - L=-31.2081796 - Gamma=21.9605525 (M=  22) - s=0.0100\n",
      "  22 - L=-23.4321744 - Gamma=22.9564321 (M=  23) - s=0.0100\n",
      "  23 - L=-20.8072026 - Gamma=23.9375708 (M=  24) - s=0.0100\n",
      "  24 - L=-16.0113583 - Gamma=24.9272078 (M=  25) - s=0.0100\n",
      "  25 - L=-13.7016379 - Gamma=25.9198318 (M=  26) - s=0.0100\n",
      "  26 - L=-11.3675166 - Gamma=26.9103815 (M=  27) - s=0.0100\n",
      "  27 - L=-10.0957502 - Gamma=27.8913338 (M=  28) - s=0.0100\n",
      "  28 - L=-8.8416865 - Gamma=28.8705212 (M=  29) - s=0.0100\n",
      "  29 - L=-6.8314963 - Gamma=29.8573948 (M=  30) - s=0.0100\n",
      "  30 - L=-5.3676069 - Gamma=30.8225607 (M=  31) - s=0.0100\n",
      "  31 - L=-5.2898694 - Gamma=29.8505938 (M=  30) - s=0.0100\n",
      "  32 - L=-5.2365307 - Gamma=28.8640469 (M=  29) - s=0.0100\n",
      "  33 - L=-4.4164367 - Gamma=29.8492706 (M=  30) - s=0.0100\n",
      "  34 - L=-4.3611468 - Gamma=28.8610726 (M=  29) - s=0.0100\n",
      "  35 - L=-2.9798425 - Gamma=29.8281243 (M=  30) - s=0.0100\n",
      "  36 - L=-2.5458498 - Gamma=30.7848215 (M=  31) - s=0.0100\n",
      "  37 - L=-2.1492535 - Gamma=31.7405669 (M=  32) - s=0.0100\n",
      "  38 - L=-1.8145546 - Gamma=31.8105187 (M=  32) - s=0.0100\n",
      "  39 - L=-1.4428932 - Gamma=32.7119272 (M=  33) - s=0.0100\n",
      "  40 - L=-0.9624050 - Gamma=33.6753748 (M=  34) - s=0.0100\n",
      "  41 - L=-0.4642040 - Gamma=34.5642855 (M=  35) - s=0.0100\n",
      "  42 - L=-0.4150486 - Gamma=33.6752044 (M=  34) - s=0.0100\n",
      "  43 - L=-0.0323880 - Gamma=34.6233263 (M=  35) - s=0.0100\n",
      "  44 - L= 0.0134040 - Gamma=33.6881589 (M=  34) - s=0.0100\n",
      "  45 - L= 0.0565645 - Gamma=32.7388916 (M=  33) - s=0.0100\n",
      "  46 - L= 0.2318703 - Gamma=32.7531683 (M=  33) - s=0.0100\n",
      "  47 - L= 0.3791997 - Gamma=32.7763407 (M=  33) - s=0.0100\n",
      "  48 - L= 0.4611658 - Gamma=32.7811075 (M=  33) - s=0.0100\n",
      "  49 - L= 0.5409295 - Gamma=32.7886336 (M=  33) - s=0.0100\n",
      "  50 - L= 0.6011272 - Gamma=33.6696685 (M=  34) - s=0.0100\n",
      "  51 - L= 0.6712194 - Gamma=34.4888684 (M=  35) - s=0.0100\n",
      "  52 - L= 0.7106882 - Gamma=33.6087459 (M=  34) - s=0.0100\n",
      "  53 - L= 0.7657758 - Gamma=33.6314893 (M=  34) - s=0.0100\n",
      "  54 - L= 0.8151199 - Gamma=34.4845918 (M=  35) - s=0.0100\n",
      "  55 - L= 0.8530973 - Gamma=34.4939171 (M=  35) - s=0.0100\n",
      "  56 - L= 0.8887175 - Gamma=34.5010496 (M=  35) - s=0.0100\n",
      "  57 - L= 0.9239830 - Gamma=34.5092164 (M=  35) - s=0.0100\n",
      "  58 - L= 0.9538088 - Gamma=34.5216312 (M=  35) - s=0.0100\n",
      "  59 - L= 0.9821692 - Gamma=34.5248783 (M=  35) - s=0.0100\n",
      "  60 - L= 1.0096361 - Gamma=35.3276467 (M=  36) - s=0.0100\n",
      "  61 - L= 1.0378932 - Gamma=35.3300018 (M=  36) - s=0.0100\n",
      "  62 - L= 1.0648674 - Gamma=35.3340485 (M=  36) - s=0.0100\n",
      "  63 - L= 1.0908312 - Gamma=36.1188213 (M=  37) - s=0.0100\n",
      "  64 - L= 1.1056028 - Gamma=36.1203597 (M=  37) - s=0.0100\n",
      "  65 - L= 1.1183829 - Gamma=36.7949820 (M=  38) - s=0.0100\n",
      "  66 - L= 1.1355116 - Gamma=37.4884357 (M=  39) - s=0.0100\n",
      "  67 - L= 1.1475403 - Gamma=37.4938048 (M=  39) - s=0.0100\n",
      "  68 - L= 1.1596160 - Gamma=37.6456695 (M=  39) - s=0.0100\n",
      "  69 - L= 1.1736185 - Gamma=38.2309344 (M=  40) - s=0.0100\n",
      "  70 - L= 1.1850702 - Gamma=38.2320314 (M=  40) - s=0.0100\n",
      "  71 - L= 1.1964418 - Gamma=38.2184925 (M=  40) - s=0.0100\n",
      "  72 - L= 1.2069862 - Gamma=38.2217791 (M=  40) - s=0.0100\n",
      "  73 - L= 1.2164700 - Gamma=38.2235629 (M=  40) - s=0.0100\n",
      "  74 - L= 1.2235110 - Gamma=38.3820827 (M=  40) - s=0.0100\n",
      "  75 - L= 1.2321753 - Gamma=38.9465569 (M=  41) - s=0.0100\n",
      "  76 - L= 1.2386528 - Gamma=38.9490917 (M=  41) - s=0.0100\n",
      "  77 - L= 1.2445466 - Gamma=38.9666375 (M=  41) - s=0.0100\n",
      "  78 - L= 1.2502868 - Gamma=38.9674097 (M=  41) - s=0.0100\n",
      "  79 - L= 1.2550992 - Gamma=39.0826462 (M=  41) - s=0.0100\n",
      "  80 - L= 1.2597742 - Gamma=39.0482162 (M=  41) - s=0.0100\n",
      "  81 - L= 1.2640120 - Gamma=39.2110700 (M=  41) - s=0.0100\n",
      "  82 - L= 1.2684991 - Gamma=39.2253825 (M=  41) - s=0.0100\n",
      "  83 - L= 1.2711273 - Gamma=39.2262945 (M=  41) - s=0.0100\n",
      "  84 - L= 1.2736992 - Gamma=39.2272376 (M=  41) - s=0.0100\n",
      "  85 - L= 1.2760473 - Gamma=39.2700983 (M=  41) - s=0.0100\n",
      "  86 - L= 1.2776209 - Gamma=39.3927487 (M=  41) - s=0.0100\n",
      "  87 - L= 1.2794854 - Gamma=39.3053266 (M=  41) - s=0.0100\n",
      "  88 - L= 1.2810260 - Gamma=39.3677363 (M=  41) - s=0.0100\n",
      "  89 - L= 1.2832991 - Gamma=39.4831682 (M=  41) - s=0.0100\n",
      "  90 - L= 1.2849724 - Gamma=39.5126091 (M=  41) - s=0.0100\n",
      "  91 - L= 1.2864527 - Gamma=39.4951743 (M=  41) - s=0.0100\n",
      "  92 - L= 1.2877317 - Gamma=39.4940741 (M=  41) - s=0.0100\n",
      "  93 - L= 1.2888679 - Gamma=39.4918323 (M=  41) - s=0.0100\n",
      "  94 - L= 1.2899035 - Gamma=39.4540694 (M=  41) - s=0.0100\n",
      "  95 - L= 1.2906491 - Gamma=39.4693678 (M=  41) - s=0.0100\n",
      "  96 - L= 1.2916041 - Gamma=39.7158707 (M=  42) - s=0.0100\n",
      "  97 - L= 1.2928558 - Gamma=39.6101830 (M=  42) - s=0.0100\n",
      "  98 - L= 1.2935540 - Gamma=39.6494418 (M=  42) - s=0.0100\n",
      "  99 - L= 1.2942485 - Gamma=39.6804299 (M=  42) - s=0.0100\n",
      " 100 - L= 1.2949466 - Gamma=39.6329330 (M=  42) - s=0.0100\n",
      " 101 - L= 1.2960886 - Gamma=39.8062035 (M=  42) - s=0.0100\n",
      " 102 - L= 1.2969659 - Gamma=39.8162227 (M=  42) - s=0.0100\n",
      " 103 - L= 1.2980645 - Gamma=39.6502333 (M=  42) - s=0.0100\n",
      " 104 - L= 1.2990359 - Gamma=39.5615370 (M=  42) - s=0.0100\n",
      " 105 - L= 1.2998944 - Gamma=39.4634717 (M=  42) - s=0.0100\n",
      " 106 - L= 1.3008375 - Gamma=39.4700099 (M=  42) - s=0.0100\n",
      " 107 - L= 1.3017273 - Gamma=39.5005091 (M=  42) - s=0.0100\n",
      " 108 - L= 1.3026321 - Gamma=39.2666005 (M=  42) - s=0.0100\n",
      " 109 - L= 1.3042624 - Gamma=39.3925342 (M=  42) - s=0.0100\n",
      " 110 - L= 1.3046057 - Gamma=39.2605426 (M=  41) - s=0.0100\n",
      " 111 - L= 1.3068104 - Gamma=38.9906642 (M=  41) - s=0.0100\n",
      " 112 - L= 1.3079450 - Gamma=38.9938251 (M=  41) - s=0.0100\n",
      " 113 - L= 1.3089191 - Gamma=38.9901654 (M=  41) - s=0.0100\n",
      " 114 - L= 1.3098315 - Gamma=39.0165576 (M=  41) - s=0.0100\n",
      " 115 - L= 1.3104295 - Gamma=39.0145619 (M=  41) - s=0.0100\n",
      " 116 - L= 1.3108732 - Gamma=39.0308187 (M=  41) - s=0.0100\n",
      " 117 - L= 1.3113241 - Gamma=38.9804544 (M=  41) - s=0.0100\n",
      " 118 - L= 1.3118579 - Gamma=39.2271593 (M=  42) - s=0.0100\n",
      " 119 - L= 1.3121968 - Gamma=39.2671189 (M=  42) - s=0.0100\n",
      " 120 - L= 1.3124871 - Gamma=39.2669818 (M=  42) - s=0.0100\n",
      " 121 - L= 1.3127243 - Gamma=39.2668646 (M=  42) - s=0.0100\n",
      " 122 - L= 1.3129341 - Gamma=39.2674240 (M=  42) - s=0.0100\n",
      " 123 - L= 1.3131380 - Gamma=39.2589123 (M=  42) - s=0.0100\n",
      " 124 - L= 1.3133006 - Gamma=39.2857879 (M=  42) - s=0.0100\n",
      " 125 - L= 1.3135229 - Gamma=39.1592443 (M=  42) - s=0.0100\n",
      " 126 - L= 1.3137924 - Gamma=39.0841077 (M=  42) - s=0.0100\n",
      " 127 - L= 1.3139452 - Gamma=39.0839932 (M=  42) - s=0.0100\n",
      " 128 - L= 1.3140927 - Gamma=39.0842004 (M=  42) - s=0.0100\n",
      " 129 - L= 1.3142298 - Gamma=39.0844925 (M=  42) - s=0.0100\n",
      " 130 - L= 1.3143506 - Gamma=39.0849344 (M=  42) - s=0.0100\n",
      " 131 - L= 1.3144684 - Gamma=39.0830902 (M=  42) - s=0.0100\n",
      " 132 - L= 1.3145826 - Gamma=39.0831995 (M=  42) - s=0.0100\n",
      " 133 - L= 1.3146928 - Gamma=39.0834202 (M=  42) - s=0.0100\n",
      " 134 - L= 1.3147943 - Gamma=39.0840848 (M=  42) - s=0.0100\n",
      " 135 - L= 1.3148881 - Gamma=39.0773559 (M=  42) - s=0.0100\n",
      " 136 - L= 1.3149745 - Gamma=39.0772224 (M=  42) - s=0.0100\n",
      " 137 - L= 1.3150534 - Gamma=39.0770935 (M=  42) - s=0.0100\n",
      " 138 - L= 1.3151115 - Gamma=39.0784544 (M=  42) - s=0.0100\n",
      " 139 - L= 1.3151981 - Gamma=39.1655482 (M=  43) - s=0.0100\n",
      " 140 - L= 1.3152862 - Gamma=39.0746695 (M=  43) - s=0.0100\n",
      " 141 - L= 1.3153938 - Gamma=38.9645972 (M=  43) - s=0.0100\n",
      " 142 - L= 1.3154758 - Gamma=39.0418819 (M=  43) - s=0.0100\n",
      " 143 - L= 1.3156105 - Gamma=39.0617594 (M=  43) - s=0.0100\n",
      " 144 - L= 1.3157319 - Gamma=38.9398505 (M=  43) - s=0.0100\n",
      " 145 - L= 1.3158811 - Gamma=38.9403228 (M=  43) - s=0.0100\n",
      " 146 - L= 1.3158841 - Gamma=38.9345534 (M=  42) - s=0.0100\n",
      " 147 - L= 1.3160399 - Gamma=39.0300696 (M=  42) - s=0.0100\n",
      " 148 - L= 1.3161666 - Gamma=38.8966783 (M=  41) - s=0.0100\n",
      " 149 - L= 1.3164949 - Gamma=38.7892852 (M=  41) - s=0.0100\n",
      " 150 - L= 1.3166642 - Gamma=38.7981324 (M=  41) - s=0.0100\n",
      " 151 - L= 1.3167927 - Gamma=38.7653678 (M=  41) - s=0.0100\n",
      " 152 - L= 1.3169815 - Gamma=38.8526777 (M=  41) - s=0.0100\n",
      " 153 - L= 1.3172001 - Gamma=38.8737696 (M=  41) - s=0.0100\n",
      " 154 - L= 1.3173893 - Gamma=38.8760389 (M=  41) - s=0.0100\n",
      " 155 - L= 1.3175226 - Gamma=38.8833794 (M=  41) - s=0.0100\n",
      " 156 - L= 1.3176288 - Gamma=38.8751453 (M=  41) - s=0.0100\n",
      " 157 - L= 1.3177543 - Gamma=38.8367446 (M=  41) - s=0.0100\n",
      " 158 - L= 1.3179128 - Gamma=38.9038316 (M=  41) - s=0.0100\n",
      " 159 - L= 1.3180452 - Gamma=38.9107443 (M=  41) - s=0.0100\n",
      " 160 - L= 1.3181553 - Gamma=38.9091161 (M=  41) - s=0.0100\n",
      " 161 - L= 1.3182419 - Gamma=38.9092256 (M=  41) - s=0.0100\n",
      " 162 - L= 1.3183193 - Gamma=38.9200860 (M=  41) - s=0.0100\n",
      " 163 - L= 1.3184152 - Gamma=38.9058960 (M=  41) - s=0.0100\n",
      " 164 - L= 1.3185135 - Gamma=38.8660894 (M=  41) - s=0.0100\n",
      " 165 - L= 1.3186255 - Gamma=38.8435956 (M=  41) - s=0.0100\n",
      " 166 - L= 1.3187385 - Gamma=38.8920094 (M=  41) - s=0.0100\n",
      " 167 - L= 1.3188302 - Gamma=38.8915654 (M=  41) - s=0.0100\n",
      " 168 - L= 1.3189214 - Gamma=38.8905043 (M=  41) - s=0.0100\n",
      " 169 - L= 1.3190078 - Gamma=38.8821465 (M=  41) - s=0.0100\n",
      " 170 - L= 1.3190898 - Gamma=38.8873863 (M=  41) - s=0.0100\n",
      " 171 - L= 1.3191840 - Gamma=38.8424518 (M=  41) - s=0.0100\n",
      " 172 - L= 1.3192884 - Gamma=38.8532078 (M=  41) - s=0.0100\n",
      " 173 - L= 1.3193589 - Gamma=38.7939689 (M=  41) - s=0.0100\n",
      " 174 - L= 1.3194607 - Gamma=38.8335148 (M=  41) - s=0.0100\n",
      " 175 - L= 1.3195727 - Gamma=38.8301586 (M=  41) - s=0.0100\n",
      " 176 - L= 1.3196704 - Gamma=38.8317360 (M=  41) - s=0.0100\n",
      " 177 - L= 1.3197593 - Gamma=38.8366811 (M=  41) - s=0.0100\n",
      " 178 - L= 1.3198504 - Gamma=38.8209841 (M=  41) - s=0.0100\n",
      " 179 - L= 1.3199589 - Gamma=38.7647581 (M=  41) - s=0.0100\n",
      " 180 - L= 1.3200784 - Gamma=38.7378845 (M=  41) - s=0.0100\n",
      " 181 - L= 1.3201693 - Gamma=38.7703234 (M=  41) - s=0.0100\n",
      " 182 - L= 1.3202602 - Gamma=38.7607411 (M=  41) - s=0.0100\n",
      " 183 - L= 1.3203470 - Gamma=38.7692060 (M=  41) - s=0.0100\n",
      " 184 - L= 1.3204638 - Gamma=38.7011577 (M=  41) - s=0.0100\n",
      " 185 - L= 1.3205704 - Gamma=38.6993876 (M=  41) - s=0.0100\n",
      " 186 - L= 1.3206594 - Gamma=38.7045058 (M=  41) - s=0.0100\n",
      " 187 - L= 1.3207419 - Gamma=38.6877154 (M=  41) - s=0.0100\n",
      " 188 - L= 1.3208253 - Gamma=38.6620352 (M=  41) - s=0.0100\n",
      " 189 - L= 1.3209056 - Gamma=38.6619345 (M=  41) - s=0.0100\n",
      " 190 - L= 1.3209799 - Gamma=38.6877084 (M=  41) - s=0.0100\n",
      " 191 - L= 1.3210818 - Gamma=38.6139444 (M=  41) - s=0.0100\n",
      " 192 - L= 1.3211891 - Gamma=38.6185238 (M=  41) - s=0.0100\n",
      " 193 - L= 1.3212866 - Gamma=38.6233440 (M=  41) - s=0.0100\n",
      " 194 - L= 1.3213738 - Gamma=38.6128818 (M=  41) - s=0.0100\n",
      " 195 - L= 1.3214757 - Gamma=38.6207425 (M=  41) - s=0.0100\n",
      " 196 - L= 1.3215431 - Gamma=38.6210281 (M=  41) - s=0.0100\n",
      " 197 - L= 1.3216085 - Gamma=38.5543197 (M=  41) - s=0.0100\n",
      " 198 - L= 1.3217232 - Gamma=38.5190802 (M=  41) - s=0.0100\n",
      " 199 - L= 1.3218678 - Gamma=38.4934106 (M=  41) - s=0.0100\n",
      " 200 - L= 1.3220014 - Gamma=38.5232559 (M=  41) - s=0.0100\n",
      "MODEL: RVM accuracy:  0.6206896551724136 +/-: 0.0011079883255864207\n",
      "Initial alpha = [[0.06059326]]\n",
      "   1 - L=-609.3033023 - Gamma= 1.9999190 (M=   2) - s=0.0100\n",
      "   2 - L=-462.1088182 - Gamma= 2.9998411 (M=   3) - s=0.0100\n",
      "   3 - L=-421.1694888 - Gamma= 3.9995692 (M=   4) - s=0.0100\n",
      "   4 - L=-363.8121026 - Gamma= 4.9993339 (M=   5) - s=0.0100\n",
      "   5 - L=-325.1126940 - Gamma= 5.9990105 (M=   6) - s=0.0100\n",
      "   6 - L=-294.2882058 - Gamma= 6.9986424 (M=   7) - s=0.0100\n",
      "   7 - L=-274.7119399 - Gamma= 7.9979618 (M=   8) - s=0.0100\n",
      "   8 - L=-246.6977558 - Gamma= 8.9973514 (M=   9) - s=0.0100\n",
      "   9 - L=-231.7705534 - Gamma= 9.9967071 (M=  10) - s=0.0100\n",
      "  10 - L=-215.1033762 - Gamma=10.9959645 (M=  11) - s=0.0100\n",
      "  11 - L=-199.4235577 - Gamma=11.9942365 (M=  12) - s=0.0100\n",
      "  12 - L=-184.8938189 - Gamma=12.9933869 (M=  13) - s=0.0100\n",
      "  13 - L=-170.2613340 - Gamma=13.9926763 (M=  14) - s=0.0100\n",
      "  14 - L=-160.4058577 - Gamma=14.9915056 (M=  15) - s=0.0100\n",
      "  15 - L=-148.2639023 - Gamma=15.9904728 (M=  16) - s=0.0100\n",
      "  16 - L=-137.1959912 - Gamma=16.9892344 (M=  17) - s=0.0100\n",
      "  17 - L=-126.4666173 - Gamma=17.9866054 (M=  18) - s=0.0100\n",
      "  18 - L=-116.3392846 - Gamma=18.9854527 (M=  19) - s=0.0100\n",
      "  19 - L=-107.6059481 - Gamma=19.9841661 (M=  20) - s=0.0100\n",
      "  20 - L=-97.6450584 - Gamma=20.9812615 (M=  21) - s=0.0100\n",
      "  21 - L=-89.4783673 - Gamma=21.9736850 (M=  22) - s=0.0100\n",
      "  22 - L=-81.9539055 - Gamma=22.9712419 (M=  23) - s=0.0100\n",
      "  23 - L=-73.0404222 - Gamma=23.9640618 (M=  24) - s=0.0100\n",
      "  24 - L=-65.9940059 - Gamma=24.9620967 (M=  25) - s=0.0100\n",
      "  25 - L=-61.4247902 - Gamma=25.9582779 (M=  26) - s=0.0100\n",
      "  26 - L=-61.3652267 - Gamma=24.9603586 (M=  25) - s=0.0100\n",
      "  27 - L=-57.3084479 - Gamma=25.9565418 (M=  26) - s=0.0100\n",
      "  28 - L=-51.7579629 - Gamma=26.9508894 (M=  27) - s=0.0100\n",
      "  29 - L=-47.9870772 - Gamma=27.9454956 (M=  28) - s=0.0100\n",
      "  30 - L=-43.0887600 - Gamma=28.9426072 (M=  29) - s=0.0100\n",
      "  31 - L=-38.7935597 - Gamma=29.9358185 (M=  30) - s=0.0100\n",
      "  32 - L=-36.0436563 - Gamma=30.9311026 (M=  31) - s=0.0100\n",
      "  33 - L=-32.8629589 - Gamma=31.9258757 (M=  32) - s=0.0100\n",
      "  34 - L=-27.7517177 - Gamma=32.9176571 (M=  33) - s=0.0100\n",
      "  35 - L=-25.6187005 - Gamma=33.9096602 (M=  34) - s=0.0100\n",
      "  36 - L=-22.4577014 - Gamma=34.8959386 (M=  35) - s=0.0100\n",
      "  37 - L=-18.9437700 - Gamma=35.8731989 (M=  36) - s=0.0100\n",
      "  38 - L=-15.9635587 - Gamma=36.8625841 (M=  37) - s=0.0100\n",
      "  39 - L=-13.7135569 - Gamma=37.8538963 (M=  38) - s=0.0100\n",
      "  40 - L=-12.3743644 - Gamma=38.8389309 (M=  39) - s=0.0100\n",
      "  41 - L=-10.0942132 - Gamma=39.8221135 (M=  40) - s=0.0100\n",
      "  42 - L=-8.0707102 - Gamma=40.8014778 (M=  41) - s=0.0100\n",
      "  43 - L=-7.1639728 - Gamma=41.7371843 (M=  42) - s=0.0100\n",
      "  44 - L=-7.1154202 - Gamma=40.7795445 (M=  41) - s=0.0100\n",
      "  45 - L=-6.2796290 - Gamma=41.7601395 (M=  42) - s=0.0100\n",
      "  46 - L=-5.6204314 - Gamma=42.7319969 (M=  43) - s=0.0100\n",
      "  47 - L=-5.0252732 - Gamma=42.7518872 (M=  43) - s=0.0100\n",
      "  48 - L=-4.4014701 - Gamma=43.7257621 (M=  44) - s=0.0100\n",
      "  49 - L=-3.8797006 - Gamma=43.7856892 (M=  44) - s=0.0100\n",
      "  50 - L=-3.3903567 - Gamma=44.7619320 (M=  45) - s=0.0100\n",
      "  51 - L=-2.8960595 - Gamma=44.7718071 (M=  45) - s=0.0100\n",
      "  52 - L=-2.5418945 - Gamma=44.7827469 (M=  45) - s=0.0100\n",
      "  53 - L=-2.2062996 - Gamma=45.7291748 (M=  46) - s=0.0100\n",
      "  54 - L=-1.7148787 - Gamma=46.6907969 (M=  47) - s=0.0100\n",
      "  55 - L=-1.4268984 - Gamma=47.6500394 (M=  48) - s=0.0100\n",
      "  56 - L=-1.1350362 - Gamma=48.5896522 (M=  49) - s=0.0100\n",
      "  57 - L=-0.9059876 - Gamma=48.6041312 (M=  49) - s=0.0100\n",
      "  58 - L=-0.7089858 - Gamma=48.6252406 (M=  49) - s=0.0100\n",
      "  59 - L=-0.5242073 - Gamma=48.6310515 (M=  49) - s=0.0100\n",
      "  60 - L=-0.4053904 - Gamma=48.6380999 (M=  49) - s=0.0100\n",
      "  61 - L=-0.3042532 - Gamma=48.6455491 (M=  49) - s=0.0100\n",
      "  62 - L=-0.2261507 - Gamma=48.6480170 (M=  49) - s=0.0100\n",
      "  63 - L=-0.1672758 - Gamma=48.6545643 (M=  49) - s=0.0100\n",
      "  64 - L=-0.1132173 - Gamma=49.5305276 (M=  50) - s=0.0100\n",
      "  65 - L=-0.0738264 - Gamma=48.5597830 (M=  49) - s=0.0100\n",
      "  66 - L=-0.0172837 - Gamma=49.4336473 (M=  50) - s=0.0100\n",
      "  67 - L= 0.0573884 - Gamma=50.3074247 (M=  51) - s=0.0100\n",
      "  68 - L= 0.1120348 - Gamma=51.0658521 (M=  52) - s=0.0100\n",
      "  69 - L= 0.1655672 - Gamma=51.0697922 (M=  52) - s=0.0100\n",
      "  70 - L= 0.2157842 - Gamma=51.0749125 (M=  52) - s=0.0100\n",
      "  71 - L= 0.2662192 - Gamma=51.0805931 (M=  52) - s=0.0100\n",
      "  72 - L= 0.3112114 - Gamma=51.0871835 (M=  52) - s=0.0100\n",
      "  73 - L= 0.3541055 - Gamma=51.0924728 (M=  52) - s=0.0100\n",
      "  74 - L= 0.3959450 - Gamma=51.1008302 (M=  52) - s=0.0100\n",
      "  75 - L= 0.4232565 - Gamma=51.1047677 (M=  52) - s=0.0100\n",
      "  76 - L= 0.4505898 - Gamma=51.1096179 (M=  52) - s=0.0100\n",
      "  77 - L= 0.4764544 - Gamma=51.1252874 (M=  52) - s=0.0100\n",
      "  78 - L= 0.4998657 - Gamma=51.1020853 (M=  52) - s=0.0100\n",
      "  79 - L= 0.5199367 - Gamma=50.6524650 (M=  52) - s=0.0100\n",
      "  80 - L= 0.5404150 - Gamma=50.7515790 (M=  52) - s=0.0100\n",
      "  81 - L= 0.5642717 - Gamma=50.4249956 (M=  52) - s=0.0100\n",
      "  82 - L= 0.5823386 - Gamma=50.4362718 (M=  52) - s=0.0100\n",
      "  83 - L= 0.6002053 - Gamma=50.4371904 (M=  52) - s=0.0100\n",
      "  84 - L= 0.6154416 - Gamma=50.4387198 (M=  52) - s=0.0100\n",
      "  85 - L= 0.6298671 - Gamma=50.4420866 (M=  52) - s=0.0100\n",
      "  86 - L= 0.6429710 - Gamma=50.4661684 (M=  52) - s=0.0100\n",
      "  87 - L= 0.6528712 - Gamma=50.4678179 (M=  52) - s=0.0100\n",
      "  88 - L= 0.6624248 - Gamma=50.5368676 (M=  52) - s=0.0100\n",
      "  89 - L= 0.6724918 - Gamma=50.2896066 (M=  52) - s=0.0100\n",
      "  90 - L= 0.6816084 - Gamma=50.2974146 (M=  52) - s=0.0100\n",
      "  91 - L= 0.6887402 - Gamma=50.3697825 (M=  52) - s=0.0100\n",
      "  92 - L= 0.6954663 - Gamma=50.3713397 (M=  52) - s=0.0100\n",
      "  93 - L= 0.7016523 - Gamma=50.3580122 (M=  52) - s=0.0100\n",
      "  94 - L= 0.7048785 - Gamma=49.7746781 (M=  51) - s=0.0100\n",
      "  95 - L= 0.7106302 - Gamma=49.8188986 (M=  51) - s=0.0100\n",
      "  96 - L= 0.7166441 - Gamma=49.8245813 (M=  51) - s=0.0100\n",
      "  97 - L= 0.7186686 - Gamma=49.3044542 (M=  50) - s=0.0100\n",
      "  98 - L= 0.7264681 - Gamma=49.9305104 (M=  51) - s=0.0100\n",
      "  99 - L= 0.7320971 - Gamma=49.9360419 (M=  51) - s=0.0100\n",
      " 100 - L= 0.7365866 - Gamma=49.9372281 (M=  51) - s=0.0100\n",
      " 101 - L= 0.7404980 - Gamma=49.9469717 (M=  51) - s=0.0100\n",
      " 102 - L= 0.7438936 - Gamma=49.9614935 (M=  51) - s=0.0100\n",
      " 103 - L= 0.7471105 - Gamma=49.9658035 (M=  51) - s=0.0100\n",
      " 104 - L= 0.7496579 - Gamma=49.9683705 (M=  51) - s=0.0100\n",
      " 105 - L= 0.7519755 - Gamma=49.5774526 (M=  51) - s=0.0100\n",
      " 106 - L= 0.7542911 - Gamma=49.5748224 (M=  51) - s=0.0100\n",
      " 107 - L= 0.7564768 - Gamma=49.5753026 (M=  51) - s=0.0100\n",
      " 108 - L= 0.7580392 - Gamma=49.5824966 (M=  51) - s=0.0100\n",
      " 109 - L= 0.7598212 - Gamma=49.9361576 (M=  52) - s=0.0100\n",
      " 110 - L= 0.7608795 - Gamma=49.7967329 (M=  51) - s=0.0100\n",
      " 111 - L= 0.7619765 - Gamma=50.0972250 (M=  52) - s=0.0100\n",
      " 112 - L= 0.7636378 - Gamma=49.7864623 (M=  52) - s=0.0100\n",
      " 113 - L= 0.7656906 - Gamma=49.9982379 (M=  52) - s=0.0100\n",
      " 114 - L= 0.7662052 - Gamma=49.7921653 (M=  51) - s=0.0100\n",
      " 115 - L= 0.7682499 - Gamma=50.0377720 (M=  51) - s=0.0100\n",
      " 116 - L= 0.7696574 - Gamma=50.0391891 (M=  51) - s=0.0100\n",
      " 117 - L= 0.7710536 - Gamma=50.0511246 (M=  51) - s=0.0100\n",
      " 118 - L= 0.7723492 - Gamma=50.0369395 (M=  51) - s=0.0100\n",
      " 119 - L= 0.7732152 - Gamma=50.0370673 (M=  51) - s=0.0100\n",
      " 120 - L= 0.7740557 - Gamma=50.0079205 (M=  51) - s=0.0100\n",
      " 121 - L= 0.7746607 - Gamma=50.0829717 (M=  51) - s=0.0100\n",
      " 122 - L= 0.7752705 - Gamma=50.0737340 (M=  51) - s=0.0100\n",
      " 123 - L= 0.7757855 - Gamma=50.0805555 (M=  51) - s=0.0100\n",
      " 124 - L= 0.7762474 - Gamma=50.0806255 (M=  51) - s=0.0100\n",
      " 125 - L= 0.7766912 - Gamma=50.0807764 (M=  51) - s=0.0100\n",
      " 126 - L= 0.7769880 - Gamma=50.0808893 (M=  51) - s=0.0100\n",
      " 127 - L= 0.7772015 - Gamma=50.0820108 (M=  51) - s=0.0100\n",
      " 128 - L= 0.7774035 - Gamma=50.0816827 (M=  51) - s=0.0100\n",
      " 129 - L= 0.7775917 - Gamma=50.1327244 (M=  51) - s=0.0100\n",
      " 130 - L= 0.7779330 - Gamma=50.3604017 (M=  52) - s=0.0100\n",
      " 131 - L= 0.7781632 - Gamma=50.3511273 (M=  52) - s=0.0100\n",
      " 132 - L= 0.7783478 - Gamma=50.3466682 (M=  52) - s=0.0100\n",
      " 133 - L= 0.7785276 - Gamma=50.3483049 (M=  52) - s=0.0100\n",
      " 134 - L= 0.7787088 - Gamma=50.3470053 (M=  52) - s=0.0100\n",
      " 135 - L= 0.7788796 - Gamma=50.3489032 (M=  52) - s=0.0100\n",
      " 136 - L= 0.7790276 - Gamma=50.3496221 (M=  52) - s=0.0100\n",
      " 137 - L= 0.7791708 - Gamma=50.3500095 (M=  52) - s=0.0100\n",
      " 138 - L= 0.7793032 - Gamma=50.3504275 (M=  52) - s=0.0100\n",
      " 139 - L= 0.7794109 - Gamma=50.3828103 (M=  52) - s=0.0100\n",
      " 140 - L= 0.7794989 - Gamma=50.4058404 (M=  52) - s=0.0100\n",
      " 141 - L= 0.7795864 - Gamma=50.3928310 (M=  52) - s=0.0100\n",
      " 142 - L= 0.7796583 - Gamma=50.3931269 (M=  52) - s=0.0100\n",
      " 143 - L= 0.7797266 - Gamma=50.3926578 (M=  52) - s=0.0100\n",
      " 144 - L= 0.7797930 - Gamma=50.3927287 (M=  52) - s=0.0100\n",
      " 145 - L= 0.7798557 - Gamma=50.3928125 (M=  52) - s=0.0100\n",
      " 146 - L= 0.7799151 - Gamma=50.3886387 (M=  52) - s=0.0100\n",
      " 147 - L= 0.7799763 - Gamma=50.4759733 (M=  53) - s=0.0100\n",
      " 148 - L= 0.7800604 - Gamma=50.4999420 (M=  53) - s=0.0100\n",
      " 149 - L= 0.7801225 - Gamma=50.4961498 (M=  53) - s=0.0100\n",
      " 150 - L= 0.7801705 - Gamma=50.5657902 (M=  53) - s=0.0100\n",
      " 151 - L= 0.7802706 - Gamma=50.5498791 (M=  53) - s=0.0100\n",
      " 152 - L= 0.7803284 - Gamma=50.5443653 (M=  53) - s=0.0100\n",
      " 153 - L= 0.7803918 - Gamma=50.5612769 (M=  53) - s=0.0100\n",
      " 154 - L= 0.7804705 - Gamma=50.5809363 (M=  53) - s=0.0100\n",
      " 155 - L= 0.7806019 - Gamma=50.6798855 (M=  53) - s=0.0100\n",
      " 156 - L= 0.7806863 - Gamma=50.6625672 (M=  53) - s=0.0100\n",
      " 157 - L= 0.7807527 - Gamma=50.6780597 (M=  53) - s=0.0100\n",
      " 158 - L= 0.7808229 - Gamma=50.6826974 (M=  53) - s=0.0100\n",
      " 159 - L= 0.7808982 - Gamma=50.7471570 (M=  53) - s=0.0100\n",
      " 160 - L= 0.7809720 - Gamma=50.7418498 (M=  53) - s=0.0100\n",
      " 161 - L= 0.7810391 - Gamma=50.7373527 (M=  53) - s=0.0100\n",
      " 162 - L= 0.7811094 - Gamma=50.7186659 (M=  53) - s=0.0100\n",
      " 163 - L= 0.7811943 - Gamma=50.7357260 (M=  53) - s=0.0100\n",
      " 164 - L= 0.7812827 - Gamma=50.7510713 (M=  53) - s=0.0100\n",
      " 165 - L= 0.7813979 - Gamma=50.8191855 (M=  53) - s=0.0100\n",
      " 166 - L= 0.7815068 - Gamma=50.8102141 (M=  53) - s=0.0100\n",
      " 167 - L= 0.7816166 - Gamma=50.7818249 (M=  53) - s=0.0100\n",
      " 168 - L= 0.7816896 - Gamma=50.7813593 (M=  53) - s=0.0100\n",
      " 169 - L= 0.7817516 - Gamma=50.7923457 (M=  53) - s=0.0100\n",
      " 170 - L= 0.7818212 - Gamma=50.8377983 (M=  53) - s=0.0100\n",
      " 171 - L= 0.7818858 - Gamma=50.8417091 (M=  53) - s=0.0100\n",
      " 172 - L= 0.7819510 - Gamma=50.8411724 (M=  53) - s=0.0100\n",
      " 173 - L= 0.7820163 - Gamma=50.8150429 (M=  53) - s=0.0100\n",
      " 174 - L= 0.7820948 - Gamma=50.7059952 (M=  53) - s=0.0100\n",
      " 175 - L= 0.7821624 - Gamma=50.7192434 (M=  53) - s=0.0100\n",
      " 176 - L= 0.7822375 - Gamma=50.7602506 (M=  53) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 177 - L= 0.7823287 - Gamma=50.7541232 (M=  53) - s=0.0100\n",
      " 178 - L= 0.7824265 - Gamma=50.7469445 (M=  53) - s=0.0100\n",
      " 179 - L= 0.7825083 - Gamma=50.7577332 (M=  53) - s=0.0100\n",
      " 180 - L= 0.7826533 - Gamma=50.7097503 (M=  53) - s=0.0100\n",
      " 181 - L= 0.7827553 - Gamma=50.7079481 (M=  53) - s=0.0100\n",
      " 182 - L= 0.7828645 - Gamma=50.7494322 (M=  53) - s=0.0100\n",
      " 183 - L= 0.7829660 - Gamma=50.7486055 (M=  53) - s=0.0100\n",
      " 184 - L= 0.7830647 - Gamma=50.7496724 (M=  53) - s=0.0100\n",
      " 185 - L= 0.7831655 - Gamma=50.7398207 (M=  53) - s=0.0100\n",
      " 186 - L= 0.7832659 - Gamma=50.7386181 (M=  53) - s=0.0100\n",
      " 187 - L= 0.7833633 - Gamma=50.6912518 (M=  53) - s=0.0100\n",
      " 188 - L= 0.7834238 - Gamma=50.5880084 (M=  52) - s=0.0100\n",
      " 189 - L= 0.7835366 - Gamma=50.5846357 (M=  52) - s=0.0100\n",
      " 190 - L= 0.7836433 - Gamma=50.5941372 (M=  52) - s=0.0100\n",
      " 191 - L= 0.7837556 - Gamma=50.6293957 (M=  52) - s=0.0100\n",
      " 192 - L= 0.7838961 - Gamma=50.5587276 (M=  52) - s=0.0100\n",
      " 193 - L= 0.7840429 - Gamma=50.5749761 (M=  52) - s=0.0100\n",
      " 194 - L= 0.7841892 - Gamma=50.5797167 (M=  52) - s=0.0100\n",
      " 195 - L= 0.7843350 - Gamma=50.5705823 (M=  52) - s=0.0100\n",
      " 196 - L= 0.7844683 - Gamma=50.5714124 (M=  52) - s=0.0100\n",
      " 197 - L= 0.7845885 - Gamma=50.5673186 (M=  52) - s=0.0100\n",
      " 198 - L= 0.7846999 - Gamma=50.5582592 (M=  52) - s=0.0100\n",
      " 199 - L= 0.7847999 - Gamma=50.4878377 (M=  52) - s=0.0100\n",
      " 200 - L= 0.7849830 - Gamma=50.5232241 (M=  52) - s=0.0100\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6893 - acc: 0.5652 - val_loss: 0.5804 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5943 - acc: 0.5652 - val_loss: 0.3995 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6418 - acc: 0.5870 - val_loss: 0.3843 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5502 - acc: 0.7609 - val_loss: 0.3103 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4891 - acc: 0.7826 - val_loss: 0.6161 - val_acc: 0.6667\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.4890 - acc: 0.7609 - val_loss: 0.4024 - val_acc: 0.8333\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.3234 - acc: 0.9565 - val_loss: 0.5243 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.3143 - acc: 0.8696 - val_loss: 0.3888 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.2141 - acc: 0.8913 - val_loss: 0.3562 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.1901 - acc: 0.9348 - val_loss: 0.8169 - val_acc: 0.8333\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.3810 - acc: 0.8478 - val_loss: 0.1195 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.3883 - acc: 0.8913 - val_loss: 0.1428 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.1813 - acc: 0.9130 - val_loss: 0.1371 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.1575 - acc: 0.9348 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.1474 - acc: 0.9348 - val_loss: 0.3810 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1448 - acc: 0.9362 - val_loss: 0.1311 - val_acc: 0.9091\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0576 - acc: 0.9787 - val_loss: 0.2420 - val_acc: 0.9091\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0325 - acc: 0.9787 - val_loss: 0.1208 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0174 - acc: 1.000 - 0s - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3001 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.2931 - acc: 0.9362 - val_loss: 0.1228 - val_acc: 0.9091\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.0829 - acc: 0.9574 - val_loss: 0.0453 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0371 - acc: 0.9787 - val_loss: 0.0268 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "MODEL: DNN accuracy:  0.8448275862068966 +/-: 0.011971678737433792\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 78, 1) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.7092 - acc: 0.3696 - val_loss: 0.6851 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6946 - acc: 0.5217 - val_loss: 0.6787 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6827 - acc: 0.5652 - val_loss: 0.6604 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6641 - acc: 0.5435 - val_loss: 0.6551 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6389 - acc: 0.6739 - val_loss: 0.6197 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6180 - acc: 0.6522 - val_loss: 0.6367 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5839 - acc: 0.7826 - val_loss: 0.6091 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5546 - acc: 0.7174 - val_loss: 0.6145 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5566 - acc: 0.8043 - val_loss: 0.5724 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4535 - acc: 0.8261 - val_loss: 0.5499 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.4777 - acc: 0.8478 - val_loss: 0.4285 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.4779 - acc: 0.8043 - val_loss: 0.3947 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4991 - acc: 0.8043 - val_loss: 0.3473 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4196 - acc: 0.7609 - val_loss: 0.3226 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.3841 - acc: 0.8696 - val_loss: 0.3012 - val_acc: 0.9167\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.3236 - acc: 0.8511 - val_loss: 0.3559 - val_acc: 0.8182\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.3675 - acc: 0.8298 - val_loss: 0.3631 - val_acc: 0.9091\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.3087 - acc: 0.8723 - val_loss: 0.3488 - val_acc: 0.7273\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.3847 - acc: 0.8723 - val_loss: 0.3803 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.2751 - acc: 0.8723 - val_loss: 0.3792 - val_acc: 0.9091\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.3221 - acc: 0.8511 - val_loss: 0.2038 - val_acc: 0.9091\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s - loss: 0.2817 - acc: 0.8723 - val_loss: 0.2022 - val_acc: 0.9091\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.2893 - acc: 0.9362 - val_loss: 0.2160 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.2548 - acc: 0.8936 - val_loss: 0.2542 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.2891 - acc: 0.8936 - val_loss: 0.1685 - val_acc: 0.9091\n",
      "MODEL: CNN accuracy:  0.7758620689655171 +/-: 0.026172846178791474\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "Rocket.X_GENOME = None\n",
    "Rocket.Y_CLASS = None\n",
    "Rocket.PREP_HASH = None\n",
    "\n",
    "RUNS, MODELS, ACC = Rocket.run_classification(method_list = METHOD_LIST, \n",
    "                          num_run = nruns,\n",
    "                          pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                      \"pre_processing\": PREPROC_DICT,\n",
    "                                      \"feature_selection\": FSELECT_DICT, # mannwhitney         \n",
    "                                      \"dim_reduction\": DIMRED_DICT},\n",
    "                          parameters = {}, \n",
    "                          features = 'genomic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on average: 0.7863984674329503 +- 0.01803683886026335, median: 0.8017241379310345+-0.017279663459806145\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "         acc model       var\n",
      "0   0.793103    RF  0.030339\n",
      "1   0.741379   XGB  0.006783\n",
      "2   0.827586  LGBM  0.023173\n",
      "3   0.810345    ET  0.032866\n",
      "4   0.879310   SVM  0.007639\n",
      "5   0.844828  MLNN  0.003873\n",
      "6   0.551724   RVM  0.019921\n",
      "7   0.775862   DNN  0.040933\n",
      "8   0.741379   CNN  0.018539\n",
      "9   0.810345    RF  0.032866\n",
      "10  0.741379   XGB  0.010310\n",
      "11  0.844828  LGBM  0.016021\n",
      "12  0.793103    ET  0.030339\n",
      "13  0.896552   SVM  0.004319\n",
      "14  0.862069  MLNN  0.007490\n",
      "15  0.620690   RVM  0.001108\n",
      "16  0.844828   DNN  0.011972\n",
      "17  0.775862   CNN  0.026173\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on average: {} +- {}, median: {}+-{}\".format(ACC.mean()[0], ACC.mean()[1], ACC.median()[0], ACC.median()[1]))\n",
    "print(\"+\"*40)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "###########\n",
    "##Runs.append(AllResults)\n",
    "final_df = pandas.DataFrame()\n",
    "\n",
    "for idx, df in enumerate(RUNS):    \n",
    "    df['run'] = idx\n",
    "    final_df = final_df.append(df, ignore_index = True)\n",
    "final_df[Rocket.MODEL_PARAMETERS['ID']] = final_df[Rocket.MODEL_PARAMETERS['ID']].astype(str)\n",
    "final_df = final_df.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "final_df['pred']= pandas.to_numeric(final_df['pred'])\n",
    "final_df_agg = final_df.groupby([Rocket.MODEL_PARAMETERS['ID'], 'method']).agg({'pred': [numpy.mean, numpy.median, numpy.std]})\n",
    "final_df_agg = final_df_agg['pred'].groupby(by=Rocket.MODEL_PARAMETERS['ID']).agg({'mean': [numpy.mean, numpy.median, numpy.std]})['mean']\n",
    "final_df.to_csv(\"out/patient_results_\"+Rocket.SET_NAME+\"_FDR0025.csv\")\n",
    "final_df_agg.to_csv(\"out/patient_results_agg_\"+Rocket.SET_NAME+\"_FDR0025.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_weights, top_coeffs = _helpers.get_top_genes(MODELS=MODELS, n_max=5000, RexR=Rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_RF</th>\n",
       "      <th>1_XGB</th>\n",
       "      <th>2_LGBM</th>\n",
       "      <th>3_ExtraTrees</th>\n",
       "      <th>9_RF</th>\n",
       "      <th>10_XGB</th>\n",
       "      <th>11_LGBM</th>\n",
       "      <th>12_ExtraTrees</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>MEDIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1569566_at</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.705969</td>\n",
       "      <td>0.646447</td>\n",
       "      <td>0.705969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223748_at</th>\n",
       "      <td>0.239810</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213193</td>\n",
       "      <td>0.354560</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292892</td>\n",
       "      <td>0.461962</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233185_at</th>\n",
       "      <td>0.289019</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.390557</td>\n",
       "      <td>0.466654</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.365009</td>\n",
       "      <td>0.422040</td>\n",
       "      <td>0.390557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209661_at</th>\n",
       "      <td>0.144378</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.394731</td>\n",
       "      <td>0.219756</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.796495</td>\n",
       "      <td>0.360095</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223017_at</th>\n",
       "      <td>0.411182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.162605</td>\n",
       "      <td>0.324446</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.390542</td>\n",
       "      <td>0.325449</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209626_s_at</th>\n",
       "      <td>0.146771</td>\n",
       "      <td>0.476191</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372427</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.212822</td>\n",
       "      <td>0.315378</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552726_at</th>\n",
       "      <td>0.114999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312695</td>\n",
       "      <td>0.307323</td>\n",
       "      <td>0.114999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201015_s_at</th>\n",
       "      <td>0.665232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718868</td>\n",
       "      <td>0.664016</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.194040</td>\n",
       "      <td>0.305732</td>\n",
       "      <td>0.194040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228667_at</th>\n",
       "      <td>0.777687</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.204861</td>\n",
       "      <td>0.294335</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.145589</td>\n",
       "      <td>0.303470</td>\n",
       "      <td>0.294335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563473_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.294400</td>\n",
       "      <td>0.296040</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.585204</td>\n",
       "      <td>0.303040</td>\n",
       "      <td>0.296040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221933_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.506893</td>\n",
       "      <td>0.419465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.432588</td>\n",
       "      <td>0.294868</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554689_a_at</th>\n",
       "      <td>0.183221</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.274078</td>\n",
       "      <td>0.273133</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244472</td>\n",
       "      <td>0.274971</td>\n",
       "      <td>0.273133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45297_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361025</td>\n",
       "      <td>0.204941</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.528291</td>\n",
       "      <td>0.257153</td>\n",
       "      <td>0.257153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225791_at</th>\n",
       "      <td>0.682172</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.246589</td>\n",
       "      <td>0.119646</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.315221</td>\n",
       "      <td>0.243536</td>\n",
       "      <td>0.243536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239886_at</th>\n",
       "      <td>0.365663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.618255</td>\n",
       "      <td>0.227033</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.277684</td>\n",
       "      <td>0.237005</td>\n",
       "      <td>0.227033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229380_at</th>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218567</td>\n",
       "      <td>0.137130</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.369293</td>\n",
       "      <td>0.224233</td>\n",
       "      <td>0.218567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227134_at</th>\n",
       "      <td>0.296832</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.340159</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.263165</td>\n",
       "      <td>0.220182</td>\n",
       "      <td>0.263165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552742_at</th>\n",
       "      <td>0.298797</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099290</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>0.099290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224252_s_at</th>\n",
       "      <td>0.232003</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339085</td>\n",
       "      <td>0.432266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564064</td>\n",
       "      <td>0.216761</td>\n",
       "      <td>0.216761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230689_at</th>\n",
       "      <td>0.185628</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200150</td>\n",
       "      <td>0.177877</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144692</td>\n",
       "      <td>0.203953</td>\n",
       "      <td>0.185628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225611_at</th>\n",
       "      <td>0.052721</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146048</td>\n",
       "      <td>0.196601</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218638_s_at</th>\n",
       "      <td>0.503735</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>0.174359</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776229</td>\n",
       "      <td>0.195798</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215784_at</th>\n",
       "      <td>0.109584</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193783</td>\n",
       "      <td>0.109584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230932_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512280</td>\n",
       "      <td>0.465298</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.191498</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556945_a_at</th>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.330533</td>\n",
       "      <td>0.175226</td>\n",
       "      <td>0.175226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206907_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.363048</td>\n",
       "      <td>0.200825</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.174578</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202552_s_at</th>\n",
       "      <td>0.289373</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110134</td>\n",
       "      <td>0.333203</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377373</td>\n",
       "      <td>0.172821</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238622_at</th>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537788</td>\n",
       "      <td>0.281261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341578</td>\n",
       "      <td>0.169658</td>\n",
       "      <td>0.169658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203522_at</th>\n",
       "      <td>0.248877</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686273</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081920</td>\n",
       "      <td>0.168493</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207375_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.295477</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.161665</td>\n",
       "      <td>0.157124</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225613_at</th>\n",
       "      <td>0.066714</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249273</td>\n",
       "      <td>0.035447</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356734</td>\n",
       "      <td>0.096788</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203325_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.091998</td>\n",
       "      <td>0.024655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237403_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483750</td>\n",
       "      <td>0.086558</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206752_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147126</td>\n",
       "      <td>0.056069</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>0.084844</td>\n",
       "      <td>0.056069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213093_at</th>\n",
       "      <td>0.013223</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216555</td>\n",
       "      <td>0.083138</td>\n",
       "      <td>0.030562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215933_s_at</th>\n",
       "      <td>0.254518</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.012974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228097_at</th>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341788</td>\n",
       "      <td>0.077078</td>\n",
       "      <td>0.002159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218337_at</th>\n",
       "      <td>0.132429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100030</td>\n",
       "      <td>0.074868</td>\n",
       "      <td>0.051670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205910_s_at</th>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323177</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208501_at</th>\n",
       "      <td>0.017848</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080279</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073765</td>\n",
       "      <td>0.055483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222978_at</th>\n",
       "      <td>0.061169</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210312</td>\n",
       "      <td>0.046922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.061169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204689_at</th>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107290</td>\n",
       "      <td>0.070754</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207908_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>0.047428</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379852</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212489_at</th>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296336</td>\n",
       "      <td>0.051742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108841</td>\n",
       "      <td>0.064810</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219693_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123878</td>\n",
       "      <td>0.079211</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073104</td>\n",
       "      <td>0.061971</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229678_at</th>\n",
       "      <td>0.115424</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089184</td>\n",
       "      <td>0.122377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>0.058991</td>\n",
       "      <td>0.058991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218376_s_at</th>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220681</td>\n",
       "      <td>0.053841</td>\n",
       "      <td>0.002130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223600_s_at</th>\n",
       "      <td>0.176172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160806</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212124_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024980</td>\n",
       "      <td>0.262009</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.052874</td>\n",
       "      <td>0.027539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211549_s_at</th>\n",
       "      <td>0.051922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015786</td>\n",
       "      <td>0.052420</td>\n",
       "      <td>0.015786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219282_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.036086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209804</td>\n",
       "      <td>0.051570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215195_at</th>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125975</td>\n",
       "      <td>0.045269</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208592_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.044532</td>\n",
       "      <td>0.029046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206310_at</th>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048259</td>\n",
       "      <td>0.042343</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223575_at</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.033316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210676_x_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.031577</td>\n",
       "      <td>0.019680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228098_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094754</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214958_s_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.057429</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>0.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215117_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217865_at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0_RF     1_XGB    2_LGBM  3_ExtraTrees      9_RF    10_XGB  \\\n",
       "1569566_at    1.000000  0.761905  0.166667      0.000000  1.000000  0.703704   \n",
       "223748_at     0.239810  0.261905  1.000000      0.213193  0.354560  0.333333   \n",
       "233185_at     0.289019  0.142857  0.833333      0.390557  0.466654  0.388889   \n",
       "209661_at     0.144378  0.214286  0.500000      0.394731  0.219756  0.277778   \n",
       "223017_at     0.411182  0.333333  0.333333      0.162605  0.324446  0.148148   \n",
       "209626_s_at   0.146771  0.476191  0.333333      0.000000  0.372427  0.481481   \n",
       "1552726_at    0.114999  1.000000  0.000000      0.016747  0.014141  1.000000   \n",
       "201015_s_at   0.665232  0.000000  0.000000      0.718868  0.664016  0.037037   \n",
       "228667_at     0.777687  0.190476  0.166667      0.204861  0.294335  0.314815   \n",
       "1563473_at    0.000000  0.285714  0.500000      0.294400  0.296040  0.296296   \n",
       "221933_at     0.000000  0.166667  0.333333      0.506893  0.419465  0.000000   \n",
       "1554689_a_at  0.183221  0.761905  0.166667      0.274078  0.273133  0.296296   \n",
       "45297_at      0.000000  0.000000  0.500000      0.361025  0.204941  0.129630   \n",
       "225791_at     0.682172  0.047619  0.166667      0.246589  0.119646  0.037037   \n",
       "239886_at     0.365663  0.000000  0.166667      0.618255  0.227033  0.074074   \n",
       "229380_at     0.407494  0.309524  0.000000      0.218567  0.137130  0.185185   \n",
       "227134_at     0.296832  0.119048  0.333333      0.001509  0.340159  0.074074   \n",
       "1552742_at    0.298797  0.833333  0.000000      0.025492  0.000000  0.481481   \n",
       "224252_s_at   0.232003  0.166667  0.000000      0.339085  0.432266  0.000000   \n",
       "230689_at     0.185628  0.404762  0.500000      0.200150  0.177877  0.018519   \n",
       "225611_at     0.052721  0.119048  0.000000      1.000000  0.254994  0.000000   \n",
       "218638_s_at   0.503735  0.071429  0.000000      0.022114  0.174359  0.018519   \n",
       "215784_at     0.109584  0.238095  0.000000      0.148497  0.017047  0.037037   \n",
       "230932_at     0.000000  0.142857  0.000000      0.512280  0.465298  0.037037   \n",
       "1556945_a_at  0.032344  0.214286  0.000000      0.269091  0.000000  0.388889   \n",
       "206907_at     0.000000  0.119048  0.166667      0.363048  0.200825  0.092593   \n",
       "202552_s_at   0.289373  0.142857  0.000000      0.110134  0.333203  0.129630   \n",
       "238622_at     0.172830  0.023810  0.000000      0.537788  0.281261  0.000000   \n",
       "203522_at     0.248877  0.190476  0.000000      0.686273  0.029284  0.111111   \n",
       "207375_s_at   0.000000  0.166667  0.166667      0.295477  0.003553  0.296296   \n",
       "...                ...       ...       ...           ...       ...       ...   \n",
       "225613_at     0.066714  0.047619  0.000000      0.249273  0.035447  0.018519   \n",
       "203325_s_at   0.000000  0.309524  0.000000      0.039506  0.010448  0.351852   \n",
       "237403_at     0.000000  0.095238  0.000000      0.094958  0.000000  0.018519   \n",
       "206752_s_at   0.000000  0.214286  0.000000      0.147126  0.056069  0.055556   \n",
       "213093_at     0.013223  0.238095  0.000000      0.030562  0.000000  0.166667   \n",
       "215933_s_at   0.254518  0.071429  0.000000      0.308700  0.012974  0.000000   \n",
       "228097_at     0.002159  0.238095  0.000000      0.034581  0.000000  0.000000   \n",
       "218337_at     0.132429  0.000000  0.000000      0.000000  0.051670  0.314815   \n",
       "205910_s_at   0.008458  0.095238  0.000000      0.145088  0.000000  0.018519   \n",
       "208501_at     0.017848  0.047619  0.000000      0.080279  0.055483  0.055556   \n",
       "222978_at     0.061169  0.166667  0.000000      0.210312  0.046922  0.000000   \n",
       "204689_at     0.004828  0.071429  0.000000      0.363966  0.000000  0.018519   \n",
       "207908_at     0.000000  0.023810  0.000000      0.063816  0.047428  0.037037   \n",
       "212489_at     0.013943  0.047619  0.000000      0.296336  0.051742  0.000000   \n",
       "219693_at     0.000000  0.071429  0.000000      0.123878  0.079211  0.148148   \n",
       "229678_at     0.115424  0.095238  0.000000      0.089184  0.122377  0.000000   \n",
       "218376_s_at   0.001569  0.095238  0.000000      0.000000  0.002130  0.111111   \n",
       "223600_s_at   0.176172  0.000000  0.000000      0.051518  0.000000  0.037037   \n",
       "212124_at     0.000000  0.071429  0.000000      0.024980  0.262009  0.037037   \n",
       "211549_s_at   0.051922  0.000000  0.000000      0.277577  0.000000  0.074074   \n",
       "219282_s_at   0.000000  0.000000  0.166667      0.036086  0.000000  0.000000   \n",
       "215195_at     0.001826  0.071429  0.000000      0.125885  0.000000  0.037037   \n",
       "208592_s_at   0.000000  0.119048  0.000000      0.078533  0.000000  0.129630   \n",
       "206310_at     0.002236  0.023810  0.000000      0.245923  0.000000  0.018519   \n",
       "223575_at     0.185185  0.000000  0.000000      0.054870  0.000000  0.000000   \n",
       "210676_x_at   0.000000  0.095238  0.000000      0.026585  0.000000  0.111111   \n",
       "228098_s_at   0.000000  0.000000  0.000000      0.038772  0.000000  0.055556   \n",
       "214958_s_at   0.000000  0.000000  0.000000      0.024102  0.057429  0.074074   \n",
       "215117_at     0.000000  0.023810  0.000000      0.017896  0.038398  0.018519   \n",
       "217865_at     0.000000  0.047619  0.000000      0.000000  0.019599  0.000000   \n",
       "\n",
       "               11_LGBM  12_ExtraTrees      MEAN    MEDIAN  \n",
       "1569566_at    0.833333       0.705969  0.646447  0.705969  \n",
       "223748_at     1.000000       0.292892  0.461962  0.333333  \n",
       "233185_at     0.500000       0.365009  0.422040  0.390557  \n",
       "209661_at     0.333333       0.796495  0.360095  0.333333  \n",
       "223017_at     0.500000       0.390542  0.325449  0.333333  \n",
       "209626_s_at   0.500000       0.212822  0.315378  0.333333  \n",
       "1552726_at    0.000000       0.312695  0.307323  0.114999  \n",
       "201015_s_at   0.166667       0.194040  0.305732  0.194040  \n",
       "228667_at     0.333333       0.145589  0.303470  0.294335  \n",
       "1563473_at    0.166667       0.585204  0.303040  0.296040  \n",
       "221933_at     0.500000       0.432588  0.294868  0.333333  \n",
       "1554689_a_at  0.000000       0.244472  0.274971  0.273133  \n",
       "45297_at      0.333333       0.528291  0.257153  0.257153  \n",
       "225791_at     0.333333       0.315221  0.243536  0.243536  \n",
       "239886_at     0.166667       0.277684  0.237005  0.227033  \n",
       "229380_at     0.166667       0.369293  0.224233  0.218567  \n",
       "227134_at     0.333333       0.263165  0.220182  0.263165  \n",
       "1552742_at    0.000000       0.099290  0.217299  0.099290  \n",
       "224252_s_at   0.000000       0.564064  0.216761  0.216761  \n",
       "230689_at     0.000000       0.144692  0.203953  0.185628  \n",
       "225611_at     0.000000       0.146048  0.196601  0.119048  \n",
       "218638_s_at   0.000000       0.776229  0.195798  0.071429  \n",
       "215784_at     0.000000       1.000000  0.193783  0.109584  \n",
       "230932_at     0.000000       0.374511  0.191498  0.142857  \n",
       "1556945_a_at  0.166667       0.330533  0.175226  0.175226  \n",
       "206907_at     0.166667       0.287776  0.174578  0.166667  \n",
       "202552_s_at   0.000000       0.377373  0.172821  0.142857  \n",
       "238622_at     0.000000       0.341578  0.169658  0.169658  \n",
       "203522_at     0.000000       0.081920  0.168493  0.111111  \n",
       "207375_s_at   0.166667       0.161665  0.157124  0.166667  \n",
       "...                ...            ...       ...       ...  \n",
       "225613_at     0.000000       0.356734  0.096788  0.047619  \n",
       "203325_s_at   0.000000       0.024655  0.091998  0.024655  \n",
       "237403_at     0.000000       0.483750  0.086558  0.018519  \n",
       "206752_s_at   0.000000       0.205714  0.084844  0.056069  \n",
       "213093_at     0.000000       0.216555  0.083138  0.030562  \n",
       "215933_s_at   0.000000       0.005204  0.081603  0.012974  \n",
       "228097_at     0.000000       0.341788  0.077078  0.002159  \n",
       "218337_at     0.000000       0.100030  0.074868  0.051670  \n",
       "205910_s_at   0.000000       0.323177  0.073810  0.018519  \n",
       "208501_at     0.333333       0.000000  0.073765  0.055483  \n",
       "222978_at     0.000000       0.086762  0.071479  0.061169  \n",
       "204689_at     0.000000       0.107290  0.070754  0.018519  \n",
       "207908_at     0.000000       0.379852  0.068993  0.037037  \n",
       "212489_at     0.000000       0.108841  0.064810  0.047619  \n",
       "219693_at     0.000000       0.073104  0.061971  0.071429  \n",
       "229678_at     0.000000       0.049706  0.058991  0.058991  \n",
       "218376_s_at   0.000000       0.220681  0.053841  0.002130  \n",
       "223600_s_at   0.000000       0.160806  0.053192  0.037037  \n",
       "212124_at     0.000000       0.027539  0.052874  0.027539  \n",
       "211549_s_at   0.000000       0.015786  0.052420  0.015786  \n",
       "219282_s_at   0.000000       0.209804  0.051570  0.000000  \n",
       "215195_at     0.000000       0.125975  0.045269  0.037037  \n",
       "208592_s_at   0.000000       0.029046  0.044532  0.029046  \n",
       "206310_at     0.000000       0.048259  0.042343  0.018519  \n",
       "223575_at     0.000000       0.026476  0.033316  0.000000  \n",
       "210676_x_at   0.000000       0.019680  0.031577  0.019680  \n",
       "228098_s_at   0.000000       0.094754  0.023635  0.000000  \n",
       "214958_s_at   0.000000       0.007504  0.020389  0.007504  \n",
       "215117_at     0.000000       0.052289  0.018864  0.018519  \n",
       "217865_at     0.000000       0.014556  0.010222  0.000000  \n",
       "\n",
       "[78 rows x 10 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17_SVM</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>MEDIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207375_s_at</th>\n",
       "      <td>-0.778240</td>\n",
       "      <td>-0.778240</td>\n",
       "      <td>-0.778240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207375_s_at</th>\n",
       "      <td>-0.778240</td>\n",
       "      <td>-0.778240</td>\n",
       "      <td>-0.778240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569566_at</th>\n",
       "      <td>-0.738152</td>\n",
       "      <td>-0.738152</td>\n",
       "      <td>-0.738152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569566_at</th>\n",
       "      <td>-0.738152</td>\n",
       "      <td>-0.738152</td>\n",
       "      <td>-0.738152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223017_at</th>\n",
       "      <td>-0.711523</td>\n",
       "      <td>-0.711523</td>\n",
       "      <td>-0.711523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223017_at</th>\n",
       "      <td>-0.711523</td>\n",
       "      <td>-0.711523</td>\n",
       "      <td>-0.711523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217865_at</th>\n",
       "      <td>-0.580438</td>\n",
       "      <td>-0.580438</td>\n",
       "      <td>-0.580438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217865_at</th>\n",
       "      <td>-0.580438</td>\n",
       "      <td>-0.580438</td>\n",
       "      <td>-0.580438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221933_at</th>\n",
       "      <td>-0.572213</td>\n",
       "      <td>-0.572213</td>\n",
       "      <td>-0.572213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221933_at</th>\n",
       "      <td>-0.572213</td>\n",
       "      <td>-0.572213</td>\n",
       "      <td>-0.572213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230689_at</th>\n",
       "      <td>-0.570741</td>\n",
       "      <td>-0.570741</td>\n",
       "      <td>-0.570741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230689_at</th>\n",
       "      <td>-0.570741</td>\n",
       "      <td>-0.570741</td>\n",
       "      <td>-0.570741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218862_at</th>\n",
       "      <td>-0.551026</td>\n",
       "      <td>-0.551026</td>\n",
       "      <td>-0.551026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218862_at</th>\n",
       "      <td>-0.551026</td>\n",
       "      <td>-0.551026</td>\n",
       "      <td>-0.551026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206589_at</th>\n",
       "      <td>-0.509342</td>\n",
       "      <td>-0.509342</td>\n",
       "      <td>-0.509342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206589_at</th>\n",
       "      <td>-0.509342</td>\n",
       "      <td>-0.509342</td>\n",
       "      <td>-0.509342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213093_at</th>\n",
       "      <td>-0.489782</td>\n",
       "      <td>-0.489782</td>\n",
       "      <td>-0.489782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213093_at</th>\n",
       "      <td>-0.489782</td>\n",
       "      <td>-0.489782</td>\n",
       "      <td>-0.489782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552726_at</th>\n",
       "      <td>-0.477115</td>\n",
       "      <td>-0.477115</td>\n",
       "      <td>-0.477115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552726_at</th>\n",
       "      <td>-0.477115</td>\n",
       "      <td>-0.477115</td>\n",
       "      <td>-0.477115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568713_a_at</th>\n",
       "      <td>-0.436315</td>\n",
       "      <td>-0.436315</td>\n",
       "      <td>-0.436315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568713_a_at</th>\n",
       "      <td>-0.436315</td>\n",
       "      <td>-0.436315</td>\n",
       "      <td>-0.436315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233185_at</th>\n",
       "      <td>-0.432951</td>\n",
       "      <td>-0.432951</td>\n",
       "      <td>-0.432951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233185_at</th>\n",
       "      <td>-0.432951</td>\n",
       "      <td>-0.432951</td>\n",
       "      <td>-0.432951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554689_a_at</th>\n",
       "      <td>-0.362968</td>\n",
       "      <td>-0.362968</td>\n",
       "      <td>-0.362968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554689_a_at</th>\n",
       "      <td>-0.362968</td>\n",
       "      <td>-0.362968</td>\n",
       "      <td>-0.362968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239886_at</th>\n",
       "      <td>-0.356627</td>\n",
       "      <td>-0.356627</td>\n",
       "      <td>-0.356627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239886_at</th>\n",
       "      <td>-0.356627</td>\n",
       "      <td>-0.356627</td>\n",
       "      <td>-0.356627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206923_at</th>\n",
       "      <td>-0.285478</td>\n",
       "      <td>-0.285478</td>\n",
       "      <td>-0.285478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206923_at</th>\n",
       "      <td>-0.285478</td>\n",
       "      <td>-0.285478</td>\n",
       "      <td>-0.285478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225611_at</th>\n",
       "      <td>0.500255</td>\n",
       "      <td>0.500255</td>\n",
       "      <td>0.500255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225611_at</th>\n",
       "      <td>0.500255</td>\n",
       "      <td>0.500255</td>\n",
       "      <td>0.500255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45297_at</th>\n",
       "      <td>0.504332</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>0.504332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45297_at</th>\n",
       "      <td>0.504332</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>0.504332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212488_at</th>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.539668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212488_at</th>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.539668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213367_at</th>\n",
       "      <td>0.545995</td>\n",
       "      <td>0.545995</td>\n",
       "      <td>0.545995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213367_at</th>\n",
       "      <td>0.545995</td>\n",
       "      <td>0.545995</td>\n",
       "      <td>0.545995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225791_at</th>\n",
       "      <td>0.582158</td>\n",
       "      <td>0.582158</td>\n",
       "      <td>0.582158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225791_at</th>\n",
       "      <td>0.582158</td>\n",
       "      <td>0.582158</td>\n",
       "      <td>0.582158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203522_at</th>\n",
       "      <td>0.585908</td>\n",
       "      <td>0.585908</td>\n",
       "      <td>0.585908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203522_at</th>\n",
       "      <td>0.585908</td>\n",
       "      <td>0.585908</td>\n",
       "      <td>0.585908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552742_at</th>\n",
       "      <td>0.602966</td>\n",
       "      <td>0.602966</td>\n",
       "      <td>0.602966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552742_at</th>\n",
       "      <td>0.602966</td>\n",
       "      <td>0.602966</td>\n",
       "      <td>0.602966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204692_at</th>\n",
       "      <td>0.643246</td>\n",
       "      <td>0.643246</td>\n",
       "      <td>0.643246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204692_at</th>\n",
       "      <td>0.643246</td>\n",
       "      <td>0.643246</td>\n",
       "      <td>0.643246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223748_at</th>\n",
       "      <td>0.665019</td>\n",
       "      <td>0.665019</td>\n",
       "      <td>0.665019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223748_at</th>\n",
       "      <td>0.665019</td>\n",
       "      <td>0.665019</td>\n",
       "      <td>0.665019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556945_a_at</th>\n",
       "      <td>0.699921</td>\n",
       "      <td>0.699921</td>\n",
       "      <td>0.699921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556945_a_at</th>\n",
       "      <td>0.699921</td>\n",
       "      <td>0.699921</td>\n",
       "      <td>0.699921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223575_at</th>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.702153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223575_at</th>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.702153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215784_at</th>\n",
       "      <td>0.722935</td>\n",
       "      <td>0.722935</td>\n",
       "      <td>0.722935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215784_at</th>\n",
       "      <td>0.722935</td>\n",
       "      <td>0.722935</td>\n",
       "      <td>0.722935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215807_s_at</th>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215807_s_at</th>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209661_at</th>\n",
       "      <td>0.932969</td>\n",
       "      <td>0.932969</td>\n",
       "      <td>0.932969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209661_at</th>\n",
       "      <td>0.932969</td>\n",
       "      <td>0.932969</td>\n",
       "      <td>0.932969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209626_s_at</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209626_s_at</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                17_SVM      MEAN    MEDIAN\n",
       "207375_s_at  -0.778240 -0.778240 -0.778240\n",
       "207375_s_at  -0.778240 -0.778240 -0.778240\n",
       "1569566_at   -0.738152 -0.738152 -0.738152\n",
       "1569566_at   -0.738152 -0.738152 -0.738152\n",
       "223017_at    -0.711523 -0.711523 -0.711523\n",
       "223017_at    -0.711523 -0.711523 -0.711523\n",
       "217865_at    -0.580438 -0.580438 -0.580438\n",
       "217865_at    -0.580438 -0.580438 -0.580438\n",
       "221933_at    -0.572213 -0.572213 -0.572213\n",
       "221933_at    -0.572213 -0.572213 -0.572213\n",
       "230689_at    -0.570741 -0.570741 -0.570741\n",
       "230689_at    -0.570741 -0.570741 -0.570741\n",
       "218862_at    -0.551026 -0.551026 -0.551026\n",
       "218862_at    -0.551026 -0.551026 -0.551026\n",
       "206589_at    -0.509342 -0.509342 -0.509342\n",
       "206589_at    -0.509342 -0.509342 -0.509342\n",
       "213093_at    -0.489782 -0.489782 -0.489782\n",
       "213093_at    -0.489782 -0.489782 -0.489782\n",
       "1552726_at   -0.477115 -0.477115 -0.477115\n",
       "1552726_at   -0.477115 -0.477115 -0.477115\n",
       "1568713_a_at -0.436315 -0.436315 -0.436315\n",
       "1568713_a_at -0.436315 -0.436315 -0.436315\n",
       "233185_at    -0.432951 -0.432951 -0.432951\n",
       "233185_at    -0.432951 -0.432951 -0.432951\n",
       "1554689_a_at -0.362968 -0.362968 -0.362968\n",
       "1554689_a_at -0.362968 -0.362968 -0.362968\n",
       "239886_at    -0.356627 -0.356627 -0.356627\n",
       "239886_at    -0.356627 -0.356627 -0.356627\n",
       "206923_at    -0.285478 -0.285478 -0.285478\n",
       "206923_at    -0.285478 -0.285478 -0.285478\n",
       "...                ...       ...       ...\n",
       "225611_at     0.500255  0.500255  0.500255\n",
       "225611_at     0.500255  0.500255  0.500255\n",
       "45297_at      0.504332  0.504332  0.504332\n",
       "45297_at      0.504332  0.504332  0.504332\n",
       "212488_at     0.539668  0.539668  0.539668\n",
       "212488_at     0.539668  0.539668  0.539668\n",
       "213367_at     0.545995  0.545995  0.545995\n",
       "213367_at     0.545995  0.545995  0.545995\n",
       "225791_at     0.582158  0.582158  0.582158\n",
       "225791_at     0.582158  0.582158  0.582158\n",
       "203522_at     0.585908  0.585908  0.585908\n",
       "203522_at     0.585908  0.585908  0.585908\n",
       "1552742_at    0.602966  0.602966  0.602966\n",
       "1552742_at    0.602966  0.602966  0.602966\n",
       "204692_at     0.643246  0.643246  0.643246\n",
       "204692_at     0.643246  0.643246  0.643246\n",
       "223748_at     0.665019  0.665019  0.665019\n",
       "223748_at     0.665019  0.665019  0.665019\n",
       "1556945_a_at  0.699921  0.699921  0.699921\n",
       "1556945_a_at  0.699921  0.699921  0.699921\n",
       "223575_at     0.702153  0.702153  0.702153\n",
       "223575_at     0.702153  0.702153  0.702153\n",
       "215784_at     0.722935  0.722935  0.722935\n",
       "215784_at     0.722935  0.722935  0.722935\n",
       "215807_s_at   0.730463  0.730463  0.730463\n",
       "215807_s_at   0.730463  0.730463  0.730463\n",
       "209661_at     0.932969  0.932969  0.932969\n",
       "209661_at     0.932969  0.932969  0.932969\n",
       "209626_s_at   1.000000  1.000000  1.000000\n",
       "209626_s_at   1.000000  1.000000  1.000000\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualise the top weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_coeffs.to_csv(\"out/coeffs_\"+Rocket.SET_NAME+\"_FDR_alpha0025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_weights.to_csv(\"out/weights_\"+Rocket.SET_NAME+\"_FDR_alpha0025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF9 = top_genomes_weights['RandomForest'].quantile(q=0.9)\n",
    "GBM9 = top_genomes_weights['GBM'].quantile(q=0.9)\n",
    "ADA9 = top_genomes_weights['AdaBoost'].quantile(q=0.9)\n",
    "ET9 = top_genomes_weights['ExtraTrees'].quantile(q=0.9)\n",
    "Overlapping_genomes = set(top_genomes_weights.loc[top_genomes_weights['RandomForest']>RF9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['GBM']>GBM9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['AdaBoost']>ADA9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['ExtraTrees']>ET9].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import*\n",
    "#from scipy.dspatial.distance import cosine\n",
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import cdist\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TransPosed = Rocket.DATA_all_samples.T # all microarrays, may be multiple per patient versus all probesets, may be multiple per genome\n",
    "Normal = Rocket.DATA_merged_processed.loc[:, (Rocket.DATA_merged_processed.columns !='target') & \n",
    "                                             (Rocket.DATA_merged_processed.columns !='ID')]\n",
    "#AllNormal = Rocket.DATA_merged\n",
    "#probeset_weights = Rocket.get_probeset_weights(method = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 9827_corr2.CEL, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'cosine', normalised = True, inflation = 2, minkowski_dim=1)\n",
    "##### apply Markov clustering\n",
    "#######################\n",
    "# non-distributed, non-sparse version, only for small-sized problems (N is order 1000)\n",
    "e = 2\n",
    "r = 2 \n",
    "epsilon = 1e-7\n",
    "convergence = 0.001\n",
    "num_iter = 10\n",
    "Orientation = 'col' # columnwise or rowwise\n",
    "\n",
    "# add loop\n",
    "def add_loop(df_matrix, value=0): \n",
    "    for i in df_matrix.index:\n",
    "        df_matrix.loc[i, i] = value\n",
    "    return df_matrix\n",
    "patient_sim = add_loop(patient_sim, 1)\n",
    "patient_sim = patient_sim - epsilon\n",
    "\n",
    "def normalise(sim, type = 'col'):\n",
    "    if(type == 'col'):\n",
    "        # column normalisation\n",
    "        for variable in sim.keys():\n",
    "            col_vec = sim[variable]\n",
    "            sum_val = sum([p for p in col_vec])\n",
    "            sim[variable] = sim[variable]/sum_val\n",
    "    elif (type == 'row'):\n",
    "        # row normalisation\n",
    "        for variable in sim.keys():\n",
    "            row_vec = sim.loc[variable, :]\n",
    "            sum_val = sum([p for p in row_vec])\n",
    "            sim.loc[variable,:] = sim.loc[variable,:]/sum_val\n",
    "    return sim\n",
    "\n",
    "# step E: expansion, get the nth power of the matrix\n",
    "def expansion(sim):\n",
    "    X = numpy.array(sim)\n",
    "    VarList = sim.keys()\n",
    "    if e == 1:\n",
    "        return sim\n",
    "    elif e > 1:        \n",
    "        return pandas.DataFrame(numpy.linalg.matrix_power(X, e), index = VarList, columns = VarList)\n",
    "     \n",
    "# step I: inflation, per column raise by rth power and column normalise\n",
    "def inflation(sim, type = 'col'):    \n",
    "    if type == 'col':\n",
    "        Axis = 0\n",
    "    elif type == 'row':\n",
    "        Axis = 1\n",
    "    return sim.apply(lambda x: x**r/sum(x**r), axis = Axis)\n",
    "\n",
    "# remove weak connections, values < epsilon\n",
    "def clean(sim):\n",
    "    return sim.applymap(lambda x:0 if x<epsilon else x)\n",
    "    \n",
    "def difference(old, new):\n",
    "    # relative zeroes over entire array\n",
    "    #return (new.apply(lambda x: numpy.ceil(x-epsilon)) - old.apply(lambda x: numpy.ceil(x-epsilon))).sum().sum()/len(old)**2    \n",
    "    return abs(new - old).sum().sum()/len(old)**2    \n",
    "\n",
    "#patient_sim = normalise(patient_sim, type = Orientation)\n",
    "_sim_a = patient_sim\n",
    "for i in range(0,num_iter):\n",
    "    # repeat E and I until convergence, the row-wise elements form the clusters.\n",
    "    _sim_b = clean(inflation(expansion(_sim_a), type = Orientation))\n",
    "    _sim_a = normalise(_sim_a, type = Orientation)\n",
    "    #if ((difference(_sim_a, _sim_b)) < convergence) & (i>0):\n",
    "    #    print(difference(_sim_a, _sim_b))\n",
    "    #    print(\"CONVERGED after \", i, \" iterations\")\n",
    "    #    break;\n",
    "    _sim_a = _sim_b\n",
    "\n",
    "result_mcl = clean(_sim_b)\n",
    "result_mcl.loc[result_mcl.loc['9827_corr2.CEL',:]>epsilon, '9827_corr2.CEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 patient clusters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'pearson', normalised = False, inflation=1, minkowski_dim=1)\n",
    "##### apply Affinity Propagation\n",
    "#######################\n",
    "X = numpy.array(patient_sim)\n",
    "af = AffinityPropagation(preference=-10).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "patient_clusters = patient_sim.keys()[cluster_centers_indices].values\n",
    "patient_cluster_members = af.labels_\n",
    "print(\"There are {} patient clusters\".format(n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AggResults = Rocket.DATA_merged\n",
    "AggResults = _helpers._preprocess(AggResults, Rclass = Rocket)\n",
    "#AggResults = _helpers._group_patients(AggResults, method = 'mean')\n",
    "AggResults['cluster_ap'] = patient_cluster_members\n",
    "\n",
    "#AggResults.groupby(['Treatment risk group in ALL10', 'cluster_ap']).agg({'Microarray file': pandas.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "AggResults['FU_RFS'] = pandas.to_numeric(AggResults['FU_RFS'])\n",
    "AggResults['FU_EFS'] = pandas.to_numeric(AggResults['FU_EFS'])\n",
    "AggResults['FU_OS'] = pandas.to_numeric(AggResults['FU_OS'])\n",
    "AggResults['WhiteBloodCellcount'] = pandas.to_numeric(AggResults['WhiteBloodCellcount'])\n",
    "AggResults['Age'] = pandas.to_numeric(AggResults['Age'])\n",
    "AggResults['Gender'] = pandas.to_numeric(AggResults['Gender'])\n",
    "AggResults['code_RFS']= pandas.to_numeric(AggResults['code_RFS'])\n",
    "AggResults['code_EFS']= pandas.to_numeric(AggResults['code_EFS'])\n",
    "AggResults['code_OS']= pandas.to_numeric(AggResults['code_OS'])\n",
    "\n",
    "AggResults['mutations_NOTCH_pathway'] = pandas.to_numeric(AggResults['mutations_NOTCH_pathway'])\n",
    "AggResults['mutations_PTEN_AKT_pathway'] = pandas.to_numeric(AggResults['mutations_PTEN_AKT_pathway'])\n",
    "AggResults['mutations_IL7R_pathway'] = pandas.to_numeric(AggResults['mutations_IL7R_pathway'])\n",
    "#AggResults.replace(to_replace=9999, value=0.5, inplace=True)\n",
    "AggResults[['mutations_NOTCH_pathway', \n",
    "            'mutations_PTEN_AKT_pathway', \n",
    "            'mutations_IL7R_pathway']] = AggResults[['mutations_NOTCH_pathway', \n",
    "                                                    'mutations_PTEN_AKT_pathway', \n",
    "                                                    'mutations_IL7R_pathway']].replace([9999],[numpy.nan],\n",
    "                                                                                       inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "AggResults['comb_mutations_NOTCH_IL7R'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_NOTCH_PTEN'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_PTEN_AKT_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN'] =  AggResults['mutations_PTEN_AKT_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN_NOTCH'] =  AggResults['mutations_PTEN_AKT_pathway']\\\n",
    "                                                + AggResults['mutations_IL7R_pathway']\\\n",
    "                                                + AggResults['mutations_NOTCH_pathway']\n",
    "\n",
    "\n",
    "patient_count = AggResults.groupby(['cluster_ap']).agg({'labnr_patient': pandas.Series.nunique})\n",
    "Clustered_by_patients_whitebloodcells = AggResults[AggResults['WhiteBloodCellcount'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'WhiteBloodCellcount': numpy.mean,\n",
    "    'Age': numpy.mean, \n",
    "    'Gender': numpy.mean})\n",
    "\n",
    "# Cancer_gene\n",
    "# Treatment_protocol\n",
    "# Treatment_risk_group_in_ALL_10\n",
    "\n",
    "Clustered_by_patients_CODE = AggResults.groupby(['cluster_ap']).agg(\n",
    "    {'code_RFS': numpy.mean, \n",
    "     'code_EFS': numpy.mean,\n",
    "     'code_OS': numpy.mean})\n",
    "\n",
    "Clustered_by_patients_FU_RFS = AggResults[AggResults['FU_RFS'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'FU_RFS': numpy.median, \n",
    "     'FU_EFS': numpy.median,\n",
    "     'FU_OS': numpy.median})\n",
    "Clustered_by_patients_NotchPath = AggResults[AggResults['mutations_NOTCH_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_NOTCH_pathway': numpy.mean})\n",
    "Clustered_by_patients_IL7RPath = AggResults[AggResults['mutations_IL7R_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_IL7R_pathway': numpy.mean})\n",
    "Clustered_by_patients_PTENAKTPath = AggResults[AggResults['mutations_PTEN_AKT_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_PTEN_AKT_pathway': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_IL7R = AggResults[AggResults['comb_mutations_NOTCH_IL7R'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_IL7R': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_PTEN = AggResults[AggResults['comb_mutations_NOTCH_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN = AggResults[AggResults['comb_mutations_IL7R_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN_NOTCH = AggResults[AggResults['comb_mutations_IL7R_PTEN_NOTCH'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN_NOTCH': numpy.mean})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_agg = pandas.merge(Clustered_by_patients_whitebloodcells, Clustered_by_patients_CODE, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN_NOTCH, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_IL7R, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_PTEN, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_FU_RFS, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_IL7RPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_NotchPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_PTENAKTPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, patient_count, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Cluster centers:\",patient_sim.keys()[cluster_centers_indices].values)\n",
    "print(patient_cluster_members)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    class_members = patient_cluster_members == k\n",
    "    cluster_center = X[cluster_centers_indices[k]]\n",
    "    plt.plot(X[class_members, 0], X[class_members, 1], col + '.', \n",
    "             label = patient_sim.keys()[cluster_centers_indices[k]])\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in X[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.title('Estimated number of clusters from Affinity Propagation: %d' % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### CREATE graph from similarity matrix\n",
    "##################\n",
    "# nodes\n",
    "VarList = TransPosed.keys()\n",
    "nodes = []\n",
    "node_index = 0\n",
    "for patient_name in VarList:\n",
    "    nodes.append((node_index, {'name': patient_name}))\n",
    "    node_index = node_index + 1\n",
    "\n",
    "edges = []\n",
    "# edges\n",
    "patient_sim = patient_similarity(Normal, sim_type = 'pearson', normalised = True, inflation=2)\n",
    "node_index_x = 0\n",
    "node_index_y = 0\n",
    "for patient_name_x in VarList:\n",
    "    for patient_name_y in VarList:        \n",
    "        edges.append((node_index_x, node_index_y, patient_sim.iloc[node_index_x, node_index_y]))\n",
    "        node_index_y = node_index_y + 1\n",
    "    node_index_x = node_index_x + 1\n",
    "    node_index_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(edges, weight = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:138: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  plt.hold(b)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.\n",
      "  warnings.warn(self.msg_depr_set % key)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0\n",
      "  warnings.warn(\"axes.hold is deprecated, will be removed in 3.0\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAFCCAYAAABSJMy8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f31beac128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### apply Spring-force\n",
    "#######################\n",
    "pos = nx.spring_layout(G, k = None, dim = 3, scale = 1.0)\n",
    "nx.draw_spring(G, k = 30, dim = 2, scale = 1.0, iterations =1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### APPLY community detector\n",
    "# maximize betweenness and modularity\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### LOAD IN DATA\n",
    "###################\n",
    "# https://stackoverflow.com/questions/14529838/apply-multiple-functions-to-multiple-groupby-columns\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
