{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++ Firing up RexR! ++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from RexR import *\n",
    "import _helpers\n",
    "Rocket = RexR(datalocation = None, #'_data/genomic_data/data.pkl', \n",
    "              seed = 3123, \n",
    "              debug = False, \n",
    "              write_out=True,\n",
    "              set_name = 'MELA') # data to read in ALL_10, or MELA\n",
    "Rocket.load_probeset_data();\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: ET accuracy:  0.674698795181 +/-: 0.00369562350512\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: RF accuracy:  0.807228915663 +/-: 0.00682899327051\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: GBM accuracy:  0.89156626506 +/-: 0.00217038719489\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: ADA accuracy:  0.903614457831 +/-: 0.00648370709391\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: LR accuracy:  0.89156626506 +/-: 0.00602403708859\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: SVM accuracy:  0.939759036145 +/-: 0.00146493130566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: GNB accuracy:  0.771084337349 +/-: 0.00760726582209\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: MLNN accuracy:  0.89156626506 +/-: 0.00332205268036\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: XGB accuracy:  0.903614457831 +/-: 0.0039293721069\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "Initial alpha = [[ 0.05742281]]\n",
      "   1 - L=-1604.9289669 - Gamma= 1.9999556 (M=   2) - s=0.0100\n",
      "   2 - L=-1409.8647296 - Gamma= 2.9999161 (M=   3) - s=0.0100\n",
      "   3 - L=-1268.2433830 - Gamma= 3.9998603 (M=   4) - s=0.0100\n",
      "   4 - L=-1159.3029303 - Gamma= 4.9997893 (M=   5) - s=0.0100\n",
      "   5 - L=-1082.5370875 - Gamma= 5.9996863 (M=   6) - s=0.0100\n",
      "   6 - L=-1020.1838659 - Gamma= 6.9995621 (M=   7) - s=0.0100\n",
      "   7 - L=-952.7900353 - Gamma= 7.9994382 (M=   8) - s=0.0100\n",
      "   8 - L=-878.4037592 - Gamma= 8.9993278 (M=   9) - s=0.0100\n",
      "   9 - L=-812.8691274 - Gamma= 9.9992056 (M=  10) - s=0.0100\n",
      "  10 - L=-748.2102361 - Gamma=10.9990837 (M=  11) - s=0.0100\n",
      "  11 - L=-688.4649297 - Gamma=11.9989457 (M=  12) - s=0.0100\n",
      "  12 - L=-633.8489603 - Gamma=12.9987976 (M=  13) - s=0.0100\n",
      "  13 - L=-573.8713560 - Gamma=13.9986623 (M=  14) - s=0.0100\n",
      "  14 - L=-518.7656416 - Gamma=14.9985211 (M=  15) - s=0.0100\n",
      "  15 - L=-474.6953766 - Gamma=15.9983344 (M=  16) - s=0.0100\n",
      "  16 - L=-441.0306204 - Gamma=16.9980916 (M=  17) - s=0.0100\n",
      "  17 - L=-403.2764057 - Gamma=17.9978654 (M=  18) - s=0.0100\n",
      "  18 - L=-368.5030420 - Gamma=18.9976242 (M=  19) - s=0.0100\n",
      "  19 - L=-331.5818393 - Gamma=19.9974084 (M=  20) - s=0.0100\n",
      "  20 - L=-331.5135714 - Gamma=18.9975765 (M=  19) - s=0.0100\n",
      "  21 - L=-299.1862345 - Gamma=19.9972968 (M=  20) - s=0.0100\n",
      "  22 - L=-246.7099443 - Gamma=20.9970583 (M=  21) - s=0.0100\n",
      "  23 - L=-221.0468716 - Gamma=21.9967474 (M=  22) - s=0.0100\n",
      "  24 - L=-196.4571081 - Gamma=22.9964133 (M=  23) - s=0.0100\n",
      "  25 - L=-174.7245196 - Gamma=23.9960254 (M=  24) - s=0.0100\n",
      "  26 - L=-157.1552405 - Gamma=24.9955763 (M=  25) - s=0.0100\n",
      "  27 - L=-138.3043683 - Gamma=25.9951329 (M=  26) - s=0.0100\n",
      "  28 - L=-118.3052037 - Gamma=26.9947259 (M=  27) - s=0.0100\n",
      "  29 - L=-103.3277153 - Gamma=27.9942007 (M=  28) - s=0.0100\n",
      "  30 - L=-92.5461304 - Gamma=28.9934740 (M=  29) - s=0.0100\n",
      "  31 - L=-80.9963521 - Gamma=29.9927683 (M=  30) - s=0.0100\n",
      "  32 - L=-69.2407281 - Gamma=30.9920341 (M=  31) - s=0.0100\n",
      "  33 - L=-58.3794239 - Gamma=31.9912979 (M=  32) - s=0.0100\n",
      "  34 - L=-49.6426064 - Gamma=32.9901638 (M=  33) - s=0.0100\n",
      "  35 - L=-41.2797260 - Gamma=33.9891848 (M=  34) - s=0.0100\n",
      "  36 - L=-35.7124997 - Gamma=34.9875904 (M=  35) - s=0.0100\n",
      "  37 - L=-30.0202416 - Gamma=35.9861895 (M=  36) - s=0.0100\n",
      "  38 - L=-26.2308289 - Gamma=36.9840710 (M=  37) - s=0.0100\n",
      "  39 - L=-22.7043604 - Gamma=37.9817760 (M=  38) - s=0.0100\n",
      "  40 - L=-19.5447649 - Gamma=38.9793172 (M=  39) - s=0.0100\n",
      "  41 - L=-17.3841905 - Gamma=39.9757668 (M=  40) - s=0.0100\n",
      "  42 - L=-15.1259766 - Gamma=40.9720157 (M=  41) - s=0.0100\n",
      "  43 - L=-13.0375652 - Gamma=41.9680861 (M=  42) - s=0.0100\n",
      "  44 - L=-10.6321694 - Gamma=42.9644307 (M=  43) - s=0.0100\n",
      "  45 - L=-8.0918683 - Gamma=43.9609607 (M=  44) - s=0.0100\n",
      "  46 - L=-5.8972046 - Gamma=44.9562283 (M=  45) - s=0.0100\n",
      "  47 - L=-4.5393399 - Gamma=45.9505026 (M=  46) - s=0.0100\n",
      "  48 - L=-3.0148566 - Gamma=46.9448437 (M=  47) - s=0.0100\n",
      "  49 - L=-1.8031264 - Gamma=47.9358741 (M=  48) - s=0.0100\n",
      "  50 - L=-1.2341440 - Gamma=48.9227140 (M=  49) - s=0.0100\n",
      "  51 - L=-0.6058507 - Gamma=49.9059504 (M=  50) - s=0.0100\n",
      "  52 - L=-0.1442569 - Gamma=50.8855131 (M=  51) - s=0.0100\n",
      "  53 - L= 0.0501824 - Gamma=51.8480087 (M=  52) - s=0.0100\n",
      "  54 - L= 0.2042831 - Gamma=52.8037371 (M=  53) - s=0.0100\n",
      "  55 - L= 0.3189330 - Gamma=53.7474995 (M=  54) - s=0.0100\n",
      "  56 - L= 0.4809986 - Gamma=54.7031384 (M=  55) - s=0.0100\n",
      "  57 - L= 0.6190378 - Gamma=55.6506352 (M=  56) - s=0.0100\n",
      "  58 - L= 0.6498155 - Gamma=56.4742528 (M=  57) - s=0.0100\n",
      "  59 - L= 0.6667912 - Gamma=56.4830460 (M=  57) - s=0.0100\n",
      "  60 - L= 0.6830359 - Gamma=56.4901527 (M=  57) - s=0.0100\n",
      "  61 - L= 0.6968786 - Gamma=56.4903390 (M=  57) - s=0.0100\n",
      "  62 - L= 0.7107186 - Gamma=56.4905199 (M=  57) - s=0.0100\n",
      "  63 - L= 0.7235548 - Gamma=57.2383987 (M=  58) - s=0.0100\n",
      "  64 - L= 0.7368911 - Gamma=57.9835395 (M=  59) - s=0.0100\n",
      "  65 - L= 0.7472320 - Gamma=57.9836079 (M=  59) - s=0.0100\n",
      "  66 - L= 0.7564738 - Gamma=57.9844265 (M=  59) - s=0.0100\n",
      "  67 - L= 0.7652418 - Gamma=57.9670908 (M=  59) - s=0.0100\n",
      "  68 - L= 0.7734477 - Gamma=57.9671050 (M=  59) - s=0.0100\n",
      "  69 - L= 0.7815697 - Gamma=58.6064005 (M=  60) - s=0.0100\n",
      "  70 - L= 0.7873347 - Gamma=58.6174122 (M=  60) - s=0.0100\n",
      "  71 - L= 0.7925480 - Gamma=58.6176452 (M=  60) - s=0.0100\n",
      "  72 - L= 0.7975226 - Gamma=58.5928968 (M=  60) - s=0.0100\n",
      "  73 - L= 0.8023622 - Gamma=58.5945661 (M=  60) - s=0.0100\n",
      "  74 - L= 0.8071588 - Gamma=58.5947612 (M=  60) - s=0.0100\n",
      "  75 - L= 0.8110770 - Gamma=58.5952420 (M=  60) - s=0.0100\n",
      "  76 - L= 0.8148807 - Gamma=58.5953696 (M=  60) - s=0.0100\n",
      "  77 - L= 0.8181893 - Gamma=58.5955086 (M=  60) - s=0.0100\n",
      "  78 - L= 0.8211810 - Gamma=58.5956958 (M=  60) - s=0.0100\n",
      "  79 - L= 0.8241443 - Gamma=58.5972960 (M=  60) - s=0.0100\n",
      "  80 - L= 0.8264710 - Gamma=58.6008254 (M=  60) - s=0.0100\n",
      "  81 - L= 0.8286204 - Gamma=58.6011738 (M=  60) - s=0.0100\n",
      "  82 - L= 0.8306982 - Gamma=58.5963705 (M=  60) - s=0.0100\n",
      "  83 - L= 0.8327639 - Gamma=58.5964196 (M=  60) - s=0.0100\n",
      "  84 - L= 0.8344980 - Gamma=58.5982134 (M=  60) - s=0.0100\n",
      "  85 - L= 0.8361735 - Gamma=58.6002354 (M=  60) - s=0.0100\n",
      "  86 - L= 0.8378044 - Gamma=58.5991762 (M=  60) - s=0.0100\n",
      "  87 - L= 0.8392453 - Gamma=58.5993002 (M=  60) - s=0.0100\n",
      "  88 - L= 0.8405598 - Gamma=58.5997686 (M=  60) - s=0.0100\n",
      "  89 - L= 0.8417705 - Gamma=58.5992215 (M=  60) - s=0.0100\n",
      "  90 - L= 0.8429977 - Gamma=58.9767148 (M=  61) - s=0.0100\n",
      "  91 - L= 0.8441094 - Gamma=58.9989171 (M=  61) - s=0.0100\n",
      "  92 - L= 0.8451612 - Gamma=58.9999103 (M=  61) - s=0.0100\n",
      "  93 - L= 0.8461859 - Gamma=59.0023393 (M=  61) - s=0.0100\n",
      "  94 - L= 0.8472084 - Gamma=59.0024559 (M=  61) - s=0.0100\n",
      "  95 - L= 0.8480689 - Gamma=59.0025113 (M=  61) - s=0.0100\n",
      "  96 - L= 0.8489197 - Gamma=59.0233963 (M=  61) - s=0.0100\n",
      "  97 - L= 0.8496100 - Gamma=59.0229157 (M=  61) - s=0.0100\n",
      "  98 - L= 0.8502696 - Gamma=59.0013182 (M=  61) - s=0.0100\n",
      "  99 - L= 0.8508602 - Gamma=59.0017124 (M=  61) - s=0.0100\n",
      " 100 - L= 0.8514306 - Gamma=58.9998671 (M=  61) - s=0.0100\n",
      " 101 - L= 0.8518438 - Gamma=59.0000686 (M=  61) - s=0.0100\n",
      " 102 - L= 0.8522457 - Gamma=58.9999077 (M=  61) - s=0.0100\n",
      " 103 - L= 0.8526265 - Gamma=59.0000233 (M=  61) - s=0.0100\n",
      " 104 - L= 0.8529918 - Gamma=59.0001553 (M=  61) - s=0.0100\n",
      " 105 - L= 0.8533504 - Gamma=58.9817267 (M=  61) - s=0.0100\n",
      " 106 - L= 0.8536564 - Gamma=58.9818022 (M=  61) - s=0.0100\n",
      " 107 - L= 0.8539270 - Gamma=58.9818796 (M=  61) - s=0.0100\n",
      " 108 - L= 0.8541938 - Gamma=58.9828501 (M=  61) - s=0.0100\n",
      " 109 - L= 0.8544304 - Gamma=58.9762063 (M=  61) - s=0.0100\n",
      " 110 - L= 0.8545734 - Gamma=58.9755679 (M=  61) - s=0.0100\n",
      " 111 - L= 0.8546521 - Gamma=58.9384240 (M=  61) - s=0.0100\n",
      " 112 - L= 0.8547241 - Gamma=58.9415279 (M=  61) - s=0.0100\n",
      " 113 - L= 0.8547883 - Gamma=58.9012546 (M=  61) - s=0.0100\n",
      " 114 - L= 0.8548530 - Gamma=58.9673780 (M=  61) - s=0.0100\n",
      " 115 - L= 0.8549029 - Gamma=58.9674589 (M=  61) - s=0.0100\n",
      " 116 - L= 0.8549422 - Gamma=58.9674718 (M=  61) - s=0.0100\n",
      " 117 - L= 0.8549795 - Gamma=58.9661876 (M=  61) - s=0.0100\n",
      " 118 - L= 0.8550074 - Gamma=58.9659409 (M=  61) - s=0.0100\n",
      " 119 - L= 0.8550336 - Gamma=58.9530940 (M=  61) - s=0.0100\n",
      " 120 - L= 0.8550540 - Gamma=58.9528810 (M=  61) - s=0.0100\n",
      " 121 - L= 0.8550728 - Gamma=58.9550257 (M=  61) - s=0.0100\n",
      " 122 - L= 0.8550853 - Gamma=58.9387678 (M=  61) - s=0.0100\n",
      " 123 - L= 0.8550952 - Gamma=58.9259474 (M=  61) - s=0.0100\n",
      " 124 - L= 0.8551016 - Gamma=58.9259439 (M=  61) - s=0.0100\n",
      " 125 - L= 0.8551076 - Gamma=58.9241834 (M=  61) - s=0.0100\n",
      " 126 - L= 0.8551120 - Gamma=58.9242554 (M=  61) - s=0.0100\n",
      " 127 - L= 0.8551156 - Gamma=58.9242668 (M=  61) - s=0.0100\n",
      " 128 - L= 0.8551184 - Gamma=58.9224130 (M=  61) - s=0.0100\n",
      " 129 - L= 0.8551211 - Gamma=58.9239339 (M=  61) - s=0.0100\n",
      " 130 - L= 0.8551229 - Gamma=58.9239876 (M=  61) - s=0.0100\n",
      " 131 - L= 0.8551244 - Gamma=58.9238592 (M=  61) - s=0.0100\n",
      " 132 - L= 0.8551259 - Gamma=58.9238804 (M=  61) - s=0.0100\n",
      " 133 - L= 0.8551274 - Gamma=58.9243040 (M=  61) - s=0.0100\n",
      " 134 - L= 0.8551288 - Gamma=58.9241408 (M=  61) - s=0.0100\n",
      " 135 - L= 0.8551301 - Gamma=58.9301352 (M=  61) - s=0.0100\n",
      " 136 - L= 0.8551314 - Gamma=58.9296131 (M=  61) - s=0.0100\n",
      " 137 - L= 0.8551326 - Gamma=58.9383646 (M=  61) - s=0.0100\n",
      " 138 - L= 0.8551338 - Gamma=58.9384326 (M=  61) - s=0.0100\n",
      " 139 - L= 0.8551346 - Gamma=58.9340872 (M=  61) - s=0.0100\n",
      " 140 - L= 0.8551352 - Gamma=58.9340620 (M=  61) - s=0.0100\n",
      " 141 - L= 0.8551358 - Gamma=58.9340587 (M=  61) - s=0.0100\n",
      " 142 - L= 0.8551364 - Gamma=58.9344177 (M=  61) - s=0.0100\n",
      " 143 - L= 0.8551369 - Gamma=58.9344301 (M=  61) - s=0.0100\n",
      " 144 - L= 0.8551374 - Gamma=58.9343888 (M=  61) - s=0.0100\n",
      " 145 - L= 0.8551379 - Gamma=58.9343658 (M=  61) - s=0.0100\n",
      " 146 - L= 0.8551384 - Gamma=58.9343728 (M=  61) - s=0.0100\n",
      " 147 - L= 0.8551387 - Gamma=58.9343734 (M=  61) - s=0.0100\n",
      " 148 - L= 0.8551390 - Gamma=58.9343628 (M=  61) - s=0.0100\n",
      " 149 - L= 0.8551393 - Gamma=58.9343659 (M=  61) - s=0.0100\n",
      " 150 - L= 0.8551396 - Gamma=58.9346904 (M=  61) - s=0.0100\n",
      " 151 - L= 0.8551399 - Gamma=58.9344245 (M=  61) - s=0.0100\n",
      " 152 - L= 0.8551401 - Gamma=58.9330426 (M=  61) - s=0.0100\n",
      " 153 - L= 0.8551403 - Gamma=58.9349500 (M=  61) - s=0.0100\n",
      " 154 - L= 0.8551404 - Gamma=58.9349481 (M=  61) - s=0.0100\n",
      " 155 - L= 0.8551405 - Gamma=58.9335518 (M=  61) - s=0.0100\n",
      " 156 - L= 0.8551406 - Gamma=58.9335799 (M=  61) - s=0.0100\n",
      " 157 - L= 0.8551407 - Gamma=58.9360469 (M=  61) - s=0.0100\n",
      " 158 - L= 0.8551408 - Gamma=58.9358893 (M=  61) - s=0.0100\n",
      " 159 - L= 0.8551409 - Gamma=58.9355848 (M=  61) - s=0.0100\n",
      " 160 - L= 0.8551410 - Gamma=58.9356752 (M=  61) - s=0.0100\n",
      " 161 - L= 0.8551410 - Gamma=58.9356748 (M=  61) - s=0.0100\n",
      " 162 - L= 0.8551411 - Gamma=58.9345654 (M=  61) - s=0.0100\n",
      " 163 - L= 0.8551411 - Gamma=58.9345659 (M=  61) - s=0.0100\n",
      " 164 - L= 0.8551412 - Gamma=58.9345770 (M=  61) - s=0.0100\n",
      " 165 - L= 0.8551412 - Gamma=58.9346793 (M=  61) - s=0.0100\n",
      " 166 - L= 0.8551413 - Gamma=58.9346787 (M=  61) - s=0.0100\n",
      " 167 - L= 0.8551413 - Gamma=58.9346538 (M=  61) - s=0.0100\n",
      " 168 - L= 0.8551413 - Gamma=58.9360202 (M=  61) - s=0.0100\n",
      " 169 - L= 0.8551414 - Gamma=58.9360228 (M=  61) - s=0.0100\n",
      " 170 - L= 0.8551414 - Gamma=58.9360601 (M=  61) - s=0.0100\n",
      " 171 - L= 0.8551414 - Gamma=58.9360633 (M=  61) - s=0.0100\n",
      " 172 - L= 0.8551414 - Gamma=58.9360632 (M=  61) - s=0.0100\n",
      " 173 - L= 0.8551415 - Gamma=58.9360489 (M=  61) - s=0.0100\n",
      " 174 - L= 0.8551415 - Gamma=58.9360487 (M=  61) - s=0.0100\n",
      " 175 - L= 0.8551415 - Gamma=58.9359782 (M=  61) - s=0.0100\n",
      " 176 - L= 0.8551415 - Gamma=58.9359823 (M=  61) - s=0.0100\n",
      " 177 - L= 0.8551415 - Gamma=58.9359761 (M=  61) - s=0.0100\n",
      " 178 - L= 0.8551415 - Gamma=58.9355353 (M=  61) - s=0.0100\n",
      " 179 - L= 0.8551415 - Gamma=58.9355358 (M=  61) - s=0.0100\n",
      " 180 - L= 0.8551415 - Gamma=58.9355358 (M=  61) - s=0.0100\n",
      " 181 - L= 0.8551416 - Gamma=58.9355356 (M=  61) - s=0.0100\n",
      " 182 - L= 0.8551416 - Gamma=58.9355348 (M=  61) - s=0.0100\n",
      " 183 - L= 0.8551416 - Gamma=58.9351000 (M=  61) - s=0.0100\n",
      " 184 - L= 0.8551416 - Gamma=58.9351002 (M=  61) - s=0.0100\n",
      " 185 - L= 0.8551416 - Gamma=58.9351047 (M=  61) - s=0.0100\n",
      " 186 - L= 0.8551416 - Gamma=58.9351085 (M=  61) - s=0.0100\n",
      " 187 - L= 0.8551416 - Gamma=58.9351625 (M=  61) - s=0.0100\n",
      " 188 - L= 0.8551416 - Gamma=58.9351669 (M=  61) - s=0.0100\n",
      " 189 - L= 0.8551416 - Gamma=58.9354786 (M=  61) - s=0.0100\n",
      " 190 - L= 0.8551416 - Gamma=58.9354175 (M=  61) - s=0.0100\n",
      " 191 - L= 0.8551416 - Gamma=58.9353882 (M=  61) - s=0.0100\n",
      " 192 - L= 0.8551416 - Gamma=58.9353882 (M=  61) - s=0.0100\n",
      "Stopping at iteration 192 - max_delta_ml=2.487817257375291e-07\n",
      "L=0.8551416126140374 - Gamma=58.935388172471214 (M=61) - s=0.01\n",
      "Initial alpha = [[ 0.06181572]]\n",
      "   1 - L=-1617.7110655 - Gamma= 1.9999633 (M=   2) - s=0.0100\n",
      "   2 - L=-1411.3944136 - Gamma= 2.9999265 (M=   3) - s=0.0100\n",
      "   3 - L=-1235.7134040 - Gamma= 3.9998819 (M=   4) - s=0.0100\n",
      "   4 - L=-1138.1912425 - Gamma= 4.9998038 (M=   5) - s=0.0100\n",
      "   5 - L=-1047.2658765 - Gamma= 5.9997194 (M=   6) - s=0.0100\n",
      "   6 - L=-976.6133778 - Gamma= 6.9996076 (M=   7) - s=0.0100\n",
      "   7 - L=-902.4798750 - Gamma= 7.9995048 (M=   8) - s=0.0100\n",
      "   8 - L=-832.1294976 - Gamma= 8.9993956 (M=   9) - s=0.0100\n",
      "   9 - L=-775.4564581 - Gamma= 9.9992594 (M=  10) - s=0.0100\n",
      "  10 - L=-729.5220407 - Gamma=10.9990913 (M=  11) - s=0.0100\n",
      "  11 - L=-682.6052397 - Gamma=11.9989277 (M=  12) - s=0.0100\n",
      "  12 - L=-636.0910193 - Gamma=12.9987632 (M=  13) - s=0.0100\n",
      "  13 - L=-591.1551897 - Gamma=13.9985881 (M=  14) - s=0.0100\n",
      "  14 - L=-541.2520657 - Gamma=14.9984266 (M=  15) - s=0.0100\n",
      "  15 - L=-496.9961271 - Gamma=15.9982415 (M=  16) - s=0.0100\n",
      "  16 - L=-448.7970717 - Gamma=16.9980818 (M=  17) - s=0.0100\n",
      "  17 - L=-413.8583992 - Gamma=17.9978605 (M=  18) - s=0.0100\n",
      "  18 - L=-377.9912908 - Gamma=18.9976456 (M=  19) - s=0.0100\n",
      "  19 - L=-338.6901068 - Gamma=19.9974449 (M=  20) - s=0.0100\n",
      "  20 - L=-305.0613920 - Gamma=20.9972060 (M=  21) - s=0.0100\n",
      "  21 - L=-274.0376865 - Gamma=21.9969491 (M=  22) - s=0.0100\n",
      "  22 - L=-245.3653262 - Gamma=22.9966833 (M=  23) - s=0.0100\n",
      "  23 - L=-218.2434336 - Gamma=23.9963953 (M=  24) - s=0.0100\n",
      "  24 - L=-196.7487097 - Gamma=24.9960359 (M=  25) - s=0.0100\n",
      "  25 - L=-177.1638434 - Gamma=25.9956320 (M=  26) - s=0.0100\n",
      "  26 - L=-158.8891037 - Gamma=26.9952133 (M=  27) - s=0.0100\n",
      "  27 - L=-143.2495444 - Gamma=27.9947111 (M=  28) - s=0.0100\n",
      "  28 - L=-124.1533393 - Gamma=28.9942933 (M=  29) - s=0.0100\n",
      "  29 - L=-100.6742961 - Gamma=29.9939422 (M=  30) - s=0.0100\n",
      "  30 - L=-83.2987659 - Gamma=30.9934715 (M=  31) - s=0.0100\n",
      "  31 - L=-65.8684300 - Gamma=31.9930084 (M=  32) - s=0.0100\n",
      "  32 - L=-58.1242477 - Gamma=32.9920310 (M=  33) - s=0.0100\n",
      "  33 - L=-51.1905902 - Gamma=33.9909330 (M=  34) - s=0.0100\n",
      "  34 - L=-45.4289661 - Gamma=34.9896064 (M=  35) - s=0.0100\n",
      "  35 - L=-39.9464678 - Gamma=35.9881682 (M=  36) - s=0.0100\n",
      "  36 - L=-35.4831646 - Gamma=36.9864682 (M=  37) - s=0.0100\n",
      "  37 - L=-30.5172140 - Gamma=37.9847819 (M=  38) - s=0.0100\n",
      "  38 - L=-25.9165607 - Gamma=38.9830884 (M=  39) - s=0.0100\n",
      "  39 - L=-21.7311644 - Gamma=39.9812853 (M=  40) - s=0.0100\n",
      "  40 - L=-17.9088926 - Gamma=40.9790236 (M=  41) - s=0.0100\n",
      "  41 - L=-14.4975655 - Gamma=41.9765366 (M=  42) - s=0.0100\n",
      "  42 - L=-12.1191496 - Gamma=42.9733385 (M=  43) - s=0.0100\n",
      "  43 - L=-8.9130798 - Gamma=43.9698928 (M=  44) - s=0.0100\n",
      "  44 - L=-6.3036148 - Gamma=44.9666613 (M=  45) - s=0.0100\n",
      "  45 - L=-5.1431827 - Gamma=45.9602326 (M=  46) - s=0.0100\n",
      "  46 - L=-3.8492921 - Gamma=46.9534436 (M=  47) - s=0.0100\n",
      "  47 - L=-2.5233436 - Gamma=47.9473892 (M=  48) - s=0.0100\n",
      "  48 - L=-1.3720402 - Gamma=48.9391674 (M=  49) - s=0.0100\n",
      "  49 - L=-0.5441863 - Gamma=49.9282424 (M=  50) - s=0.0100\n",
      "  50 - L= 0.0721492 - Gamma=50.9147666 (M=  51) - s=0.0100\n",
      "  51 - L= 0.2856584 - Gamma=51.8819756 (M=  52) - s=0.0100\n",
      "  52 - L= 0.4815620 - Gamma=52.8468524 (M=  53) - s=0.0100\n",
      "  53 - L= 0.6046288 - Gamma=53.7939742 (M=  54) - s=0.0100\n",
      "  54 - L= 0.7124459 - Gamma=54.7278676 (M=  55) - s=0.0100\n",
      "  55 - L= 0.7602986 - Gamma=55.6179828 (M=  56) - s=0.0100\n",
      "  56 - L= 0.8142521 - Gamma=56.5125089 (M=  57) - s=0.0100\n",
      "  57 - L= 0.8335281 - Gamma=57.3057463 (M=  58) - s=0.0100\n",
      "  58 - L= 0.8431228 - Gamma=57.3058272 (M=  58) - s=0.0100\n",
      "  59 - L= 0.8522356 - Gamma=57.3121125 (M=  58) - s=0.0100\n",
      "  60 - L= 0.8597023 - Gamma=57.9708402 (M=  59) - s=0.0100\n",
      "  61 - L= 0.8668717 - Gamma=57.9709490 (M=  59) - s=0.0100\n",
      "  62 - L= 0.8736454 - Gamma=57.9710147 (M=  59) - s=0.0100\n",
      "  63 - L= 0.8791253 - Gamma=57.9664266 (M=  59) - s=0.0100\n",
      "  64 - L= 0.8840717 - Gamma=57.9545212 (M=  59) - s=0.0100\n",
      "  65 - L= 0.8884252 - Gamma=57.9545321 (M=  59) - s=0.0100\n",
      "  66 - L= 0.8926661 - Gamma=57.9524658 (M=  59) - s=0.0100\n",
      "  67 - L= 0.8966421 - Gamma=57.9548455 (M=  59) - s=0.0100\n",
      "  68 - L= 0.9004646 - Gamma=57.9549219 (M=  59) - s=0.0100\n",
      "  69 - L= 0.9039584 - Gamma=57.9549595 (M=  59) - s=0.0100\n",
      "  70 - L= 0.9072898 - Gamma=57.9553094 (M=  59) - s=0.0100\n",
      "  71 - L= 0.9102658 - Gamma=57.9511116 (M=  59) - s=0.0100\n",
      "  72 - L= 0.9130247 - Gamma=57.9507508 (M=  59) - s=0.0100\n",
      "  73 - L= 0.9155972 - Gamma=57.9521534 (M=  59) - s=0.0100\n",
      "  74 - L= 0.9179598 - Gamma=57.9522624 (M=  59) - s=0.0100\n",
      "  75 - L= 0.9202134 - Gamma=57.9525013 (M=  59) - s=0.0100\n",
      "  76 - L= 0.9222379 - Gamma=57.9534327 (M=  59) - s=0.0100\n",
      "  77 - L= 0.9238360 - Gamma=57.9533610 (M=  59) - s=0.0100\n",
      "  78 - L= 0.9253783 - Gamma=57.9536152 (M=  59) - s=0.0100\n",
      "  79 - L= 0.9268954 - Gamma=57.9532633 (M=  59) - s=0.0100\n",
      "  80 - L= 0.9281745 - Gamma=57.9534556 (M=  59) - s=0.0100\n",
      "  81 - L= 0.9293878 - Gamma=57.9538096 (M=  59) - s=0.0100\n",
      "  82 - L= 0.9305784 - Gamma=57.9577724 (M=  59) - s=0.0100\n",
      "  83 - L= 0.9313786 - Gamma=57.9608052 (M=  59) - s=0.0100\n",
      "  84 - L= 0.9321046 - Gamma=57.9614610 (M=  59) - s=0.0100\n",
      "  85 - L= 0.9327904 - Gamma=57.9615169 (M=  59) - s=0.0100\n",
      "  86 - L= 0.9333686 - Gamma=57.9615637 (M=  59) - s=0.0100\n",
      "  87 - L= 0.9339189 - Gamma=57.9621332 (M=  59) - s=0.0100\n",
      "  88 - L= 0.9344105 - Gamma=57.9603036 (M=  59) - s=0.0100\n",
      "  89 - L= 0.9348326 - Gamma=57.9603898 (M=  59) - s=0.0100\n",
      "  90 - L= 0.9352088 - Gamma=57.9604391 (M=  59) - s=0.0100\n",
      "  91 - L= 0.9355690 - Gamma=57.9605095 (M=  59) - s=0.0100\n",
      "  92 - L= 0.9358931 - Gamma=57.9614050 (M=  59) - s=0.0100\n",
      "  93 - L= 0.9361868 - Gamma=57.9614719 (M=  59) - s=0.0100\n",
      "  94 - L= 0.9364540 - Gamma=57.9616036 (M=  59) - s=0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in log\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n",
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in absolute\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  95 - L= 0.9367128 - Gamma=58.0041920 (M=  59) - s=0.0100\n",
      "  96 - L= 0.9369591 - Gamma=58.0043808 (M=  59) - s=0.0100\n",
      "  97 - L= 0.9371847 - Gamma=58.0044314 (M=  59) - s=0.0100\n",
      "  98 - L= 0.9374005 - Gamma=58.0047748 (M=  59) - s=0.0100\n",
      "  99 - L= 0.9376045 - Gamma=58.0048319 (M=  59) - s=0.0100\n",
      " 100 - L= 0.9377621 - Gamma=58.0047557 (M=  59) - s=0.0100\n",
      " 101 - L= 0.9378988 - Gamma=58.0047033 (M=  59) - s=0.0100\n",
      " 102 - L= 0.9380334 - Gamma=58.1710932 (M=  60) - s=0.0100\n",
      " 103 - L= 0.9381818 - Gamma=58.1817188 (M=  60) - s=0.0100\n",
      " 104 - L= 0.9382856 - Gamma=58.1635410 (M=  60) - s=0.0100\n",
      " 105 - L= 0.9383764 - Gamma=58.1635649 (M=  60) - s=0.0100\n",
      " 106 - L= 0.9384510 - Gamma=58.1636061 (M=  60) - s=0.0100\n",
      " 107 - L= 0.9385188 - Gamma=58.1631173 (M=  60) - s=0.0100\n",
      " 108 - L= 0.9385498 - Gamma=58.1637371 (M=  60) - s=0.0100\n",
      " 109 - L= 0.9385663 - Gamma=58.1636596 (M=  60) - s=0.0100\n",
      " 110 - L= 0.9385774 - Gamma=58.1667811 (M=  60) - s=0.0100\n",
      " 111 - L= 0.9385873 - Gamma=58.1650158 (M=  60) - s=0.0100\n",
      " 112 - L= 0.9385952 - Gamma=58.1650284 (M=  60) - s=0.0100\n",
      " 113 - L= 0.9386015 - Gamma=58.1647606 (M=  60) - s=0.0100\n",
      " 114 - L= 0.9386077 - Gamma=58.1631426 (M=  60) - s=0.0100\n",
      " 115 - L= 0.9386125 - Gamma=58.1625097 (M=  60) - s=0.0100\n",
      " 116 - L= 0.9386169 - Gamma=58.1674981 (M=  60) - s=0.0100\n",
      " 117 - L= 0.9386188 - Gamma=58.1674813 (M=  60) - s=0.0100\n",
      " 118 - L= 0.9386202 - Gamma=58.1676061 (M=  60) - s=0.0100\n",
      " 119 - L= 0.9386209 - Gamma=58.1792240 (M=  60) - s=0.0100\n",
      " 120 - L= 0.9386217 - Gamma=58.1799169 (M=  60) - s=0.0100\n",
      " 121 - L= 0.9386221 - Gamma=58.1799775 (M=  60) - s=0.0100\n",
      " 122 - L= 0.9386223 - Gamma=58.1799547 (M=  60) - s=0.0100\n",
      " 123 - L= 0.9386226 - Gamma=58.1799754 (M=  60) - s=0.0100\n",
      " 124 - L= 0.9386228 - Gamma=58.1799304 (M=  60) - s=0.0100\n",
      " 125 - L= 0.9386229 - Gamma=58.1798912 (M=  60) - s=0.0100\n",
      " 126 - L= 0.9386231 - Gamma=58.1798731 (M=  60) - s=0.0100\n",
      " 127 - L= 0.9386232 - Gamma=58.1780232 (M=  60) - s=0.0100\n",
      " 128 - L= 0.9386233 - Gamma=58.1780298 (M=  60) - s=0.0100\n",
      " 129 - L= 0.9386234 - Gamma=58.1780973 (M=  60) - s=0.0100\n",
      " 130 - L= 0.9386235 - Gamma=58.1780971 (M=  60) - s=0.0100\n",
      " 131 - L= 0.9386235 - Gamma=58.1776874 (M=  60) - s=0.0100\n",
      " 132 - L= 0.9386235 - Gamma=58.1776882 (M=  60) - s=0.0100\n",
      " 133 - L= 0.9386235 - Gamma=58.1777759 (M=  60) - s=0.0100\n",
      " 134 - L= 0.9386236 - Gamma=58.1777771 (M=  60) - s=0.0100\n",
      " 135 - L= 0.9386236 - Gamma=58.1780801 (M=  60) - s=0.0100\n",
      " 136 - L= 0.9386236 - Gamma=58.1780826 (M=  60) - s=0.0100\n",
      " 137 - L= 0.9386236 - Gamma=58.1780821 (M=  60) - s=0.0100\n",
      " 138 - L= 0.9386236 - Gamma=58.1794743 (M=  60) - s=0.0100\n",
      " 139 - L= 0.9386236 - Gamma=58.1794743 (M=  60) - s=0.0100\n",
      " 140 - L= 0.9386236 - Gamma=58.1794746 (M=  60) - s=0.0100\n",
      " 141 - L= 0.9386236 - Gamma=58.1794736 (M=  60) - s=0.0100\n",
      " 142 - L= 0.9386237 - Gamma=58.1794721 (M=  60) - s=0.0100\n",
      " 143 - L= 0.9386237 - Gamma=58.1794718 (M=  60) - s=0.0100\n",
      " 144 - L= 0.9386237 - Gamma=58.1795452 (M=  60) - s=0.0100\n",
      " 145 - L= 0.9386237 - Gamma=58.1795472 (M=  60) - s=0.0100\n",
      " 146 - L= 0.9386237 - Gamma=58.1795473 (M=  60) - s=0.0100\n",
      " 147 - L= 0.9386237 - Gamma=58.1795475 (M=  60) - s=0.0100\n",
      " 148 - L= 0.9386237 - Gamma=58.1795542 (M=  60) - s=0.0100\n",
      " 149 - L= 0.9386237 - Gamma=58.1795542 (M=  60) - s=0.0100\n",
      "Stopping at iteration 149 - max_delta_ml=2.4399998213900896e-07\n",
      "L=0.9386236844491666 - Gamma=58.179554189774365 (M=60) - s=0.01\n",
      "Initial alpha = [[ 0.07201744]]\n",
      "   1 - L=-1766.1559217 - Gamma= 1.9999700 (M=   2) - s=0.0100\n",
      "   2 - L=-1492.3513464 - Gamma= 2.9999415 (M=   3) - s=0.0100\n",
      "   3 - L=-1342.2002034 - Gamma= 3.9998884 (M=   4) - s=0.0100\n",
      "   4 - L=-1259.7772875 - Gamma= 4.9997976 (M=   5) - s=0.0100\n",
      "   5 - L=-1194.5772543 - Gamma= 5.9996818 (M=   6) - s=0.0100\n",
      "   6 - L=-1123.3477973 - Gamma= 6.9995761 (M=   7) - s=0.0100\n",
      "   7 - L=-1062.3424293 - Gamma= 7.9994531 (M=   8) - s=0.0100\n",
      "   8 - L=-1006.3043736 - Gamma= 8.9993170 (M=   9) - s=0.0100\n",
      "   9 - L=-944.0007714 - Gamma= 9.9991927 (M=  10) - s=0.0100\n",
      "  10 - L=-878.6744125 - Gamma=10.9990729 (M=  11) - s=0.0100\n",
      "  11 - L=-813.0421549 - Gamma=11.9989512 (M=  12) - s=0.0100\n",
      "  12 - L=-759.0148963 - Gamma=12.9988078 (M=  13) - s=0.0100\n",
      "  13 - L=-717.1949222 - Gamma=13.9986248 (M=  14) - s=0.0100\n",
      "  14 - L=-674.4224239 - Gamma=14.9984437 (M=  15) - s=0.0100\n",
      "  15 - L=-621.0800004 - Gamma=15.9982873 (M=  16) - s=0.0100\n",
      "  16 - L=-573.0592473 - Gamma=16.9981124 (M=  17) - s=0.0100\n",
      "  17 - L=-534.8573151 - Gamma=17.9979126 (M=  18) - s=0.0100\n",
      "  18 - L=-500.7023514 - Gamma=18.9976906 (M=  19) - s=0.0100\n",
      "  19 - L=-461.4211925 - Gamma=19.9974940 (M=  20) - s=0.0100\n",
      "  20 - L=-423.1987118 - Gamma=20.9972914 (M=  21) - s=0.0100\n",
      "  21 - L=-381.7371008 - Gamma=21.9971022 (M=  22) - s=0.0100\n",
      "  22 - L=-346.0518922 - Gamma=22.9968654 (M=  23) - s=0.0100\n",
      "  23 - L=-312.5569878 - Gamma=23.9966366 (M=  24) - s=0.0100\n",
      "  24 - L=-282.0716660 - Gamma=24.9963839 (M=  25) - s=0.0100\n",
      "  25 - L=-252.7184545 - Gamma=25.9961130 (M=  26) - s=0.0100\n",
      "  26 - L=-231.9884494 - Gamma=26.9957311 (M=  27) - s=0.0100\n",
      "  27 - L=-209.3667643 - Gamma=27.9953914 (M=  28) - s=0.0100\n",
      "  28 - L=-192.7725358 - Gamma=28.9949293 (M=  29) - s=0.0100\n",
      "  29 - L=-179.2476012 - Gamma=29.9943713 (M=  30) - s=0.0100\n",
      "  30 - L=-166.7669739 - Gamma=30.9937463 (M=  31) - s=0.0100\n",
      "  31 - L=-152.6898703 - Gamma=31.9931562 (M=  32) - s=0.0100\n",
      "  32 - L=-137.4844125 - Gamma=32.9925671 (M=  33) - s=0.0100\n",
      "  33 - L=-118.2618658 - Gamma=33.9920074 (M=  34) - s=0.0100\n",
      "  34 - L=-104.8497289 - Gamma=34.9914196 (M=  35) - s=0.0100\n",
      "  35 - L=-92.5809303 - Gamma=35.9908037 (M=  36) - s=0.0100\n",
      "  36 - L=-81.6938646 - Gamma=36.9900721 (M=  37) - s=0.0100\n",
      "  37 - L=-68.8905025 - Gamma=37.9894501 (M=  38) - s=0.0100\n",
      "  38 - L=-59.5718390 - Gamma=38.9886165 (M=  39) - s=0.0100\n",
      "  39 - L=-50.3275657 - Gamma=39.9877718 (M=  40) - s=0.0100\n",
      "  40 - L=-42.4836001 - Gamma=40.9868030 (M=  41) - s=0.0100\n",
      "  41 - L=-42.4183243 - Gamma=39.9871014 (M=  40) - s=0.0100\n",
      "  42 - L=-36.0476366 - Gamma=40.9858881 (M=  41) - s=0.0100\n",
      "  43 - L=-28.8180591 - Gamma=41.9846833 (M=  42) - s=0.0100\n",
      "  44 - L=-23.9108170 - Gamma=42.9831322 (M=  43) - s=0.0100\n",
      "  45 - L=-18.4954056 - Gamma=43.9816489 (M=  44) - s=0.0100\n",
      "  46 - L=-13.1893758 - Gamma=44.9799618 (M=  45) - s=0.0100\n",
      "  47 - L=-10.3165510 - Gamma=45.9769386 (M=  46) - s=0.0100\n",
      "  48 - L=-8.5180295 - Gamma=46.9727303 (M=  47) - s=0.0100\n",
      "  49 - L=-6.2883850 - Gamma=47.9689063 (M=  48) - s=0.0100\n",
      "  50 - L=-3.7655922 - Gamma=48.9655226 (M=  49) - s=0.0100\n",
      "  51 - L=-3.0016659 - Gamma=49.9560351 (M=  50) - s=0.0100\n",
      "  52 - L=-1.9551695 - Gamma=50.9471045 (M=  51) - s=0.0100\n",
      "  53 - L=-1.4087509 - Gamma=51.9334332 (M=  52) - s=0.0100\n",
      "  54 - L=-0.7233790 - Gamma=52.9219156 (M=  53) - s=0.0100\n",
      "  55 - L=-0.2998906 - Gamma=53.9052515 (M=  54) - s=0.0100\n",
      "  56 - L= 0.0374627 - Gamma=54.8840736 (M=  55) - s=0.0100\n",
      "  57 - L= 0.3015911 - Gamma=55.8561400 (M=  56) - s=0.0100\n",
      "  58 - L= 0.4351269 - Gamma=56.8083006 (M=  57) - s=0.0100\n",
      "  59 - L= 0.5141313 - Gamma=57.7316775 (M=  58) - s=0.0100\n",
      "  60 - L= 0.5519470 - Gamma=58.6055638 (M=  59) - s=0.0100\n",
      "  61 - L= 0.5721196 - Gamma=58.6057589 (M=  59) - s=0.0100\n",
      "  62 - L= 0.5905848 - Gamma=58.6057862 (M=  59) - s=0.0100\n",
      "  63 - L= 0.6078050 - Gamma=58.6059168 (M=  59) - s=0.0100\n",
      "  64 - L= 0.6179942 - Gamma=58.6061198 (M=  59) - s=0.0100\n",
      "  65 - L= 0.6262957 - Gamma=58.6063531 (M=  59) - s=0.0100\n",
      "  66 - L= 0.6341605 - Gamma=58.6065333 (M=  59) - s=0.0100\n",
      "  67 - L= 0.6419701 - Gamma=58.6070198 (M=  59) - s=0.0100\n",
      "  68 - L= 0.6480672 - Gamma=58.6077205 (M=  59) - s=0.0100\n",
      "  69 - L= 0.6539200 - Gamma=58.6081647 (M=  59) - s=0.0100\n",
      "  70 - L= 0.6592282 - Gamma=58.6082520 (M=  59) - s=0.0100\n",
      "  71 - L= 0.6644604 - Gamma=58.6084137 (M=  59) - s=0.0100\n",
      "  72 - L= 0.6692093 - Gamma=58.6106110 (M=  59) - s=0.0100\n",
      "  73 - L= 0.6738065 - Gamma=58.6107229 (M=  59) - s=0.0100\n",
      "  74 - L= 0.6782758 - Gamma=59.2025548 (M=  60) - s=0.0100\n",
      "  75 - L= 0.6820586 - Gamma=59.2054038 (M=  60) - s=0.0100\n",
      "  76 - L= 0.6854292 - Gamma=59.2056029 (M=  60) - s=0.0100\n",
      "  77 - L= 0.6885178 - Gamma=59.2057647 (M=  60) - s=0.0100\n",
      "  78 - L= 0.6914485 - Gamma=59.2066999 (M=  60) - s=0.0100\n",
      "  79 - L= 0.6941756 - Gamma=59.2055189 (M=  60) - s=0.0100\n",
      "  80 - L= 0.6968596 - Gamma=59.2056442 (M=  60) - s=0.0100\n",
      "  81 - L= 0.6994285 - Gamma=59.2057238 (M=  60) - s=0.0100\n",
      "  82 - L= 0.7019405 - Gamma=59.2057489 (M=  60) - s=0.0100\n",
      "  83 - L= 0.7044365 - Gamma=59.2057724 (M=  60) - s=0.0100\n",
      "  84 - L= 0.7069200 - Gamma=59.2060953 (M=  60) - s=0.0100\n",
      "  85 - L= 0.7091640 - Gamma=59.2062269 (M=  60) - s=0.0100\n",
      "  86 - L= 0.7112294 - Gamma=59.2085793 (M=  60) - s=0.0100\n",
      "  87 - L= 0.7127919 - Gamma=59.2082514 (M=  60) - s=0.0100\n",
      "  88 - L= 0.7142934 - Gamma=59.2083121 (M=  60) - s=0.0100\n",
      "  89 - L= 0.7157232 - Gamma=59.2084957 (M=  60) - s=0.0100\n",
      "  90 - L= 0.7170766 - Gamma=59.2005833 (M=  60) - s=0.0100\n",
      "  91 - L= 0.7184195 - Gamma=59.2011842 (M=  60) - s=0.0100\n",
      "  92 - L= 0.7196284 - Gamma=59.2009007 (M=  60) - s=0.0100\n",
      "  93 - L= 0.7206344 - Gamma=59.2115135 (M=  60) - s=0.0100\n",
      "  94 - L= 0.7215924 - Gamma=59.2154588 (M=  60) - s=0.0100\n",
      "  95 - L= 0.7225195 - Gamma=59.2157023 (M=  60) - s=0.0100\n",
      "  96 - L= 0.7233619 - Gamma=59.2162073 (M=  60) - s=0.0100\n",
      "  97 - L= 0.7241226 - Gamma=59.2213214 (M=  60) - s=0.0100\n",
      "  98 - L= 0.7248302 - Gamma=59.2215380 (M=  60) - s=0.0100\n",
      "  99 - L= 0.7253692 - Gamma=59.2212878 (M=  60) - s=0.0100\n",
      " 100 - L= 0.7257898 - Gamma=59.2210005 (M=  60) - s=0.0100\n",
      " 101 - L= 0.7261434 - Gamma=59.2210638 (M=  60) - s=0.0100\n",
      " 102 - L= 0.7264770 - Gamma=59.2206967 (M=  60) - s=0.0100\n",
      " 103 - L= 0.7267935 - Gamma=59.2199559 (M=  60) - s=0.0100\n",
      " 104 - L= 0.7270746 - Gamma=59.1958064 (M=  60) - s=0.0100\n",
      " 105 - L= 0.7273459 - Gamma=59.1965665 (M=  60) - s=0.0100\n",
      " 106 - L= 0.7274709 - Gamma=59.1969361 (M=  60) - s=0.0100\n",
      " 107 - L= 0.7275569 - Gamma=59.1969828 (M=  60) - s=0.0100\n",
      " 108 - L= 0.7276313 - Gamma=59.2033156 (M=  60) - s=0.0100\n",
      " 109 - L= 0.7277031 - Gamma=59.2046550 (M=  60) - s=0.0100\n",
      " 110 - L= 0.7277716 - Gamma=59.1470897 (M=  60) - s=0.0100\n",
      " 111 - L= 0.7278331 - Gamma=59.1469621 (M=  60) - s=0.0100\n",
      " 112 - L= 0.7278776 - Gamma=59.1469808 (M=  60) - s=0.0100\n",
      " 113 - L= 0.7279122 - Gamma=59.1488820 (M=  60) - s=0.0100\n",
      " 114 - L= 0.7279420 - Gamma=59.1489028 (M=  60) - s=0.0100\n",
      " 115 - L= 0.7279485 - Gamma=59.1489490 (M=  60) - s=0.0100\n",
      " 116 - L= 0.7279545 - Gamma=59.1489621 (M=  60) - s=0.0100\n",
      " 117 - L= 0.7279595 - Gamma=59.1489372 (M=  60) - s=0.0100\n",
      " 118 - L= 0.7279623 - Gamma=59.1522203 (M=  60) - s=0.0100\n",
      " 119 - L= 0.7279646 - Gamma=59.1517776 (M=  60) - s=0.0100\n",
      " 120 - L= 0.7279667 - Gamma=59.1517541 (M=  60) - s=0.0100\n",
      " 121 - L= 0.7279686 - Gamma=59.1538938 (M=  60) - s=0.0100\n",
      " 122 - L= 0.7279700 - Gamma=59.1539209 (M=  60) - s=0.0100\n",
      " 123 - L= 0.7279706 - Gamma=59.1544628 (M=  60) - s=0.0100\n",
      " 124 - L= 0.7279710 - Gamma=59.1544845 (M=  60) - s=0.0100\n",
      " 125 - L= 0.7279713 - Gamma=59.1544694 (M=  60) - s=0.0100\n",
      " 126 - L= 0.7279715 - Gamma=59.1545454 (M=  60) - s=0.0100\n",
      " 127 - L= 0.7279717 - Gamma=59.1546621 (M=  60) - s=0.0100\n",
      " 128 - L= 0.7279719 - Gamma=59.1545540 (M=  60) - s=0.0100\n",
      " 129 - L= 0.7279720 - Gamma=59.1545546 (M=  60) - s=0.0100\n",
      " 130 - L= 0.7279721 - Gamma=59.1521347 (M=  60) - s=0.0100\n",
      " 131 - L= 0.7279722 - Gamma=59.1521702 (M=  60) - s=0.0100\n",
      " 132 - L= 0.7279723 - Gamma=59.1521783 (M=  60) - s=0.0100\n",
      " 133 - L= 0.7279723 - Gamma=59.1521728 (M=  60) - s=0.0100\n",
      " 134 - L= 0.7279724 - Gamma=59.1521757 (M=  60) - s=0.0100\n",
      " 135 - L= 0.7279724 - Gamma=59.1521849 (M=  60) - s=0.0100\n",
      " 136 - L= 0.7279725 - Gamma=59.1522169 (M=  60) - s=0.0100\n",
      " 137 - L= 0.7279725 - Gamma=59.1522172 (M=  60) - s=0.0100\n",
      " 138 - L= 0.7279726 - Gamma=59.1522159 (M=  60) - s=0.0100\n",
      " 139 - L= 0.7279726 - Gamma=59.1522140 (M=  60) - s=0.0100\n",
      " 140 - L= 0.7279726 - Gamma=59.1522147 (M=  60) - s=0.0100\n",
      " 141 - L= 0.7279726 - Gamma=59.1522153 (M=  60) - s=0.0100\n",
      " 142 - L= 0.7279727 - Gamma=59.1522152 (M=  60) - s=0.0100\n",
      " 143 - L= 0.7279727 - Gamma=59.1522208 (M=  60) - s=0.0100\n",
      " 144 - L= 0.7279727 - Gamma=59.1522207 (M=  60) - s=0.0100\n",
      " 145 - L= 0.7279727 - Gamma=59.1522208 (M=  60) - s=0.0100\n",
      " 146 - L= 0.7279727 - Gamma=59.1522209 (M=  60) - s=0.0100\n",
      " 147 - L= 0.7279727 - Gamma=59.1522195 (M=  60) - s=0.0100\n",
      " 148 - L= 0.7279728 - Gamma=59.1522197 (M=  60) - s=0.0100\n",
      " 149 - L= 0.7279728 - Gamma=59.1522196 (M=  60) - s=0.0100\n",
      " 150 - L= 0.7279728 - Gamma=59.1523614 (M=  60) - s=0.0100\n",
      " 151 - L= 0.7279728 - Gamma=59.1523620 (M=  60) - s=0.0100\n",
      " 152 - L= 0.7279728 - Gamma=59.1523659 (M=  60) - s=0.0100\n",
      " 153 - L= 0.7279728 - Gamma=59.1523668 (M=  60) - s=0.0100\n",
      " 154 - L= 0.7279728 - Gamma=59.1523686 (M=  60) - s=0.0100\n",
      " 155 - L= 0.7279728 - Gamma=59.1523688 (M=  60) - s=0.0100\n",
      " 156 - L= 0.7279728 - Gamma=59.1523688 (M=  60) - s=0.0100\n",
      " 157 - L= 0.7279728 - Gamma=59.1523687 (M=  60) - s=0.0100\n",
      " 158 - L= 0.7279728 - Gamma=59.1523684 (M=  60) - s=0.0100\n",
      " 159 - L= 0.7279728 - Gamma=59.1523684 (M=  60) - s=0.0100\n",
      "Stopping at iteration 159 - max_delta_ml=2.383526288708259e-07\n",
      "L=0.7279728118222354 - Gamma=59.15236838439787 (M=60) - s=0.01\n",
      "Initial alpha = [[ 0.06437648]]\n",
      "   1 - L=-1703.0930262 - Gamma= 1.9999657 (M=   2) - s=0.0100\n",
      "   2 - L=-1548.1546293 - Gamma= 2.9999163 (M=   3) - s=0.0100\n",
      "   3 - L=-1411.5582372 - Gamma= 3.9998615 (M=   4) - s=0.0100\n",
      "   4 - L=-1307.0082607 - Gamma= 4.9997871 (M=   5) - s=0.0100\n",
      "   5 - L=-1240.9524168 - Gamma= 5.9996729 (M=   6) - s=0.0100\n",
      "   6 - L=-1181.2254033 - Gamma= 6.9995472 (M=   7) - s=0.0100\n",
      "   7 - L=-1118.3471059 - Gamma= 7.9994277 (M=   8) - s=0.0100\n",
      "   8 - L=-1058.0569026 - Gamma= 8.9993002 (M=   9) - s=0.0100\n",
      "   9 - L=-1002.2285904 - Gamma= 9.9991638 (M=  10) - s=0.0100\n",
      "  10 - L=-941.3289388 - Gamma=10.9990373 (M=  11) - s=0.0100\n",
      "  11 - L=-890.3642428 - Gamma=11.9988898 (M=  12) - s=0.0100\n",
      "  12 - L=-842.5519369 - Gamma=12.9987271 (M=  13) - s=0.0100\n",
      "  13 - L=-779.8772802 - Gamma=13.9986027 (M=  14) - s=0.0100\n",
      "  14 - L=-726.9009661 - Gamma=14.9984505 (M=  15) - s=0.0100\n",
      "  15 - L=-671.8740315 - Gamma=15.9983102 (M=  16) - s=0.0100\n",
      "  16 - L=-623.8280975 - Gamma=16.9981458 (M=  17) - s=0.0100\n",
      "  17 - L=-577.1771303 - Gamma=17.9979834 (M=  18) - s=0.0100\n",
      "  18 - L=-529.4945697 - Gamma=18.9978221 (M=  19) - s=0.0100\n",
      "  19 - L=-485.8560537 - Gamma=19.9976486 (M=  20) - s=0.0100\n",
      "  20 - L=-443.3098880 - Gamma=20.9974572 (M=  21) - s=0.0100\n",
      "  21 - L=-406.7916010 - Gamma=21.9972481 (M=  22) - s=0.0100\n",
      "  22 - L=-376.9188759 - Gamma=22.9969873 (M=  23) - s=0.0100\n",
      "  23 - L=-345.1683787 - Gamma=23.9967392 (M=  24) - s=0.0100\n",
      "  24 - L=-319.6474053 - Gamma=24.9964211 (M=  25) - s=0.0100\n",
      "  25 - L=-293.4453621 - Gamma=25.9960920 (M=  26) - s=0.0100\n",
      "  26 - L=-265.9736005 - Gamma=26.9958083 (M=  27) - s=0.0100\n",
      "  27 - L=-245.2372856 - Gamma=27.9954124 (M=  28) - s=0.0100\n",
      "  28 - L=-224.6700106 - Gamma=28.9950266 (M=  29) - s=0.0100\n",
      "  29 - L=-203.5098072 - Gamma=29.9946402 (M=  30) - s=0.0100\n",
      "  30 - L=-186.6349482 - Gamma=30.9941881 (M=  31) - s=0.0100\n",
      "  31 - L=-168.6204173 - Gamma=31.9937662 (M=  32) - s=0.0100\n",
      "  32 - L=-153.0601518 - Gamma=32.9932844 (M=  33) - s=0.0100\n",
      "  33 - L=-137.1531702 - Gamma=33.9927811 (M=  34) - s=0.0100\n",
      "  34 - L=-118.2717677 - Gamma=34.9923064 (M=  35) - s=0.0100\n",
      "  35 - L=-100.4900453 - Gamma=35.9918069 (M=  36) - s=0.0100\n",
      "  36 - L=-100.4210507 - Gamma=34.9920334 (M=  35) - s=0.0100\n",
      "  37 - L=-84.7057423 - Gamma=35.9914919 (M=  36) - s=0.0100\n",
      "  38 - L=-71.3114973 - Gamma=36.9909120 (M=  37) - s=0.0100\n",
      "  39 - L=-60.6531816 - Gamma=37.9901426 (M=  38) - s=0.0100\n",
      "  40 - L=-52.1860810 - Gamma=38.9891815 (M=  39) - s=0.0100\n",
      "  41 - L=-44.9325010 - Gamma=39.9880914 (M=  40) - s=0.0100\n",
      "  42 - L=-37.7731233 - Gamma=40.9869926 (M=  41) - s=0.0100\n",
      "  43 - L=-32.7140682 - Gamma=41.9854774 (M=  42) - s=0.0100\n",
      "  44 - L=-26.9141611 - Gamma=42.9838269 (M=  43) - s=0.0100\n",
      "  45 - L=-21.5062916 - Gamma=43.9823726 (M=  44) - s=0.0100\n",
      "  46 - L=-17.1629399 - Gamma=44.9805954 (M=  45) - s=0.0100\n",
      "  47 - L=-13.0025634 - Gamma=45.9783928 (M=  46) - s=0.0100\n",
      "  48 - L=-7.7496188 - Gamma=46.9766282 (M=  47) - s=0.0100\n",
      "  49 - L=-5.7756102 - Gamma=47.9725551 (M=  48) - s=0.0100\n",
      "  50 - L=-4.0893335 - Gamma=48.9676290 (M=  49) - s=0.0100\n",
      "  51 - L=-3.0935787 - Gamma=49.9597911 (M=  50) - s=0.0100\n",
      "  52 - L=-2.2490489 - Gamma=50.9505345 (M=  51) - s=0.0100\n",
      "  53 - L=-1.2565792 - Gamma=51.9429475 (M=  52) - s=0.0100\n",
      "  54 - L=-0.7422937 - Gamma=52.9289540 (M=  53) - s=0.0100\n",
      "  55 - L=-0.3533912 - Gamma=53.9106872 (M=  54) - s=0.0100\n",
      "  56 - L= 0.0376579 - Gamma=54.8913329 (M=  55) - s=0.0100\n",
      "  57 - L= 0.2644248 - Gamma=55.8589246 (M=  56) - s=0.0100\n",
      "  58 - L= 0.3614584 - Gamma=56.7977764 (M=  57) - s=0.0100\n",
      "  59 - L= 0.4206481 - Gamma=57.7042488 (M=  58) - s=0.0100\n",
      "  60 - L= 0.5334358 - Gamma=58.6369463 (M=  59) - s=0.0100\n",
      "  61 - L= 0.5832211 - Gamma=59.5307386 (M=  60) - s=0.0100\n",
      "  62 - L= 0.5922383 - Gamma=59.5313737 (M=  60) - s=0.0100\n",
      "  63 - L= 0.6010705 - Gamma=59.5313970 (M=  60) - s=0.0100\n",
      "  64 - L= 0.6098868 - Gamma=59.5314835 (M=  60) - s=0.0100\n",
      "  65 - L= 0.6157967 - Gamma=59.5315949 (M=  60) - s=0.0100\n",
      "  66 - L= 0.6212933 - Gamma=59.5319974 (M=  60) - s=0.0100\n",
      "  67 - L= 0.6267472 - Gamma=59.5321182 (M=  60) - s=0.0100\n",
      "  68 - L= 0.6321715 - Gamma=59.5322969 (M=  60) - s=0.0100\n",
      "  69 - L= 0.6375831 - Gamma=59.5324685 (M=  60) - s=0.0100\n",
      "  70 - L= 0.6429616 - Gamma=59.5336037 (M=  60) - s=0.0100\n",
      "  71 - L= 0.6480638 - Gamma=59.5337240 (M=  60) - s=0.0100\n",
      "  72 - L= 0.6524798 - Gamma=59.5344625 (M=  60) - s=0.0100\n",
      "  73 - L= 0.6567322 - Gamma=59.5346030 (M=  60) - s=0.0100\n",
      "  74 - L= 0.6608827 - Gamma=59.5347311 (M=  60) - s=0.0100\n",
      "  75 - L= 0.6650055 - Gamma=59.5336212 (M=  60) - s=0.0100\n",
      "  76 - L= 0.6688489 - Gamma=59.5337402 (M=  60) - s=0.0100\n",
      "  77 - L= 0.6725480 - Gamma=59.5351883 (M=  60) - s=0.0100\n",
      "  78 - L= 0.6760166 - Gamma=59.5900707 (M=  60) - s=0.0100\n",
      "  79 - L= 0.6794599 - Gamma=59.5888871 (M=  60) - s=0.0100\n",
      "  80 - L= 0.6826900 - Gamma=60.0750399 (M=  61) - s=0.0100\n",
      "  81 - L= 0.6856057 - Gamma=60.0753500 (M=  61) - s=0.0100\n",
      "  82 - L= 0.6884340 - Gamma=60.0587781 (M=  61) - s=0.0100\n",
      "  83 - L= 0.6909033 - Gamma=60.0592086 (M=  61) - s=0.0100\n",
      "  84 - L= 0.6929348 - Gamma=60.0593134 (M=  61) - s=0.0100\n",
      "  85 - L= 0.6947377 - Gamma=60.0456625 (M=  61) - s=0.0100\n",
      "  86 - L= 0.6963885 - Gamma=60.0459001 (M=  61) - s=0.0100\n",
      "  87 - L= 0.6980306 - Gamma=60.0464175 (M=  61) - s=0.0100\n",
      "  88 - L= 0.6995547 - Gamma=60.0466485 (M=  61) - s=0.0100\n",
      "  89 - L= 0.7010510 - Gamma=60.0475748 (M=  61) - s=0.0100\n",
      "  90 - L= 0.7024940 - Gamma=60.0476999 (M=  61) - s=0.0100\n",
      "  91 - L= 0.7038956 - Gamma=60.0477711 (M=  61) - s=0.0100\n",
      "  92 - L= 0.7052386 - Gamma=60.0479882 (M=  61) - s=0.0100\n",
      "  93 - L= 0.7064894 - Gamma=60.0481205 (M=  61) - s=0.0100\n",
      "  94 - L= 0.7077390 - Gamma=59.9358742 (M=  61) - s=0.0100\n",
      "  95 - L= 0.7088887 - Gamma=59.9358953 (M=  61) - s=0.0100\n",
      "  96 - L= 0.7099682 - Gamma=59.9354007 (M=  61) - s=0.0100\n",
      "  97 - L= 0.7109992 - Gamma=59.9356768 (M=  61) - s=0.0100\n",
      "  98 - L= 0.7120215 - Gamma=59.9363805 (M=  61) - s=0.0100\n",
      "  99 - L= 0.7128710 - Gamma=59.9364203 (M=  61) - s=0.0100\n",
      " 100 - L= 0.7137190 - Gamma=59.9366086 (M=  61) - s=0.0100\n",
      " 101 - L= 0.7144308 - Gamma=59.9368027 (M=  61) - s=0.0100\n",
      " 102 - L= 0.7150487 - Gamma=59.9368661 (M=  61) - s=0.0100\n",
      " 103 - L= 0.7155519 - Gamma=59.9386592 (M=  61) - s=0.0100\n",
      " 104 - L= 0.7159113 - Gamma=59.9387478 (M=  61) - s=0.0100\n",
      " 105 - L= 0.7162496 - Gamma=59.9383459 (M=  61) - s=0.0100\n",
      " 106 - L= 0.7165653 - Gamma=59.9382021 (M=  61) - s=0.0100\n",
      " 107 - L= 0.7168537 - Gamma=60.0181449 (M=  61) - s=0.0100\n",
      " 108 - L= 0.7170821 - Gamma=60.0155475 (M=  61) - s=0.0100\n",
      " 109 - L= 0.7172906 - Gamma=60.0156069 (M=  61) - s=0.0100\n",
      " 110 - L= 0.7174968 - Gamma=60.0150704 (M=  61) - s=0.0100\n",
      " 111 - L= 0.7176631 - Gamma=60.0176621 (M=  61) - s=0.0100\n",
      " 112 - L= 0.7178256 - Gamma=60.0101506 (M=  61) - s=0.0100\n",
      " 113 - L= 0.7179785 - Gamma=60.0101037 (M=  61) - s=0.0100\n",
      " 114 - L= 0.7181014 - Gamma=60.0100304 (M=  61) - s=0.0100\n",
      " 115 - L= 0.7181879 - Gamma=59.9664713 (M=  61) - s=0.0100\n",
      " 116 - L= 0.7182460 - Gamma=59.9714193 (M=  61) - s=0.0100\n",
      " 117 - L= 0.7183019 - Gamma=59.9716398 (M=  61) - s=0.0100\n",
      " 118 - L= 0.7183348 - Gamma=59.9937872 (M=  61) - s=0.0100\n",
      " 119 - L= 0.7183461 - Gamma=59.9923356 (M=  61) - s=0.0100\n",
      " 120 - L= 0.7183567 - Gamma=59.9912922 (M=  61) - s=0.0100\n",
      " 121 - L= 0.7183661 - Gamma=59.9751976 (M=  61) - s=0.0100\n",
      " 122 - L= 0.7183748 - Gamma=59.9751775 (M=  61) - s=0.0100\n",
      " 123 - L= 0.7183828 - Gamma=59.9751965 (M=  61) - s=0.0100\n",
      " 124 - L= 0.7183879 - Gamma=59.9751367 (M=  61) - s=0.0100\n",
      " 125 - L= 0.7183925 - Gamma=59.9751841 (M=  61) - s=0.0100\n",
      " 126 - L= 0.7183962 - Gamma=59.9745369 (M=  61) - s=0.0100\n",
      " 127 - L= 0.7183998 - Gamma=59.9726264 (M=  61) - s=0.0100\n",
      " 128 - L= 0.7184031 - Gamma=59.9741882 (M=  61) - s=0.0100\n",
      " 129 - L= 0.7184057 - Gamma=59.9800227 (M=  61) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 130 - L= 0.7184080 - Gamma=59.9801402 (M=  61) - s=0.0100\n",
      " 131 - L= 0.7184100 - Gamma=59.9801801 (M=  61) - s=0.0100\n",
      " 132 - L= 0.7184119 - Gamma=59.9795947 (M=  61) - s=0.0100\n",
      " 133 - L= 0.7184132 - Gamma=59.9795926 (M=  61) - s=0.0100\n",
      " 134 - L= 0.7184140 - Gamma=59.9746937 (M=  61) - s=0.0100\n",
      " 135 - L= 0.7184145 - Gamma=59.9747014 (M=  61) - s=0.0100\n",
      " 136 - L= 0.7184150 - Gamma=59.9747020 (M=  61) - s=0.0100\n",
      " 137 - L= 0.7184154 - Gamma=59.9747011 (M=  61) - s=0.0100\n",
      " 138 - L= 0.7184157 - Gamma=59.9746971 (M=  61) - s=0.0100\n",
      " 139 - L= 0.7184161 - Gamma=59.9750594 (M=  61) - s=0.0100\n",
      " 140 - L= 0.7184164 - Gamma=59.9771679 (M=  61) - s=0.0100\n",
      " 141 - L= 0.7184167 - Gamma=59.9771659 (M=  61) - s=0.0100\n",
      " 142 - L= 0.7184170 - Gamma=59.9771630 (M=  61) - s=0.0100\n",
      " 143 - L= 0.7184172 - Gamma=59.9771274 (M=  61) - s=0.0100\n",
      " 144 - L= 0.7184174 - Gamma=59.9771355 (M=  61) - s=0.0100\n",
      " 145 - L= 0.7184176 - Gamma=59.9770541 (M=  61) - s=0.0100\n",
      " 146 - L= 0.7184178 - Gamma=59.9770365 (M=  61) - s=0.0100\n",
      " 147 - L= 0.7184180 - Gamma=59.9768457 (M=  61) - s=0.0100\n",
      " 148 - L= 0.7184182 - Gamma=59.9768436 (M=  61) - s=0.0100\n",
      " 149 - L= 0.7184183 - Gamma=59.9768439 (M=  61) - s=0.0100\n",
      " 150 - L= 0.7184185 - Gamma=59.9768466 (M=  61) - s=0.0100\n",
      " 151 - L= 0.7184187 - Gamma=59.9746785 (M=  61) - s=0.0100\n",
      " 152 - L= 0.7184188 - Gamma=59.9746778 (M=  61) - s=0.0100\n",
      " 153 - L= 0.7184190 - Gamma=59.9746814 (M=  61) - s=0.0100\n",
      " 154 - L= 0.7184191 - Gamma=59.9746819 (M=  61) - s=0.0100\n",
      " 155 - L= 0.7184192 - Gamma=59.9746803 (M=  61) - s=0.0100\n",
      " 156 - L= 0.7184194 - Gamma=59.9749741 (M=  61) - s=0.0100\n",
      " 157 - L= 0.7184195 - Gamma=59.9749732 (M=  61) - s=0.0100\n",
      " 158 - L= 0.7184195 - Gamma=59.9750284 (M=  61) - s=0.0100\n",
      " 159 - L= 0.7184196 - Gamma=59.9750285 (M=  61) - s=0.0100\n",
      " 160 - L= 0.7184197 - Gamma=59.9760287 (M=  61) - s=0.0100\n",
      " 161 - L= 0.7184198 - Gamma=59.9760298 (M=  61) - s=0.0100\n",
      " 162 - L= 0.7184198 - Gamma=59.9761112 (M=  61) - s=0.0100\n",
      " 163 - L= 0.7184199 - Gamma=59.9761114 (M=  61) - s=0.0100\n",
      " 164 - L= 0.7184199 - Gamma=59.9761105 (M=  61) - s=0.0100\n",
      " 165 - L= 0.7184200 - Gamma=59.9761781 (M=  61) - s=0.0100\n",
      " 166 - L= 0.7184200 - Gamma=59.9750026 (M=  61) - s=0.0100\n",
      " 167 - L= 0.7184201 - Gamma=59.9750041 (M=  61) - s=0.0100\n",
      " 168 - L= 0.7184201 - Gamma=59.9749992 (M=  61) - s=0.0100\n",
      " 169 - L= 0.7184201 - Gamma=59.9749994 (M=  61) - s=0.0100\n",
      " 170 - L= 0.7184201 - Gamma=59.9750003 (M=  61) - s=0.0100\n",
      " 171 - L= 0.7184201 - Gamma=59.9749978 (M=  61) - s=0.0100\n",
      " 172 - L= 0.7184202 - Gamma=59.9754433 (M=  61) - s=0.0100\n",
      " 173 - L= 0.7184202 - Gamma=59.9754456 (M=  61) - s=0.0100\n",
      " 174 - L= 0.7184202 - Gamma=59.9754443 (M=  61) - s=0.0100\n",
      " 175 - L= 0.7184202 - Gamma=59.9755613 (M=  61) - s=0.0100\n",
      " 176 - L= 0.7184202 - Gamma=59.9755128 (M=  61) - s=0.0100\n",
      " 177 - L= 0.7184202 - Gamma=59.9755127 (M=  61) - s=0.0100\n",
      " 178 - L= 0.7184202 - Gamma=59.9755707 (M=  61) - s=0.0100\n",
      " 179 - L= 0.7184202 - Gamma=59.9755708 (M=  61) - s=0.0100\n",
      " 180 - L= 0.7184202 - Gamma=59.9755365 (M=  61) - s=0.0100\n",
      " 181 - L= 0.7184203 - Gamma=59.9750999 (M=  61) - s=0.0100\n",
      " 182 - L= 0.7184203 - Gamma=59.9750527 (M=  61) - s=0.0100\n",
      " 183 - L= 0.7184203 - Gamma=59.9750526 (M=  61) - s=0.0100\n",
      " 184 - L= 0.7184203 - Gamma=59.9750528 (M=  61) - s=0.0100\n",
      " 185 - L= 0.7184203 - Gamma=59.9750525 (M=  61) - s=0.0100\n",
      " 186 - L= 0.7184203 - Gamma=59.9750537 (M=  61) - s=0.0100\n",
      " 187 - L= 0.7184203 - Gamma=59.9750521 (M=  61) - s=0.0100\n",
      " 188 - L= 0.7184203 - Gamma=59.9750518 (M=  61) - s=0.0100\n",
      " 189 - L= 0.7184203 - Gamma=59.9751041 (M=  61) - s=0.0100\n",
      " 190 - L= 0.7184203 - Gamma=59.9753226 (M=  61) - s=0.0100\n",
      " 191 - L= 0.7184203 - Gamma=59.9753226 (M=  61) - s=0.0100\n",
      "Stopping at iteration 191 - max_delta_ml=1.8527347949478645e-07\n",
      "L=0.7184202964619908 - Gamma=59.97532256020948 (M=61) - s=0.01\n",
      "Initial alpha = [[ 0.07481184]]\n",
      "   1 - L=-1833.4264615 - Gamma= 1.9999661 (M=   2) - s=0.0100\n",
      "   2 - L=-1545.4872011 - Gamma= 2.9999401 (M=   3) - s=0.0100\n",
      "   3 - L=-1405.2997994 - Gamma= 3.9998850 (M=   4) - s=0.0100\n",
      "   4 - L=-1306.5295636 - Gamma= 4.9998089 (M=   5) - s=0.0100\n",
      "   5 - L=-1213.4236933 - Gamma= 5.9997282 (M=   6) - s=0.0100\n",
      "   6 - L=-1150.7605597 - Gamma= 6.9996090 (M=   7) - s=0.0100\n",
      "   7 - L=-1095.1183206 - Gamma= 7.9994736 (M=   8) - s=0.0100\n",
      "   8 - L=-1048.1092501 - Gamma= 8.9993110 (M=   9) - s=0.0100\n",
      "   9 - L=-1000.9995646 - Gamma= 9.9991469 (M=  10) - s=0.0100\n",
      "  10 - L=-955.2630057 - Gamma=10.9989781 (M=  11) - s=0.0100\n",
      "  11 - L=-909.2818069 - Gamma=11.9987986 (M=  12) - s=0.0100\n",
      "  12 - L=-855.4002475 - Gamma=12.9986419 (M=  13) - s=0.0100\n",
      "  13 - L=-798.4098020 - Gamma=13.9984949 (M=  14) - s=0.0100\n",
      "  14 - L=-739.8401156 - Gamma=14.9983389 (M=  15) - s=0.0100\n",
      "  15 - L=-688.2868492 - Gamma=15.9981882 (M=  16) - s=0.0100\n",
      "  16 - L=-647.0684367 - Gamma=16.9980023 (M=  17) - s=0.0100\n",
      "  17 - L=-609.4215332 - Gamma=17.9977746 (M=  18) - s=0.0100\n",
      "  18 - L=-562.4060576 - Gamma=18.9975274 (M=  19) - s=0.0100\n",
      "  19 - L=-524.4781976 - Gamma=19.9973212 (M=  20) - s=0.0100\n",
      "  20 - L=-484.0742363 - Gamma=20.9970965 (M=  21) - s=0.0100\n",
      "  21 - L=-437.9833669 - Gamma=21.9969076 (M=  22) - s=0.0100\n",
      "  22 - L=-395.2351915 - Gamma=22.9967256 (M=  23) - s=0.0100\n",
      "  23 - L=-362.0906066 - Gamma=23.9964925 (M=  24) - s=0.0100\n",
      "  24 - L=-337.1555607 - Gamma=24.9961756 (M=  25) - s=0.0100\n",
      "  25 - L=-303.3900891 - Gamma=25.9959179 (M=  26) - s=0.0100\n",
      "  26 - L=-281.1125273 - Gamma=26.9955708 (M=  27) - s=0.0100\n",
      "  27 - L=-254.8672765 - Gamma=27.9952377 (M=  28) - s=0.0100\n",
      "  28 - L=-232.3625684 - Gamma=28.9948936 (M=  29) - s=0.0100\n",
      "  29 - L=-209.7122101 - Gamma=29.9945201 (M=  30) - s=0.0100\n",
      "  30 - L=-184.3708647 - Gamma=30.9941841 (M=  31) - s=0.0100\n",
      "  31 - L=-160.9519939 - Gamma=31.9938298 (M=  32) - s=0.0100\n",
      "  32 - L=-139.5930055 - Gamma=32.9934627 (M=  33) - s=0.0100\n",
      "  33 - L=-118.7785157 - Gamma=33.9930784 (M=  34) - s=0.0100\n",
      "  34 - L=-102.6986019 - Gamma=34.9925673 (M=  35) - s=0.0100\n",
      "  35 - L=-86.3289538 - Gamma=35.9920297 (M=  36) - s=0.0100\n",
      "  36 - L=-73.4839472 - Gamma=36.9913914 (M=  37) - s=0.0100\n",
      "  37 - L=-62.5504670 - Gamma=37.9906411 (M=  38) - s=0.0100\n",
      "  38 - L=-54.1337970 - Gamma=38.9897116 (M=  39) - s=0.0100\n",
      "  39 - L=-46.8630150 - Gamma=39.9885774 (M=  40) - s=0.0100\n",
      "  40 - L=-39.8368182 - Gamma=40.9874825 (M=  41) - s=0.0100\n",
      "  41 - L=-32.9516451 - Gamma=41.9862049 (M=  42) - s=0.0100\n",
      "  42 - L=-26.5434874 - Gamma=42.9843047 (M=  43) - s=0.0100\n",
      "  43 - L=-22.5990168 - Gamma=43.9805921 (M=  44) - s=0.0100\n",
      "  44 - L=-18.2250047 - Gamma=44.9786750 (M=  45) - s=0.0100\n",
      "  45 - L=-13.6062472 - Gamma=45.9765104 (M=  46) - s=0.0100\n",
      "  46 - L=-9.8702677 - Gamma=46.9740068 (M=  47) - s=0.0100\n",
      "  47 - L=-6.6830967 - Gamma=47.9715589 (M=  48) - s=0.0100\n",
      "  48 - L=-4.5434594 - Gamma=48.9667301 (M=  49) - s=0.0100\n",
      "  49 - L=-2.9608981 - Gamma=49.9613524 (M=  50) - s=0.0100\n",
      "  50 - L=-2.2104823 - Gamma=50.9515857 (M=  51) - s=0.0100\n",
      "  51 - L=-1.6397953 - Gamma=51.9386387 (M=  52) - s=0.0100\n",
      "  52 - L=-1.0871089 - Gamma=52.9242429 (M=  53) - s=0.0100\n",
      "  53 - L=-0.7378622 - Gamma=53.9023492 (M=  54) - s=0.0100\n",
      "  54 - L=-0.3445281 - Gamma=54.8804087 (M=  55) - s=0.0100\n",
      "  55 - L=-0.0254655 - Gamma=55.8571346 (M=  56) - s=0.0100\n",
      "  56 - L= 0.1932867 - Gamma=56.8202901 (M=  57) - s=0.0100\n",
      "  57 - L= 0.3216166 - Gamma=57.7552217 (M=  58) - s=0.0100\n",
      "  58 - L= 0.3739348 - Gamma=57.7557619 (M=  58) - s=0.0100\n",
      "  59 - L= 0.4204800 - Gamma=57.7562163 (M=  58) - s=0.0100\n",
      "  60 - L= 0.4381432 - Gamma=57.7562490 (M=  58) - s=0.0100\n",
      "  61 - L= 0.4551766 - Gamma=58.5448054 (M=  59) - s=0.0100\n",
      "  62 - L= 0.4719064 - Gamma=59.3130223 (M=  60) - s=0.0100\n",
      "  63 - L= 0.4864307 - Gamma=59.3134603 (M=  60) - s=0.0100\n",
      "  64 - L= 0.4955204 - Gamma=59.3136645 (M=  60) - s=0.0100\n",
      "  65 - L= 0.5038121 - Gamma=59.3138450 (M=  60) - s=0.0100\n",
      "  66 - L= 0.5120188 - Gamma=59.3138873 (M=  60) - s=0.0100\n",
      "  67 - L= 0.5200961 - Gamma=59.3140542 (M=  60) - s=0.0100\n",
      "  68 - L= 0.5281207 - Gamma=59.3142490 (M=  60) - s=0.0100\n",
      "  69 - L= 0.5357483 - Gamma=59.3143953 (M=  60) - s=0.0100\n",
      "  70 - L= 0.5426728 - Gamma=59.3147910 (M=  60) - s=0.0100\n",
      "  71 - L= 0.5492661 - Gamma=59.3150257 (M=  60) - s=0.0100\n",
      "  72 - L= 0.5556305 - Gamma=59.3152416 (M=  60) - s=0.0100\n",
      "  73 - L= 0.5617969 - Gamma=59.3123525 (M=  60) - s=0.0100\n",
      "  74 - L= 0.5673578 - Gamma=59.3123811 (M=  60) - s=0.0100\n",
      "  75 - L= 0.5724048 - Gamma=59.3126985 (M=  60) - s=0.0100\n",
      "  76 - L= 0.5769924 - Gamma=59.3036566 (M=  60) - s=0.0100\n",
      "  77 - L= 0.5813445 - Gamma=59.3198106 (M=  60) - s=0.0100\n",
      "  78 - L= 0.5856861 - Gamma=59.3200304 (M=  60) - s=0.0100\n",
      "  79 - L= 0.5900110 - Gamma=59.3202951 (M=  60) - s=0.0100\n",
      "  80 - L= 0.5940469 - Gamma=59.3211333 (M=  60) - s=0.0100\n",
      "  81 - L= 0.5980168 - Gamma=59.3214246 (M=  60) - s=0.0100\n",
      "  82 - L= 0.6018766 - Gamma=59.3217016 (M=  60) - s=0.0100\n",
      "  83 - L= 0.6056364 - Gamma=59.3219614 (M=  60) - s=0.0100\n",
      "  84 - L= 0.6093833 - Gamma=59.3216918 (M=  60) - s=0.0100\n",
      "  85 - L= 0.6131131 - Gamma=59.3231000 (M=  60) - s=0.0100\n",
      "  86 - L= 0.6162854 - Gamma=59.3213395 (M=  60) - s=0.0100\n",
      "  87 - L= 0.6193277 - Gamma=59.3193238 (M=  60) - s=0.0100\n",
      "  88 - L= 0.6223696 - Gamma=59.3194572 (M=  60) - s=0.0100\n",
      "  89 - L= 0.6253329 - Gamma=59.3130430 (M=  60) - s=0.0100\n",
      "  90 - L= 0.6283132 - Gamma=59.3232782 (M=  60) - s=0.0100\n",
      "  91 - L= 0.6309115 - Gamma=59.3240662 (M=  60) - s=0.0100\n",
      "  92 - L= 0.6334596 - Gamma=59.3064498 (M=  60) - s=0.0100\n",
      "  93 - L= 0.6357570 - Gamma=59.3067659 (M=  60) - s=0.0100\n",
      "  94 - L= 0.6379512 - Gamma=59.3085609 (M=  60) - s=0.0100\n",
      "  95 - L= 0.6398112 - Gamma=59.3082598 (M=  60) - s=0.0100\n",
      "  96 - L= 0.6416043 - Gamma=59.7428745 (M=  61) - s=0.0100\n",
      "  97 - L= 0.6431200 - Gamma=59.7439432 (M=  61) - s=0.0100\n",
      "  98 - L= 0.6446273 - Gamma=59.7434742 (M=  61) - s=0.0100\n",
      "  99 - L= 0.6460344 - Gamma=59.7457735 (M=  61) - s=0.0100\n",
      " 100 - L= 0.6474254 - Gamma=59.7460989 (M=  61) - s=0.0100\n",
      " 101 - L= 0.6487855 - Gamma=60.1460650 (M=  62) - s=0.0100\n",
      " 102 - L= 0.6499191 - Gamma=60.1483601 (M=  62) - s=0.0100\n",
      " 103 - L= 0.6509836 - Gamma=60.1482388 (M=  62) - s=0.0100\n",
      " 104 - L= 0.6516761 - Gamma=60.1556501 (M=  62) - s=0.0100\n",
      " 105 - L= 0.6523663 - Gamma=60.1558983 (M=  62) - s=0.0100\n",
      " 106 - L= 0.6529186 - Gamma=60.1547834 (M=  62) - s=0.0100\n",
      " 107 - L= 0.6533304 - Gamma=60.1548589 (M=  62) - s=0.0100\n",
      " 108 - L= 0.6536811 - Gamma=60.1589597 (M=  62) - s=0.0100\n",
      " 109 - L= 0.6540234 - Gamma=60.1587208 (M=  62) - s=0.0100\n",
      " 110 - L= 0.6543143 - Gamma=60.1587773 (M=  62) - s=0.0100\n",
      " 111 - L= 0.6545772 - Gamma=60.1586283 (M=  62) - s=0.0100\n",
      " 112 - L= 0.6548045 - Gamma=60.1637725 (M=  62) - s=0.0100\n",
      " 113 - L= 0.6550260 - Gamma=60.1638544 (M=  62) - s=0.0100\n",
      " 114 - L= 0.6552307 - Gamma=60.1639640 (M=  62) - s=0.0100\n",
      " 115 - L= 0.6554027 - Gamma=60.1501740 (M=  62) - s=0.0100\n",
      " 116 - L= 0.6554565 - Gamma=60.1240393 (M=  62) - s=0.0100\n",
      " 117 - L= 0.6555109 - Gamma=60.1202255 (M=  62) - s=0.0100\n",
      " 118 - L= 0.6555530 - Gamma=60.1206308 (M=  62) - s=0.0100\n",
      " 119 - L= 0.6555884 - Gamma=60.0984125 (M=  62) - s=0.0100\n",
      " 120 - L= 0.6556206 - Gamma=60.1010509 (M=  62) - s=0.0100\n",
      " 121 - L= 0.6556469 - Gamma=60.1408552 (M=  62) - s=0.0100\n",
      " 122 - L= 0.6556693 - Gamma=60.1415147 (M=  62) - s=0.0100\n",
      " 123 - L= 0.6556890 - Gamma=60.1417447 (M=  62) - s=0.0100\n",
      " 124 - L= 0.6557046 - Gamma=60.1418790 (M=  62) - s=0.0100\n",
      " 125 - L= 0.6557177 - Gamma=60.1424812 (M=  62) - s=0.0100\n",
      " 126 - L= 0.6557247 - Gamma=60.1423961 (M=  62) - s=0.0100\n",
      " 127 - L= 0.6557315 - Gamma=60.1422594 (M=  62) - s=0.0100\n",
      " 128 - L= 0.6557366 - Gamma=60.1332417 (M=  62) - s=0.0100\n",
      " 129 - L= 0.6557424 - Gamma=60.1540668 (M=  62) - s=0.0100\n",
      " 130 - L= 0.6557466 - Gamma=60.1537256 (M=  62) - s=0.0100\n",
      " 131 - L= 0.6557504 - Gamma=60.1463857 (M=  62) - s=0.0100\n",
      " 132 - L= 0.6557546 - Gamma=60.1486300 (M=  62) - s=0.0100\n",
      " 133 - L= 0.6557569 - Gamma=60.1600083 (M=  62) - s=0.0100\n",
      " 134 - L= 0.6557589 - Gamma=60.1599838 (M=  62) - s=0.0100\n",
      " 135 - L= 0.6557608 - Gamma=60.1542769 (M=  62) - s=0.0100\n",
      " 136 - L= 0.6557630 - Gamma=60.1534743 (M=  62) - s=0.0100\n",
      " 137 - L= 0.6557647 - Gamma=60.1644558 (M=  62) - s=0.0100\n",
      " 138 - L= 0.6557658 - Gamma=60.1646760 (M=  62) - s=0.0100\n",
      " 139 - L= 0.6557667 - Gamma=60.1651047 (M=  62) - s=0.0100\n",
      " 140 - L= 0.6557676 - Gamma=60.1649210 (M=  62) - s=0.0100\n",
      " 141 - L= 0.6557684 - Gamma=60.1649196 (M=  62) - s=0.0100\n",
      " 142 - L= 0.6557692 - Gamma=60.1649176 (M=  62) - s=0.0100\n",
      " 143 - L= 0.6557700 - Gamma=60.1649204 (M=  62) - s=0.0100\n",
      " 144 - L= 0.6557707 - Gamma=60.1649125 (M=  62) - s=0.0100\n",
      " 145 - L= 0.6557714 - Gamma=60.1616346 (M=  62) - s=0.0100\n",
      " 146 - L= 0.6557722 - Gamma=60.1679384 (M=  62) - s=0.0100\n",
      " 147 - L= 0.6557729 - Gamma=60.1643116 (M=  62) - s=0.0100\n",
      " 148 - L= 0.6557737 - Gamma=60.1643086 (M=  62) - s=0.0100\n",
      " 149 - L= 0.6557744 - Gamma=60.1642652 (M=  62) - s=0.0100\n",
      " 150 - L= 0.6557751 - Gamma=60.1645266 (M=  62) - s=0.0100\n",
      " 151 - L= 0.6557757 - Gamma=60.1645439 (M=  62) - s=0.0100\n",
      " 152 - L= 0.6557763 - Gamma=60.1645414 (M=  62) - s=0.0100\n",
      " 153 - L= 0.6557767 - Gamma=60.1645436 (M=  62) - s=0.0100\n",
      " 154 - L= 0.6557772 - Gamma=60.1645370 (M=  62) - s=0.0100\n",
      " 155 - L= 0.6557777 - Gamma=60.1645787 (M=  62) - s=0.0100\n",
      " 156 - L= 0.6557781 - Gamma=60.1645371 (M=  62) - s=0.0100\n",
      " 157 - L= 0.6557785 - Gamma=60.1645379 (M=  62) - s=0.0100\n",
      " 158 - L= 0.6557789 - Gamma=60.1645285 (M=  62) - s=0.0100\n",
      " 159 - L= 0.6557792 - Gamma=60.1645247 (M=  62) - s=0.0100\n",
      " 160 - L= 0.6557796 - Gamma=60.1645321 (M=  62) - s=0.0100\n",
      " 161 - L= 0.6557798 - Gamma=60.1646183 (M=  62) - s=0.0100\n",
      " 162 - L= 0.6557801 - Gamma=60.1690210 (M=  62) - s=0.0100\n",
      " 163 - L= 0.6557805 - Gamma=60.1696807 (M=  62) - s=0.0100\n",
      " 164 - L= 0.6557807 - Gamma=60.1697076 (M=  62) - s=0.0100\n",
      " 165 - L= 0.6557810 - Gamma=60.1697081 (M=  62) - s=0.0100\n",
      " 166 - L= 0.6557811 - Gamma=60.1728040 (M=  62) - s=0.0100\n",
      " 167 - L= 0.6557813 - Gamma=60.1725742 (M=  62) - s=0.0100\n",
      " 168 - L= 0.6557815 - Gamma=60.1709502 (M=  62) - s=0.0100\n",
      " 169 - L= 0.6557817 - Gamma=60.1690490 (M=  62) - s=0.0100\n",
      " 170 - L= 0.6557818 - Gamma=60.1690494 (M=  62) - s=0.0100\n",
      " 171 - L= 0.6557820 - Gamma=60.1690487 (M=  62) - s=0.0100\n",
      " 172 - L= 0.6557821 - Gamma=60.1690540 (M=  62) - s=0.0100\n",
      " 173 - L= 0.6557823 - Gamma=60.1691042 (M=  62) - s=0.0100\n",
      " 174 - L= 0.6557824 - Gamma=60.1721357 (M=  62) - s=0.0100\n",
      " 175 - L= 0.6557825 - Gamma=60.1721238 (M=  62) - s=0.0100\n",
      " 176 - L= 0.6557827 - Gamma=60.1722114 (M=  62) - s=0.0100\n",
      " 177 - L= 0.6557828 - Gamma=60.1722123 (M=  62) - s=0.0100\n",
      " 178 - L= 0.6557829 - Gamma=60.1722140 (M=  62) - s=0.0100\n",
      " 179 - L= 0.6557830 - Gamma=60.1722134 (M=  62) - s=0.0100\n",
      " 180 - L= 0.6557831 - Gamma=60.1722305 (M=  62) - s=0.0100\n",
      " 181 - L= 0.6557832 - Gamma=60.1722313 (M=  62) - s=0.0100\n",
      " 182 - L= 0.6557833 - Gamma=60.1722314 (M=  62) - s=0.0100\n",
      " 183 - L= 0.6557833 - Gamma=60.1722170 (M=  62) - s=0.0100\n",
      " 184 - L= 0.6557834 - Gamma=60.1722165 (M=  62) - s=0.0100\n",
      " 185 - L= 0.6557835 - Gamma=60.1739797 (M=  62) - s=0.0100\n",
      " 186 - L= 0.6557835 - Gamma=60.1740915 (M=  62) - s=0.0100\n",
      " 187 - L= 0.6557836 - Gamma=60.1740433 (M=  62) - s=0.0100\n",
      " 188 - L= 0.6557836 - Gamma=60.1740448 (M=  62) - s=0.0100\n",
      " 189 - L= 0.6557837 - Gamma=60.1731465 (M=  62) - s=0.0100\n",
      " 190 - L= 0.6557837 - Gamma=60.1723648 (M=  62) - s=0.0100\n",
      " 191 - L= 0.6557837 - Gamma=60.1723640 (M=  62) - s=0.0100\n",
      " 192 - L= 0.6557838 - Gamma=60.1723653 (M=  62) - s=0.0100\n",
      " 193 - L= 0.6557838 - Gamma=60.1725637 (M=  62) - s=0.0100\n",
      " 194 - L= 0.6557838 - Gamma=60.1725575 (M=  62) - s=0.0100\n",
      " 195 - L= 0.6557839 - Gamma=60.1740970 (M=  62) - s=0.0100\n",
      " 196 - L= 0.6557839 - Gamma=60.1740970 (M=  62) - s=0.0100\n",
      " 197 - L= 0.6557839 - Gamma=60.1740074 (M=  62) - s=0.0100\n",
      " 198 - L= 0.6557840 - Gamma=60.1740082 (M=  62) - s=0.0100\n",
      " 199 - L= 0.6557840 - Gamma=60.1740300 (M=  62) - s=0.0100\n",
      " 200 - L= 0.6557840 - Gamma=60.1748804 (M=  62) - s=0.0100\n",
      "MODEL: RVM accuracy:  0.506024096386 +/-: 0.0168449607549\n",
      "Initial alpha = [[ 0.05297935]]\n",
      "   1 - L=-1744.0282321 - Gamma= 1.9999703 (M=   2) - s=0.0100\n",
      "   2 - L=-1510.3870987 - Gamma= 2.9999436 (M=   3) - s=0.0100\n",
      "   3 - L=-1371.6221438 - Gamma= 3.9998984 (M=   4) - s=0.0100\n",
      "   4 - L=-1291.1185354 - Gamma= 4.9998231 (M=   5) - s=0.0100\n",
      "   5 - L=-1235.0538350 - Gamma= 5.9997150 (M=   6) - s=0.0100\n",
      "   6 - L=-1197.9039250 - Gamma= 6.9995528 (M=   7) - s=0.0100\n",
      "   7 - L=-1162.5380871 - Gamma= 7.9993827 (M=   8) - s=0.0100\n",
      "   8 - L=-1127.6653520 - Gamma= 8.9992102 (M=   9) - s=0.0100\n",
      "   9 - L=-1093.6627035 - Gamma= 9.9990323 (M=  10) - s=0.0100\n",
      "  10 - L=-1058.3644277 - Gamma=10.9988609 (M=  11) - s=0.0100\n",
      "  11 - L=-1021.8909588 - Gamma=11.9986950 (M=  12) - s=0.0100\n",
      "  12 - L=-985.7063916 - Gamma=12.9985269 (M=  13) - s=0.0100\n",
      "  13 - L=-947.8135001 - Gamma=13.9983673 (M=  14) - s=0.0100\n",
      "  14 - L=-908.9482360 - Gamma=14.9982115 (M=  15) - s=0.0100\n",
      "  15 - L=-867.7727145 - Gamma=15.9980609 (M=  16) - s=0.0100\n",
      "  16 - L=-829.6218257 - Gamma=16.9979013 (M=  17) - s=0.0100\n",
      "  17 - L=-793.8485585 - Gamma=17.9977326 (M=  18) - s=0.0100\n",
      "  18 - L=-758.8364756 - Gamma=18.9975607 (M=  19) - s=0.0100\n",
      "  19 - L=-727.2674539 - Gamma=19.9973701 (M=  20) - s=0.0100\n",
      "  20 - L=-699.3817977 - Gamma=20.9971529 (M=  21) - s=0.0100\n",
      "  21 - L=-670.7013836 - Gamma=21.9969418 (M=  22) - s=0.0100\n",
      "  22 - L=-641.5286123 - Gamma=22.9967350 (M=  23) - s=0.0100\n",
      "  23 - L=-611.8993204 - Gamma=23.9965311 (M=  24) - s=0.0100\n",
      "  24 - L=-582.4689572 - Gamma=24.9963252 (M=  25) - s=0.0100\n",
      "  25 - L=-552.3957231 - Gamma=25.9961212 (M=  26) - s=0.0100\n",
      "  26 - L=-521.9647043 - Gamma=26.9959231 (M=  27) - s=0.0100\n",
      "  27 - L=-493.4146786 - Gamma=27.9957112 (M=  28) - s=0.0100\n",
      "  28 - L=-465.8144231 - Gamma=28.9954929 (M=  29) - s=0.0100\n",
      "  29 - L=-440.3831869 - Gamma=29.9952560 (M=  30) - s=0.0100\n",
      "  30 - L=-414.6363844 - Gamma=30.9950197 (M=  31) - s=0.0100\n",
      "  31 - L=-389.1536347 - Gamma=31.9947803 (M=  32) - s=0.0100\n",
      "  32 - L=-363.3447027 - Gamma=32.9945469 (M=  33) - s=0.0100\n",
      "  33 - L=-339.4254224 - Gamma=33.9942942 (M=  34) - s=0.0100\n",
      "  34 - L=-316.0004677 - Gamma=34.9940357 (M=  35) - s=0.0100\n",
      "  35 - L=-296.1450315 - Gamma=35.9937324 (M=  36) - s=0.0100\n",
      "  36 - L=-276.6067369 - Gamma=36.9934222 (M=  37) - s=0.0100\n",
      "  37 - L=-257.3276700 - Gamma=37.9931095 (M=  38) - s=0.0100\n",
      "  38 - L=-240.0114176 - Gamma=38.9927613 (M=  39) - s=0.0100\n",
      "  39 - L=-223.6827057 - Gamma=39.9923925 (M=  40) - s=0.0100\n",
      "  40 - L=-208.0026477 - Gamma=40.9920051 (M=  41) - s=0.0100\n",
      "  41 - L=-193.4162401 - Gamma=41.9915932 (M=  42) - s=0.0100\n",
      "  42 - L=-180.0467380 - Gamma=42.9911426 (M=  43) - s=0.0100\n",
      "  43 - L=-166.9178125 - Gamma=43.9906841 (M=  44) - s=0.0100\n",
      "  44 - L=-153.7042149 - Gamma=44.9902286 (M=  45) - s=0.0100\n",
      "  45 - L=-141.9875825 - Gamma=45.9897139 (M=  46) - s=0.0100\n",
      "  46 - L=-130.2270969 - Gamma=46.9892016 (M=  47) - s=0.0100\n",
      "  47 - L=-118.7521888 - Gamma=47.9886765 (M=  48) - s=0.0100\n",
      "  48 - L=-108.5600884 - Gamma=48.9880883 (M=  49) - s=0.0100\n",
      "  49 - L=-98.9886009 - Gamma=49.9874586 (M=  50) - s=0.0100\n",
      "  50 - L=-90.2958046 - Gamma=50.9867687 (M=  51) - s=0.0100\n",
      "  51 - L=-81.6932402 - Gamma=51.9860709 (M=  52) - s=0.0100\n",
      "  52 - L=-73.2683238 - Gamma=52.9853592 (M=  53) - s=0.0100\n",
      "  53 - L=-64.9236582 - Gamma=53.9846415 (M=  54) - s=0.0100\n",
      "  54 - L=-57.6028355 - Gamma=54.9838239 (M=  55) - s=0.0100\n",
      "  55 - L=-51.1345780 - Gamma=55.9828987 (M=  56) - s=0.0100\n",
      "  56 - L=-45.5165723 - Gamma=56.9818344 (M=  57) - s=0.0100\n",
      "  57 - L=-40.2519614 - Gamma=57.9806992 (M=  58) - s=0.0100\n",
      "  58 - L=-35.9374367 - Gamma=58.9793175 (M=  59) - s=0.0100\n",
      "  59 - L=-31.7510365 - Gamma=59.9778930 (M=  60) - s=0.0100\n",
      "  60 - L=-28.1428627 - Gamma=60.9762438 (M=  61) - s=0.0100\n",
      "  61 - L=-24.8786388 - Gamma=61.9744228 (M=  62) - s=0.0100\n",
      "  62 - L=-21.8996970 - Gamma=62.9724296 (M=  63) - s=0.0100\n",
      "  63 - L=-18.9400691 - Gamma=63.9704233 (M=  64) - s=0.0100\n",
      "  64 - L=-16.0140776 - Gamma=64.9683877 (M=  65) - s=0.0100\n",
      "  65 - L=-13.0506614 - Gamma=65.9663832 (M=  66) - s=0.0100\n",
      "  66 - L=-10.9355753 - Gamma=66.9635898 (M=  67) - s=0.0100\n",
      "  67 - L=-8.8918595 - Gamma=67.9606999 (M=  68) - s=0.0100\n",
      "  68 - L=-7.0904134 - Gamma=68.9574288 (M=  69) - s=0.0100\n",
      "  69 - L=-5.8372165 - Gamma=69.9527642 (M=  70) - s=0.0100\n",
      "  70 - L=-4.8054295 - Gamma=70.9471282 (M=  71) - s=0.0100\n",
      "  71 - L=-3.8024647 - Gamma=71.9413359 (M=  72) - s=0.0100\n",
      "  72 - L=-2.8278911 - Gamma=72.9353799 (M=  73) - s=0.0100\n",
      "  73 - L=-2.1900389 - Gamma=73.9264182 (M=  74) - s=0.0100\n",
      "  74 - L=-1.5993090 - Gamma=74.9167751 (M=  75) - s=0.0100\n",
      "  75 - L=-1.0661585 - Gamma=75.9061420 (M=  76) - s=0.0100\n",
      "  76 - L=-0.6126852 - Gamma=76.8937451 (M=  77) - s=0.0100\n",
      "  77 - L=-0.2093417 - Gamma=77.8798969 (M=  78) - s=0.0100\n",
      "  78 - L= 0.0427815 - Gamma=78.8584818 (M=  79) - s=0.0100\n",
      "  79 - L= 0.1521853 - Gamma=79.8135662 (M=  80) - s=0.0100\n",
      "  80 - L= 0.2066027 - Gamma=80.7339726 (M=  81) - s=0.0100\n",
      "  81 - L= 0.2220309 - Gamma=80.7339855 (M=  81) - s=0.0100\n",
      "  82 - L= 0.2356384 - Gamma=80.7327493 (M=  81) - s=0.0100\n",
      "  83 - L= 0.2490878 - Gamma=81.5244825 (M=  82) - s=0.0100\n",
      "  84 - L= 0.2573497 - Gamma=81.5246155 (M=  82) - s=0.0100\n",
      "  85 - L= 0.2640335 - Gamma=81.5246374 (M=  82) - s=0.0100\n",
      "  86 - L= 0.2704031 - Gamma=81.5247423 (M=  82) - s=0.0100\n",
      "  87 - L= 0.2767400 - Gamma=81.5248604 (M=  82) - s=0.0100\n",
      "  88 - L= 0.2830000 - Gamma=81.5249369 (M=  82) - s=0.0100\n",
      "  89 - L= 0.2885940 - Gamma=81.5250540 (M=  82) - s=0.0100\n",
      "  90 - L= 0.2930167 - Gamma=81.5251609 (M=  82) - s=0.0100\n",
      "  91 - L= 0.2968461 - Gamma=81.5252081 (M=  82) - s=0.0100\n",
      "  92 - L= 0.3002138 - Gamma=81.5253054 (M=  82) - s=0.0100\n",
      "  93 - L= 0.3026612 - Gamma=81.5253906 (M=  82) - s=0.0100\n",
      "  94 - L= 0.3050697 - Gamma=81.5254771 (M=  82) - s=0.0100\n",
      "  95 - L= 0.3073481 - Gamma=81.5255625 (M=  82) - s=0.0100\n",
      "  96 - L= 0.3094058 - Gamma=81.5256672 (M=  82) - s=0.0100\n",
      "  97 - L= 0.3113390 - Gamma=81.5257775 (M=  82) - s=0.0100\n",
      "  98 - L= 0.3129231 - Gamma=81.5258782 (M=  82) - s=0.0100\n",
      "  99 - L= 0.3140750 - Gamma=81.5259666 (M=  82) - s=0.0100\n",
      " 100 - L= 0.3149941 - Gamma=81.5260599 (M=  82) - s=0.0100\n",
      " 101 - L= 0.3159017 - Gamma=81.5261538 (M=  82) - s=0.0100\n",
      " 102 - L= 0.3166535 - Gamma=81.5262291 (M=  82) - s=0.0100\n",
      " 103 - L= 0.3173064 - Gamma=81.5262883 (M=  82) - s=0.0100\n",
      " 104 - L= 0.3179556 - Gamma=81.5263607 (M=  82) - s=0.0100\n",
      " 105 - L= 0.3185822 - Gamma=81.5264196 (M=  82) - s=0.0100\n",
      " 106 - L= 0.3191651 - Gamma=81.5264907 (M=  82) - s=0.0100\n",
      " 107 - L= 0.3195954 - Gamma=81.5265831 (M=  82) - s=0.0100\n",
      " 108 - L= 0.3200112 - Gamma=81.5266341 (M=  82) - s=0.0100\n",
      " 109 - L= 0.3204167 - Gamma=81.5267465 (M=  82) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 110 - L= 0.3207650 - Gamma=81.5268173 (M=  82) - s=0.0100\n",
      " 111 - L= 0.3210922 - Gamma=81.5268849 (M=  82) - s=0.0100\n",
      " 112 - L= 0.3213628 - Gamma=81.5268910 (M=  82) - s=0.0100\n",
      " 113 - L= 0.3216295 - Gamma=81.5269399 (M=  82) - s=0.0100\n",
      " 114 - L= 0.3218651 - Gamma=81.5269954 (M=  82) - s=0.0100\n",
      " 115 - L= 0.3220654 - Gamma=81.5270432 (M=  82) - s=0.0100\n",
      " 116 - L= 0.3222496 - Gamma=81.5271166 (M=  82) - s=0.0100\n",
      " 117 - L= 0.3224248 - Gamma=81.5271561 (M=  82) - s=0.0100\n",
      " 118 - L= 0.3225868 - Gamma=81.5272185 (M=  82) - s=0.0100\n",
      " 119 - L= 0.3227467 - Gamma=81.5272528 (M=  82) - s=0.0100\n",
      " 120 - L= 0.3228871 - Gamma=81.5273097 (M=  82) - s=0.0100\n",
      " 121 - L= 0.3230267 - Gamma=81.5273941 (M=  82) - s=0.0100\n",
      " 122 - L= 0.3231566 - Gamma=81.5274611 (M=  82) - s=0.0100\n",
      " 123 - L= 0.3232846 - Gamma=81.5275537 (M=  82) - s=0.0100\n",
      " 124 - L= 0.3234029 - Gamma=81.5275944 (M=  82) - s=0.0100\n",
      " 125 - L= 0.3234994 - Gamma=81.5276674 (M=  82) - s=0.0100\n",
      " 126 - L= 0.3235756 - Gamma=81.5277407 (M=  82) - s=0.0100\n",
      " 127 - L= 0.3236512 - Gamma=81.5278057 (M=  82) - s=0.0100\n",
      " 128 - L= 0.3237167 - Gamma=81.5278897 (M=  82) - s=0.0100\n",
      " 129 - L= 0.3237787 - Gamma=81.5279582 (M=  82) - s=0.0100\n",
      " 130 - L= 0.3238138 - Gamma=81.5279996 (M=  82) - s=0.0100\n",
      " 131 - L= 0.3238326 - Gamma=81.5280518 (M=  82) - s=0.0100\n",
      " 132 - L= 0.3238460 - Gamma=81.5280957 (M=  82) - s=0.0100\n",
      " 133 - L= 0.3238542 - Gamma=81.5281316 (M=  82) - s=0.0100\n",
      " 134 - L= 0.3238610 - Gamma=81.5281805 (M=  82) - s=0.0100\n",
      " 135 - L= 0.3238666 - Gamma=81.5282196 (M=  82) - s=0.0100\n",
      " 136 - L= 0.3238722 - Gamma=81.5282669 (M=  82) - s=0.0100\n",
      " 137 - L= 0.3238764 - Gamma=81.5283406 (M=  82) - s=0.0100\n",
      " 138 - L= 0.3238801 - Gamma=81.5283897 (M=  82) - s=0.0100\n",
      " 139 - L= 0.3238827 - Gamma=81.5284067 (M=  82) - s=0.0100\n",
      " 140 - L= 0.3238848 - Gamma=81.5284280 (M=  82) - s=0.0100\n",
      " 141 - L= 0.3238859 - Gamma=81.5284651 (M=  82) - s=0.0100\n",
      " 142 - L= 0.3238866 - Gamma=81.5284863 (M=  82) - s=0.0100\n",
      " 143 - L= 0.3238871 - Gamma=81.5283790 (M=  82) - s=0.0100\n",
      " 144 - L= 0.3238873 - Gamma=81.5283510 (M=  82) - s=0.0100\n",
      " 145 - L= 0.3238876 - Gamma=81.5283668 (M=  82) - s=0.0100\n",
      " 146 - L= 0.3238879 - Gamma=81.5283850 (M=  82) - s=0.0100\n",
      " 147 - L= 0.3238880 - Gamma=81.5283982 (M=  82) - s=0.0100\n",
      " 148 - L= 0.3238882 - Gamma=81.5284123 (M=  82) - s=0.0100\n",
      " 149 - L= 0.3238883 - Gamma=81.5284334 (M=  82) - s=0.0100\n",
      " 150 - L= 0.3238884 - Gamma=81.5283655 (M=  82) - s=0.0100\n",
      " 151 - L= 0.3238884 - Gamma=81.5284057 (M=  82) - s=0.0100\n",
      " 152 - L= 0.3238885 - Gamma=81.5284250 (M=  82) - s=0.0100\n",
      " 153 - L= 0.3238885 - Gamma=81.5284736 (M=  82) - s=0.0100\n",
      " 154 - L= 0.3238886 - Gamma=81.5284710 (M=  82) - s=0.0100\n",
      " 155 - L= 0.3238886 - Gamma=81.5284968 (M=  82) - s=0.0100\n",
      " 156 - L= 0.3238886 - Gamma=81.5284827 (M=  82) - s=0.0100\n",
      " 157 - L= 0.3238886 - Gamma=81.5284949 (M=  82) - s=0.0100\n",
      " 158 - L= 0.3238886 - Gamma=81.5284976 (M=  82) - s=0.0100\n",
      " 159 - L= 0.3238886 - Gamma=81.5283790 (M=  82) - s=0.0100\n",
      " 160 - L= 0.3238886 - Gamma=81.5283820 (M=  82) - s=0.0100\n",
      " 161 - L= 0.3238886 - Gamma=81.5283820 (M=  82) - s=0.0100\n",
      "Stopping at iteration 161 - max_delta_ml=1.055000637877686e-07\n",
      "L=0.32388863966289894 - Gamma=81.52838198762156 (M=82) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 0s - loss: 0.6556 - acc: 0.6308 - val_loss: 0.5009 - val_acc: 0.6111\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 0s - loss: 0.3693 - acc: 0.7077 - val_loss: 0.3461 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 0s - loss: 0.2439 - acc: 0.9385 - val_loss: 0.2858 - val_acc: 0.9444\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 0s - loss: 0.1246 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 0.9444\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 0s - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9444\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s - loss: 0.0450 - acc: 0.9848 - val_loss: 6.7127e-04 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 2.8649e-04 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s - loss: 4.1714e-04 - acc: 1.0000 - val_loss: 1.6093e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s - loss: 2.0849e-04 - acc: 1.0000 - val_loss: 1.0537e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s - loss: 2.1424e-04 - acc: 1.0000 - val_loss: 5.9100e-05 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 1.2919e-04 - acc: 1.0000 - val_loss: 1.7547e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 3.3007e-05 - acc: 1.0000 - val_loss: 1.2915e-05 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 3.9299e-05 - acc: 1.0000 - val_loss: 8.1598e-06 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 3.1151e-05 - acc: 1.0000 - val_loss: 4.9083e-06 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 7.8707e-06 - acc: 1.0000 - val_loss: 3.8395e-06 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 1.3293e-05 - acc: 1.0000 - val_loss: 8.8750e-07 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 6.4610e-06 - acc: 1.0000 - val_loss: 5.0728e-07 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 7.8395e-06 - acc: 1.0000 - val_loss: 2.8542e-07 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 2.4513e-06 - acc: 1.0000 - val_loss: 1.9669e-07 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 1.7233e-06 - acc: 1.0000 - val_loss: 1.5020e-07 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 1.1509e-06 - acc: 1.0000 - val_loss: 1.5927e-07 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 1.4413e-06 - acc: 1.0000 - val_loss: 1.3722e-07 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 5.7462e-07 - acc: 1.0000 - val_loss: 1.2085e-07 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 2.8008e-07 - acc: 1.0000 - val_loss: 1.1357e-07 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 3.4575e-07 - acc: 1.0000 - val_loss: 1.1201e-07 - val_acc: 1.0000\n",
      "MODEL: DNN accuracy:  0.987951807229 +/-: 0.000524185093789\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83, 1) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 0s - loss: 0.7282 - acc: 0.5077 - val_loss: 0.7907 - val_acc: 0.3889\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 0s - loss: 0.6534 - acc: 0.6769 - val_loss: 0.6481 - val_acc: 0.6111\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 0s - loss: 0.6005 - acc: 0.6615 - val_loss: 0.6109 - val_acc: 0.6667\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 0s - loss: 0.5854 - acc: 0.7077 - val_loss: 0.6026 - val_acc: 0.7222\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 0s - loss: 0.5143 - acc: 0.7538 - val_loss: 0.6133 - val_acc: 0.7222\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s - loss: 0.5209 - acc: 0.7727 - val_loss: 0.4874 - val_acc: 0.8235\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s - loss: 0.3940 - acc: 0.8182 - val_loss: 0.5002 - val_acc: 0.8235\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s - loss: 0.4047 - acc: 0.7879 - val_loss: 0.5204 - val_acc: 0.7647\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s - loss: 0.3685 - acc: 0.8485 - val_loss: 0.5047 - val_acc: 0.7647\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s - loss: 0.3754 - acc: 0.8333 - val_loss: 0.5376 - val_acc: 0.7647\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.3314 - acc: 0.9104 - val_loss: 0.2391 - val_acc: 0.9375\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.3124 - acc: 0.8507 - val_loss: 0.2723 - val_acc: 0.8125\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.1961 - acc: 0.9254 - val_loss: 0.1935 - val_acc: 0.9375\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.2435 - acc: 0.9254 - val_loss: 0.2912 - val_acc: 0.8125\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.1995 - acc: 0.9254 - val_loss: 0.1819 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.1409 - acc: 0.9552 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.1440 - acc: 0.9701 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.1387 - acc: 0.9701 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.0790 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.0913 - acc: 0.9851 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.0588 - acc: 0.9851 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.1395 - acc: 0.9851 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.89156626506 +/-: 0.0163152017472\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: ET accuracy:  0.650602409639 +/-: 0.00147928116909\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: RF accuracy:  0.722891566265 +/-: 0.00812409809329\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: GBM accuracy:  0.915662650602 +/-: 0.00229740127531\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: ADA accuracy:  0.903614457831 +/-: 0.00648370709391\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: LR accuracy:  0.89156626506 +/-: 0.00602403708859\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: SVM accuracy:  0.939759036145 +/-: 0.00146493130566\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: GNB accuracy:  0.771084337349 +/-: 0.00760726582209\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: MLNN accuracy:  0.89156626506 +/-: 0.00332205268036\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "MODEL: XGB accuracy:  0.903614457831 +/-: 0.0039293721069\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "Initial alpha = [[ 0.05742281]]\n",
      "   1 - L=-1604.9289669 - Gamma= 1.9999556 (M=   2) - s=0.0100\n",
      "   2 - L=-1409.8647296 - Gamma= 2.9999161 (M=   3) - s=0.0100\n",
      "   3 - L=-1268.2433830 - Gamma= 3.9998603 (M=   4) - s=0.0100\n",
      "   4 - L=-1159.3029303 - Gamma= 4.9997893 (M=   5) - s=0.0100\n",
      "   5 - L=-1082.5370875 - Gamma= 5.9996863 (M=   6) - s=0.0100\n",
      "   6 - L=-1020.1838659 - Gamma= 6.9995621 (M=   7) - s=0.0100\n",
      "   7 - L=-952.7900353 - Gamma= 7.9994382 (M=   8) - s=0.0100\n",
      "   8 - L=-878.4037592 - Gamma= 8.9993278 (M=   9) - s=0.0100\n",
      "   9 - L=-812.8691274 - Gamma= 9.9992056 (M=  10) - s=0.0100\n",
      "  10 - L=-748.2102361 - Gamma=10.9990837 (M=  11) - s=0.0100\n",
      "  11 - L=-688.4649297 - Gamma=11.9989457 (M=  12) - s=0.0100\n",
      "  12 - L=-633.8489603 - Gamma=12.9987976 (M=  13) - s=0.0100\n",
      "  13 - L=-573.8713560 - Gamma=13.9986623 (M=  14) - s=0.0100\n",
      "  14 - L=-518.7656416 - Gamma=14.9985211 (M=  15) - s=0.0100\n",
      "  15 - L=-474.6953766 - Gamma=15.9983344 (M=  16) - s=0.0100\n",
      "  16 - L=-441.0306204 - Gamma=16.9980916 (M=  17) - s=0.0100\n",
      "  17 - L=-403.2764057 - Gamma=17.9978654 (M=  18) - s=0.0100\n",
      "  18 - L=-368.5030420 - Gamma=18.9976242 (M=  19) - s=0.0100\n",
      "  19 - L=-331.5818393 - Gamma=19.9974084 (M=  20) - s=0.0100\n",
      "  20 - L=-331.5135714 - Gamma=18.9975765 (M=  19) - s=0.0100\n",
      "  21 - L=-299.1862345 - Gamma=19.9972968 (M=  20) - s=0.0100\n",
      "  22 - L=-246.7099443 - Gamma=20.9970583 (M=  21) - s=0.0100\n",
      "  23 - L=-221.0468716 - Gamma=21.9967474 (M=  22) - s=0.0100\n",
      "  24 - L=-196.4571081 - Gamma=22.9964133 (M=  23) - s=0.0100\n",
      "  25 - L=-174.7245196 - Gamma=23.9960254 (M=  24) - s=0.0100\n",
      "  26 - L=-157.1552405 - Gamma=24.9955763 (M=  25) - s=0.0100\n",
      "  27 - L=-138.3043683 - Gamma=25.9951329 (M=  26) - s=0.0100\n",
      "  28 - L=-118.3052037 - Gamma=26.9947259 (M=  27) - s=0.0100\n",
      "  29 - L=-103.3277153 - Gamma=27.9942007 (M=  28) - s=0.0100\n",
      "  30 - L=-92.5461304 - Gamma=28.9934740 (M=  29) - s=0.0100\n",
      "  31 - L=-80.9963521 - Gamma=29.9927683 (M=  30) - s=0.0100\n",
      "  32 - L=-69.2407281 - Gamma=30.9920341 (M=  31) - s=0.0100\n",
      "  33 - L=-58.3794239 - Gamma=31.9912979 (M=  32) - s=0.0100\n",
      "  34 - L=-49.6426064 - Gamma=32.9901638 (M=  33) - s=0.0100\n",
      "  35 - L=-41.2797260 - Gamma=33.9891848 (M=  34) - s=0.0100\n",
      "  36 - L=-35.7124997 - Gamma=34.9875904 (M=  35) - s=0.0100\n",
      "  37 - L=-30.0202416 - Gamma=35.9861895 (M=  36) - s=0.0100\n",
      "  38 - L=-26.2308289 - Gamma=36.9840710 (M=  37) - s=0.0100\n",
      "  39 - L=-22.7043604 - Gamma=37.9817760 (M=  38) - s=0.0100\n",
      "  40 - L=-19.5447649 - Gamma=38.9793172 (M=  39) - s=0.0100\n",
      "  41 - L=-17.3841905 - Gamma=39.9757668 (M=  40) - s=0.0100\n",
      "  42 - L=-15.1259766 - Gamma=40.9720157 (M=  41) - s=0.0100\n",
      "  43 - L=-13.0375652 - Gamma=41.9680861 (M=  42) - s=0.0100\n",
      "  44 - L=-10.6321694 - Gamma=42.9644307 (M=  43) - s=0.0100\n",
      "  45 - L=-8.0918683 - Gamma=43.9609607 (M=  44) - s=0.0100\n",
      "  46 - L=-5.8972046 - Gamma=44.9562283 (M=  45) - s=0.0100\n",
      "  47 - L=-4.5393399 - Gamma=45.9505026 (M=  46) - s=0.0100\n",
      "  48 - L=-3.0148566 - Gamma=46.9448437 (M=  47) - s=0.0100\n",
      "  49 - L=-1.8031264 - Gamma=47.9358741 (M=  48) - s=0.0100\n",
      "  50 - L=-1.2341440 - Gamma=48.9227140 (M=  49) - s=0.0100\n",
      "  51 - L=-0.6058507 - Gamma=49.9059504 (M=  50) - s=0.0100\n",
      "  52 - L=-0.1442569 - Gamma=50.8855131 (M=  51) - s=0.0100\n",
      "  53 - L= 0.0501824 - Gamma=51.8480087 (M=  52) - s=0.0100\n",
      "  54 - L= 0.2042831 - Gamma=52.8037371 (M=  53) - s=0.0100\n",
      "  55 - L= 0.3189330 - Gamma=53.7474995 (M=  54) - s=0.0100\n",
      "  56 - L= 0.4809986 - Gamma=54.7031384 (M=  55) - s=0.0100\n",
      "  57 - L= 0.6190378 - Gamma=55.6506352 (M=  56) - s=0.0100\n",
      "  58 - L= 0.6498155 - Gamma=56.4742528 (M=  57) - s=0.0100\n",
      "  59 - L= 0.6667912 - Gamma=56.4830460 (M=  57) - s=0.0100\n",
      "  60 - L= 0.6830359 - Gamma=56.4901527 (M=  57) - s=0.0100\n",
      "  61 - L= 0.6968786 - Gamma=56.4903390 (M=  57) - s=0.0100\n",
      "  62 - L= 0.7107186 - Gamma=56.4905199 (M=  57) - s=0.0100\n",
      "  63 - L= 0.7235548 - Gamma=57.2383987 (M=  58) - s=0.0100\n",
      "  64 - L= 0.7368911 - Gamma=57.9835395 (M=  59) - s=0.0100\n",
      "  65 - L= 0.7472320 - Gamma=57.9836079 (M=  59) - s=0.0100\n",
      "  66 - L= 0.7564738 - Gamma=57.9844265 (M=  59) - s=0.0100\n",
      "  67 - L= 0.7652418 - Gamma=57.9670908 (M=  59) - s=0.0100\n",
      "  68 - L= 0.7734477 - Gamma=57.9671050 (M=  59) - s=0.0100\n",
      "  69 - L= 0.7815697 - Gamma=58.6064005 (M=  60) - s=0.0100\n",
      "  70 - L= 0.7873347 - Gamma=58.6174122 (M=  60) - s=0.0100\n",
      "  71 - L= 0.7925480 - Gamma=58.6176452 (M=  60) - s=0.0100\n",
      "  72 - L= 0.7975226 - Gamma=58.5928968 (M=  60) - s=0.0100\n",
      "  73 - L= 0.8023622 - Gamma=58.5945661 (M=  60) - s=0.0100\n",
      "  74 - L= 0.8071588 - Gamma=58.5947612 (M=  60) - s=0.0100\n",
      "  75 - L= 0.8110770 - Gamma=58.5952420 (M=  60) - s=0.0100\n",
      "  76 - L= 0.8148807 - Gamma=58.5953696 (M=  60) - s=0.0100\n",
      "  77 - L= 0.8181893 - Gamma=58.5955086 (M=  60) - s=0.0100\n",
      "  78 - L= 0.8211810 - Gamma=58.5956958 (M=  60) - s=0.0100\n",
      "  79 - L= 0.8241443 - Gamma=58.5972960 (M=  60) - s=0.0100\n",
      "  80 - L= 0.8264710 - Gamma=58.6008254 (M=  60) - s=0.0100\n",
      "  81 - L= 0.8286204 - Gamma=58.6011738 (M=  60) - s=0.0100\n",
      "  82 - L= 0.8306982 - Gamma=58.5963705 (M=  60) - s=0.0100\n",
      "  83 - L= 0.8327639 - Gamma=58.5964196 (M=  60) - s=0.0100\n",
      "  84 - L= 0.8344980 - Gamma=58.5982134 (M=  60) - s=0.0100\n",
      "  85 - L= 0.8361735 - Gamma=58.6002354 (M=  60) - s=0.0100\n",
      "  86 - L= 0.8378044 - Gamma=58.5991762 (M=  60) - s=0.0100\n",
      "  87 - L= 0.8392453 - Gamma=58.5993002 (M=  60) - s=0.0100\n",
      "  88 - L= 0.8405598 - Gamma=58.5997686 (M=  60) - s=0.0100\n",
      "  89 - L= 0.8417705 - Gamma=58.5992215 (M=  60) - s=0.0100\n",
      "  90 - L= 0.8429977 - Gamma=58.9767148 (M=  61) - s=0.0100\n",
      "  91 - L= 0.8441094 - Gamma=58.9989171 (M=  61) - s=0.0100\n",
      "  92 - L= 0.8451612 - Gamma=58.9999103 (M=  61) - s=0.0100\n",
      "  93 - L= 0.8461859 - Gamma=59.0023393 (M=  61) - s=0.0100\n",
      "  94 - L= 0.8472084 - Gamma=59.0024559 (M=  61) - s=0.0100\n",
      "  95 - L= 0.8480689 - Gamma=59.0025113 (M=  61) - s=0.0100\n",
      "  96 - L= 0.8489197 - Gamma=59.0233963 (M=  61) - s=0.0100\n",
      "  97 - L= 0.8496100 - Gamma=59.0229157 (M=  61) - s=0.0100\n",
      "  98 - L= 0.8502696 - Gamma=59.0013182 (M=  61) - s=0.0100\n",
      "  99 - L= 0.8508602 - Gamma=59.0017124 (M=  61) - s=0.0100\n",
      " 100 - L= 0.8514306 - Gamma=58.9998671 (M=  61) - s=0.0100\n",
      " 101 - L= 0.8518438 - Gamma=59.0000686 (M=  61) - s=0.0100\n",
      " 102 - L= 0.8522457 - Gamma=58.9999077 (M=  61) - s=0.0100\n",
      " 103 - L= 0.8526265 - Gamma=59.0000233 (M=  61) - s=0.0100\n",
      " 104 - L= 0.8529918 - Gamma=59.0001553 (M=  61) - s=0.0100\n",
      " 105 - L= 0.8533504 - Gamma=58.9817267 (M=  61) - s=0.0100\n",
      " 106 - L= 0.8536564 - Gamma=58.9818022 (M=  61) - s=0.0100\n",
      " 107 - L= 0.8539270 - Gamma=58.9818796 (M=  61) - s=0.0100\n",
      " 108 - L= 0.8541938 - Gamma=58.9828501 (M=  61) - s=0.0100\n",
      " 109 - L= 0.8544304 - Gamma=58.9762063 (M=  61) - s=0.0100\n",
      " 110 - L= 0.8545734 - Gamma=58.9755679 (M=  61) - s=0.0100\n",
      " 111 - L= 0.8546521 - Gamma=58.9384240 (M=  61) - s=0.0100\n",
      " 112 - L= 0.8547241 - Gamma=58.9415279 (M=  61) - s=0.0100\n",
      " 113 - L= 0.8547883 - Gamma=58.9012546 (M=  61) - s=0.0100\n",
      " 114 - L= 0.8548530 - Gamma=58.9673780 (M=  61) - s=0.0100\n",
      " 115 - L= 0.8549029 - Gamma=58.9674589 (M=  61) - s=0.0100\n",
      " 116 - L= 0.8549422 - Gamma=58.9674718 (M=  61) - s=0.0100\n",
      " 117 - L= 0.8549795 - Gamma=58.9661876 (M=  61) - s=0.0100\n",
      " 118 - L= 0.8550074 - Gamma=58.9659409 (M=  61) - s=0.0100\n",
      " 119 - L= 0.8550336 - Gamma=58.9530940 (M=  61) - s=0.0100\n",
      " 120 - L= 0.8550540 - Gamma=58.9528810 (M=  61) - s=0.0100\n",
      " 121 - L= 0.8550728 - Gamma=58.9550257 (M=  61) - s=0.0100\n",
      " 122 - L= 0.8550853 - Gamma=58.9387678 (M=  61) - s=0.0100\n",
      " 123 - L= 0.8550952 - Gamma=58.9259474 (M=  61) - s=0.0100\n",
      " 124 - L= 0.8551016 - Gamma=58.9259439 (M=  61) - s=0.0100\n",
      " 125 - L= 0.8551076 - Gamma=58.9241834 (M=  61) - s=0.0100\n",
      " 126 - L= 0.8551120 - Gamma=58.9242554 (M=  61) - s=0.0100\n",
      " 127 - L= 0.8551156 - Gamma=58.9242668 (M=  61) - s=0.0100\n",
      " 128 - L= 0.8551184 - Gamma=58.9224130 (M=  61) - s=0.0100\n",
      " 129 - L= 0.8551211 - Gamma=58.9239339 (M=  61) - s=0.0100\n",
      " 130 - L= 0.8551229 - Gamma=58.9239876 (M=  61) - s=0.0100\n",
      " 131 - L= 0.8551244 - Gamma=58.9238592 (M=  61) - s=0.0100\n",
      " 132 - L= 0.8551259 - Gamma=58.9238804 (M=  61) - s=0.0100\n",
      " 133 - L= 0.8551274 - Gamma=58.9243040 (M=  61) - s=0.0100\n",
      " 134 - L= 0.8551288 - Gamma=58.9241408 (M=  61) - s=0.0100\n",
      " 135 - L= 0.8551301 - Gamma=58.9301352 (M=  61) - s=0.0100\n",
      " 136 - L= 0.8551314 - Gamma=58.9296131 (M=  61) - s=0.0100\n",
      " 137 - L= 0.8551326 - Gamma=58.9383646 (M=  61) - s=0.0100\n",
      " 138 - L= 0.8551338 - Gamma=58.9384326 (M=  61) - s=0.0100\n",
      " 139 - L= 0.8551346 - Gamma=58.9340872 (M=  61) - s=0.0100\n",
      " 140 - L= 0.8551352 - Gamma=58.9340620 (M=  61) - s=0.0100\n",
      " 141 - L= 0.8551358 - Gamma=58.9340587 (M=  61) - s=0.0100\n",
      " 142 - L= 0.8551364 - Gamma=58.9344177 (M=  61) - s=0.0100\n",
      " 143 - L= 0.8551369 - Gamma=58.9344301 (M=  61) - s=0.0100\n",
      " 144 - L= 0.8551374 - Gamma=58.9343888 (M=  61) - s=0.0100\n",
      " 145 - L= 0.8551379 - Gamma=58.9343658 (M=  61) - s=0.0100\n",
      " 146 - L= 0.8551384 - Gamma=58.9343728 (M=  61) - s=0.0100\n",
      " 147 - L= 0.8551387 - Gamma=58.9343734 (M=  61) - s=0.0100\n",
      " 148 - L= 0.8551390 - Gamma=58.9343628 (M=  61) - s=0.0100\n",
      " 149 - L= 0.8551393 - Gamma=58.9343659 (M=  61) - s=0.0100\n",
      " 150 - L= 0.8551396 - Gamma=58.9346904 (M=  61) - s=0.0100\n",
      " 151 - L= 0.8551399 - Gamma=58.9344245 (M=  61) - s=0.0100\n",
      " 152 - L= 0.8551401 - Gamma=58.9330426 (M=  61) - s=0.0100\n",
      " 153 - L= 0.8551403 - Gamma=58.9349500 (M=  61) - s=0.0100\n",
      " 154 - L= 0.8551404 - Gamma=58.9349481 (M=  61) - s=0.0100\n",
      " 155 - L= 0.8551405 - Gamma=58.9335518 (M=  61) - s=0.0100\n",
      " 156 - L= 0.8551406 - Gamma=58.9335799 (M=  61) - s=0.0100\n",
      " 157 - L= 0.8551407 - Gamma=58.9360469 (M=  61) - s=0.0100\n",
      " 158 - L= 0.8551408 - Gamma=58.9358893 (M=  61) - s=0.0100\n",
      " 159 - L= 0.8551409 - Gamma=58.9355848 (M=  61) - s=0.0100\n",
      " 160 - L= 0.8551410 - Gamma=58.9356752 (M=  61) - s=0.0100\n",
      " 161 - L= 0.8551410 - Gamma=58.9356748 (M=  61) - s=0.0100\n",
      " 162 - L= 0.8551411 - Gamma=58.9345654 (M=  61) - s=0.0100\n",
      " 163 - L= 0.8551411 - Gamma=58.9345659 (M=  61) - s=0.0100\n",
      " 164 - L= 0.8551412 - Gamma=58.9345770 (M=  61) - s=0.0100\n",
      " 165 - L= 0.8551412 - Gamma=58.9346793 (M=  61) - s=0.0100\n",
      " 166 - L= 0.8551413 - Gamma=58.9346787 (M=  61) - s=0.0100\n",
      " 167 - L= 0.8551413 - Gamma=58.9346538 (M=  61) - s=0.0100\n",
      " 168 - L= 0.8551413 - Gamma=58.9360202 (M=  61) - s=0.0100\n",
      " 169 - L= 0.8551414 - Gamma=58.9360228 (M=  61) - s=0.0100\n",
      " 170 - L= 0.8551414 - Gamma=58.9360601 (M=  61) - s=0.0100\n",
      " 171 - L= 0.8551414 - Gamma=58.9360633 (M=  61) - s=0.0100\n",
      " 172 - L= 0.8551414 - Gamma=58.9360632 (M=  61) - s=0.0100\n",
      " 173 - L= 0.8551415 - Gamma=58.9360489 (M=  61) - s=0.0100\n",
      " 174 - L= 0.8551415 - Gamma=58.9360487 (M=  61) - s=0.0100\n",
      " 175 - L= 0.8551415 - Gamma=58.9359782 (M=  61) - s=0.0100\n",
      " 176 - L= 0.8551415 - Gamma=58.9359823 (M=  61) - s=0.0100\n",
      " 177 - L= 0.8551415 - Gamma=58.9359761 (M=  61) - s=0.0100\n",
      " 178 - L= 0.8551415 - Gamma=58.9355353 (M=  61) - s=0.0100\n",
      " 179 - L= 0.8551415 - Gamma=58.9355358 (M=  61) - s=0.0100\n",
      " 180 - L= 0.8551415 - Gamma=58.9355358 (M=  61) - s=0.0100\n",
      " 181 - L= 0.8551416 - Gamma=58.9355356 (M=  61) - s=0.0100\n",
      " 182 - L= 0.8551416 - Gamma=58.9355348 (M=  61) - s=0.0100\n",
      " 183 - L= 0.8551416 - Gamma=58.9351000 (M=  61) - s=0.0100\n",
      " 184 - L= 0.8551416 - Gamma=58.9351002 (M=  61) - s=0.0100\n",
      " 185 - L= 0.8551416 - Gamma=58.9351047 (M=  61) - s=0.0100\n",
      " 186 - L= 0.8551416 - Gamma=58.9351085 (M=  61) - s=0.0100\n",
      " 187 - L= 0.8551416 - Gamma=58.9351625 (M=  61) - s=0.0100\n",
      " 188 - L= 0.8551416 - Gamma=58.9351669 (M=  61) - s=0.0100\n",
      " 189 - L= 0.8551416 - Gamma=58.9354786 (M=  61) - s=0.0100\n",
      " 190 - L= 0.8551416 - Gamma=58.9354175 (M=  61) - s=0.0100\n",
      " 191 - L= 0.8551416 - Gamma=58.9353882 (M=  61) - s=0.0100\n",
      " 192 - L= 0.8551416 - Gamma=58.9353882 (M=  61) - s=0.0100\n",
      "Stopping at iteration 192 - max_delta_ml=2.487817257375291e-07\n",
      "L=0.8551416126140374 - Gamma=58.935388172471214 (M=61) - s=0.01\n",
      "Initial alpha = [[ 0.06181572]]\n",
      "   1 - L=-1617.7110655 - Gamma= 1.9999633 (M=   2) - s=0.0100\n",
      "   2 - L=-1411.3944136 - Gamma= 2.9999265 (M=   3) - s=0.0100\n",
      "   3 - L=-1235.7134040 - Gamma= 3.9998819 (M=   4) - s=0.0100\n",
      "   4 - L=-1138.1912425 - Gamma= 4.9998038 (M=   5) - s=0.0100\n",
      "   5 - L=-1047.2658765 - Gamma= 5.9997194 (M=   6) - s=0.0100\n",
      "   6 - L=-976.6133778 - Gamma= 6.9996076 (M=   7) - s=0.0100\n",
      "   7 - L=-902.4798750 - Gamma= 7.9995048 (M=   8) - s=0.0100\n",
      "   8 - L=-832.1294976 - Gamma= 8.9993956 (M=   9) - s=0.0100\n",
      "   9 - L=-775.4564581 - Gamma= 9.9992594 (M=  10) - s=0.0100\n",
      "  10 - L=-729.5220407 - Gamma=10.9990913 (M=  11) - s=0.0100\n",
      "  11 - L=-682.6052397 - Gamma=11.9989277 (M=  12) - s=0.0100\n",
      "  12 - L=-636.0910193 - Gamma=12.9987632 (M=  13) - s=0.0100\n",
      "  13 - L=-591.1551897 - Gamma=13.9985881 (M=  14) - s=0.0100\n",
      "  14 - L=-541.2520657 - Gamma=14.9984266 (M=  15) - s=0.0100\n",
      "  15 - L=-496.9961271 - Gamma=15.9982415 (M=  16) - s=0.0100\n",
      "  16 - L=-448.7970717 - Gamma=16.9980818 (M=  17) - s=0.0100\n",
      "  17 - L=-413.8583992 - Gamma=17.9978605 (M=  18) - s=0.0100\n",
      "  18 - L=-377.9912908 - Gamma=18.9976456 (M=  19) - s=0.0100\n",
      "  19 - L=-338.6901068 - Gamma=19.9974449 (M=  20) - s=0.0100\n",
      "  20 - L=-305.0613920 - Gamma=20.9972060 (M=  21) - s=0.0100\n",
      "  21 - L=-274.0376865 - Gamma=21.9969491 (M=  22) - s=0.0100\n",
      "  22 - L=-245.3653262 - Gamma=22.9966833 (M=  23) - s=0.0100\n",
      "  23 - L=-218.2434336 - Gamma=23.9963953 (M=  24) - s=0.0100\n",
      "  24 - L=-196.7487097 - Gamma=24.9960359 (M=  25) - s=0.0100\n",
      "  25 - L=-177.1638434 - Gamma=25.9956320 (M=  26) - s=0.0100\n",
      "  26 - L=-158.8891037 - Gamma=26.9952133 (M=  27) - s=0.0100\n",
      "  27 - L=-143.2495444 - Gamma=27.9947111 (M=  28) - s=0.0100\n",
      "  28 - L=-124.1533393 - Gamma=28.9942933 (M=  29) - s=0.0100\n",
      "  29 - L=-100.6742961 - Gamma=29.9939422 (M=  30) - s=0.0100\n",
      "  30 - L=-83.2987659 - Gamma=30.9934715 (M=  31) - s=0.0100\n",
      "  31 - L=-65.8684300 - Gamma=31.9930084 (M=  32) - s=0.0100\n",
      "  32 - L=-58.1242477 - Gamma=32.9920310 (M=  33) - s=0.0100\n",
      "  33 - L=-51.1905902 - Gamma=33.9909330 (M=  34) - s=0.0100\n",
      "  34 - L=-45.4289661 - Gamma=34.9896064 (M=  35) - s=0.0100\n",
      "  35 - L=-39.9464678 - Gamma=35.9881682 (M=  36) - s=0.0100\n",
      "  36 - L=-35.4831646 - Gamma=36.9864682 (M=  37) - s=0.0100\n",
      "  37 - L=-30.5172140 - Gamma=37.9847819 (M=  38) - s=0.0100\n",
      "  38 - L=-25.9165607 - Gamma=38.9830884 (M=  39) - s=0.0100\n",
      "  39 - L=-21.7311644 - Gamma=39.9812853 (M=  40) - s=0.0100\n",
      "  40 - L=-17.9088926 - Gamma=40.9790236 (M=  41) - s=0.0100\n",
      "  41 - L=-14.4975655 - Gamma=41.9765366 (M=  42) - s=0.0100\n",
      "  42 - L=-12.1191496 - Gamma=42.9733385 (M=  43) - s=0.0100\n",
      "  43 - L=-8.9130798 - Gamma=43.9698928 (M=  44) - s=0.0100\n",
      "  44 - L=-6.3036148 - Gamma=44.9666613 (M=  45) - s=0.0100\n",
      "  45 - L=-5.1431827 - Gamma=45.9602326 (M=  46) - s=0.0100\n",
      "  46 - L=-3.8492921 - Gamma=46.9534436 (M=  47) - s=0.0100\n",
      "  47 - L=-2.5233436 - Gamma=47.9473892 (M=  48) - s=0.0100\n",
      "  48 - L=-1.3720402 - Gamma=48.9391674 (M=  49) - s=0.0100\n",
      "  49 - L=-0.5441863 - Gamma=49.9282424 (M=  50) - s=0.0100\n",
      "  50 - L= 0.0721492 - Gamma=50.9147666 (M=  51) - s=0.0100\n",
      "  51 - L= 0.2856584 - Gamma=51.8819756 (M=  52) - s=0.0100\n",
      "  52 - L= 0.4815620 - Gamma=52.8468524 (M=  53) - s=0.0100\n",
      "  53 - L= 0.6046288 - Gamma=53.7939742 (M=  54) - s=0.0100\n",
      "  54 - L= 0.7124459 - Gamma=54.7278676 (M=  55) - s=0.0100\n",
      "  55 - L= 0.7602986 - Gamma=55.6179828 (M=  56) - s=0.0100\n",
      "  56 - L= 0.8142521 - Gamma=56.5125089 (M=  57) - s=0.0100\n",
      "  57 - L= 0.8335281 - Gamma=57.3057463 (M=  58) - s=0.0100\n",
      "  58 - L= 0.8431228 - Gamma=57.3058272 (M=  58) - s=0.0100\n",
      "  59 - L= 0.8522356 - Gamma=57.3121125 (M=  58) - s=0.0100\n",
      "  60 - L= 0.8597023 - Gamma=57.9708402 (M=  59) - s=0.0100\n",
      "  61 - L= 0.8668717 - Gamma=57.9709490 (M=  59) - s=0.0100\n",
      "  62 - L= 0.8736454 - Gamma=57.9710147 (M=  59) - s=0.0100\n",
      "  63 - L= 0.8791253 - Gamma=57.9664266 (M=  59) - s=0.0100\n",
      "  64 - L= 0.8840717 - Gamma=57.9545212 (M=  59) - s=0.0100\n",
      "  65 - L= 0.8884252 - Gamma=57.9545321 (M=  59) - s=0.0100\n",
      "  66 - L= 0.8926661 - Gamma=57.9524658 (M=  59) - s=0.0100\n",
      "  67 - L= 0.8966421 - Gamma=57.9548455 (M=  59) - s=0.0100\n",
      "  68 - L= 0.9004646 - Gamma=57.9549219 (M=  59) - s=0.0100\n",
      "  69 - L= 0.9039584 - Gamma=57.9549595 (M=  59) - s=0.0100\n",
      "  70 - L= 0.9072898 - Gamma=57.9553094 (M=  59) - s=0.0100\n",
      "  71 - L= 0.9102658 - Gamma=57.9511116 (M=  59) - s=0.0100\n",
      "  72 - L= 0.9130247 - Gamma=57.9507508 (M=  59) - s=0.0100\n",
      "  73 - L= 0.9155972 - Gamma=57.9521534 (M=  59) - s=0.0100\n",
      "  74 - L= 0.9179598 - Gamma=57.9522624 (M=  59) - s=0.0100\n",
      "  75 - L= 0.9202134 - Gamma=57.9525013 (M=  59) - s=0.0100\n",
      "  76 - L= 0.9222379 - Gamma=57.9534327 (M=  59) - s=0.0100\n",
      "  77 - L= 0.9238360 - Gamma=57.9533610 (M=  59) - s=0.0100\n",
      "  78 - L= 0.9253783 - Gamma=57.9536152 (M=  59) - s=0.0100\n",
      "  79 - L= 0.9268954 - Gamma=57.9532633 (M=  59) - s=0.0100\n",
      "  80 - L= 0.9281745 - Gamma=57.9534556 (M=  59) - s=0.0100\n",
      "  81 - L= 0.9293878 - Gamma=57.9538096 (M=  59) - s=0.0100\n",
      "  82 - L= 0.9305784 - Gamma=57.9577724 (M=  59) - s=0.0100\n",
      "  83 - L= 0.9313786 - Gamma=57.9608052 (M=  59) - s=0.0100\n",
      "  84 - L= 0.9321046 - Gamma=57.9614610 (M=  59) - s=0.0100\n",
      "  85 - L= 0.9327904 - Gamma=57.9615169 (M=  59) - s=0.0100\n",
      "  86 - L= 0.9333686 - Gamma=57.9615637 (M=  59) - s=0.0100\n",
      "  87 - L= 0.9339189 - Gamma=57.9621332 (M=  59) - s=0.0100\n",
      "  88 - L= 0.9344105 - Gamma=57.9603036 (M=  59) - s=0.0100\n",
      "  89 - L= 0.9348326 - Gamma=57.9603898 (M=  59) - s=0.0100\n",
      "  90 - L= 0.9352088 - Gamma=57.9604391 (M=  59) - s=0.0100\n",
      "  91 - L= 0.9355690 - Gamma=57.9605095 (M=  59) - s=0.0100\n",
      "  92 - L= 0.9358931 - Gamma=57.9614050 (M=  59) - s=0.0100\n",
      "  93 - L= 0.9361868 - Gamma=57.9614719 (M=  59) - s=0.0100\n",
      "  94 - L= 0.9364540 - Gamma=57.9616036 (M=  59) - s=0.0100\n",
      "  95 - L= 0.9367128 - Gamma=58.0041920 (M=  59) - s=0.0100\n",
      "  96 - L= 0.9369591 - Gamma=58.0043808 (M=  59) - s=0.0100\n",
      "  97 - L= 0.9371847 - Gamma=58.0044314 (M=  59) - s=0.0100\n",
      "  98 - L= 0.9374005 - Gamma=58.0047748 (M=  59) - s=0.0100\n",
      "  99 - L= 0.9376045 - Gamma=58.0048319 (M=  59) - s=0.0100\n",
      " 100 - L= 0.9377621 - Gamma=58.0047557 (M=  59) - s=0.0100\n",
      " 101 - L= 0.9378988 - Gamma=58.0047033 (M=  59) - s=0.0100\n",
      " 102 - L= 0.9380334 - Gamma=58.1710932 (M=  60) - s=0.0100\n",
      " 103 - L= 0.9381818 - Gamma=58.1817188 (M=  60) - s=0.0100\n",
      " 104 - L= 0.9382856 - Gamma=58.1635410 (M=  60) - s=0.0100\n",
      " 105 - L= 0.9383764 - Gamma=58.1635649 (M=  60) - s=0.0100\n",
      " 106 - L= 0.9384510 - Gamma=58.1636061 (M=  60) - s=0.0100\n",
      " 107 - L= 0.9385188 - Gamma=58.1631173 (M=  60) - s=0.0100\n",
      " 108 - L= 0.9385498 - Gamma=58.1637371 (M=  60) - s=0.0100\n",
      " 109 - L= 0.9385663 - Gamma=58.1636596 (M=  60) - s=0.0100\n",
      " 110 - L= 0.9385774 - Gamma=58.1667811 (M=  60) - s=0.0100\n",
      " 111 - L= 0.9385873 - Gamma=58.1650158 (M=  60) - s=0.0100\n",
      " 112 - L= 0.9385952 - Gamma=58.1650284 (M=  60) - s=0.0100\n",
      " 113 - L= 0.9386015 - Gamma=58.1647606 (M=  60) - s=0.0100\n",
      " 114 - L= 0.9386077 - Gamma=58.1631426 (M=  60) - s=0.0100\n",
      " 115 - L= 0.9386125 - Gamma=58.1625097 (M=  60) - s=0.0100\n",
      " 116 - L= 0.9386169 - Gamma=58.1674981 (M=  60) - s=0.0100\n",
      " 117 - L= 0.9386188 - Gamma=58.1674813 (M=  60) - s=0.0100\n",
      " 118 - L= 0.9386202 - Gamma=58.1676061 (M=  60) - s=0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in log\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n",
      "/home/bramiozo/DEV/GIT/RexR/rvm.py:289: RuntimeWarning: invalid value encountered in absolute\n",
      "  change = np.abs(np.log(newAlpha) - np.log(self.Alpha[j]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 119 - L= 0.9386209 - Gamma=58.1792240 (M=  60) - s=0.0100\n",
      " 120 - L= 0.9386217 - Gamma=58.1799169 (M=  60) - s=0.0100\n",
      " 121 - L= 0.9386221 - Gamma=58.1799775 (M=  60) - s=0.0100\n",
      " 122 - L= 0.9386223 - Gamma=58.1799547 (M=  60) - s=0.0100\n",
      " 123 - L= 0.9386226 - Gamma=58.1799754 (M=  60) - s=0.0100\n",
      " 124 - L= 0.9386228 - Gamma=58.1799304 (M=  60) - s=0.0100\n",
      " 125 - L= 0.9386229 - Gamma=58.1798912 (M=  60) - s=0.0100\n",
      " 126 - L= 0.9386231 - Gamma=58.1798731 (M=  60) - s=0.0100\n",
      " 127 - L= 0.9386232 - Gamma=58.1780232 (M=  60) - s=0.0100\n",
      " 128 - L= 0.9386233 - Gamma=58.1780298 (M=  60) - s=0.0100\n",
      " 129 - L= 0.9386234 - Gamma=58.1780973 (M=  60) - s=0.0100\n",
      " 130 - L= 0.9386235 - Gamma=58.1780971 (M=  60) - s=0.0100\n",
      " 131 - L= 0.9386235 - Gamma=58.1776874 (M=  60) - s=0.0100\n",
      " 132 - L= 0.9386235 - Gamma=58.1776882 (M=  60) - s=0.0100\n",
      " 133 - L= 0.9386235 - Gamma=58.1777759 (M=  60) - s=0.0100\n",
      " 134 - L= 0.9386236 - Gamma=58.1777771 (M=  60) - s=0.0100\n",
      " 135 - L= 0.9386236 - Gamma=58.1780801 (M=  60) - s=0.0100\n",
      " 136 - L= 0.9386236 - Gamma=58.1780826 (M=  60) - s=0.0100\n",
      " 137 - L= 0.9386236 - Gamma=58.1780821 (M=  60) - s=0.0100\n",
      " 138 - L= 0.9386236 - Gamma=58.1794743 (M=  60) - s=0.0100\n",
      " 139 - L= 0.9386236 - Gamma=58.1794743 (M=  60) - s=0.0100\n",
      " 140 - L= 0.9386236 - Gamma=58.1794746 (M=  60) - s=0.0100\n",
      " 141 - L= 0.9386236 - Gamma=58.1794736 (M=  60) - s=0.0100\n",
      " 142 - L= 0.9386237 - Gamma=58.1794721 (M=  60) - s=0.0100\n",
      " 143 - L= 0.9386237 - Gamma=58.1794718 (M=  60) - s=0.0100\n",
      " 144 - L= 0.9386237 - Gamma=58.1795452 (M=  60) - s=0.0100\n",
      " 145 - L= 0.9386237 - Gamma=58.1795472 (M=  60) - s=0.0100\n",
      " 146 - L= 0.9386237 - Gamma=58.1795473 (M=  60) - s=0.0100\n",
      " 147 - L= 0.9386237 - Gamma=58.1795475 (M=  60) - s=0.0100\n",
      " 148 - L= 0.9386237 - Gamma=58.1795542 (M=  60) - s=0.0100\n",
      " 149 - L= 0.9386237 - Gamma=58.1795542 (M=  60) - s=0.0100\n",
      "Stopping at iteration 149 - max_delta_ml=2.4399998213900896e-07\n",
      "L=0.9386236844491666 - Gamma=58.179554189774365 (M=60) - s=0.01\n",
      "Initial alpha = [[ 0.07201744]]\n",
      "   1 - L=-1766.1559217 - Gamma= 1.9999700 (M=   2) - s=0.0100\n",
      "   2 - L=-1492.3513464 - Gamma= 2.9999415 (M=   3) - s=0.0100\n",
      "   3 - L=-1342.2002034 - Gamma= 3.9998884 (M=   4) - s=0.0100\n",
      "   4 - L=-1259.7772875 - Gamma= 4.9997976 (M=   5) - s=0.0100\n",
      "   5 - L=-1194.5772543 - Gamma= 5.9996818 (M=   6) - s=0.0100\n",
      "   6 - L=-1123.3477973 - Gamma= 6.9995761 (M=   7) - s=0.0100\n",
      "   7 - L=-1062.3424293 - Gamma= 7.9994531 (M=   8) - s=0.0100\n",
      "   8 - L=-1006.3043736 - Gamma= 8.9993170 (M=   9) - s=0.0100\n",
      "   9 - L=-944.0007714 - Gamma= 9.9991927 (M=  10) - s=0.0100\n",
      "  10 - L=-878.6744125 - Gamma=10.9990729 (M=  11) - s=0.0100\n",
      "  11 - L=-813.0421549 - Gamma=11.9989512 (M=  12) - s=0.0100\n",
      "  12 - L=-759.0148963 - Gamma=12.9988078 (M=  13) - s=0.0100\n",
      "  13 - L=-717.1949222 - Gamma=13.9986248 (M=  14) - s=0.0100\n",
      "  14 - L=-674.4224239 - Gamma=14.9984437 (M=  15) - s=0.0100\n",
      "  15 - L=-621.0800004 - Gamma=15.9982873 (M=  16) - s=0.0100\n",
      "  16 - L=-573.0592473 - Gamma=16.9981124 (M=  17) - s=0.0100\n",
      "  17 - L=-534.8573151 - Gamma=17.9979126 (M=  18) - s=0.0100\n",
      "  18 - L=-500.7023514 - Gamma=18.9976906 (M=  19) - s=0.0100\n",
      "  19 - L=-461.4211925 - Gamma=19.9974940 (M=  20) - s=0.0100\n",
      "  20 - L=-423.1987118 - Gamma=20.9972914 (M=  21) - s=0.0100\n",
      "  21 - L=-381.7371008 - Gamma=21.9971022 (M=  22) - s=0.0100\n",
      "  22 - L=-346.0518922 - Gamma=22.9968654 (M=  23) - s=0.0100\n",
      "  23 - L=-312.5569878 - Gamma=23.9966366 (M=  24) - s=0.0100\n",
      "  24 - L=-282.0716660 - Gamma=24.9963839 (M=  25) - s=0.0100\n",
      "  25 - L=-252.7184545 - Gamma=25.9961130 (M=  26) - s=0.0100\n",
      "  26 - L=-231.9884494 - Gamma=26.9957311 (M=  27) - s=0.0100\n",
      "  27 - L=-209.3667643 - Gamma=27.9953914 (M=  28) - s=0.0100\n",
      "  28 - L=-192.7725358 - Gamma=28.9949293 (M=  29) - s=0.0100\n",
      "  29 - L=-179.2476012 - Gamma=29.9943713 (M=  30) - s=0.0100\n",
      "  30 - L=-166.7669739 - Gamma=30.9937463 (M=  31) - s=0.0100\n",
      "  31 - L=-152.6898703 - Gamma=31.9931562 (M=  32) - s=0.0100\n",
      "  32 - L=-137.4844125 - Gamma=32.9925671 (M=  33) - s=0.0100\n",
      "  33 - L=-118.2618658 - Gamma=33.9920074 (M=  34) - s=0.0100\n",
      "  34 - L=-104.8497289 - Gamma=34.9914196 (M=  35) - s=0.0100\n",
      "  35 - L=-92.5809303 - Gamma=35.9908037 (M=  36) - s=0.0100\n",
      "  36 - L=-81.6938646 - Gamma=36.9900721 (M=  37) - s=0.0100\n",
      "  37 - L=-68.8905025 - Gamma=37.9894501 (M=  38) - s=0.0100\n",
      "  38 - L=-59.5718390 - Gamma=38.9886165 (M=  39) - s=0.0100\n",
      "  39 - L=-50.3275657 - Gamma=39.9877718 (M=  40) - s=0.0100\n",
      "  40 - L=-42.4836001 - Gamma=40.9868030 (M=  41) - s=0.0100\n",
      "  41 - L=-42.4183243 - Gamma=39.9871014 (M=  40) - s=0.0100\n",
      "  42 - L=-36.0476366 - Gamma=40.9858881 (M=  41) - s=0.0100\n",
      "  43 - L=-28.8180591 - Gamma=41.9846833 (M=  42) - s=0.0100\n",
      "  44 - L=-23.9108170 - Gamma=42.9831322 (M=  43) - s=0.0100\n",
      "  45 - L=-18.4954056 - Gamma=43.9816489 (M=  44) - s=0.0100\n",
      "  46 - L=-13.1893758 - Gamma=44.9799618 (M=  45) - s=0.0100\n",
      "  47 - L=-10.3165510 - Gamma=45.9769386 (M=  46) - s=0.0100\n",
      "  48 - L=-8.5180295 - Gamma=46.9727303 (M=  47) - s=0.0100\n",
      "  49 - L=-6.2883850 - Gamma=47.9689063 (M=  48) - s=0.0100\n",
      "  50 - L=-3.7655922 - Gamma=48.9655226 (M=  49) - s=0.0100\n",
      "  51 - L=-3.0016659 - Gamma=49.9560351 (M=  50) - s=0.0100\n",
      "  52 - L=-1.9551695 - Gamma=50.9471045 (M=  51) - s=0.0100\n",
      "  53 - L=-1.4087509 - Gamma=51.9334332 (M=  52) - s=0.0100\n",
      "  54 - L=-0.7233790 - Gamma=52.9219156 (M=  53) - s=0.0100\n",
      "  55 - L=-0.2998906 - Gamma=53.9052515 (M=  54) - s=0.0100\n",
      "  56 - L= 0.0374627 - Gamma=54.8840736 (M=  55) - s=0.0100\n",
      "  57 - L= 0.3015911 - Gamma=55.8561400 (M=  56) - s=0.0100\n",
      "  58 - L= 0.4351269 - Gamma=56.8083006 (M=  57) - s=0.0100\n",
      "  59 - L= 0.5141313 - Gamma=57.7316775 (M=  58) - s=0.0100\n",
      "  60 - L= 0.5519470 - Gamma=58.6055638 (M=  59) - s=0.0100\n",
      "  61 - L= 0.5721196 - Gamma=58.6057589 (M=  59) - s=0.0100\n",
      "  62 - L= 0.5905848 - Gamma=58.6057862 (M=  59) - s=0.0100\n",
      "  63 - L= 0.6078050 - Gamma=58.6059168 (M=  59) - s=0.0100\n",
      "  64 - L= 0.6179942 - Gamma=58.6061198 (M=  59) - s=0.0100\n",
      "  65 - L= 0.6262957 - Gamma=58.6063531 (M=  59) - s=0.0100\n",
      "  66 - L= 0.6341605 - Gamma=58.6065333 (M=  59) - s=0.0100\n",
      "  67 - L= 0.6419701 - Gamma=58.6070198 (M=  59) - s=0.0100\n",
      "  68 - L= 0.6480672 - Gamma=58.6077205 (M=  59) - s=0.0100\n",
      "  69 - L= 0.6539200 - Gamma=58.6081647 (M=  59) - s=0.0100\n",
      "  70 - L= 0.6592282 - Gamma=58.6082520 (M=  59) - s=0.0100\n",
      "  71 - L= 0.6644604 - Gamma=58.6084137 (M=  59) - s=0.0100\n",
      "  72 - L= 0.6692093 - Gamma=58.6106110 (M=  59) - s=0.0100\n",
      "  73 - L= 0.6738065 - Gamma=58.6107229 (M=  59) - s=0.0100\n",
      "  74 - L= 0.6782758 - Gamma=59.2025548 (M=  60) - s=0.0100\n",
      "  75 - L= 0.6820586 - Gamma=59.2054038 (M=  60) - s=0.0100\n",
      "  76 - L= 0.6854292 - Gamma=59.2056029 (M=  60) - s=0.0100\n",
      "  77 - L= 0.6885178 - Gamma=59.2057647 (M=  60) - s=0.0100\n",
      "  78 - L= 0.6914485 - Gamma=59.2066999 (M=  60) - s=0.0100\n",
      "  79 - L= 0.6941756 - Gamma=59.2055189 (M=  60) - s=0.0100\n",
      "  80 - L= 0.6968596 - Gamma=59.2056442 (M=  60) - s=0.0100\n",
      "  81 - L= 0.6994285 - Gamma=59.2057238 (M=  60) - s=0.0100\n",
      "  82 - L= 0.7019405 - Gamma=59.2057489 (M=  60) - s=0.0100\n",
      "  83 - L= 0.7044365 - Gamma=59.2057724 (M=  60) - s=0.0100\n",
      "  84 - L= 0.7069200 - Gamma=59.2060953 (M=  60) - s=0.0100\n",
      "  85 - L= 0.7091640 - Gamma=59.2062269 (M=  60) - s=0.0100\n",
      "  86 - L= 0.7112294 - Gamma=59.2085793 (M=  60) - s=0.0100\n",
      "  87 - L= 0.7127919 - Gamma=59.2082514 (M=  60) - s=0.0100\n",
      "  88 - L= 0.7142934 - Gamma=59.2083121 (M=  60) - s=0.0100\n",
      "  89 - L= 0.7157232 - Gamma=59.2084957 (M=  60) - s=0.0100\n",
      "  90 - L= 0.7170766 - Gamma=59.2005833 (M=  60) - s=0.0100\n",
      "  91 - L= 0.7184195 - Gamma=59.2011842 (M=  60) - s=0.0100\n",
      "  92 - L= 0.7196284 - Gamma=59.2009007 (M=  60) - s=0.0100\n",
      "  93 - L= 0.7206344 - Gamma=59.2115135 (M=  60) - s=0.0100\n",
      "  94 - L= 0.7215924 - Gamma=59.2154588 (M=  60) - s=0.0100\n",
      "  95 - L= 0.7225195 - Gamma=59.2157023 (M=  60) - s=0.0100\n",
      "  96 - L= 0.7233619 - Gamma=59.2162073 (M=  60) - s=0.0100\n",
      "  97 - L= 0.7241226 - Gamma=59.2213214 (M=  60) - s=0.0100\n",
      "  98 - L= 0.7248302 - Gamma=59.2215380 (M=  60) - s=0.0100\n",
      "  99 - L= 0.7253692 - Gamma=59.2212878 (M=  60) - s=0.0100\n",
      " 100 - L= 0.7257898 - Gamma=59.2210005 (M=  60) - s=0.0100\n",
      " 101 - L= 0.7261434 - Gamma=59.2210638 (M=  60) - s=0.0100\n",
      " 102 - L= 0.7264770 - Gamma=59.2206967 (M=  60) - s=0.0100\n",
      " 103 - L= 0.7267935 - Gamma=59.2199559 (M=  60) - s=0.0100\n",
      " 104 - L= 0.7270746 - Gamma=59.1958064 (M=  60) - s=0.0100\n",
      " 105 - L= 0.7273459 - Gamma=59.1965665 (M=  60) - s=0.0100\n",
      " 106 - L= 0.7274709 - Gamma=59.1969361 (M=  60) - s=0.0100\n",
      " 107 - L= 0.7275569 - Gamma=59.1969828 (M=  60) - s=0.0100\n",
      " 108 - L= 0.7276313 - Gamma=59.2033156 (M=  60) - s=0.0100\n",
      " 109 - L= 0.7277031 - Gamma=59.2046550 (M=  60) - s=0.0100\n",
      " 110 - L= 0.7277716 - Gamma=59.1470897 (M=  60) - s=0.0100\n",
      " 111 - L= 0.7278331 - Gamma=59.1469621 (M=  60) - s=0.0100\n",
      " 112 - L= 0.7278776 - Gamma=59.1469808 (M=  60) - s=0.0100\n",
      " 113 - L= 0.7279122 - Gamma=59.1488820 (M=  60) - s=0.0100\n",
      " 114 - L= 0.7279420 - Gamma=59.1489028 (M=  60) - s=0.0100\n",
      " 115 - L= 0.7279485 - Gamma=59.1489490 (M=  60) - s=0.0100\n",
      " 116 - L= 0.7279545 - Gamma=59.1489621 (M=  60) - s=0.0100\n",
      " 117 - L= 0.7279595 - Gamma=59.1489372 (M=  60) - s=0.0100\n",
      " 118 - L= 0.7279623 - Gamma=59.1522203 (M=  60) - s=0.0100\n",
      " 119 - L= 0.7279646 - Gamma=59.1517776 (M=  60) - s=0.0100\n",
      " 120 - L= 0.7279667 - Gamma=59.1517541 (M=  60) - s=0.0100\n",
      " 121 - L= 0.7279686 - Gamma=59.1538938 (M=  60) - s=0.0100\n",
      " 122 - L= 0.7279700 - Gamma=59.1539209 (M=  60) - s=0.0100\n",
      " 123 - L= 0.7279706 - Gamma=59.1544628 (M=  60) - s=0.0100\n",
      " 124 - L= 0.7279710 - Gamma=59.1544845 (M=  60) - s=0.0100\n",
      " 125 - L= 0.7279713 - Gamma=59.1544694 (M=  60) - s=0.0100\n",
      " 126 - L= 0.7279715 - Gamma=59.1545454 (M=  60) - s=0.0100\n",
      " 127 - L= 0.7279717 - Gamma=59.1546621 (M=  60) - s=0.0100\n",
      " 128 - L= 0.7279719 - Gamma=59.1545540 (M=  60) - s=0.0100\n",
      " 129 - L= 0.7279720 - Gamma=59.1545546 (M=  60) - s=0.0100\n",
      " 130 - L= 0.7279721 - Gamma=59.1521347 (M=  60) - s=0.0100\n",
      " 131 - L= 0.7279722 - Gamma=59.1521702 (M=  60) - s=0.0100\n",
      " 132 - L= 0.7279723 - Gamma=59.1521783 (M=  60) - s=0.0100\n",
      " 133 - L= 0.7279723 - Gamma=59.1521728 (M=  60) - s=0.0100\n",
      " 134 - L= 0.7279724 - Gamma=59.1521757 (M=  60) - s=0.0100\n",
      " 135 - L= 0.7279724 - Gamma=59.1521849 (M=  60) - s=0.0100\n",
      " 136 - L= 0.7279725 - Gamma=59.1522169 (M=  60) - s=0.0100\n",
      " 137 - L= 0.7279725 - Gamma=59.1522172 (M=  60) - s=0.0100\n",
      " 138 - L= 0.7279726 - Gamma=59.1522159 (M=  60) - s=0.0100\n",
      " 139 - L= 0.7279726 - Gamma=59.1522140 (M=  60) - s=0.0100\n",
      " 140 - L= 0.7279726 - Gamma=59.1522147 (M=  60) - s=0.0100\n",
      " 141 - L= 0.7279726 - Gamma=59.1522153 (M=  60) - s=0.0100\n",
      " 142 - L= 0.7279727 - Gamma=59.1522152 (M=  60) - s=0.0100\n",
      " 143 - L= 0.7279727 - Gamma=59.1522208 (M=  60) - s=0.0100\n",
      " 144 - L= 0.7279727 - Gamma=59.1522207 (M=  60) - s=0.0100\n",
      " 145 - L= 0.7279727 - Gamma=59.1522208 (M=  60) - s=0.0100\n",
      " 146 - L= 0.7279727 - Gamma=59.1522209 (M=  60) - s=0.0100\n",
      " 147 - L= 0.7279727 - Gamma=59.1522195 (M=  60) - s=0.0100\n",
      " 148 - L= 0.7279728 - Gamma=59.1522197 (M=  60) - s=0.0100\n",
      " 149 - L= 0.7279728 - Gamma=59.1522196 (M=  60) - s=0.0100\n",
      " 150 - L= 0.7279728 - Gamma=59.1523614 (M=  60) - s=0.0100\n",
      " 151 - L= 0.7279728 - Gamma=59.1523620 (M=  60) - s=0.0100\n",
      " 152 - L= 0.7279728 - Gamma=59.1523659 (M=  60) - s=0.0100\n",
      " 153 - L= 0.7279728 - Gamma=59.1523668 (M=  60) - s=0.0100\n",
      " 154 - L= 0.7279728 - Gamma=59.1523686 (M=  60) - s=0.0100\n",
      " 155 - L= 0.7279728 - Gamma=59.1523688 (M=  60) - s=0.0100\n",
      " 156 - L= 0.7279728 - Gamma=59.1523688 (M=  60) - s=0.0100\n",
      " 157 - L= 0.7279728 - Gamma=59.1523687 (M=  60) - s=0.0100\n",
      " 158 - L= 0.7279728 - Gamma=59.1523684 (M=  60) - s=0.0100\n",
      " 159 - L= 0.7279728 - Gamma=59.1523684 (M=  60) - s=0.0100\n",
      "Stopping at iteration 159 - max_delta_ml=2.383526288708259e-07\n",
      "L=0.7279728118222354 - Gamma=59.15236838439787 (M=60) - s=0.01\n",
      "Initial alpha = [[ 0.06437648]]\n",
      "   1 - L=-1703.0930262 - Gamma= 1.9999657 (M=   2) - s=0.0100\n",
      "   2 - L=-1548.1546293 - Gamma= 2.9999163 (M=   3) - s=0.0100\n",
      "   3 - L=-1411.5582372 - Gamma= 3.9998615 (M=   4) - s=0.0100\n",
      "   4 - L=-1307.0082607 - Gamma= 4.9997871 (M=   5) - s=0.0100\n",
      "   5 - L=-1240.9524168 - Gamma= 5.9996729 (M=   6) - s=0.0100\n",
      "   6 - L=-1181.2254033 - Gamma= 6.9995472 (M=   7) - s=0.0100\n",
      "   7 - L=-1118.3471059 - Gamma= 7.9994277 (M=   8) - s=0.0100\n",
      "   8 - L=-1058.0569026 - Gamma= 8.9993002 (M=   9) - s=0.0100\n",
      "   9 - L=-1002.2285904 - Gamma= 9.9991638 (M=  10) - s=0.0100\n",
      "  10 - L=-941.3289388 - Gamma=10.9990373 (M=  11) - s=0.0100\n",
      "  11 - L=-890.3642428 - Gamma=11.9988898 (M=  12) - s=0.0100\n",
      "  12 - L=-842.5519369 - Gamma=12.9987271 (M=  13) - s=0.0100\n",
      "  13 - L=-779.8772802 - Gamma=13.9986027 (M=  14) - s=0.0100\n",
      "  14 - L=-726.9009661 - Gamma=14.9984505 (M=  15) - s=0.0100\n",
      "  15 - L=-671.8740315 - Gamma=15.9983102 (M=  16) - s=0.0100\n",
      "  16 - L=-623.8280975 - Gamma=16.9981458 (M=  17) - s=0.0100\n",
      "  17 - L=-577.1771303 - Gamma=17.9979834 (M=  18) - s=0.0100\n",
      "  18 - L=-529.4945697 - Gamma=18.9978221 (M=  19) - s=0.0100\n",
      "  19 - L=-485.8560537 - Gamma=19.9976486 (M=  20) - s=0.0100\n",
      "  20 - L=-443.3098880 - Gamma=20.9974572 (M=  21) - s=0.0100\n",
      "  21 - L=-406.7916010 - Gamma=21.9972481 (M=  22) - s=0.0100\n",
      "  22 - L=-376.9188759 - Gamma=22.9969873 (M=  23) - s=0.0100\n",
      "  23 - L=-345.1683787 - Gamma=23.9967392 (M=  24) - s=0.0100\n",
      "  24 - L=-319.6474053 - Gamma=24.9964211 (M=  25) - s=0.0100\n",
      "  25 - L=-293.4453621 - Gamma=25.9960920 (M=  26) - s=0.0100\n",
      "  26 - L=-265.9736005 - Gamma=26.9958083 (M=  27) - s=0.0100\n",
      "  27 - L=-245.2372856 - Gamma=27.9954124 (M=  28) - s=0.0100\n",
      "  28 - L=-224.6700106 - Gamma=28.9950266 (M=  29) - s=0.0100\n",
      "  29 - L=-203.5098072 - Gamma=29.9946402 (M=  30) - s=0.0100\n",
      "  30 - L=-186.6349482 - Gamma=30.9941881 (M=  31) - s=0.0100\n",
      "  31 - L=-168.6204173 - Gamma=31.9937662 (M=  32) - s=0.0100\n",
      "  32 - L=-153.0601518 - Gamma=32.9932844 (M=  33) - s=0.0100\n",
      "  33 - L=-137.1531702 - Gamma=33.9927811 (M=  34) - s=0.0100\n",
      "  34 - L=-118.2717677 - Gamma=34.9923064 (M=  35) - s=0.0100\n",
      "  35 - L=-100.4900453 - Gamma=35.9918069 (M=  36) - s=0.0100\n",
      "  36 - L=-100.4210507 - Gamma=34.9920334 (M=  35) - s=0.0100\n",
      "  37 - L=-84.7057423 - Gamma=35.9914919 (M=  36) - s=0.0100\n",
      "  38 - L=-71.3114973 - Gamma=36.9909120 (M=  37) - s=0.0100\n",
      "  39 - L=-60.6531816 - Gamma=37.9901426 (M=  38) - s=0.0100\n",
      "  40 - L=-52.1860810 - Gamma=38.9891815 (M=  39) - s=0.0100\n",
      "  41 - L=-44.9325010 - Gamma=39.9880914 (M=  40) - s=0.0100\n",
      "  42 - L=-37.7731233 - Gamma=40.9869926 (M=  41) - s=0.0100\n",
      "  43 - L=-32.7140682 - Gamma=41.9854774 (M=  42) - s=0.0100\n",
      "  44 - L=-26.9141611 - Gamma=42.9838269 (M=  43) - s=0.0100\n",
      "  45 - L=-21.5062916 - Gamma=43.9823726 (M=  44) - s=0.0100\n",
      "  46 - L=-17.1629399 - Gamma=44.9805954 (M=  45) - s=0.0100\n",
      "  47 - L=-13.0025634 - Gamma=45.9783928 (M=  46) - s=0.0100\n",
      "  48 - L=-7.7496188 - Gamma=46.9766282 (M=  47) - s=0.0100\n",
      "  49 - L=-5.7756102 - Gamma=47.9725551 (M=  48) - s=0.0100\n",
      "  50 - L=-4.0893335 - Gamma=48.9676290 (M=  49) - s=0.0100\n",
      "  51 - L=-3.0935787 - Gamma=49.9597911 (M=  50) - s=0.0100\n",
      "  52 - L=-2.2490489 - Gamma=50.9505345 (M=  51) - s=0.0100\n",
      "  53 - L=-1.2565792 - Gamma=51.9429475 (M=  52) - s=0.0100\n",
      "  54 - L=-0.7422937 - Gamma=52.9289540 (M=  53) - s=0.0100\n",
      "  55 - L=-0.3533912 - Gamma=53.9106872 (M=  54) - s=0.0100\n",
      "  56 - L= 0.0376579 - Gamma=54.8913329 (M=  55) - s=0.0100\n",
      "  57 - L= 0.2644248 - Gamma=55.8589246 (M=  56) - s=0.0100\n",
      "  58 - L= 0.3614584 - Gamma=56.7977764 (M=  57) - s=0.0100\n",
      "  59 - L= 0.4206481 - Gamma=57.7042488 (M=  58) - s=0.0100\n",
      "  60 - L= 0.5334358 - Gamma=58.6369463 (M=  59) - s=0.0100\n",
      "  61 - L= 0.5832211 - Gamma=59.5307386 (M=  60) - s=0.0100\n",
      "  62 - L= 0.5922383 - Gamma=59.5313737 (M=  60) - s=0.0100\n",
      "  63 - L= 0.6010705 - Gamma=59.5313970 (M=  60) - s=0.0100\n",
      "  64 - L= 0.6098868 - Gamma=59.5314835 (M=  60) - s=0.0100\n",
      "  65 - L= 0.6157967 - Gamma=59.5315949 (M=  60) - s=0.0100\n",
      "  66 - L= 0.6212933 - Gamma=59.5319974 (M=  60) - s=0.0100\n",
      "  67 - L= 0.6267472 - Gamma=59.5321182 (M=  60) - s=0.0100\n",
      "  68 - L= 0.6321715 - Gamma=59.5322969 (M=  60) - s=0.0100\n",
      "  69 - L= 0.6375831 - Gamma=59.5324685 (M=  60) - s=0.0100\n",
      "  70 - L= 0.6429616 - Gamma=59.5336037 (M=  60) - s=0.0100\n",
      "  71 - L= 0.6480638 - Gamma=59.5337240 (M=  60) - s=0.0100\n",
      "  72 - L= 0.6524798 - Gamma=59.5344625 (M=  60) - s=0.0100\n",
      "  73 - L= 0.6567322 - Gamma=59.5346030 (M=  60) - s=0.0100\n",
      "  74 - L= 0.6608827 - Gamma=59.5347311 (M=  60) - s=0.0100\n",
      "  75 - L= 0.6650055 - Gamma=59.5336212 (M=  60) - s=0.0100\n",
      "  76 - L= 0.6688489 - Gamma=59.5337402 (M=  60) - s=0.0100\n",
      "  77 - L= 0.6725480 - Gamma=59.5351883 (M=  60) - s=0.0100\n",
      "  78 - L= 0.6760166 - Gamma=59.5900707 (M=  60) - s=0.0100\n",
      "  79 - L= 0.6794599 - Gamma=59.5888871 (M=  60) - s=0.0100\n",
      "  80 - L= 0.6826900 - Gamma=60.0750399 (M=  61) - s=0.0100\n",
      "  81 - L= 0.6856057 - Gamma=60.0753500 (M=  61) - s=0.0100\n",
      "  82 - L= 0.6884340 - Gamma=60.0587781 (M=  61) - s=0.0100\n",
      "  83 - L= 0.6909033 - Gamma=60.0592086 (M=  61) - s=0.0100\n",
      "  84 - L= 0.6929348 - Gamma=60.0593134 (M=  61) - s=0.0100\n",
      "  85 - L= 0.6947377 - Gamma=60.0456625 (M=  61) - s=0.0100\n",
      "  86 - L= 0.6963885 - Gamma=60.0459001 (M=  61) - s=0.0100\n",
      "  87 - L= 0.6980306 - Gamma=60.0464175 (M=  61) - s=0.0100\n",
      "  88 - L= 0.6995547 - Gamma=60.0466485 (M=  61) - s=0.0100\n",
      "  89 - L= 0.7010510 - Gamma=60.0475748 (M=  61) - s=0.0100\n",
      "  90 - L= 0.7024940 - Gamma=60.0476999 (M=  61) - s=0.0100\n",
      "  91 - L= 0.7038956 - Gamma=60.0477711 (M=  61) - s=0.0100\n",
      "  92 - L= 0.7052386 - Gamma=60.0479882 (M=  61) - s=0.0100\n",
      "  93 - L= 0.7064894 - Gamma=60.0481205 (M=  61) - s=0.0100\n",
      "  94 - L= 0.7077390 - Gamma=59.9358742 (M=  61) - s=0.0100\n",
      "  95 - L= 0.7088887 - Gamma=59.9358953 (M=  61) - s=0.0100\n",
      "  96 - L= 0.7099682 - Gamma=59.9354007 (M=  61) - s=0.0100\n",
      "  97 - L= 0.7109992 - Gamma=59.9356768 (M=  61) - s=0.0100\n",
      "  98 - L= 0.7120215 - Gamma=59.9363805 (M=  61) - s=0.0100\n",
      "  99 - L= 0.7128710 - Gamma=59.9364203 (M=  61) - s=0.0100\n",
      " 100 - L= 0.7137190 - Gamma=59.9366086 (M=  61) - s=0.0100\n",
      " 101 - L= 0.7144308 - Gamma=59.9368027 (M=  61) - s=0.0100\n",
      " 102 - L= 0.7150487 - Gamma=59.9368661 (M=  61) - s=0.0100\n",
      " 103 - L= 0.7155519 - Gamma=59.9386592 (M=  61) - s=0.0100\n",
      " 104 - L= 0.7159113 - Gamma=59.9387478 (M=  61) - s=0.0100\n",
      " 105 - L= 0.7162496 - Gamma=59.9383459 (M=  61) - s=0.0100\n",
      " 106 - L= 0.7165653 - Gamma=59.9382021 (M=  61) - s=0.0100\n",
      " 107 - L= 0.7168537 - Gamma=60.0181449 (M=  61) - s=0.0100\n",
      " 108 - L= 0.7170821 - Gamma=60.0155475 (M=  61) - s=0.0100\n",
      " 109 - L= 0.7172906 - Gamma=60.0156069 (M=  61) - s=0.0100\n",
      " 110 - L= 0.7174968 - Gamma=60.0150704 (M=  61) - s=0.0100\n",
      " 111 - L= 0.7176631 - Gamma=60.0176621 (M=  61) - s=0.0100\n",
      " 112 - L= 0.7178256 - Gamma=60.0101506 (M=  61) - s=0.0100\n",
      " 113 - L= 0.7179785 - Gamma=60.0101037 (M=  61) - s=0.0100\n",
      " 114 - L= 0.7181014 - Gamma=60.0100304 (M=  61) - s=0.0100\n",
      " 115 - L= 0.7181879 - Gamma=59.9664713 (M=  61) - s=0.0100\n",
      " 116 - L= 0.7182460 - Gamma=59.9714193 (M=  61) - s=0.0100\n",
      " 117 - L= 0.7183019 - Gamma=59.9716398 (M=  61) - s=0.0100\n",
      " 118 - L= 0.7183348 - Gamma=59.9937872 (M=  61) - s=0.0100\n",
      " 119 - L= 0.7183461 - Gamma=59.9923356 (M=  61) - s=0.0100\n",
      " 120 - L= 0.7183567 - Gamma=59.9912922 (M=  61) - s=0.0100\n",
      " 121 - L= 0.7183661 - Gamma=59.9751976 (M=  61) - s=0.0100\n",
      " 122 - L= 0.7183748 - Gamma=59.9751775 (M=  61) - s=0.0100\n",
      " 123 - L= 0.7183828 - Gamma=59.9751965 (M=  61) - s=0.0100\n",
      " 124 - L= 0.7183879 - Gamma=59.9751367 (M=  61) - s=0.0100\n",
      " 125 - L= 0.7183925 - Gamma=59.9751841 (M=  61) - s=0.0100\n",
      " 126 - L= 0.7183962 - Gamma=59.9745369 (M=  61) - s=0.0100\n",
      " 127 - L= 0.7183998 - Gamma=59.9726264 (M=  61) - s=0.0100\n",
      " 128 - L= 0.7184031 - Gamma=59.9741882 (M=  61) - s=0.0100\n",
      " 129 - L= 0.7184057 - Gamma=59.9800227 (M=  61) - s=0.0100\n",
      " 130 - L= 0.7184080 - Gamma=59.9801402 (M=  61) - s=0.0100\n",
      " 131 - L= 0.7184100 - Gamma=59.9801801 (M=  61) - s=0.0100\n",
      " 132 - L= 0.7184119 - Gamma=59.9795947 (M=  61) - s=0.0100\n",
      " 133 - L= 0.7184132 - Gamma=59.9795926 (M=  61) - s=0.0100\n",
      " 134 - L= 0.7184140 - Gamma=59.9746937 (M=  61) - s=0.0100\n",
      " 135 - L= 0.7184145 - Gamma=59.9747014 (M=  61) - s=0.0100\n",
      " 136 - L= 0.7184150 - Gamma=59.9747020 (M=  61) - s=0.0100\n",
      " 137 - L= 0.7184154 - Gamma=59.9747011 (M=  61) - s=0.0100\n",
      " 138 - L= 0.7184157 - Gamma=59.9746971 (M=  61) - s=0.0100\n",
      " 139 - L= 0.7184161 - Gamma=59.9750594 (M=  61) - s=0.0100\n",
      " 140 - L= 0.7184164 - Gamma=59.9771679 (M=  61) - s=0.0100\n",
      " 141 - L= 0.7184167 - Gamma=59.9771659 (M=  61) - s=0.0100\n",
      " 142 - L= 0.7184170 - Gamma=59.9771630 (M=  61) - s=0.0100\n",
      " 143 - L= 0.7184172 - Gamma=59.9771274 (M=  61) - s=0.0100\n",
      " 144 - L= 0.7184174 - Gamma=59.9771355 (M=  61) - s=0.0100\n",
      " 145 - L= 0.7184176 - Gamma=59.9770541 (M=  61) - s=0.0100\n",
      " 146 - L= 0.7184178 - Gamma=59.9770365 (M=  61) - s=0.0100\n",
      " 147 - L= 0.7184180 - Gamma=59.9768457 (M=  61) - s=0.0100\n",
      " 148 - L= 0.7184182 - Gamma=59.9768436 (M=  61) - s=0.0100\n",
      " 149 - L= 0.7184183 - Gamma=59.9768439 (M=  61) - s=0.0100\n",
      " 150 - L= 0.7184185 - Gamma=59.9768466 (M=  61) - s=0.0100\n",
      " 151 - L= 0.7184187 - Gamma=59.9746785 (M=  61) - s=0.0100\n",
      " 152 - L= 0.7184188 - Gamma=59.9746778 (M=  61) - s=0.0100\n",
      " 153 - L= 0.7184190 - Gamma=59.9746814 (M=  61) - s=0.0100\n",
      " 154 - L= 0.7184191 - Gamma=59.9746819 (M=  61) - s=0.0100\n",
      " 155 - L= 0.7184192 - Gamma=59.9746803 (M=  61) - s=0.0100\n",
      " 156 - L= 0.7184194 - Gamma=59.9749741 (M=  61) - s=0.0100\n",
      " 157 - L= 0.7184195 - Gamma=59.9749732 (M=  61) - s=0.0100\n",
      " 158 - L= 0.7184195 - Gamma=59.9750284 (M=  61) - s=0.0100\n",
      " 159 - L= 0.7184196 - Gamma=59.9750285 (M=  61) - s=0.0100\n",
      " 160 - L= 0.7184197 - Gamma=59.9760287 (M=  61) - s=0.0100\n",
      " 161 - L= 0.7184198 - Gamma=59.9760298 (M=  61) - s=0.0100\n",
      " 162 - L= 0.7184198 - Gamma=59.9761112 (M=  61) - s=0.0100\n",
      " 163 - L= 0.7184199 - Gamma=59.9761114 (M=  61) - s=0.0100\n",
      " 164 - L= 0.7184199 - Gamma=59.9761105 (M=  61) - s=0.0100\n",
      " 165 - L= 0.7184200 - Gamma=59.9761781 (M=  61) - s=0.0100\n",
      " 166 - L= 0.7184200 - Gamma=59.9750026 (M=  61) - s=0.0100\n",
      " 167 - L= 0.7184201 - Gamma=59.9750041 (M=  61) - s=0.0100\n",
      " 168 - L= 0.7184201 - Gamma=59.9749992 (M=  61) - s=0.0100\n",
      " 169 - L= 0.7184201 - Gamma=59.9749994 (M=  61) - s=0.0100\n",
      " 170 - L= 0.7184201 - Gamma=59.9750003 (M=  61) - s=0.0100\n",
      " 171 - L= 0.7184201 - Gamma=59.9749978 (M=  61) - s=0.0100\n",
      " 172 - L= 0.7184202 - Gamma=59.9754433 (M=  61) - s=0.0100\n",
      " 173 - L= 0.7184202 - Gamma=59.9754456 (M=  61) - s=0.0100\n",
      " 174 - L= 0.7184202 - Gamma=59.9754443 (M=  61) - s=0.0100\n",
      " 175 - L= 0.7184202 - Gamma=59.9755613 (M=  61) - s=0.0100\n",
      " 176 - L= 0.7184202 - Gamma=59.9755128 (M=  61) - s=0.0100\n",
      " 177 - L= 0.7184202 - Gamma=59.9755127 (M=  61) - s=0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 178 - L= 0.7184202 - Gamma=59.9755707 (M=  61) - s=0.0100\n",
      " 179 - L= 0.7184202 - Gamma=59.9755708 (M=  61) - s=0.0100\n",
      " 180 - L= 0.7184202 - Gamma=59.9755365 (M=  61) - s=0.0100\n",
      " 181 - L= 0.7184203 - Gamma=59.9750999 (M=  61) - s=0.0100\n",
      " 182 - L= 0.7184203 - Gamma=59.9750527 (M=  61) - s=0.0100\n",
      " 183 - L= 0.7184203 - Gamma=59.9750526 (M=  61) - s=0.0100\n",
      " 184 - L= 0.7184203 - Gamma=59.9750528 (M=  61) - s=0.0100\n",
      " 185 - L= 0.7184203 - Gamma=59.9750525 (M=  61) - s=0.0100\n",
      " 186 - L= 0.7184203 - Gamma=59.9750537 (M=  61) - s=0.0100\n",
      " 187 - L= 0.7184203 - Gamma=59.9750521 (M=  61) - s=0.0100\n",
      " 188 - L= 0.7184203 - Gamma=59.9750518 (M=  61) - s=0.0100\n",
      " 189 - L= 0.7184203 - Gamma=59.9751041 (M=  61) - s=0.0100\n",
      " 190 - L= 0.7184203 - Gamma=59.9753226 (M=  61) - s=0.0100\n",
      " 191 - L= 0.7184203 - Gamma=59.9753226 (M=  61) - s=0.0100\n",
      "Stopping at iteration 191 - max_delta_ml=1.8527347949478645e-07\n",
      "L=0.7184202964619908 - Gamma=59.97532256020948 (M=61) - s=0.01\n",
      "Initial alpha = [[ 0.07481184]]\n",
      "   1 - L=-1833.4264615 - Gamma= 1.9999661 (M=   2) - s=0.0100\n",
      "   2 - L=-1545.4872011 - Gamma= 2.9999401 (M=   3) - s=0.0100\n",
      "   3 - L=-1405.2997994 - Gamma= 3.9998850 (M=   4) - s=0.0100\n",
      "   4 - L=-1306.5295636 - Gamma= 4.9998089 (M=   5) - s=0.0100\n",
      "   5 - L=-1213.4236933 - Gamma= 5.9997282 (M=   6) - s=0.0100\n",
      "   6 - L=-1150.7605597 - Gamma= 6.9996090 (M=   7) - s=0.0100\n",
      "   7 - L=-1095.1183206 - Gamma= 7.9994736 (M=   8) - s=0.0100\n",
      "   8 - L=-1048.1092501 - Gamma= 8.9993110 (M=   9) - s=0.0100\n",
      "   9 - L=-1000.9995646 - Gamma= 9.9991469 (M=  10) - s=0.0100\n",
      "  10 - L=-955.2630057 - Gamma=10.9989781 (M=  11) - s=0.0100\n",
      "  11 - L=-909.2818069 - Gamma=11.9987986 (M=  12) - s=0.0100\n",
      "  12 - L=-855.4002475 - Gamma=12.9986419 (M=  13) - s=0.0100\n",
      "  13 - L=-798.4098020 - Gamma=13.9984949 (M=  14) - s=0.0100\n",
      "  14 - L=-739.8401156 - Gamma=14.9983389 (M=  15) - s=0.0100\n",
      "  15 - L=-688.2868492 - Gamma=15.9981882 (M=  16) - s=0.0100\n",
      "  16 - L=-647.0684367 - Gamma=16.9980023 (M=  17) - s=0.0100\n",
      "  17 - L=-609.4215332 - Gamma=17.9977746 (M=  18) - s=0.0100\n",
      "  18 - L=-562.4060576 - Gamma=18.9975274 (M=  19) - s=0.0100\n",
      "  19 - L=-524.4781976 - Gamma=19.9973212 (M=  20) - s=0.0100\n",
      "  20 - L=-484.0742363 - Gamma=20.9970965 (M=  21) - s=0.0100\n",
      "  21 - L=-437.9833669 - Gamma=21.9969076 (M=  22) - s=0.0100\n",
      "  22 - L=-395.2351915 - Gamma=22.9967256 (M=  23) - s=0.0100\n",
      "  23 - L=-362.0906066 - Gamma=23.9964925 (M=  24) - s=0.0100\n",
      "  24 - L=-337.1555607 - Gamma=24.9961756 (M=  25) - s=0.0100\n",
      "  25 - L=-303.3900891 - Gamma=25.9959179 (M=  26) - s=0.0100\n",
      "  26 - L=-281.1125273 - Gamma=26.9955708 (M=  27) - s=0.0100\n",
      "  27 - L=-254.8672765 - Gamma=27.9952377 (M=  28) - s=0.0100\n",
      "  28 - L=-232.3625684 - Gamma=28.9948936 (M=  29) - s=0.0100\n",
      "  29 - L=-209.7122101 - Gamma=29.9945201 (M=  30) - s=0.0100\n",
      "  30 - L=-184.3708647 - Gamma=30.9941841 (M=  31) - s=0.0100\n",
      "  31 - L=-160.9519939 - Gamma=31.9938298 (M=  32) - s=0.0100\n",
      "  32 - L=-139.5930055 - Gamma=32.9934627 (M=  33) - s=0.0100\n",
      "  33 - L=-118.7785157 - Gamma=33.9930784 (M=  34) - s=0.0100\n",
      "  34 - L=-102.6986019 - Gamma=34.9925673 (M=  35) - s=0.0100\n",
      "  35 - L=-86.3289538 - Gamma=35.9920297 (M=  36) - s=0.0100\n",
      "  36 - L=-73.4839472 - Gamma=36.9913914 (M=  37) - s=0.0100\n",
      "  37 - L=-62.5504670 - Gamma=37.9906411 (M=  38) - s=0.0100\n",
      "  38 - L=-54.1337970 - Gamma=38.9897116 (M=  39) - s=0.0100\n",
      "  39 - L=-46.8630150 - Gamma=39.9885774 (M=  40) - s=0.0100\n",
      "  40 - L=-39.8368182 - Gamma=40.9874825 (M=  41) - s=0.0100\n",
      "  41 - L=-32.9516451 - Gamma=41.9862049 (M=  42) - s=0.0100\n",
      "  42 - L=-26.5434874 - Gamma=42.9843047 (M=  43) - s=0.0100\n",
      "  43 - L=-22.5990168 - Gamma=43.9805921 (M=  44) - s=0.0100\n",
      "  44 - L=-18.2250047 - Gamma=44.9786750 (M=  45) - s=0.0100\n",
      "  45 - L=-13.6062472 - Gamma=45.9765104 (M=  46) - s=0.0100\n",
      "  46 - L=-9.8702677 - Gamma=46.9740068 (M=  47) - s=0.0100\n",
      "  47 - L=-6.6830967 - Gamma=47.9715589 (M=  48) - s=0.0100\n",
      "  48 - L=-4.5434594 - Gamma=48.9667301 (M=  49) - s=0.0100\n",
      "  49 - L=-2.9608981 - Gamma=49.9613524 (M=  50) - s=0.0100\n",
      "  50 - L=-2.2104823 - Gamma=50.9515857 (M=  51) - s=0.0100\n",
      "  51 - L=-1.6397953 - Gamma=51.9386387 (M=  52) - s=0.0100\n",
      "  52 - L=-1.0871089 - Gamma=52.9242429 (M=  53) - s=0.0100\n",
      "  53 - L=-0.7378622 - Gamma=53.9023492 (M=  54) - s=0.0100\n",
      "  54 - L=-0.3445281 - Gamma=54.8804087 (M=  55) - s=0.0100\n",
      "  55 - L=-0.0254655 - Gamma=55.8571346 (M=  56) - s=0.0100\n",
      "  56 - L= 0.1932867 - Gamma=56.8202901 (M=  57) - s=0.0100\n",
      "  57 - L= 0.3216166 - Gamma=57.7552217 (M=  58) - s=0.0100\n",
      "  58 - L= 0.3739348 - Gamma=57.7557619 (M=  58) - s=0.0100\n",
      "  59 - L= 0.4204800 - Gamma=57.7562163 (M=  58) - s=0.0100\n",
      "  60 - L= 0.4381432 - Gamma=57.7562490 (M=  58) - s=0.0100\n",
      "  61 - L= 0.4551766 - Gamma=58.5448054 (M=  59) - s=0.0100\n",
      "  62 - L= 0.4719064 - Gamma=59.3130223 (M=  60) - s=0.0100\n",
      "  63 - L= 0.4864307 - Gamma=59.3134603 (M=  60) - s=0.0100\n",
      "  64 - L= 0.4955204 - Gamma=59.3136645 (M=  60) - s=0.0100\n",
      "  65 - L= 0.5038121 - Gamma=59.3138450 (M=  60) - s=0.0100\n",
      "  66 - L= 0.5120188 - Gamma=59.3138873 (M=  60) - s=0.0100\n",
      "  67 - L= 0.5200961 - Gamma=59.3140542 (M=  60) - s=0.0100\n",
      "  68 - L= 0.5281207 - Gamma=59.3142490 (M=  60) - s=0.0100\n",
      "  69 - L= 0.5357483 - Gamma=59.3143953 (M=  60) - s=0.0100\n",
      "  70 - L= 0.5426728 - Gamma=59.3147910 (M=  60) - s=0.0100\n",
      "  71 - L= 0.5492661 - Gamma=59.3150257 (M=  60) - s=0.0100\n",
      "  72 - L= 0.5556305 - Gamma=59.3152416 (M=  60) - s=0.0100\n",
      "  73 - L= 0.5617969 - Gamma=59.3123525 (M=  60) - s=0.0100\n",
      "  74 - L= 0.5673578 - Gamma=59.3123811 (M=  60) - s=0.0100\n",
      "  75 - L= 0.5724048 - Gamma=59.3126985 (M=  60) - s=0.0100\n",
      "  76 - L= 0.5769924 - Gamma=59.3036566 (M=  60) - s=0.0100\n",
      "  77 - L= 0.5813445 - Gamma=59.3198106 (M=  60) - s=0.0100\n",
      "  78 - L= 0.5856861 - Gamma=59.3200304 (M=  60) - s=0.0100\n",
      "  79 - L= 0.5900110 - Gamma=59.3202951 (M=  60) - s=0.0100\n",
      "  80 - L= 0.5940469 - Gamma=59.3211333 (M=  60) - s=0.0100\n",
      "  81 - L= 0.5980168 - Gamma=59.3214246 (M=  60) - s=0.0100\n",
      "  82 - L= 0.6018766 - Gamma=59.3217016 (M=  60) - s=0.0100\n",
      "  83 - L= 0.6056364 - Gamma=59.3219614 (M=  60) - s=0.0100\n",
      "  84 - L= 0.6093833 - Gamma=59.3216918 (M=  60) - s=0.0100\n",
      "  85 - L= 0.6131131 - Gamma=59.3231000 (M=  60) - s=0.0100\n",
      "  86 - L= 0.6162854 - Gamma=59.3213395 (M=  60) - s=0.0100\n",
      "  87 - L= 0.6193277 - Gamma=59.3193238 (M=  60) - s=0.0100\n",
      "  88 - L= 0.6223696 - Gamma=59.3194572 (M=  60) - s=0.0100\n",
      "  89 - L= 0.6253329 - Gamma=59.3130430 (M=  60) - s=0.0100\n",
      "  90 - L= 0.6283132 - Gamma=59.3232782 (M=  60) - s=0.0100\n",
      "  91 - L= 0.6309115 - Gamma=59.3240662 (M=  60) - s=0.0100\n",
      "  92 - L= 0.6334596 - Gamma=59.3064498 (M=  60) - s=0.0100\n",
      "  93 - L= 0.6357570 - Gamma=59.3067659 (M=  60) - s=0.0100\n",
      "  94 - L= 0.6379512 - Gamma=59.3085609 (M=  60) - s=0.0100\n",
      "  95 - L= 0.6398112 - Gamma=59.3082598 (M=  60) - s=0.0100\n",
      "  96 - L= 0.6416043 - Gamma=59.7428745 (M=  61) - s=0.0100\n",
      "  97 - L= 0.6431200 - Gamma=59.7439432 (M=  61) - s=0.0100\n",
      "  98 - L= 0.6446273 - Gamma=59.7434742 (M=  61) - s=0.0100\n",
      "  99 - L= 0.6460344 - Gamma=59.7457735 (M=  61) - s=0.0100\n",
      " 100 - L= 0.6474254 - Gamma=59.7460989 (M=  61) - s=0.0100\n",
      " 101 - L= 0.6487855 - Gamma=60.1460650 (M=  62) - s=0.0100\n",
      " 102 - L= 0.6499191 - Gamma=60.1483601 (M=  62) - s=0.0100\n",
      " 103 - L= 0.6509836 - Gamma=60.1482388 (M=  62) - s=0.0100\n",
      " 104 - L= 0.6516761 - Gamma=60.1556501 (M=  62) - s=0.0100\n",
      " 105 - L= 0.6523663 - Gamma=60.1558983 (M=  62) - s=0.0100\n",
      " 106 - L= 0.6529186 - Gamma=60.1547834 (M=  62) - s=0.0100\n",
      " 107 - L= 0.6533304 - Gamma=60.1548589 (M=  62) - s=0.0100\n",
      " 108 - L= 0.6536811 - Gamma=60.1589597 (M=  62) - s=0.0100\n",
      " 109 - L= 0.6540234 - Gamma=60.1587208 (M=  62) - s=0.0100\n",
      " 110 - L= 0.6543143 - Gamma=60.1587773 (M=  62) - s=0.0100\n",
      " 111 - L= 0.6545772 - Gamma=60.1586283 (M=  62) - s=0.0100\n",
      " 112 - L= 0.6548045 - Gamma=60.1637725 (M=  62) - s=0.0100\n",
      " 113 - L= 0.6550260 - Gamma=60.1638544 (M=  62) - s=0.0100\n",
      " 114 - L= 0.6552307 - Gamma=60.1639640 (M=  62) - s=0.0100\n",
      " 115 - L= 0.6554027 - Gamma=60.1501740 (M=  62) - s=0.0100\n",
      " 116 - L= 0.6554565 - Gamma=60.1240393 (M=  62) - s=0.0100\n",
      " 117 - L= 0.6555109 - Gamma=60.1202255 (M=  62) - s=0.0100\n",
      " 118 - L= 0.6555530 - Gamma=60.1206308 (M=  62) - s=0.0100\n",
      " 119 - L= 0.6555884 - Gamma=60.0984125 (M=  62) - s=0.0100\n",
      " 120 - L= 0.6556206 - Gamma=60.1010509 (M=  62) - s=0.0100\n",
      " 121 - L= 0.6556469 - Gamma=60.1408552 (M=  62) - s=0.0100\n",
      " 122 - L= 0.6556693 - Gamma=60.1415147 (M=  62) - s=0.0100\n",
      " 123 - L= 0.6556890 - Gamma=60.1417447 (M=  62) - s=0.0100\n",
      " 124 - L= 0.6557046 - Gamma=60.1418790 (M=  62) - s=0.0100\n",
      " 125 - L= 0.6557177 - Gamma=60.1424812 (M=  62) - s=0.0100\n",
      " 126 - L= 0.6557247 - Gamma=60.1423961 (M=  62) - s=0.0100\n",
      " 127 - L= 0.6557315 - Gamma=60.1422594 (M=  62) - s=0.0100\n",
      " 128 - L= 0.6557366 - Gamma=60.1332417 (M=  62) - s=0.0100\n",
      " 129 - L= 0.6557424 - Gamma=60.1540668 (M=  62) - s=0.0100\n",
      " 130 - L= 0.6557466 - Gamma=60.1537256 (M=  62) - s=0.0100\n",
      " 131 - L= 0.6557504 - Gamma=60.1463857 (M=  62) - s=0.0100\n",
      " 132 - L= 0.6557546 - Gamma=60.1486300 (M=  62) - s=0.0100\n",
      " 133 - L= 0.6557569 - Gamma=60.1600083 (M=  62) - s=0.0100\n",
      " 134 - L= 0.6557589 - Gamma=60.1599838 (M=  62) - s=0.0100\n",
      " 135 - L= 0.6557608 - Gamma=60.1542769 (M=  62) - s=0.0100\n",
      " 136 - L= 0.6557630 - Gamma=60.1534743 (M=  62) - s=0.0100\n",
      " 137 - L= 0.6557647 - Gamma=60.1644558 (M=  62) - s=0.0100\n",
      " 138 - L= 0.6557658 - Gamma=60.1646760 (M=  62) - s=0.0100\n",
      " 139 - L= 0.6557667 - Gamma=60.1651047 (M=  62) - s=0.0100\n",
      " 140 - L= 0.6557676 - Gamma=60.1649210 (M=  62) - s=0.0100\n",
      " 141 - L= 0.6557684 - Gamma=60.1649196 (M=  62) - s=0.0100\n",
      " 142 - L= 0.6557692 - Gamma=60.1649176 (M=  62) - s=0.0100\n",
      " 143 - L= 0.6557700 - Gamma=60.1649204 (M=  62) - s=0.0100\n",
      " 144 - L= 0.6557707 - Gamma=60.1649125 (M=  62) - s=0.0100\n",
      " 145 - L= 0.6557714 - Gamma=60.1616346 (M=  62) - s=0.0100\n",
      " 146 - L= 0.6557722 - Gamma=60.1679384 (M=  62) - s=0.0100\n",
      " 147 - L= 0.6557729 - Gamma=60.1643116 (M=  62) - s=0.0100\n",
      " 148 - L= 0.6557737 - Gamma=60.1643086 (M=  62) - s=0.0100\n",
      " 149 - L= 0.6557744 - Gamma=60.1642652 (M=  62) - s=0.0100\n",
      " 150 - L= 0.6557751 - Gamma=60.1645266 (M=  62) - s=0.0100\n",
      " 151 - L= 0.6557757 - Gamma=60.1645439 (M=  62) - s=0.0100\n",
      " 152 - L= 0.6557763 - Gamma=60.1645414 (M=  62) - s=0.0100\n",
      " 153 - L= 0.6557767 - Gamma=60.1645436 (M=  62) - s=0.0100\n",
      " 154 - L= 0.6557772 - Gamma=60.1645370 (M=  62) - s=0.0100\n",
      " 155 - L= 0.6557777 - Gamma=60.1645787 (M=  62) - s=0.0100\n",
      " 156 - L= 0.6557781 - Gamma=60.1645371 (M=  62) - s=0.0100\n",
      " 157 - L= 0.6557785 - Gamma=60.1645379 (M=  62) - s=0.0100\n",
      " 158 - L= 0.6557789 - Gamma=60.1645285 (M=  62) - s=0.0100\n",
      " 159 - L= 0.6557792 - Gamma=60.1645247 (M=  62) - s=0.0100\n",
      " 160 - L= 0.6557796 - Gamma=60.1645321 (M=  62) - s=0.0100\n",
      " 161 - L= 0.6557798 - Gamma=60.1646183 (M=  62) - s=0.0100\n",
      " 162 - L= 0.6557801 - Gamma=60.1690210 (M=  62) - s=0.0100\n",
      " 163 - L= 0.6557805 - Gamma=60.1696807 (M=  62) - s=0.0100\n",
      " 164 - L= 0.6557807 - Gamma=60.1697076 (M=  62) - s=0.0100\n",
      " 165 - L= 0.6557810 - Gamma=60.1697081 (M=  62) - s=0.0100\n",
      " 166 - L= 0.6557811 - Gamma=60.1728040 (M=  62) - s=0.0100\n",
      " 167 - L= 0.6557813 - Gamma=60.1725742 (M=  62) - s=0.0100\n",
      " 168 - L= 0.6557815 - Gamma=60.1709502 (M=  62) - s=0.0100\n",
      " 169 - L= 0.6557817 - Gamma=60.1690490 (M=  62) - s=0.0100\n",
      " 170 - L= 0.6557818 - Gamma=60.1690494 (M=  62) - s=0.0100\n",
      " 171 - L= 0.6557820 - Gamma=60.1690487 (M=  62) - s=0.0100\n",
      " 172 - L= 0.6557821 - Gamma=60.1690540 (M=  62) - s=0.0100\n",
      " 173 - L= 0.6557823 - Gamma=60.1691042 (M=  62) - s=0.0100\n",
      " 174 - L= 0.6557824 - Gamma=60.1721357 (M=  62) - s=0.0100\n",
      " 175 - L= 0.6557825 - Gamma=60.1721238 (M=  62) - s=0.0100\n",
      " 176 - L= 0.6557827 - Gamma=60.1722114 (M=  62) - s=0.0100\n",
      " 177 - L= 0.6557828 - Gamma=60.1722123 (M=  62) - s=0.0100\n",
      " 178 - L= 0.6557829 - Gamma=60.1722140 (M=  62) - s=0.0100\n",
      " 179 - L= 0.6557830 - Gamma=60.1722134 (M=  62) - s=0.0100\n",
      " 180 - L= 0.6557831 - Gamma=60.1722305 (M=  62) - s=0.0100\n",
      " 181 - L= 0.6557832 - Gamma=60.1722313 (M=  62) - s=0.0100\n",
      " 182 - L= 0.6557833 - Gamma=60.1722314 (M=  62) - s=0.0100\n",
      " 183 - L= 0.6557833 - Gamma=60.1722170 (M=  62) - s=0.0100\n",
      " 184 - L= 0.6557834 - Gamma=60.1722165 (M=  62) - s=0.0100\n",
      " 185 - L= 0.6557835 - Gamma=60.1739797 (M=  62) - s=0.0100\n",
      " 186 - L= 0.6557835 - Gamma=60.1740915 (M=  62) - s=0.0100\n",
      " 187 - L= 0.6557836 - Gamma=60.1740433 (M=  62) - s=0.0100\n",
      " 188 - L= 0.6557836 - Gamma=60.1740448 (M=  62) - s=0.0100\n",
      " 189 - L= 0.6557837 - Gamma=60.1731465 (M=  62) - s=0.0100\n",
      " 190 - L= 0.6557837 - Gamma=60.1723648 (M=  62) - s=0.0100\n",
      " 191 - L= 0.6557837 - Gamma=60.1723640 (M=  62) - s=0.0100\n",
      " 192 - L= 0.6557838 - Gamma=60.1723653 (M=  62) - s=0.0100\n",
      " 193 - L= 0.6557838 - Gamma=60.1725637 (M=  62) - s=0.0100\n",
      " 194 - L= 0.6557838 - Gamma=60.1725575 (M=  62) - s=0.0100\n",
      " 195 - L= 0.6557839 - Gamma=60.1740970 (M=  62) - s=0.0100\n",
      " 196 - L= 0.6557839 - Gamma=60.1740970 (M=  62) - s=0.0100\n",
      " 197 - L= 0.6557839 - Gamma=60.1740074 (M=  62) - s=0.0100\n",
      " 198 - L= 0.6557840 - Gamma=60.1740082 (M=  62) - s=0.0100\n",
      " 199 - L= 0.6557840 - Gamma=60.1740300 (M=  62) - s=0.0100\n",
      " 200 - L= 0.6557840 - Gamma=60.1748804 (M=  62) - s=0.0100\n",
      "MODEL: RVM accuracy:  0.506024096386 +/-: 0.0168449607549\n",
      "Initial alpha = [[ 0.05297935]]\n",
      "   1 - L=-1744.0282321 - Gamma= 1.9999703 (M=   2) - s=0.0100\n",
      "   2 - L=-1510.3870987 - Gamma= 2.9999436 (M=   3) - s=0.0100\n",
      "   3 - L=-1371.6221438 - Gamma= 3.9998984 (M=   4) - s=0.0100\n",
      "   4 - L=-1291.1185354 - Gamma= 4.9998231 (M=   5) - s=0.0100\n",
      "   5 - L=-1235.0538350 - Gamma= 5.9997150 (M=   6) - s=0.0100\n",
      "   6 - L=-1197.9039250 - Gamma= 6.9995528 (M=   7) - s=0.0100\n",
      "   7 - L=-1162.5380871 - Gamma= 7.9993827 (M=   8) - s=0.0100\n",
      "   8 - L=-1127.6653520 - Gamma= 8.9992102 (M=   9) - s=0.0100\n",
      "   9 - L=-1093.6627035 - Gamma= 9.9990323 (M=  10) - s=0.0100\n",
      "  10 - L=-1058.3644277 - Gamma=10.9988609 (M=  11) - s=0.0100\n",
      "  11 - L=-1021.8909588 - Gamma=11.9986950 (M=  12) - s=0.0100\n",
      "  12 - L=-985.7063916 - Gamma=12.9985269 (M=  13) - s=0.0100\n",
      "  13 - L=-947.8135001 - Gamma=13.9983673 (M=  14) - s=0.0100\n",
      "  14 - L=-908.9482360 - Gamma=14.9982115 (M=  15) - s=0.0100\n",
      "  15 - L=-867.7727145 - Gamma=15.9980609 (M=  16) - s=0.0100\n",
      "  16 - L=-829.6218257 - Gamma=16.9979013 (M=  17) - s=0.0100\n",
      "  17 - L=-793.8485585 - Gamma=17.9977326 (M=  18) - s=0.0100\n",
      "  18 - L=-758.8364756 - Gamma=18.9975607 (M=  19) - s=0.0100\n",
      "  19 - L=-727.2674539 - Gamma=19.9973701 (M=  20) - s=0.0100\n",
      "  20 - L=-699.3817977 - Gamma=20.9971529 (M=  21) - s=0.0100\n",
      "  21 - L=-670.7013836 - Gamma=21.9969418 (M=  22) - s=0.0100\n",
      "  22 - L=-641.5286123 - Gamma=22.9967350 (M=  23) - s=0.0100\n",
      "  23 - L=-611.8993204 - Gamma=23.9965311 (M=  24) - s=0.0100\n",
      "  24 - L=-582.4689572 - Gamma=24.9963252 (M=  25) - s=0.0100\n",
      "  25 - L=-552.3957231 - Gamma=25.9961212 (M=  26) - s=0.0100\n",
      "  26 - L=-521.9647043 - Gamma=26.9959231 (M=  27) - s=0.0100\n",
      "  27 - L=-493.4146786 - Gamma=27.9957112 (M=  28) - s=0.0100\n",
      "  28 - L=-465.8144231 - Gamma=28.9954929 (M=  29) - s=0.0100\n",
      "  29 - L=-440.3831869 - Gamma=29.9952560 (M=  30) - s=0.0100\n",
      "  30 - L=-414.6363844 - Gamma=30.9950197 (M=  31) - s=0.0100\n",
      "  31 - L=-389.1536347 - Gamma=31.9947803 (M=  32) - s=0.0100\n",
      "  32 - L=-363.3447027 - Gamma=32.9945469 (M=  33) - s=0.0100\n",
      "  33 - L=-339.4254224 - Gamma=33.9942942 (M=  34) - s=0.0100\n",
      "  34 - L=-316.0004677 - Gamma=34.9940357 (M=  35) - s=0.0100\n",
      "  35 - L=-296.1450315 - Gamma=35.9937324 (M=  36) - s=0.0100\n",
      "  36 - L=-276.6067369 - Gamma=36.9934222 (M=  37) - s=0.0100\n",
      "  37 - L=-257.3276700 - Gamma=37.9931095 (M=  38) - s=0.0100\n",
      "  38 - L=-240.0114176 - Gamma=38.9927613 (M=  39) - s=0.0100\n",
      "  39 - L=-223.6827057 - Gamma=39.9923925 (M=  40) - s=0.0100\n",
      "  40 - L=-208.0026477 - Gamma=40.9920051 (M=  41) - s=0.0100\n",
      "  41 - L=-193.4162401 - Gamma=41.9915932 (M=  42) - s=0.0100\n",
      "  42 - L=-180.0467380 - Gamma=42.9911426 (M=  43) - s=0.0100\n",
      "  43 - L=-166.9178125 - Gamma=43.9906841 (M=  44) - s=0.0100\n",
      "  44 - L=-153.7042149 - Gamma=44.9902286 (M=  45) - s=0.0100\n",
      "  45 - L=-141.9875825 - Gamma=45.9897139 (M=  46) - s=0.0100\n",
      "  46 - L=-130.2270969 - Gamma=46.9892016 (M=  47) - s=0.0100\n",
      "  47 - L=-118.7521888 - Gamma=47.9886765 (M=  48) - s=0.0100\n",
      "  48 - L=-108.5600884 - Gamma=48.9880883 (M=  49) - s=0.0100\n",
      "  49 - L=-98.9886009 - Gamma=49.9874586 (M=  50) - s=0.0100\n",
      "  50 - L=-90.2958046 - Gamma=50.9867687 (M=  51) - s=0.0100\n",
      "  51 - L=-81.6932402 - Gamma=51.9860709 (M=  52) - s=0.0100\n",
      "  52 - L=-73.2683238 - Gamma=52.9853592 (M=  53) - s=0.0100\n",
      "  53 - L=-64.9236582 - Gamma=53.9846415 (M=  54) - s=0.0100\n",
      "  54 - L=-57.6028355 - Gamma=54.9838239 (M=  55) - s=0.0100\n",
      "  55 - L=-51.1345780 - Gamma=55.9828987 (M=  56) - s=0.0100\n",
      "  56 - L=-45.5165723 - Gamma=56.9818344 (M=  57) - s=0.0100\n",
      "  57 - L=-40.2519614 - Gamma=57.9806992 (M=  58) - s=0.0100\n",
      "  58 - L=-35.9374367 - Gamma=58.9793175 (M=  59) - s=0.0100\n",
      "  59 - L=-31.7510365 - Gamma=59.9778930 (M=  60) - s=0.0100\n",
      "  60 - L=-28.1428627 - Gamma=60.9762438 (M=  61) - s=0.0100\n",
      "  61 - L=-24.8786388 - Gamma=61.9744228 (M=  62) - s=0.0100\n",
      "  62 - L=-21.8996970 - Gamma=62.9724296 (M=  63) - s=0.0100\n",
      "  63 - L=-18.9400691 - Gamma=63.9704233 (M=  64) - s=0.0100\n",
      "  64 - L=-16.0140776 - Gamma=64.9683877 (M=  65) - s=0.0100\n",
      "  65 - L=-13.0506614 - Gamma=65.9663832 (M=  66) - s=0.0100\n",
      "  66 - L=-10.9355753 - Gamma=66.9635898 (M=  67) - s=0.0100\n",
      "  67 - L=-8.8918595 - Gamma=67.9606999 (M=  68) - s=0.0100\n",
      "  68 - L=-7.0904134 - Gamma=68.9574288 (M=  69) - s=0.0100\n",
      "  69 - L=-5.8372165 - Gamma=69.9527642 (M=  70) - s=0.0100\n",
      "  70 - L=-4.8054295 - Gamma=70.9471282 (M=  71) - s=0.0100\n",
      "  71 - L=-3.8024647 - Gamma=71.9413359 (M=  72) - s=0.0100\n",
      "  72 - L=-2.8278911 - Gamma=72.9353799 (M=  73) - s=0.0100\n",
      "  73 - L=-2.1900389 - Gamma=73.9264182 (M=  74) - s=0.0100\n",
      "  74 - L=-1.5993090 - Gamma=74.9167751 (M=  75) - s=0.0100\n",
      "  75 - L=-1.0661585 - Gamma=75.9061420 (M=  76) - s=0.0100\n",
      "  76 - L=-0.6126852 - Gamma=76.8937451 (M=  77) - s=0.0100\n",
      "  77 - L=-0.2093417 - Gamma=77.8798969 (M=  78) - s=0.0100\n",
      "  78 - L= 0.0427815 - Gamma=78.8584818 (M=  79) - s=0.0100\n",
      "  79 - L= 0.1521853 - Gamma=79.8135662 (M=  80) - s=0.0100\n",
      "  80 - L= 0.2066027 - Gamma=80.7339726 (M=  81) - s=0.0100\n",
      "  81 - L= 0.2220309 - Gamma=80.7339855 (M=  81) - s=0.0100\n",
      "  82 - L= 0.2356384 - Gamma=80.7327493 (M=  81) - s=0.0100\n",
      "  83 - L= 0.2490878 - Gamma=81.5244825 (M=  82) - s=0.0100\n",
      "  84 - L= 0.2573497 - Gamma=81.5246155 (M=  82) - s=0.0100\n",
      "  85 - L= 0.2640335 - Gamma=81.5246374 (M=  82) - s=0.0100\n",
      "  86 - L= 0.2704031 - Gamma=81.5247423 (M=  82) - s=0.0100\n",
      "  87 - L= 0.2767400 - Gamma=81.5248604 (M=  82) - s=0.0100\n",
      "  88 - L= 0.2830000 - Gamma=81.5249369 (M=  82) - s=0.0100\n",
      "  89 - L= 0.2885940 - Gamma=81.5250540 (M=  82) - s=0.0100\n",
      "  90 - L= 0.2930167 - Gamma=81.5251609 (M=  82) - s=0.0100\n",
      "  91 - L= 0.2968461 - Gamma=81.5252081 (M=  82) - s=0.0100\n",
      "  92 - L= 0.3002138 - Gamma=81.5253054 (M=  82) - s=0.0100\n",
      "  93 - L= 0.3026612 - Gamma=81.5253906 (M=  82) - s=0.0100\n",
      "  94 - L= 0.3050697 - Gamma=81.5254771 (M=  82) - s=0.0100\n",
      "  95 - L= 0.3073481 - Gamma=81.5255625 (M=  82) - s=0.0100\n",
      "  96 - L= 0.3094058 - Gamma=81.5256672 (M=  82) - s=0.0100\n",
      "  97 - L= 0.3113390 - Gamma=81.5257775 (M=  82) - s=0.0100\n",
      "  98 - L= 0.3129231 - Gamma=81.5258782 (M=  82) - s=0.0100\n",
      "  99 - L= 0.3140750 - Gamma=81.5259666 (M=  82) - s=0.0100\n",
      " 100 - L= 0.3149941 - Gamma=81.5260599 (M=  82) - s=0.0100\n",
      " 101 - L= 0.3159017 - Gamma=81.5261538 (M=  82) - s=0.0100\n",
      " 102 - L= 0.3166535 - Gamma=81.5262291 (M=  82) - s=0.0100\n",
      " 103 - L= 0.3173064 - Gamma=81.5262883 (M=  82) - s=0.0100\n",
      " 104 - L= 0.3179556 - Gamma=81.5263607 (M=  82) - s=0.0100\n",
      " 105 - L= 0.3185822 - Gamma=81.5264196 (M=  82) - s=0.0100\n",
      " 106 - L= 0.3191651 - Gamma=81.5264907 (M=  82) - s=0.0100\n",
      " 107 - L= 0.3195954 - Gamma=81.5265831 (M=  82) - s=0.0100\n",
      " 108 - L= 0.3200112 - Gamma=81.5266341 (M=  82) - s=0.0100\n",
      " 109 - L= 0.3204167 - Gamma=81.5267465 (M=  82) - s=0.0100\n",
      " 110 - L= 0.3207650 - Gamma=81.5268173 (M=  82) - s=0.0100\n",
      " 111 - L= 0.3210922 - Gamma=81.5268849 (M=  82) - s=0.0100\n",
      " 112 - L= 0.3213628 - Gamma=81.5268910 (M=  82) - s=0.0100\n",
      " 113 - L= 0.3216295 - Gamma=81.5269399 (M=  82) - s=0.0100\n",
      " 114 - L= 0.3218651 - Gamma=81.5269954 (M=  82) - s=0.0100\n",
      " 115 - L= 0.3220654 - Gamma=81.5270432 (M=  82) - s=0.0100\n",
      " 116 - L= 0.3222496 - Gamma=81.5271166 (M=  82) - s=0.0100\n",
      " 117 - L= 0.3224248 - Gamma=81.5271561 (M=  82) - s=0.0100\n",
      " 118 - L= 0.3225868 - Gamma=81.5272185 (M=  82) - s=0.0100\n",
      " 119 - L= 0.3227467 - Gamma=81.5272528 (M=  82) - s=0.0100\n",
      " 120 - L= 0.3228871 - Gamma=81.5273097 (M=  82) - s=0.0100\n",
      " 121 - L= 0.3230267 - Gamma=81.5273941 (M=  82) - s=0.0100\n",
      " 122 - L= 0.3231566 - Gamma=81.5274611 (M=  82) - s=0.0100\n",
      " 123 - L= 0.3232846 - Gamma=81.5275537 (M=  82) - s=0.0100\n",
      " 124 - L= 0.3234029 - Gamma=81.5275944 (M=  82) - s=0.0100\n",
      " 125 - L= 0.3234994 - Gamma=81.5276674 (M=  82) - s=0.0100\n",
      " 126 - L= 0.3235756 - Gamma=81.5277407 (M=  82) - s=0.0100\n",
      " 127 - L= 0.3236512 - Gamma=81.5278057 (M=  82) - s=0.0100\n",
      " 128 - L= 0.3237167 - Gamma=81.5278897 (M=  82) - s=0.0100\n",
      " 129 - L= 0.3237787 - Gamma=81.5279582 (M=  82) - s=0.0100\n",
      " 130 - L= 0.3238138 - Gamma=81.5279996 (M=  82) - s=0.0100\n",
      " 131 - L= 0.3238326 - Gamma=81.5280518 (M=  82) - s=0.0100\n",
      " 132 - L= 0.3238460 - Gamma=81.5280957 (M=  82) - s=0.0100\n",
      " 133 - L= 0.3238542 - Gamma=81.5281316 (M=  82) - s=0.0100\n",
      " 134 - L= 0.3238610 - Gamma=81.5281805 (M=  82) - s=0.0100\n",
      " 135 - L= 0.3238666 - Gamma=81.5282196 (M=  82) - s=0.0100\n",
      " 136 - L= 0.3238722 - Gamma=81.5282669 (M=  82) - s=0.0100\n",
      " 137 - L= 0.3238764 - Gamma=81.5283406 (M=  82) - s=0.0100\n",
      " 138 - L= 0.3238801 - Gamma=81.5283897 (M=  82) - s=0.0100\n",
      " 139 - L= 0.3238827 - Gamma=81.5284067 (M=  82) - s=0.0100\n",
      " 140 - L= 0.3238848 - Gamma=81.5284280 (M=  82) - s=0.0100\n",
      " 141 - L= 0.3238859 - Gamma=81.5284651 (M=  82) - s=0.0100\n",
      " 142 - L= 0.3238866 - Gamma=81.5284863 (M=  82) - s=0.0100\n",
      " 143 - L= 0.3238871 - Gamma=81.5283790 (M=  82) - s=0.0100\n",
      " 144 - L= 0.3238873 - Gamma=81.5283510 (M=  82) - s=0.0100\n",
      " 145 - L= 0.3238876 - Gamma=81.5283668 (M=  82) - s=0.0100\n",
      " 146 - L= 0.3238879 - Gamma=81.5283850 (M=  82) - s=0.0100\n",
      " 147 - L= 0.3238880 - Gamma=81.5283982 (M=  82) - s=0.0100\n",
      " 148 - L= 0.3238882 - Gamma=81.5284123 (M=  82) - s=0.0100\n",
      " 149 - L= 0.3238883 - Gamma=81.5284334 (M=  82) - s=0.0100\n",
      " 150 - L= 0.3238884 - Gamma=81.5283655 (M=  82) - s=0.0100\n",
      " 151 - L= 0.3238884 - Gamma=81.5284057 (M=  82) - s=0.0100\n",
      " 152 - L= 0.3238885 - Gamma=81.5284250 (M=  82) - s=0.0100\n",
      " 153 - L= 0.3238885 - Gamma=81.5284736 (M=  82) - s=0.0100\n",
      " 154 - L= 0.3238886 - Gamma=81.5284710 (M=  82) - s=0.0100\n",
      " 155 - L= 0.3238886 - Gamma=81.5284968 (M=  82) - s=0.0100\n",
      " 156 - L= 0.3238886 - Gamma=81.5284827 (M=  82) - s=0.0100\n",
      " 157 - L= 0.3238886 - Gamma=81.5284949 (M=  82) - s=0.0100\n",
      " 158 - L= 0.3238886 - Gamma=81.5284976 (M=  82) - s=0.0100\n",
      " 159 - L= 0.3238886 - Gamma=81.5283790 (M=  82) - s=0.0100\n",
      " 160 - L= 0.3238886 - Gamma=81.5283820 (M=  82) - s=0.0100\n",
      " 161 - L= 0.3238886 - Gamma=81.5283820 (M=  82) - s=0.0100\n",
      "Stopping at iteration 161 - max_delta_ml=1.055000637877686e-07\n",
      "L=0.32388863966289894 - Gamma=81.52838198762156 (M=82) - s=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 0s - loss: 0.5896 - acc: 0.6462 - val_loss: 0.4520 - val_acc: 0.7778\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 0s - loss: 0.2826 - acc: 0.9231 - val_loss: 0.2547 - val_acc: 0.9444\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 0s - loss: 0.0670 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 0s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 1.0000\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s - loss: 0.0156 - acc: 0.9848 - val_loss: 9.8460e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s - loss: 7.9814e-04 - acc: 1.0000 - val_loss: 5.4758e-05 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s - loss: 2.3715e-04 - acc: 1.0000 - val_loss: 4.0852e-05 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s - loss: 1.5890e-04 - acc: 1.0000 - val_loss: 3.0065e-05 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s - loss: 2.3771e-04 - acc: 1.0000 - val_loss: 1.5912e-05 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 5.5226e-05 - acc: 1.0000 - val_loss: 1.0309e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 6.8960e-05 - acc: 1.0000 - val_loss: 5.9055e-06 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 4.4205e-05 - acc: 1.0000 - val_loss: 3.6535e-06 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 1.7005e-05 - acc: 1.0000 - val_loss: 2.7299e-06 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 1.8981e-05 - acc: 1.0000 - val_loss: 1.8388e-06 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 6.6759e-06 - acc: 1.0000 - val_loss: 8.1687e-07 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 1.0091e-05 - acc: 1.0000 - val_loss: 4.5083e-07 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 4.8893e-06 - acc: 1.0000 - val_loss: 2.4979e-07 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 1.3663e-06 - acc: 1.0000 - val_loss: 2.1680e-07 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 4.3070e-06 - acc: 1.0000 - val_loss: 1.3727e-07 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 7.9895e-07 - acc: 1.0000 - val_loss: 1.5154e-07 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 7.6405e-07 - acc: 1.0000 - val_loss: 1.3945e-07 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 3.7563e-07 - acc: 1.0000 - val_loss: 1.3075e-07 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 1.6270e-07 - acc: 1.0000 - val_loss: 1.2803e-07 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 3.5046e-07 - acc: 1.0000 - val_loss: 1.1902e-07 - val_acc: 1.0000\n",
      "MODEL: DNN accuracy:  1.0 +/-: 0.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (83, 83, 1) and class vector (83,)\n",
      "Train on 65 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 0s - loss: 0.7344 - acc: 0.5846 - val_loss: 0.6766 - val_acc: 0.6111\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 0s - loss: 0.6000 - acc: 0.6923 - val_loss: 0.6574 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 0s - loss: 0.5306 - acc: 0.7231 - val_loss: 0.6594 - val_acc: 0.5556\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 0s - loss: 0.5250 - acc: 0.7231 - val_loss: 0.6668 - val_acc: 0.6111\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 0s - loss: 0.4577 - acc: 0.7692 - val_loss: 0.6331 - val_acc: 0.6111\n",
      "Train on 66 samples, validate on 17 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s - loss: 0.5030 - acc: 0.7727 - val_loss: 0.3755 - val_acc: 0.9412\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s - loss: 0.3452 - acc: 0.8636 - val_loss: 0.3501 - val_acc: 0.8235\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s - loss: 0.3159 - acc: 0.8485 - val_loss: 0.4460 - val_acc: 0.7059\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s - loss: 0.3215 - acc: 0.8939 - val_loss: 0.5827 - val_acc: 0.6471\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s - loss: 0.2074 - acc: 0.9697 - val_loss: 0.5102 - val_acc: 0.6471\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.2866 - acc: 0.8358 - val_loss: 0.1444 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.2251 - acc: 0.9403 - val_loss: 0.1844 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.1509 - acc: 0.9701 - val_loss: 0.0963 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.1144 - acc: 0.9851 - val_loss: 0.1245 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.1102 - acc: 0.9851 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.0848 - acc: 0.9851 - val_loss: 0.0292 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s - loss: 0.0786 - acc: 0.9851 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.0449 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Train on 67 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 0s - loss: 0.0707 - acc: 0.9851 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0295 - acc: 1.000 - 0s - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.843373493976 +/-: 0.0337798156956\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "METHOD_LIST = ['ExtraTrees', 'RandomForest', 'GBM', 'AdaBoost', 'LR', 'SVM', 'MLNN', 'XGB'] # XGB\n",
    "Runs = []\n",
    "nruns = 2\n",
    "SCALER = \"minmax\"\n",
    "GROUPING = \"mean\"\n",
    "DIM_TYPE = None # \"LDA\" # \"PCA\" # \"PLS\"\n",
    "DIM_NUM = 1000\n",
    "Results = None\n",
    "ACC = pd.DataFrame()\n",
    "Rocket.VIZ = False\n",
    "for i in range(0, nruns):\n",
    "    Rocket.SEED = np.random.randint(0,10000)\n",
    "    MODELS  = []\n",
    "    for idx, METHOD in enumerate(METHOD_LIST):\n",
    "        preds, class_model, accuracy = Rocket.classify_treatment(model_type = METHOD, \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "        MODELS.append({'method': METHOD, 'model': class_model})\n",
    "        ACC = ACC.append(accuracy, ignore_index= True)\n",
    "        preds = [pred_[1]for pred_ in preds]\n",
    "        #len(Rocket.DATA_merged[Rocket.DATA_merged[\"array-batch\"].isin([\"cohort 1\", \"cohort 2\", \"JB\", \"IA\", \"ALL-10\"])])\n",
    "        if Results is None:\n",
    "            Results = Rocket.DATA_merged_processed.copy()\n",
    "        Results['pred'] = preds\n",
    "        Results['method'] = METHOD\n",
    "        if idx == 0:\n",
    "            AllResults = Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]]\n",
    "        else:\n",
    "            AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], \n",
    "                                                    'pred', \n",
    "                                                    'method', \n",
    "                                                    Rocket.MODEL_PARAMETERS['target']]], \n",
    "                                      ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"RVM\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': METHOD, 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"RVM\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]], ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"DNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': METHOD, 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"DNN\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]],\n",
    "                                   ignore_index = True)\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"CNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': METHOD, 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"CNN\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]],\n",
    "                                   ignore_index = True)\n",
    "    \n",
    "    \n",
    "    AllResults[Rocket.MODEL_PARAMETERS['ID']] = AllResults[Rocket.MODEL_PARAMETERS['ID']].astype('str')\n",
    "    AllResults = AllResults.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "    #AllResults[AllResults['Treatment_risk_group_in_ALL10'].notnull()]\n",
    "    ####\n",
    "    ####\n",
    "    Runs.append(AllResults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on average: 0.8333333333333334 +- 0.006940318364567807, median: 0.891566265060241+-0.004976704597743681\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "         acc model       var\n",
      "0   0.674699    ET  0.003696\n",
      "1   0.807229    RF  0.006829\n",
      "2   0.891566   GBM  0.002170\n",
      "3   0.903614   ADA  0.006484\n",
      "4   0.891566    LR  0.006024\n",
      "5   0.939759   SVM  0.001465\n",
      "6   0.771084   GNB  0.007607\n",
      "7   0.891566  MLNN  0.003322\n",
      "8   0.903614   XGB  0.003929\n",
      "9   0.506024   RVM  0.016845\n",
      "10  0.987952   DNN  0.000524\n",
      "11  0.891566   CNN  0.016315\n",
      "12  0.650602    ET  0.001479\n",
      "13  0.722892    RF  0.008124\n",
      "14  0.915663   GBM  0.002297\n",
      "15  0.903614   ADA  0.006484\n",
      "16  0.891566    LR  0.006024\n",
      "17  0.939759   SVM  0.001465\n",
      "18  0.771084   GNB  0.007607\n",
      "19  0.891566  MLNN  0.003322\n",
      "20  0.903614   XGB  0.003929\n",
      "21  0.506024   RVM  0.016845\n",
      "22  1.000000   DNN  0.000000\n",
      "23  0.843373   CNN  0.033780\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on average: {} +- {}, median: {}+-{}\".format(ACC.mean()[0], ACC.mean()[1], ACC.median()[0], ACC.median()[1]))\n",
    "print(\"+\"*40)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "###########\n",
    "##Runs.append(AllResults)\n",
    "final_df = pandas.DataFrame()\n",
    "for idx, df in enumerate(Runs):\n",
    "    df['run'] = idx\n",
    "    final_df = final_df.append(df, ignore_index = True)\n",
    "#final_df = final_df.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "final_df['pred']= pandas.to_numeric(final_df['pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df_agg = final_df.groupby([Rocket.MODEL_PARAMETERS['ID']], as_index=True).agg({'pred': [numpy.mean, numpy.median, numpy.std]})['pred']\n",
    "\n",
    "final_df.to_csv(\"out/patient_results_\"+Rocket.SET_NAME+\".csv\")\n",
    "final_df_agg.to_csv(\"out/patient_results_agg_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop through models..\n",
    "### Tree weights\n",
    "top_genomes_weights = pandas.DataFrame()\n",
    "#top_genomes.index = Rocket.DATA_merged_processed\n",
    "for mod in MODELS:\n",
    "    if(mod['method'] in ['RandomForest', 'GBM', 'AdaBoost', 'ExtraTrees']): # RF, ET, GBM, ADA\n",
    "        top_genomes_weights[mod['method']]=mod['model'].feature_importances_\n",
    "        # column normalise\n",
    "        top_genomes_weights[mod['method']] = top_genomes_weights[mod['method']]/top_genomes_weights[mod['method']].max()\n",
    "        \n",
    "top_genomes_weights.index = Rocket.DATA_merged_processed.drop(['target', 'ID'], axis=1).columns\n",
    "#top_genomes['ALL'] = top_genomes.sum(axis=1)\n",
    "top_genomes_weights['MED'] = top_genomes_weights.median(axis=1)\n",
    "top_genomes_weights = top_genomes_weights.sort_values(by='MED', ascending=False)\n",
    "       \n",
    "### Coefficients\n",
    "top_genomes_coeffs = pandas.DataFrame()\n",
    "for mod in MODELS:\n",
    "    if(mod['method'] in ['LR', 'SVM']):\n",
    "        top_genomes_coeffs[mod['method']] = mod['model'].coef_[0,:]\n",
    "        top_genomes_coeffs[mod['method']] = top_genomes_coeffs[mod['method']]/top_genomes_coeffs[mod['method']].max() #\\\n",
    "                                                               #  -top_genomes[mod['method']].min())\n",
    "                                                                 #+numpy.abs(top_genomes[mod['method']].min())\n",
    "top_genomes_coeffs.index = Rocket.DATA_merged_processed.drop(['target', 'ID'], axis=1).columns\n",
    "#top_genomes['ALL'] = top_genomes.sum(axis=1)\n",
    "top_genomes_coeffs['MEAN'] = top_genomes_coeffs.mean(axis=1)\n",
    "top_genomes_coeffs = top_genomes_coeffs.sort_values(by='MEAN', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genomes_coeffs.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/coeffs_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genomes_weights.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/weights_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF9 = top_genomes_weights['RandomForest'].quantile(q=0.9)\n",
    "GBM9 = top_genomes_weights['GBM'].quantile(q=0.9)\n",
    "ADA9 = top_genomes_weights['AdaBoost'].quantile(q=0.9)\n",
    "ET9 = top_genomes_weights['ExtraTrees'].quantile(q=0.9)\n",
    "Overlapping_genomes = set(top_genomes_weights.loc[top_genomes_weights['RandomForest']>RF9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['GBM']>GBM9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['AdaBoost']>ADA9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['ExtraTrees']>ET9].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import*\n",
    "#from scipy.dspatial.distance import cosine\n",
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import cdist\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TransPosed = Rocket.DATA_all_samples.T # all microarrays, may be multiple per patient versus all probesets, may be multiple per genome\n",
    "Normal = Rocket.DATA_merged_processed.loc[:, (Rocket.DATA_merged_processed.columns !='target') & \n",
    "                                             (Rocket.DATA_merged_processed.columns !='ID')]\n",
    "#AllNormal = Rocket.DATA_merged\n",
    "#probeset_weights = Rocket.get_probeset_weights(method = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 9827_corr2.CEL, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'cosine', normalised = True, inflation = 2, minkowski_dim=1)\n",
    "##### apply Markov clustering\n",
    "#######################\n",
    "# non-distributed, non-sparse version, only for small-sized problems (N is order 1000)\n",
    "e = 2\n",
    "r = 2 \n",
    "epsilon = 1e-7\n",
    "convergence = 0.001\n",
    "num_iter = 10\n",
    "Orientation = 'col' # columnwise or rowwise\n",
    "\n",
    "# add loop\n",
    "def add_loop(df_matrix, value=0): \n",
    "    for i in df_matrix.index:\n",
    "        df_matrix.loc[i, i] = value\n",
    "    return df_matrix\n",
    "patient_sim = add_loop(patient_sim, 1)\n",
    "patient_sim = patient_sim - epsilon\n",
    "\n",
    "def normalise(sim, type = 'col'):\n",
    "    if(type == 'col'):\n",
    "        # column normalisation\n",
    "        for variable in sim.keys():\n",
    "            col_vec = sim[variable]\n",
    "            sum_val = sum([p for p in col_vec])\n",
    "            sim[variable] = sim[variable]/sum_val\n",
    "    elif (type == 'row'):\n",
    "        # row normalisation\n",
    "        for variable in sim.keys():\n",
    "            row_vec = sim.loc[variable, :]\n",
    "            sum_val = sum([p for p in row_vec])\n",
    "            sim.loc[variable,:] = sim.loc[variable,:]/sum_val\n",
    "    return sim\n",
    "\n",
    "# step E: expansion, get the nth power of the matrix\n",
    "def expansion(sim):\n",
    "    X = numpy.array(sim)\n",
    "    VarList = sim.keys()\n",
    "    if e == 1:\n",
    "        return sim\n",
    "    elif e > 1:        \n",
    "        return pandas.DataFrame(numpy.linalg.matrix_power(X, e), index = VarList, columns = VarList)\n",
    "     \n",
    "# step I: inflation, per column raise by rth power and column normalise\n",
    "def inflation(sim, type = 'col'):    \n",
    "    if type == 'col':\n",
    "        Axis = 0\n",
    "    elif type == 'row':\n",
    "        Axis = 1\n",
    "    return sim.apply(lambda x: x**r/sum(x**r), axis = Axis)\n",
    "\n",
    "# remove weak connections, values < epsilon\n",
    "def clean(sim):\n",
    "    return sim.applymap(lambda x:0 if x<epsilon else x)\n",
    "    \n",
    "def difference(old, new):\n",
    "    # relative zeroes over entire array\n",
    "    #return (new.apply(lambda x: numpy.ceil(x-epsilon)) - old.apply(lambda x: numpy.ceil(x-epsilon))).sum().sum()/len(old)**2    \n",
    "    return abs(new - old).sum().sum()/len(old)**2    \n",
    "\n",
    "#patient_sim = normalise(patient_sim, type = Orientation)\n",
    "_sim_a = patient_sim\n",
    "for i in range(0,num_iter):\n",
    "    # repeat E and I until convergence, the row-wise elements form the clusters.\n",
    "    _sim_b = clean(inflation(expansion(_sim_a), type = Orientation))\n",
    "    _sim_a = normalise(_sim_a, type = Orientation)\n",
    "    #if ((difference(_sim_a, _sim_b)) < convergence) & (i>0):\n",
    "    #    print(difference(_sim_a, _sim_b))\n",
    "    #    print(\"CONVERGED after \", i, \" iterations\")\n",
    "    #    break;\n",
    "    _sim_a = _sim_b\n",
    "\n",
    "result_mcl = clean(_sim_b)\n",
    "result_mcl.loc[result_mcl.loc['9827_corr2.CEL',:]>epsilon, '9827_corr2.CEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 patient clusters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'pearson', normalised = False, inflation=1, minkowski_dim=1)\n",
    "##### apply Affinity Propagation\n",
    "#######################\n",
    "X = numpy.array(patient_sim)\n",
    "af = AffinityPropagation(preference=-10).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "patient_clusters = patient_sim.keys()[cluster_centers_indices].values\n",
    "patient_cluster_members = af.labels_\n",
    "print(\"There are {} patient clusters\".format(n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AggResults = Rocket.DATA_merged\n",
    "AggResults = _helpers._preprocess(AggResults, Rclass = Rocket)\n",
    "#AggResults = _helpers._group_patients(AggResults, method = 'mean')\n",
    "AggResults['cluster_ap'] = patient_cluster_members\n",
    "\n",
    "#AggResults.groupby(['Treatment risk group in ALL10', 'cluster_ap']).agg({'Microarray file': pandas.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "AggResults['FU_RFS'] = pandas.to_numeric(AggResults['FU_RFS'])\n",
    "AggResults['FU_EFS'] = pandas.to_numeric(AggResults['FU_EFS'])\n",
    "AggResults['FU_OS'] = pandas.to_numeric(AggResults['FU_OS'])\n",
    "AggResults['WhiteBloodCellcount'] = pandas.to_numeric(AggResults['WhiteBloodCellcount'])\n",
    "AggResults['Age'] = pandas.to_numeric(AggResults['Age'])\n",
    "AggResults['Gender'] = pandas.to_numeric(AggResults['Gender'])\n",
    "AggResults['code_RFS']= pandas.to_numeric(AggResults['code_RFS'])\n",
    "AggResults['code_EFS']= pandas.to_numeric(AggResults['code_EFS'])\n",
    "AggResults['code_OS']= pandas.to_numeric(AggResults['code_OS'])\n",
    "\n",
    "AggResults['mutations_NOTCH_pathway'] = pandas.to_numeric(AggResults['mutations_NOTCH_pathway'])\n",
    "AggResults['mutations_PTEN_AKT_pathway'] = pandas.to_numeric(AggResults['mutations_PTEN_AKT_pathway'])\n",
    "AggResults['mutations_IL7R_pathway'] = pandas.to_numeric(AggResults['mutations_IL7R_pathway'])\n",
    "#AggResults.replace(to_replace=9999, value=0.5, inplace=True)\n",
    "AggResults[['mutations_NOTCH_pathway', \n",
    "            'mutations_PTEN_AKT_pathway', \n",
    "            'mutations_IL7R_pathway']] = AggResults[['mutations_NOTCH_pathway', \n",
    "                                                    'mutations_PTEN_AKT_pathway', \n",
    "                                                    'mutations_IL7R_pathway']].replace([9999],[numpy.nan],\n",
    "                                                                                       inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "AggResults['comb_mutations_NOTCH_IL7R'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_NOTCH_PTEN'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_PTEN_AKT_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN'] =  AggResults['mutations_PTEN_AKT_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN_NOTCH'] =  AggResults['mutations_PTEN_AKT_pathway']\\\n",
    "                                                + AggResults['mutations_IL7R_pathway']\\\n",
    "                                                + AggResults['mutations_NOTCH_pathway']\n",
    "\n",
    "\n",
    "patient_count = AggResults.groupby(['cluster_ap']).agg({'labnr_patient': pandas.Series.nunique})\n",
    "Clustered_by_patients_whitebloodcells = AggResults[AggResults['WhiteBloodCellcount'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'WhiteBloodCellcount': numpy.mean,\n",
    "    'Age': numpy.mean, \n",
    "    'Gender': numpy.mean})\n",
    "\n",
    "# Cancer_gene\n",
    "# Treatment_protocol\n",
    "# Treatment_risk_group_in_ALL_10\n",
    "\n",
    "Clustered_by_patients_CODE = AggResults.groupby(['cluster_ap']).agg(\n",
    "    {'code_RFS': numpy.mean, \n",
    "     'code_EFS': numpy.mean,\n",
    "     'code_OS': numpy.mean})\n",
    "\n",
    "Clustered_by_patients_FU_RFS = AggResults[AggResults['FU_RFS'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'FU_RFS': numpy.median, \n",
    "     'FU_EFS': numpy.median,\n",
    "     'FU_OS': numpy.median})\n",
    "Clustered_by_patients_NotchPath = AggResults[AggResults['mutations_NOTCH_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_NOTCH_pathway': numpy.mean})\n",
    "Clustered_by_patients_IL7RPath = AggResults[AggResults['mutations_IL7R_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_IL7R_pathway': numpy.mean})\n",
    "Clustered_by_patients_PTENAKTPath = AggResults[AggResults['mutations_PTEN_AKT_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_PTEN_AKT_pathway': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_IL7R = AggResults[AggResults['comb_mutations_NOTCH_IL7R'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_IL7R': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_PTEN = AggResults[AggResults['comb_mutations_NOTCH_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN = AggResults[AggResults['comb_mutations_IL7R_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN_NOTCH = AggResults[AggResults['comb_mutations_IL7R_PTEN_NOTCH'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN_NOTCH': numpy.mean})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_agg = pandas.merge(Clustered_by_patients_whitebloodcells, Clustered_by_patients_CODE, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN_NOTCH, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_IL7R, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_PTEN, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_FU_RFS, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_IL7RPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_NotchPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_PTENAKTPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, patient_count, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Cluster centers:\",patient_sim.keys()[cluster_centers_indices].values)\n",
    "print(patient_cluster_members)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    class_members = patient_cluster_members == k\n",
    "    cluster_center = X[cluster_centers_indices[k]]\n",
    "    plt.plot(X[class_members, 0], X[class_members, 1], col + '.', \n",
    "             label = patient_sim.keys()[cluster_centers_indices[k]])\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in X[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.title('Estimated number of clusters from Affinity Propagation: %d' % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### CREATE graph from similarity matrix\n",
    "##################\n",
    "# nodes\n",
    "VarList = TransPosed.keys()\n",
    "nodes = []\n",
    "node_index = 0\n",
    "for patient_name in VarList:\n",
    "    nodes.append((node_index, {'name': patient_name}))\n",
    "    node_index = node_index + 1\n",
    "\n",
    "edges = []\n",
    "# edges\n",
    "patient_sim = patient_similarity(Normal, sim_type = 'pearson', normalised = True, inflation=2)\n",
    "node_index_x = 0\n",
    "node_index_y = 0\n",
    "for patient_name_x in VarList:\n",
    "    for patient_name_y in VarList:        \n",
    "        edges.append((node_index_x, node_index_y, patient_sim.iloc[node_index_x, node_index_y]))\n",
    "        node_index_y = node_index_y + 1\n",
    "    node_index_x = node_index_x + 1\n",
    "    node_index_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(edges, weight = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:138: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  plt.hold(b)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.\n",
      "  warnings.warn(self.msg_depr_set % key)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0\n",
      "  warnings.warn(\"axes.hold is deprecated, will be removed in 3.0\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAFCCAYAAABSJMy8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f31beac128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### apply Spring-force\n",
    "#######################\n",
    "pos = nx.spring_layout(G, k = None, dim = 3, scale = 1.0)\n",
    "nx.draw_spring(G, k = 30, dim = 2, scale = 1.0, iterations =1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### APPLY community detector\n",
    "# maximize betweenness and modularity\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### LOAD IN DATA\n",
    "###################\n",
    "# https://stackoverflow.com/questions/14529838/apply-multiple-functions-to-multiple-groupby-columns\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
