{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++ Firing up RexR! ++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from RexR import *\n",
    "import _helpers\n",
    "Rocket = RexR(datalocation = None, #'_data/genomic_data/data.pkl', \n",
    "              seed = 3123, \n",
    "              debug = False, \n",
    "              write_out=True,\n",
    "              set_name = 'ALL_10') # data to read in ALL_10, or MELA\n",
    "Rocket.load_probeset_data();\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHOD_LIST = ['ExtraTrees', 'RandomForest', 'XGB'] #, 'NaiveBayes','MLNN', 'XGB'] # \n",
    "Runs = []\n",
    "nruns = 1\n",
    "SCALER = \"minmax\" # minmax, standard, normaliser\n",
    "GROUPING = \"mean\"\n",
    "DIM_TYPE =  None #\"LDA\", \"PCA\", \"PLS\" \n",
    "DIM_NUM = 500\n",
    "Results = None\n",
    "ACC = pd.DataFrame()\n",
    "Rocket.VIZ = False\n",
    "MODELS  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Prepping data, this may take a while..\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Grouping probesets\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 54613) and class vector (58,)\n",
      "MODEL: ET accuracy:  0.655172413793 +/-: 0.0148452419558\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 54613) and class vector (58,)\n",
      "MODEL: RF accuracy:  0.672413793103 +/-: 0.0311407775736\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 54613) and class vector (58,)\n",
      "MODEL: GBM accuracy:  0.706896551724 +/-: 0.0193672756098\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 54613) and class vector (58,)\n",
      "MODEL: ADA accuracy:  0.672413793103 +/-: 0.0123320001441\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 54613) and class vector (58,)\n",
      "MODEL: LR accuracy:  0.724137931034 +/-: 0.0249972975894\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 54613) and class vector (58,)\n",
      "MODEL: SVM accuracy:  0.724137931034 +/-: 0.0249972975894\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, nruns):\n",
    "    Rocket.SEED = np.random.randint(0,10000)    \n",
    "    for idx, METHOD in enumerate(METHOD_LIST):\n",
    "        preds, class_model, accuracy = Rocket.classify_treatment(model_type = METHOD, \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "        MODELS.append({'method': METHOD, 'model': class_model})\n",
    "        ACC = ACC.append(accuracy, ignore_index= True)\n",
    "        preds = [pred_[1]for pred_ in preds]\n",
    "        #len(Rocket.DATA_merged[Rocket.DATA_merged[\"array-batch\"].isin([\"cohort 1\", \"cohort 2\", \"JB\", \"IA\", \"ALL-10\"])])\n",
    "        if Results is None:\n",
    "            Results = Rocket.DATA_merged_processed.copy()\n",
    "        Results['pred'] = preds\n",
    "        Results['method'] = METHOD\n",
    "        if idx == 0:\n",
    "            AllResults = Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]]\n",
    "        else:\n",
    "            AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], \n",
    "                                                    'pred', \n",
    "                                                    'method', \n",
    "                                                    Rocket.MODEL_PARAMETERS['target']]], \n",
    "                                      ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 1) and class vector (58,)\n",
      "Initial alpha = [[ 0.2992679]]\n",
      "   1 - L=-1806.2159211 - Gamma= 0.9999701 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-2.2174816025093235e-18\n",
      "L=-1806.21592110324 - Gamma=0.9999700741052429 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19187211]]\n",
      "   1 - L=-1602.9254022 - Gamma= 0.9999808 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-2.6015361537697004e-17\n",
      "L=-1602.9254021934887 - Gamma=0.9999808131570636 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26646848]]\n",
      "   1 - L=-1761.5105091 - Gamma= 0.9999734 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-5.380330854024958e-17\n",
      "L=-1761.510509148557 - Gamma=0.9999733538617794 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.29111194]]\n",
      "   1 - L=-1757.7288371 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=7.689277756988464e-18\n",
      "L=-1757.7288371067928 - Gamma=0.9999708896538623 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40772308]]\n",
      "   1 - L=-1862.2422432 - Gamma= 0.9999592 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.3394705059844514e-17\n",
      "L=-1862.2422431917266 - Gamma=0.999959229354383 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22304674]]\n",
      "   1 - L=-1764.1625778 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-3.6908375648287015e-18\n",
      "L=-1764.1625778097944 - Gamma=0.9999776958232955 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"RVM\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "MODELS.append({'method': \"RVM\", 'model': class_model})\n",
    "ACC = ACC.append(accuracy, ignore_index = True)\n",
    "Results = Rocket.DATA_merged_processed.copy()\n",
    "preds = [pred_ for pred_ in preds]\n",
    "Results['pred'] = preds\n",
    "Results['method'] = \"RVM\"\n",
    "AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]], ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 58, 1) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.8436 - acc: 0.4348 - val_loss: 0.6523 - val_acc: 0.6667\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.7096 - acc: 0.5435 - val_loss: 0.6793 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6384 - acc: 0.6087 - val_loss: 0.6910 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6754 - acc: 0.5435 - val_loss: 0.6865 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6010 - acc: 0.6739 - val_loss: 0.6583 - val_acc: 0.6667\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5450 - acc: 0.8478 - val_loss: 0.5101 - val_acc: 0.8333\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5256 - acc: 0.6957 - val_loss: 0.5444 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4699 - acc: 0.7609 - val_loss: 0.5851 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4284 - acc: 0.8478 - val_loss: 0.5572 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.3650 - acc: 0.9348 - val_loss: 0.5679 - val_acc: 0.6667\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.3779 - acc: 0.8696 - val_loss: 0.2859 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.3703 - acc: 0.8043 - val_loss: 0.2365 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2606 - acc: 0.8913 - val_loss: 0.2965 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.2571 - acc: 0.9348 - val_loss: 0.2353 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.1633 - acc: 0.9783 - val_loss: 0.2107 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1368 - acc: 0.9787 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.1441 - acc: 0.9787 - val_loss: 0.1433 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.1359 - acc: 0.9787 - val_loss: 0.1355 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0809 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0968 - acc: 0.9787 - val_loss: 0.1074 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.0640 - acc: 0.9787 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0835 - acc: 0.9787 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0486 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0332 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.862068965517 +/-: 0.0269520412208\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 58, 1) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.8296 - acc: 0.3696 - val_loss: 0.6617 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6178 - acc: 0.6522 - val_loss: 0.6486 - val_acc: 0.6667\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.7104 - acc: 0.5435 - val_loss: 0.6491 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6069 - acc: 0.6087 - val_loss: 0.7033 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5082 - acc: 0.8696 - val_loss: 0.6433 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5422 - acc: 0.7391 - val_loss: 0.4609 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.4741 - acc: 0.8261 - val_loss: 0.4766 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.3662 - acc: 0.9348 - val_loss: 0.4750 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.3471 - acc: 0.8913 - val_loss: 0.5010 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.3076 - acc: 0.8913 - val_loss: 0.4939 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.3826 - acc: 0.8478 - val_loss: 0.3162 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.3412 - acc: 0.9130 - val_loss: 0.1987 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2306 - acc: 0.9565 - val_loss: 0.1962 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.1661 - acc: 0.9783 - val_loss: 0.1812 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.1548 - acc: 1.0000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1504 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.1318 - acc: 0.9787 - val_loss: 0.0746 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.1024 - acc: 0.9787 - val_loss: 0.0695 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.1047 - acc: 0.9787 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0780 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1814 - acc: 0.9149 - val_loss: 0.0666 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0606 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0666 - acc: 0.9787 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0259 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.862068965517 +/-: 0.0298256044392\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 58, 1) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.7788 - acc: 0.4783 - val_loss: 0.7277 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6506 - acc: 0.5870 - val_loss: 0.6873 - val_acc: 0.6667\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.7104 - acc: 0.5000 - val_loss: 0.7051 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6299 - acc: 0.6087 - val_loss: 0.6792 - val_acc: 0.4167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5913 - acc: 0.7826 - val_loss: 0.6685 - val_acc: 0.3333\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5832 - acc: 0.7391 - val_loss: 0.5010 - val_acc: 0.8333\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5766 - acc: 0.6957 - val_loss: 0.4974 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4864 - acc: 0.8696 - val_loss: 0.5221 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4243 - acc: 0.8696 - val_loss: 0.4485 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4522 - acc: 0.8043 - val_loss: 0.5392 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.3791 - acc: 0.9130 - val_loss: 0.2849 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.2709 - acc: 0.9348 - val_loss: 0.2560 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2079 - acc: 1.0000 - val_loss: 0.2304 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.1572 - acc: 0.9783 - val_loss: 0.2881 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.2371 - acc: 0.9565 - val_loss: 0.2426 - val_acc: 0.9167\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1635 - acc: 0.9787 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.1260 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0949 - acc: 1.0000 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0818 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0710 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.1689 - acc: 0.9149 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0549 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0456 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0284 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.0311 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "MODEL: CNN accuracy:  0.758620689655 +/-: 0.071046373365\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "nruns = 3\n",
    "for i in range(0, nruns):\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"CNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': \"CNN\", 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"CNN\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]],\n",
    "                                   ignore_index = True)\n",
    "\n",
    "    AllResults[Rocket.MODEL_PARAMETERS['ID']] = AllResults[Rocket.MODEL_PARAMETERS['ID']].astype('str')\n",
    "    AllResults = AllResults.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "    #AllResults[AllResults['Treatment_risk_group_in_ALL10'].notnull()]\n",
    "    ####\n",
    "    ####\n",
    "    Runs.append(AllResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 58) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6886 - acc: 0.5652 - val_loss: 0.6688 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5933 - acc: 0.8478 - val_loss: 0.5349 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4617 - acc: 0.8043 - val_loss: 0.4813 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.1972 - acc: 0.9783 - val_loss: 0.3147 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.0824 - acc: 0.9783 - val_loss: 0.2474 - val_acc: 0.9167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.0948 - acc: 0.9348 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 7.8194e-04 - acc: 1.0000 - val_loss: 1.5301e-04 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 9.0030e-05 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 9.5913e-04 - acc: 1.0000 - val_loss: 5.0335e-05 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 3.7056e-04 - acc: 1.0000 - val_loss: 3.6441e-05 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 3.7330e-04 - acc: 1.0000 - val_loss: 2.0993e-05 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 6.5057e-05 - acc: 1.0000 - val_loss: 2.9946e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 9.7437e-05 - acc: 1.0000 - val_loss: 2.3111e-05 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 8.1000e-05 - acc: 1.0000 - val_loss: 1.6103e-05 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 5.2000e-05 - acc: 1.0000 - val_loss: 1.3460e-05 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 3.3426e-05 - acc: 1.0000 - val_loss: 1.0410e-05 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 5.6101e-05 - acc: 1.0000 - val_loss: 4.5613e-06 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 1.9582e-05 - acc: 1.0000 - val_loss: 3.6900e-06 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 7.1310e-05 - acc: 1.0000 - val_loss: 3.8739e-06 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 6.3114e-06 - acc: 1.0000 - val_loss: 3.1103e-06 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 3.0097e-06 - acc: 1.0000 - val_loss: 2.6316e-06 - val_acc: 1.0000\n",
      "MODEL: DNN accuracy:  0.98275862069 +/-: 0.00113951644867\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 58) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6713 - acc: 0.5652 - val_loss: 0.6246 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5594 - acc: 0.5652 - val_loss: 0.6660 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4169 - acc: 0.5652 - val_loss: 0.6329 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.3233 - acc: 0.6087 - val_loss: 0.6229 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.3103 - acc: 0.6522 - val_loss: 0.5972 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3578 - acc: 0.900 - 0s - loss: 0.3665 - acc: 0.9130 - val_loss: 0.2903 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.3050 - acc: 0.9783 - val_loss: 0.2855 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2982 - acc: 0.9783 - val_loss: 0.2815 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.2919 - acc: 1.0000 - val_loss: 0.2804 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.2886 - acc: 1.0000 - val_loss: 0.2760 - val_acc: 1.0000\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.2851 - acc: 1.0000 - val_loss: 0.2685 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.2719 - acc: 1.0000 - val_loss: 0.2592 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2455 - acc: 1.0000 - val_loss: 0.2268 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.1700 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.0457 - acc: 1.0000 - val_loss: 0.0871 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 9.6729e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 7.2951e-04 - acc: 1.0000 - val_loss: 7.0384e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 3.9111e-04 - acc: 1.0000 - val_loss: 4.9958e-04 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 3.2833e-04 - acc: 1.0000 - val_loss: 2.8846e-05 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 2.7681e-04 - acc: 1.0000 - val_loss: 1.5441e-05 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 1.4168e-04 - acc: 1.0000 - val_loss: 9.1797e-06 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 7.1492e-05 - acc: 1.0000 - val_loss: 6.0500e-06 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 5.8577e-05 - acc: 1.0000 - val_loss: 4.1584e-06 - val_acc: 1.0000\n",
      "MODEL: DNN accuracy:  0.948275862069 +/-: 0.010255648038\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++ ..processing feature array (58, 58) and class vector (58,)\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.7277 - acc: 0.5652 - val_loss: 0.6690 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6333 - acc: 0.5652 - val_loss: 0.6477 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4648 - acc: 0.5652 - val_loss: 0.6594 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.3753 - acc: 0.5652 - val_loss: 0.6617 - val_acc: 0.5833\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.3220 - acc: 0.7174 - val_loss: 0.6976 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.4028 - acc: 0.7826 - val_loss: 0.2953 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.3201 - acc: 0.9348 - val_loss: 0.2863 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.3010 - acc: 0.9565 - val_loss: 0.2845 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.2970 - acc: 1.0000 - val_loss: 0.2825 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.2941 - acc: 1.0000 - val_loss: 0.2810 - val_acc: 1.0000\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.2936 - acc: 1.0000 - val_loss: 0.2788 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.2915 - acc: 1.0000 - val_loss: 0.2773 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.2894 - acc: 1.0000 - val_loss: 0.2759 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.2876 - acc: 1.0000 - val_loss: 0.2742 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.2857 - acc: 1.0000 - val_loss: 0.2723 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.2773 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.2740 - acc: 1.0000 - val_loss: 0.2891 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.2673 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.2424 - acc: 1.0000 - val_loss: 0.2240 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.1547 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 1.0000\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.0399 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 6.5742e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 4.3406e-04 - acc: 1.0000 - val_loss: 4.5547e-04 - val_acc: 1.0000\n",
      "MODEL: DNN accuracy:  0.913793103448 +/-: 0.0284879112168\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "nruns = 3\n",
    "for i in range(0, nruns):\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"DNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append({'method': \"DNN\", 'model': class_model})\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"DNN\"\n",
    "    AllResults = AllResults.append(Results[[Rocket.MODEL_PARAMETERS['ID'], 'pred', 'method', Rocket.MODEL_PARAMETERS['target']]],\n",
    "                                   ignore_index = True)\n",
    "\n",
    "    AllResults[Rocket.MODEL_PARAMETERS['ID']] = AllResults[Rocket.MODEL_PARAMETERS['ID']].astype('str')\n",
    "    AllResults = AllResults.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "    #AllResults[AllResults['Treatment_risk_group_in_ALL10'].notnull()]\n",
    "    ####\n",
    "    ####\n",
    "    Runs.append(AllResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on average: 0.6925287356321839 +- 0.021279981743715395, median: 0.6896551724137931+-0.022182286599646883\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "        acc model       var\n",
      "0  0.655172    ET  0.014845\n",
      "1  0.672414    RF  0.031141\n",
      "2  0.706897   GBM  0.019367\n",
      "3  0.672414   ADA  0.012332\n",
      "4  0.724138    LR  0.024997\n",
      "5  0.724138   SVM  0.024997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of _helpers failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.5/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 626, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 767, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 727, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n",
      "  File \"/home/bramiozo/DEV/GIT/RexR/_helpers.py\", line 534\n",
      "    def get_top_genes(x,y, MODELS=None, n_max = 1000, RexR):\n",
      "                     ^\n",
      "SyntaxError: non-default argument follows default argument\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on average: {} +- {}, median: {}+-{}\".format(ACC.mean()[0], ACC.mean()[1], ACC.median()[0], ACC.median()[1]))\n",
    "print(\"+\"*40)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "###########\n",
    "##Runs.append(AllResults)\n",
    "final_df = pandas.DataFrame()\n",
    "for idx, df in enumerate(Runs):\n",
    "    df['run'] = idx\n",
    "    final_df = final_df.append(df, ignore_index = True)\n",
    "final_df = final_df.sort_values(by=Rocket.MODEL_PARAMETERS['ID'])\n",
    "final_df['pred']= pandas.to_numeric(final_df['pred'])\n",
    "final_df_agg = final_df.groupby([Rocket.MODEL_PARAMETERS['ID'], 'method']).agg({'pred': [numpy.mean, numpy.median, numpy.std]})\n",
    "final_df_agg = final_df_agg['pred'].groupby(by=Rocket.MODEL_PARAMETERS['ID']).agg({'mean': [numpy.mean, numpy.median, numpy.std]})['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/patient_results_\"+Rocket.SET_NAME+\".csv\")\n",
    "final_df_agg.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/patient_results_agg_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_weights, top_coeffs = _helpers.get_top_genes(MODELS=MODELS, n_max=1000, RexR=Rocket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualise the top weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genomes_coeffs.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/coeffs_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genomes_weights.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/weights_\"+Rocket.SET_NAME+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF9 = top_genomes_weights['RandomForest'].quantile(q=0.9)\n",
    "GBM9 = top_genomes_weights['GBM'].quantile(q=0.9)\n",
    "ADA9 = top_genomes_weights['AdaBoost'].quantile(q=0.9)\n",
    "ET9 = top_genomes_weights['ExtraTrees'].quantile(q=0.9)\n",
    "Overlapping_genomes = set(top_genomes_weights.loc[top_genomes_weights['RandomForest']>RF9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['GBM']>GBM9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['AdaBoost']>ADA9].index.values)\\\n",
    "                      & set(top_genomes_weights.loc[top_genomes_weights['ExtraTrees']>ET9].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import*\n",
    "#from scipy.dspatial.distance import cosine\n",
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import cdist\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TransPosed = Rocket.DATA_all_samples.T # all microarrays, may be multiple per patient versus all probesets, may be multiple per genome\n",
    "Normal = Rocket.DATA_merged_processed.loc[:, (Rocket.DATA_merged_processed.columns !='target') & \n",
    "                                             (Rocket.DATA_merged_processed.columns !='ID')]\n",
    "#AllNormal = Rocket.DATA_merged\n",
    "#probeset_weights = Rocket.get_probeset_weights(method = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 9827_corr2.CEL, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'cosine', normalised = True, inflation = 2, minkowski_dim=1)\n",
    "##### apply Markov clustering\n",
    "#######################\n",
    "# non-distributed, non-sparse version, only for small-sized problems (N is order 1000)\n",
    "e = 2\n",
    "r = 2 \n",
    "epsilon = 1e-7\n",
    "convergence = 0.001\n",
    "num_iter = 10\n",
    "Orientation = 'col' # columnwise or rowwise\n",
    "\n",
    "# add loop\n",
    "def add_loop(df_matrix, value=0): \n",
    "    for i in df_matrix.index:\n",
    "        df_matrix.loc[i, i] = value\n",
    "    return df_matrix\n",
    "patient_sim = add_loop(patient_sim, 1)\n",
    "patient_sim = patient_sim - epsilon\n",
    "\n",
    "def normalise(sim, type = 'col'):\n",
    "    if(type == 'col'):\n",
    "        # column normalisation\n",
    "        for variable in sim.keys():\n",
    "            col_vec = sim[variable]\n",
    "            sum_val = sum([p for p in col_vec])\n",
    "            sim[variable] = sim[variable]/sum_val\n",
    "    elif (type == 'row'):\n",
    "        # row normalisation\n",
    "        for variable in sim.keys():\n",
    "            row_vec = sim.loc[variable, :]\n",
    "            sum_val = sum([p for p in row_vec])\n",
    "            sim.loc[variable,:] = sim.loc[variable,:]/sum_val\n",
    "    return sim\n",
    "\n",
    "# step E: expansion, get the nth power of the matrix\n",
    "def expansion(sim):\n",
    "    X = numpy.array(sim)\n",
    "    VarList = sim.keys()\n",
    "    if e == 1:\n",
    "        return sim\n",
    "    elif e > 1:        \n",
    "        return pandas.DataFrame(numpy.linalg.matrix_power(X, e), index = VarList, columns = VarList)\n",
    "     \n",
    "# step I: inflation, per column raise by rth power and column normalise\n",
    "def inflation(sim, type = 'col'):    \n",
    "    if type == 'col':\n",
    "        Axis = 0\n",
    "    elif type == 'row':\n",
    "        Axis = 1\n",
    "    return sim.apply(lambda x: x**r/sum(x**r), axis = Axis)\n",
    "\n",
    "# remove weak connections, values < epsilon\n",
    "def clean(sim):\n",
    "    return sim.applymap(lambda x:0 if x<epsilon else x)\n",
    "    \n",
    "def difference(old, new):\n",
    "    # relative zeroes over entire array\n",
    "    #return (new.apply(lambda x: numpy.ceil(x-epsilon)) - old.apply(lambda x: numpy.ceil(x-epsilon))).sum().sum()/len(old)**2    \n",
    "    return abs(new - old).sum().sum()/len(old)**2    \n",
    "\n",
    "#patient_sim = normalise(patient_sim, type = Orientation)\n",
    "_sim_a = patient_sim\n",
    "for i in range(0,num_iter):\n",
    "    # repeat E and I until convergence, the row-wise elements form the clusters.\n",
    "    _sim_b = clean(inflation(expansion(_sim_a), type = Orientation))\n",
    "    _sim_a = normalise(_sim_a, type = Orientation)\n",
    "    #if ((difference(_sim_a, _sim_b)) < convergence) & (i>0):\n",
    "    #    print(difference(_sim_a, _sim_b))\n",
    "    #    print(\"CONVERGED after \", i, \" iterations\")\n",
    "    #    break;\n",
    "    _sim_a = _sim_b\n",
    "\n",
    "result_mcl = clean(_sim_b)\n",
    "result_mcl.loc[result_mcl.loc['9827_corr2.CEL',:]>epsilon, '9827_corr2.CEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 patient clusters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'pearson', normalised = False, inflation=1, minkowski_dim=1)\n",
    "##### apply Affinity Propagation\n",
    "#######################\n",
    "X = numpy.array(patient_sim)\n",
    "af = AffinityPropagation(preference=-10).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "patient_clusters = patient_sim.keys()[cluster_centers_indices].values\n",
    "patient_cluster_members = af.labels_\n",
    "print(\"There are {} patient clusters\".format(n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AggResults = Rocket.DATA_merged\n",
    "AggResults = _helpers._preprocess(AggResults, Rclass = Rocket)\n",
    "#AggResults = _helpers._group_patients(AggResults, method = 'mean')\n",
    "AggResults['cluster_ap'] = patient_cluster_members\n",
    "\n",
    "#AggResults.groupby(['Treatment risk group in ALL10', 'cluster_ap']).agg({'Microarray file': pandas.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "AggResults['FU_RFS'] = pandas.to_numeric(AggResults['FU_RFS'])\n",
    "AggResults['FU_EFS'] = pandas.to_numeric(AggResults['FU_EFS'])\n",
    "AggResults['FU_OS'] = pandas.to_numeric(AggResults['FU_OS'])\n",
    "AggResults['WhiteBloodCellcount'] = pandas.to_numeric(AggResults['WhiteBloodCellcount'])\n",
    "AggResults['Age'] = pandas.to_numeric(AggResults['Age'])\n",
    "AggResults['Gender'] = pandas.to_numeric(AggResults['Gender'])\n",
    "AggResults['code_RFS']= pandas.to_numeric(AggResults['code_RFS'])\n",
    "AggResults['code_EFS']= pandas.to_numeric(AggResults['code_EFS'])\n",
    "AggResults['code_OS']= pandas.to_numeric(AggResults['code_OS'])\n",
    "\n",
    "AggResults['mutations_NOTCH_pathway'] = pandas.to_numeric(AggResults['mutations_NOTCH_pathway'])\n",
    "AggResults['mutations_PTEN_AKT_pathway'] = pandas.to_numeric(AggResults['mutations_PTEN_AKT_pathway'])\n",
    "AggResults['mutations_IL7R_pathway'] = pandas.to_numeric(AggResults['mutations_IL7R_pathway'])\n",
    "#AggResults.replace(to_replace=9999, value=0.5, inplace=True)\n",
    "AggResults[['mutations_NOTCH_pathway', \n",
    "            'mutations_PTEN_AKT_pathway', \n",
    "            'mutations_IL7R_pathway']] = AggResults[['mutations_NOTCH_pathway', \n",
    "                                                    'mutations_PTEN_AKT_pathway', \n",
    "                                                    'mutations_IL7R_pathway']].replace([9999],[numpy.nan],\n",
    "                                                                                       inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "AggResults['comb_mutations_NOTCH_IL7R'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_NOTCH_PTEN'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_PTEN_AKT_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN'] =  AggResults['mutations_PTEN_AKT_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN_NOTCH'] =  AggResults['mutations_PTEN_AKT_pathway']\\\n",
    "                                                + AggResults['mutations_IL7R_pathway']\\\n",
    "                                                + AggResults['mutations_NOTCH_pathway']\n",
    "\n",
    "\n",
    "patient_count = AggResults.groupby(['cluster_ap']).agg({'labnr_patient': pandas.Series.nunique})\n",
    "Clustered_by_patients_whitebloodcells = AggResults[AggResults['WhiteBloodCellcount'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'WhiteBloodCellcount': numpy.mean,\n",
    "    'Age': numpy.mean, \n",
    "    'Gender': numpy.mean})\n",
    "\n",
    "# Cancer_gene\n",
    "# Treatment_protocol\n",
    "# Treatment_risk_group_in_ALL_10\n",
    "\n",
    "Clustered_by_patients_CODE = AggResults.groupby(['cluster_ap']).agg(\n",
    "    {'code_RFS': numpy.mean, \n",
    "     'code_EFS': numpy.mean,\n",
    "     'code_OS': numpy.mean})\n",
    "\n",
    "Clustered_by_patients_FU_RFS = AggResults[AggResults['FU_RFS'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'FU_RFS': numpy.median, \n",
    "     'FU_EFS': numpy.median,\n",
    "     'FU_OS': numpy.median})\n",
    "Clustered_by_patients_NotchPath = AggResults[AggResults['mutations_NOTCH_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_NOTCH_pathway': numpy.mean})\n",
    "Clustered_by_patients_IL7RPath = AggResults[AggResults['mutations_IL7R_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_IL7R_pathway': numpy.mean})\n",
    "Clustered_by_patients_PTENAKTPath = AggResults[AggResults['mutations_PTEN_AKT_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_PTEN_AKT_pathway': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_IL7R = AggResults[AggResults['comb_mutations_NOTCH_IL7R'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_IL7R': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_PTEN = AggResults[AggResults['comb_mutations_NOTCH_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN = AggResults[AggResults['comb_mutations_IL7R_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN_NOTCH = AggResults[AggResults['comb_mutations_IL7R_PTEN_NOTCH'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN_NOTCH': numpy.mean})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_agg = pandas.merge(Clustered_by_patients_whitebloodcells, Clustered_by_patients_CODE, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN_NOTCH, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_IL7R, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_PTEN, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_FU_RFS, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_IL7RPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_NotchPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_PTENAKTPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, patient_count, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Cluster centers:\",patient_sim.keys()[cluster_centers_indices].values)\n",
    "print(patient_cluster_members)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    class_members = patient_cluster_members == k\n",
    "    cluster_center = X[cluster_centers_indices[k]]\n",
    "    plt.plot(X[class_members, 0], X[class_members, 1], col + '.', \n",
    "             label = patient_sim.keys()[cluster_centers_indices[k]])\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in X[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.title('Estimated number of clusters from Affinity Propagation: %d' % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### CREATE graph from similarity matrix\n",
    "##################\n",
    "# nodes\n",
    "VarList = TransPosed.keys()\n",
    "nodes = []\n",
    "node_index = 0\n",
    "for patient_name in VarList:\n",
    "    nodes.append((node_index, {'name': patient_name}))\n",
    "    node_index = node_index + 1\n",
    "\n",
    "edges = []\n",
    "# edges\n",
    "patient_sim = patient_similarity(Normal, sim_type = 'pearson', normalised = True, inflation=2)\n",
    "node_index_x = 0\n",
    "node_index_y = 0\n",
    "for patient_name_x in VarList:\n",
    "    for patient_name_y in VarList:        \n",
    "        edges.append((node_index_x, node_index_y, patient_sim.iloc[node_index_x, node_index_y]))\n",
    "        node_index_y = node_index_y + 1\n",
    "    node_index_x = node_index_x + 1\n",
    "    node_index_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(edges, weight = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:138: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  plt.hold(b)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.\n",
      "  warnings.warn(self.msg_depr_set % key)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0\n",
      "  warnings.warn(\"axes.hold is deprecated, will be removed in 3.0\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAFCCAYAAABSJMy8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f31beac128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### apply Spring-force\n",
    "#######################\n",
    "pos = nx.spring_layout(G, k = None, dim = 3, scale = 1.0)\n",
    "nx.draw_spring(G, k = 30, dim = 2, scale = 1.0, iterations =1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### APPLY community detector\n",
    "# maximize betweenness and modularity\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### LOAD IN DATA\n",
    "###################\n",
    "# https://stackoverflow.com/questions/14529838/apply-multiple-functions-to-multiple-groupby-columns\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
