{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++ Firing up RexR! ++++++++++++++++++++++++++++++\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from RexR import *\n",
    "import _helpers\n",
    "Rocket = RexR(datalocation = None, #'_data/genomic_data/data.pkl', \n",
    "              seed = 3123, \n",
    "              debug = False, \n",
    "              write_out=True,\n",
    "              set_name = 'ALL_10') # data to read in \n",
    "Rocket.load_probeset_data();\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ch1 = pandas.read_csv('_data/genomic_data/mela.txt', sep=\"\\t\", skiprows=28, skipfooter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ids = ch1.loc[ch1.ix[:,0]=='ID_REF'].ix[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = ch1.ix[64-30:22300,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ch1.loc[ch1.ix[:,0]=='!Sample_characteristics_ch1'].reset_index(drop=True).loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_row = ch1.loc[ch1.ix[:,0]=='!Sample_characteristics_ch1'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22267,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.append(gene)'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_m = ch1.values[list(range(64-30, 22301))+[target_row],1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (22268, 83), indices imply (22267, 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   4293\u001b[0m                 blocks = [make_block(values=blocks[0],\n\u001b[1;32m-> 4294\u001b[1;33m                                      placement=slice(0, len(axes[0])))]\n\u001b[0m\u001b[0;32m   4295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   2718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2719\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, ndim, fastpath, placement, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m         super(ObjectBlock, self).__init__(values, ndim=ndim, fastpath=fastpath,\n\u001b[1;32m-> 1844\u001b[1;33m                                           placement=placement, **kwargs)\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[0;32m    114\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[1;32m--> 115\u001b[1;33m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 22268, placement implies 22267",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-8ec889f5c271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mch1_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mch1_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgene_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 306\u001b[1;33m                                          copy=copy)\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[1;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   4301\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4302\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4303\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   4278\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4279\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 4280\u001b[1;33m         passed, implied))\n\u001b[0m\u001b[0;32m   4281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (22268, 83), indices imply (22267, 83)"
     ]
    }
   ],
   "source": [
    "ch1_n = pandas.DataFrame(data=ch1_m, index=ids[0,:],columns=gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import*\n",
    "#from scipy.dspatial.distance import cosine\n",
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import cdist\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TransPosed = Rocket.DATA_all_samples.T # all microarrays, may be multiple per patient versus all probesets, may be multiple per genome\n",
    "Normal = Rocket.DATA_all_samples\n",
    "AllNormal = Rocket.DATA_merged\n",
    "#probeset_weights = Rocket.get_probeset_weights(method = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 9827_corr2.CEL, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'cosine', normalised = True, inflation = 2, minkowski_dim=1)\n",
    "##### apply Markov clustering\n",
    "#######################\n",
    "# non-distributed, non-sparse version, only for small-sized problems (N is order 1000)\n",
    "e = 2\n",
    "r = 2 \n",
    "epsilon = 1e-7\n",
    "convergence = 0.001\n",
    "num_iter = 10\n",
    "Orientation = 'col' # columnwise or rowwise\n",
    "\n",
    "# add loop\n",
    "def add_loop(df_matrix, value=0): \n",
    "    for i in df_matrix.index:\n",
    "        df_matrix.loc[i, i] = value\n",
    "    return df_matrix\n",
    "patient_sim = add_loop(patient_sim, 1)\n",
    "patient_sim = patient_sim - epsilon\n",
    "\n",
    "def normalise(sim, type = 'col'):\n",
    "    if(type == 'col'):\n",
    "        # column normalisation\n",
    "        for variable in sim.keys():\n",
    "            col_vec = sim[variable]\n",
    "            sum_val = sum([p for p in col_vec])\n",
    "            sim[variable] = sim[variable]/sum_val\n",
    "    elif (type == 'row'):\n",
    "        # row normalisation\n",
    "        for variable in sim.keys():\n",
    "            row_vec = sim.loc[variable, :]\n",
    "            sum_val = sum([p for p in row_vec])\n",
    "            sim.loc[variable,:] = sim.loc[variable,:]/sum_val\n",
    "    return sim\n",
    "\n",
    "# step E: expansion, get the nth power of the matrix\n",
    "def expansion(sim):\n",
    "    X = numpy.array(sim)\n",
    "    VarList = sim.keys()\n",
    "    if e == 1:\n",
    "        return sim\n",
    "    elif e > 1:        \n",
    "        return pandas.DataFrame(numpy.linalg.matrix_power(X, e), index = VarList, columns = VarList)\n",
    "     \n",
    "# step I: inflation, per column raise by rth power and column normalise\n",
    "def inflation(sim, type = 'col'):    \n",
    "    if type == 'col':\n",
    "        Axis = 0\n",
    "    elif type == 'row':\n",
    "        Axis = 1\n",
    "    return sim.apply(lambda x: x**r/sum(x**r), axis = Axis)\n",
    "\n",
    "# remove weak connections, values < epsilon\n",
    "def clean(sim):\n",
    "    return sim.applymap(lambda x:0 if x<epsilon else x)\n",
    "    \n",
    "def difference(old, new):\n",
    "    # relative zeroes over entire array\n",
    "    #return (new.apply(lambda x: numpy.ceil(x-epsilon)) - old.apply(lambda x: numpy.ceil(x-epsilon))).sum().sum()/len(old)**2    \n",
    "    return abs(new - old).sum().sum()/len(old)**2    \n",
    "\n",
    "#patient_sim = normalise(patient_sim, type = Orientation)\n",
    "_sim_a = patient_sim\n",
    "for i in range(0,num_iter):\n",
    "    # repeat E and I until convergence, the row-wise elements form the clusters.\n",
    "    _sim_b = clean(inflation(expansion(_sim_a), type = Orientation))\n",
    "    _sim_a = normalise(_sim_a, type = Orientation)\n",
    "    #if ((difference(_sim_a, _sim_b)) < convergence) & (i>0):\n",
    "    #    print(difference(_sim_a, _sim_b))\n",
    "    #    print(\"CONVERGED after \", i, \" iterations\")\n",
    "    #    break;\n",
    "    _sim_a = _sim_b\n",
    "\n",
    "result_mcl = clean(_sim_b)\n",
    "result_mcl.loc[result_mcl.loc['9827_corr2.CEL',:]>epsilon, '9827_corr2.CEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 patient clusters\n"
     ]
    }
   ],
   "source": [
    "patient_sim = _helpers.patient_similarity(Normal, sim_type = 'cosine', normalised = True, inflation=1, minkowski_dim=1)\n",
    "##### apply Affinity Propagation\n",
    "#######################\n",
    "X = numpy.array(patient_sim)\n",
    "af = AffinityPropagation(preference=-50).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "patient_clusters = patient_sim.keys()[cluster_centers_indices].values\n",
    "patient_cluster_members = af.labels_\n",
    "print(\"There are {} patient clusters\".format(n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "AggResults = Rocket.DATA_merged\n",
    "AggResults = _helpers._preprocess(AggResults)\n",
    "#AggResults = _helpers._group_patients(AggResults, method = 'mean')\n",
    "AggResults['cluster_ap'] = patient_cluster_members\n",
    "\n",
    "#AggResults.groupby(['Treatment risk group in ALL10', 'cluster_ap']).agg({'Microarray file': pandas.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "AggResults['FU_RFS'] = pandas.to_numeric(AggResults['FU_RFS'])\n",
    "AggResults['FU_EFS'] = pandas.to_numeric(AggResults['FU_EFS'])\n",
    "AggResults['FU_OS'] = pandas.to_numeric(AggResults['FU_OS'])\n",
    "AggResults['WhiteBloodCellcount'] = pandas.to_numeric(AggResults['WhiteBloodCellcount'])\n",
    "AggResults['Age'] = pandas.to_numeric(AggResults['Age'])\n",
    "AggResults['Gender'] = pandas.to_numeric(AggResults['Gender'])\n",
    "AggResults['code_RFS']= pandas.to_numeric(AggResults['code_RFS'])\n",
    "AggResults['code_EFS']= pandas.to_numeric(AggResults['code_EFS'])\n",
    "AggResults['code_OS']= pandas.to_numeric(AggResults['code_OS'])\n",
    "\n",
    "AggResults['mutations_NOTCH_pathway'] = pandas.to_numeric(AggResults['mutations_NOTCH_pathway'])\n",
    "AggResults['mutations_PTEN_AKT_pathway'] = pandas.to_numeric(AggResults['mutations_PTEN_AKT_pathway'])\n",
    "AggResults['mutations_IL7R_pathway'] = pandas.to_numeric(AggResults['mutations_IL7R_pathway'])\n",
    "#AggResults.replace(to_replace=9999, value=0.5, inplace=True)\n",
    "AggResults[['mutations_NOTCH_pathway', \n",
    "            'mutations_PTEN_AKT_pathway', \n",
    "            'mutations_IL7R_pathway']] = AggResults[['mutations_NOTCH_pathway', \n",
    "                                                    'mutations_PTEN_AKT_pathway', \n",
    "                                                    'mutations_IL7R_pathway']].replace([9999],[numpy.nan],\n",
    "                                                                                       inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "AggResults['comb_mutations_NOTCH_IL7R'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_NOTCH_PTEN'] = AggResults['mutations_NOTCH_pathway'] + AggResults['mutations_PTEN_AKT_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN'] =  AggResults['mutations_PTEN_AKT_pathway'] + AggResults['mutations_IL7R_pathway']\n",
    "AggResults['comb_mutations_IL7R_PTEN_NOTCH'] =  AggResults['mutations_PTEN_AKT_pathway']\\\n",
    "                                                + AggResults['mutations_IL7R_pathway']\\\n",
    "                                                + AggResults['mutations_NOTCH_pathway']\n",
    "\n",
    "\n",
    "patient_count = AggResults.groupby(['cluster_ap']).agg({'labnr_patient': pandas.Series.nunique})\n",
    "Clustered_by_patients_whitebloodcells = AggResults[AggResults['WhiteBloodCellcount'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'WhiteBloodCellcount': numpy.mean,\n",
    "    'Age': numpy.mean, \n",
    "    'Gender': numpy.mean})\n",
    "\n",
    "# Cancer_gene\n",
    "# Treatment_protocol\n",
    "# Treatment_risk_group_in_ALL_10\n",
    "\n",
    "Clustered_by_patients_CODE = AggResults.groupby(['cluster_ap']).agg(\n",
    "    {'code_RFS': numpy.mean, \n",
    "     'code_EFS': numpy.mean,\n",
    "     'code_OS': numpy.mean})\n",
    "\n",
    "Clustered_by_patients_FU_RFS = AggResults[AggResults['FU_RFS'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'FU_RFS': numpy.median, \n",
    "     'FU_EFS': numpy.median,\n",
    "     'FU_OS': numpy.median})\n",
    "Clustered_by_patients_NotchPath = AggResults[AggResults['mutations_NOTCH_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_NOTCH_pathway': numpy.mean})\n",
    "Clustered_by_patients_IL7RPath = AggResults[AggResults['mutations_IL7R_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_IL7R_pathway': numpy.mean})\n",
    "Clustered_by_patients_PTENAKTPath = AggResults[AggResults['mutations_PTEN_AKT_pathway'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'mutations_PTEN_AKT_pathway': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_IL7R = AggResults[AggResults['comb_mutations_NOTCH_IL7R'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_IL7R': numpy.mean})\n",
    "Clustered_by_patients_comb_NOTCH_PTEN = AggResults[AggResults['comb_mutations_NOTCH_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_NOTCH_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN = AggResults[AggResults['comb_mutations_IL7R_PTEN'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN': numpy.mean})\n",
    "Clustered_by_patients_comb_IL7R_PTEN_NOTCH = AggResults[AggResults['comb_mutations_IL7R_PTEN_NOTCH'].apply(lambda x: isnan(x) is False)].groupby(['cluster_ap']).agg(\n",
    "    {'comb_mutations_IL7R_PTEN_NOTCH': numpy.mean})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_agg = pandas.merge(Clustered_by_patients_whitebloodcells, Clustered_by_patients_CODE, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_IL7R_PTEN_NOTCH, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_IL7R, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_comb_NOTCH_PTEN, how = 'inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_FU_RFS, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_IL7RPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_NotchPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, Clustered_by_patients_PTENAKTPath, how='inner', left_index=True, right_index=True)\n",
    "cluster_agg = pandas.merge(cluster_agg, patient_count, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WhiteBloodCellcount</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>code_RFS</th>\n",
       "      <th>code_EFS</th>\n",
       "      <th>code_OS</th>\n",
       "      <th>comb_mutations_IL7R_PTEN</th>\n",
       "      <th>comb_mutations_IL7R_PTEN_NOTCH</th>\n",
       "      <th>comb_mutations_NOTCH_IL7R</th>\n",
       "      <th>comb_mutations_NOTCH_PTEN</th>\n",
       "      <th>FU_RFS</th>\n",
       "      <th>FU_EFS</th>\n",
       "      <th>FU_OS</th>\n",
       "      <th>mutations_IL7R_pathway</th>\n",
       "      <th>mutations_NOTCH_pathway</th>\n",
       "      <th>mutations_PTEN_AKT_pathway</th>\n",
       "      <th>labnr_patient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_ap</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.511765</td>\n",
       "      <td>10.124738</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>61.610959</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>61.610959</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.676623</td>\n",
       "      <td>8.955880</td>\n",
       "      <td>1.324675</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>50.235616</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>53.687671</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.405063</td>\n",
       "      <td>8.850928</td>\n",
       "      <td>1.303797</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.146341</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>62.334247</td>\n",
       "      <td>66.476712</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.493878</td>\n",
       "      <td>8.401062</td>\n",
       "      <td>1.204082</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>46.323288</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WhiteBloodCellcount        Age    Gender  code_RFS  code_EFS  \\\n",
       "cluster_ap                                                                 \n",
       "0                    173.511765  10.124738  1.176471  0.100000  0.222222   \n",
       "1                    149.676623   8.955880  1.324675  0.155556  0.309524   \n",
       "2                    160.405063   8.850928  1.303797  0.276596  0.340426   \n",
       "3                    161.493878   8.401062  1.204082  0.392857  0.464286   \n",
       "\n",
       "             code_OS  comb_mutations_IL7R_PTEN  \\\n",
       "cluster_ap                                       \n",
       "0           0.100000                  0.333333   \n",
       "1           0.266667                  0.619048   \n",
       "2           0.255319                  0.500000   \n",
       "3           0.428571                  0.615385   \n",
       "\n",
       "            comb_mutations_IL7R_PTEN_NOTCH  comb_mutations_NOTCH_IL7R  \\\n",
       "cluster_ap                                                              \n",
       "0                                 0.777778                   0.666667   \n",
       "1                                 1.214286                   0.928571   \n",
       "2                                 1.146341                   0.951220   \n",
       "3                                 1.269231                   1.000000   \n",
       "\n",
       "            comb_mutations_NOTCH_PTEN     FU_RFS     FU_EFS      FU_OS  \\\n",
       "cluster_ap                                                               \n",
       "0                            0.555556  61.610959  41.000000  61.610959   \n",
       "1                            0.880952  50.235616  52.000000  53.687671   \n",
       "2                            0.883721  63.000000  62.334247  66.476712   \n",
       "3                            0.925926  46.500000  46.323288  62.500000   \n",
       "\n",
       "            mutations_IL7R_pathway  mutations_NOTCH_pathway  \\\n",
       "cluster_ap                                                    \n",
       "0                         0.222222                 0.444444   \n",
       "1                         0.333333                 0.595238   \n",
       "2                         0.318182                 0.674419   \n",
       "3                         0.346154                 0.666667   \n",
       "\n",
       "            mutations_PTEN_AKT_pathway  labnr_patient  \n",
       "cluster_ap                                             \n",
       "0                             0.111111             16  \n",
       "1                             0.285714             92  \n",
       "2                             0.204545            113  \n",
       "3                             0.259259             66  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers: ['2113.CEL' '8639.CEL' '3854.CEL' '6278.CEL']\n",
      "[1 1 1 3 3 2 3 3 2 3 3 2 2 3 3 3 3 2 3 3 2 3 3 3 2 3 2 2 3 2 2 2 3 2 2 2 2\n",
      " 2 2 3 2 3 3 1 2 2 2 3 3 2 2 2 2 1 1 2 2 1 3 2 2 3 1 3 2 2 2 2 2 2 1 2 1 2\n",
      " 2 2 3 2 2 3 2 1 1 1 1 1 2 1 1 1 0 0 1 1 2 1 1 1 1 1 1 0 0 0 1 1 1 2 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 0 1 1 2 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 2 3 2 1 1 1\n",
      " 1 2 0 1 1 1 1 1 1 0 2 2 0 1 1 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 3 3 3 2 2 2 1 2 2 2\n",
      " 3 2 2 2 2 2 3 2 3 3 2 2 3 2 2 1 2 2 2 2 3 2 2 2 2 1 3 2 2 3 3 3 3 2 3 3 2\n",
      " 3 2 2 3 2 2 3 2 2 3 3 2 3 2 3 2 3 3 1 2 3 2 3 2 1 2 3 3 3 3 3 2 2 2 3 2 3\n",
      " 3 3 2 2 2 2 2 3 1 2 3 3 3 1 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAAIYCAYAAABUqcKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x253007dd860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Cluster centers:\",patient_sim.keys()[cluster_centers_indices].values)\n",
    "print(patient_cluster_members)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    class_members = patient_cluster_members == k\n",
    "    cluster_center = X[cluster_centers_indices[k]]\n",
    "    plt.plot(X[class_members, 0], X[class_members, 1], col + '.', \n",
    "             label = patient_sim.keys()[cluster_centers_indices[k]])\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in X[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.title('Estimated number of clusters from Affinity Propagation: %d' % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### CREATE graph from similarity matrix\n",
    "##################\n",
    "# nodes\n",
    "VarList = TransPosed.keys()\n",
    "nodes = []\n",
    "node_index = 0\n",
    "for patient_name in VarList:\n",
    "    nodes.append((node_index, {'name': patient_name}))\n",
    "    node_index = node_index + 1\n",
    "\n",
    "edges = []\n",
    "# edges\n",
    "patient_sim = patient_similarity(Normal, sim_type = 'pearson', normalised = True, inflation=2)\n",
    "node_index_x = 0\n",
    "node_index_y = 0\n",
    "for patient_name_x in VarList:\n",
    "    for patient_name_y in VarList:        \n",
    "        edges.append((node_index_x, node_index_y, patient_sim.iloc[node_index_x, node_index_y]))\n",
    "        node_index_y = node_index_y + 1\n",
    "    node_index_x = node_index_x + 1\n",
    "    node_index_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(edges, weight = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:138: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  plt.hold(b)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.\n",
      "  warnings.warn(self.msg_depr_set % key)\n",
      "c:\\users\\bramva~1\\envs\\worken~1\\lib\\site-packages\\matplotlib\\rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0\n",
      "  warnings.warn(\"axes.hold is deprecated, will be removed in 3.0\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAFCCAYAAABSJMy8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XtwVOXh//HP2U2y2RCIJCGiQRHlIo0gVFJFLCJCNQIi\nIFpBBhD8AWpAgcHS4qVVy4yDo1YdryNUR7GUSlEErYpGBBwC4ZKEBIlyUS5JIDESkqwJe35/bPGr\nFUIu5+zZy/s102mFc57nM2rz4Xn27HMM0zRNAQAAS7mcDgAAQCSiYAEAsAEFCwCADShYAABsQMEC\nAGADChYAABtQsAAA2ICCBQDABhQsAAA2oGABALABBQsAgA0oWAAAbEDBAgBgAwoWAAAbULAAANiA\nggUAwAYULAAANqBgAQCwAQULAIANKFgAAGxAwQIAYAMKFgAAG1CwAADYgIIFAMAGFCwAADaIcTpA\nSCgrk5YskXbskKqqpKQkqXdvafJkqUMHp9MBAMKQYZqm6XQIx+TmSgsXSmvWBP66ru7/fs/rlUxT\nysqS5s+XMjOdyQgACEvRW7DPPy/NnSvV1gaK9HQMI1C2ixZJM2YELx8AIKxF5xbxyXKtqTnztaYZ\nuG7u3MBfU7IAgCaIvhVsbq40aFDTyvV/JSRIOTlSv36WxwIARJboe4p44cLAtnBL1NYG7gcA4Ayi\nawVbViZ17vzzh5maKz5e2r+fp4sBAI2KrhXskiWtH8MwrBkHABDRoqtgd+xo3epVCmwT5+dbkwcA\nELGiq2CrqqwZp7LSmnEAABErugo2Kcmacdq3t2YcAEDEiq6C7d078JBSa3i9Uq9e1uQBAEQsniJu\nJjM+XgZPEQMAziC6VrBpaYGzhQ2jRbefkPR2XZ2MtDRrcwEAIk50FawUOLjf623RrXWSTh4zYRiG\nrrzySstiAQAiS/QVbGZm4OD+hIRm3WYmJGiOpC0/+bWNGzfKMAx9+umnViYEAESA6PoM9qda+DYd\no5HtZZ/Pp7i4OBvCAgDCTfStYE+aMSNwcP+oUYEni/9329jrDfz6qFGB6/77Fh3TNHX77befckiP\nx9NoAQMAokf0rmB/qrw8cPxhfn7gEIn27QNfxZk06bRPC1dXV6tt27anHfL666/XmpMvcgcARB0K\ntpXOtGJds2aNrr/++iClAQCEiujdIraIaZqaOnXqaX8/KytLhmHo2LFjQUwFAHAaK1iLVFRUKCUl\npdFrXC6XGhoa+JwWAKIAK1iLJCcny+/3N3qN3++Xy+ViyxgAogAFayHDMM64ZSxJH3zwgQzD0LJl\ny4KUDAAQbGwR2+TgwYNKT09v0rXl5eVKTU21OREAIJgoWBv5/X653e4mXevxeHT8+PEmXw8ACG1s\nEdvI5XI1ejDFT/l8PsXExGjgwIFBSAYAsBsr2CD58ssv1aNHjyZf/9JLL+nOO++0MREAwE4UbBDV\n19fL4/GoOX/L9+zZowsuuMC+UAAAW7BFHESxsbHy+/0aO3Zsk+/p0qWL4uPj5fP5bEwGALAaBeuA\nZcuWKS8vr8nX+3w+xcfH6/LLL2/W6hcA4BwK1iF9+/ZVTU1Ns+7ZtGmTXC6XFi1aZFMqAIBV+Aw2\nBIwYMUKrVq1q9n0FBQXKyMiwIREAoLUo2BCRk5OjQYMGNfu+2NhYVVRUKDEx0fpQAIAWo2BDSFVV\nlc4666wW3durVy9t27ZNLhe7/gAQCvhpHEKSkpLk9/t17bXXNvve/Px8ud1uzZ8/34ZkAIDmYgUb\not59913deOONLb4/JyeHU6EAwEEUbAgrLS3VOeec0+Kv5rjdbh0+fJgXCQCAA9giDmFnn3226uvr\n1b9//xbdf+LECXXo0EHdunXTDz/8YHE6AEBjKNgQ53a7tWHDBv39739v8RglJSXyeDyaNm0aB1UA\nQJCwRRxG9u3bZ8m5xCtXrmzV57sAgDOjYMOMz+fT5Zdfru3bt7dqHJfLpa+++ooXCQCATdgiDjMe\nj0fbtm3T008/3apx/H6/unTpok6dOun48eMWpQMAnMQKNowVFhbqkksusWSsW265RUuXLuWgCgCw\nCD9Nw1hGRoaOHTum7t27t3qsZcuWye12a/HixRYkAwBQsGEuMTFRxcXFevDBBy0Z74477pDL5VJB\nQYEl4wFAtGKLOIJ88cUXLf7O7Kl06NBBRUVFSklJsWxMAIgWrGAjyBVXXKGjR4/q/PPPt2S88vJy\npaamKisri4MqAKCZKNgIk5ycrD179mjmzJmWjfn+++/L4/Fo0aJFHFQBAE3EFnEE+89//qPrrrvO\n8nHXrVunq666yvJxASCSULAR7uDBg+rTp4/Ky8stHTcpKUkFBQXq1KmTpeMCQKRgizjCnXvuuTpw\n4IAmTJhg6bhVVVU677zzdOWVV3JQBQCcAgUbBWJjY/Xaa69p2bJllo+9ceNGJSYm6g9/+IP8fr/l\n4wNAuGKLOMqUlJSoX79+qqqqsmX8VatWadiwYbaMDQDhhBVslOnatasOHTqk4cOH2zL+8OHD1aZN\nG+3atcuW8QEgXFCwUcjr9erdd9/VCy+8YMv4NTU1uvjii9WrVy9VVFTYMgcAhDq2iKPc9u3b1b9/\nf9XW1to2x5133qlnn31WcXFxts0BAKGGFWyUu/TSS3Xo0CENHDjQtjlefvlleTweLVmyhIMqAEQN\nChZKSkrSp59+qoULF9o6z+TJk+X1erV582Zb5wGAUMAWMX5m/fr1Gjx4sO1nD1900UX67LPPdO65\n59o6DwA4hRUsfmbAgAH65ptvdOmll9o6z1dffaX09HSNHTuWgyoARCQKFr+QlpamLVu2aN68ebbP\ntXz5ciUmJurJJ5/koAoAEYUtYjRq9erVGjlypBoaGmyfKyYmRqtXr9bQoUNtnwsA7EbB4oz27dun\noUOHavfu3UGZr2PHjsrJyVH37t2DMh8A2IEtYpxR586dlZ+frylTpgRlvsOHD6tHjx4aOnQoB1UA\nCFsULJrE4/HolVde0RtvvKGYmJigzPnRRx8pJSVFf/rTn2x/qhkArMYWMZqtqKhIQ4YM0cGDB4M2\np8vl0tKlSzV27FgZhhG0eQGgpVjBotl69uypXbt2afTo0UGb0+/369Zbb1VKSory8vKCNi8AtBQF\nixZJTEzU8uXL9dxzz8ntdgdt3srKSl122WXKzMwM6goaAJqLLWK0Wm5urrKysnT06NGgzz19+nQt\nWrRIbdq0CfrcANAYChaWqKio0NixY7V27VpH5n/xxRc1depUuVxsygAIDfw0giWSk5P14Ycf6tFH\nHw3aU8Y/NW3aNLVr106ffPJJ0OcGgFNhBQvLrV27VqNGjdL333/vyPw9e/bUypUr1a1bN0fmBwCJ\nFSxsMHjwYO3cuVP9+vVzZP6ioiJ1795dv//971VZWelIBgCgYGGL9PR0bdiwQbNnz1ZsbKwjGf7x\nj38oOTlZCxcuVH19vSMZAEQvtohhuxUrVmjChAmOvpbO4/Horbfe0siRIzmoAkBQULAIipKSEo0Y\nMULFxcWO5jjvvPO0cuVK9e3b19EcACIfW8QIiq5duyovL0+TJ09WXFycYzm++eYb/frXv1ZWVhYH\nVQCwFQWLoPF6vXr11Vf1wgsvKCEhwdEs77//vtLT0zVv3jxHt64BRC62iOGI7du3a8SIEfrmm2+c\njiK3262XXnpJkyZN4qAKAJahYOGYqqoqTZw4UR988IHq6uqcjqOUlBQtX75cgwYNcjoKgAjAH9fh\nmKSkJK1YsUJ//etfHd8ylqSjR4/qmmuuUf/+/VVSUuJ0HABhjhUsQsL69es1evRolZWVOR3lR1On\nTtXjjz+u9u3bOx0FQBiiYBEyysrKdMstt2jTpk2qra11Oo4kyTAMLVq0SNnZ2Y4dmAEgPLFFjJCR\nlpamjz/+WHPmzFFiYqLTcSRJpmlqzpw5SklJ0cqVK8WfRwE0FStYhKQ1a9Zo3LhxqqqqCqlS69mz\np95880316dPH6SgAQhwrWISkrKwsbdu2TX369AmJB6BOKioqUt++fTV27FgOqgDQKAoWIatz587a\nuHGjJk2apKSkJKfj/Mzy5cuVnp6uBQsWqKamxuk4AEIQW8QIC0uXLtX06dN17NixkNoylgIvEnjx\nxRc1YcIEDqoA8CMKFmGjqKhII0eO1MGDB0PyeMPzzz9fr7/+ugYOHOh0FAAhgD9uI2z07NlTeXl5\nuvHGG5WSkuJ0nF/Yv3+/rr76ag0ZMoSDKgBQsAgviYmJeuONN/TII48oKSkpJN/t+vHHH6tbt266\n5557VFlZ6XQcAA5hixhhKzc3V6NHj9Z3332n6upqp+Ocktvt1hNPPKG77rqLgyqAKEPBIqwdPXpU\nEyZM0JYtW0LqmMX/lZqaqldffVXDhw8PyVU3AOuxRYywlpKSolWrVmnWrFkhfWbwkSNHdOONNyoz\nM1Pbtm1zOg6AIGAFi4ixdu1a3XbbbaqpqQnZLeOTxo0bp0WLFumcc85xOgoAm1CwiCgHDhzQrbfe\nqq+//lqHDh1yOk6jDMPQgw8+qHnz5oXUaVUArMEWMSJKenq6PvnkE40fP16pqalOx2mUaZr685//\nrLPPPluvvfaa/H6/05EAWIgVLCLWihUrNHXqVPl8vpA8mKKDpImSeks6S5K/bVv1GjdOFz7yiNSh\ng7PhALQaBYuIVlJSojFjxqiiokLffvut03EkSf0kzZeUJcmU9NPN4RpJMS6Xfrj2WiU+9piUmelE\nRAAWoGAR8Wpra5Wdna3Vq1c7/rnsNElPSIqX5G7kuhOSTsTEqOFPfwp8Prtpk1RYKB0/LtXVSfHx\nUmKi9KtfSb/5jTR5MqteIMRQsIgaixcv1uzZs1VfX+/IlvHJcm3TjHvM//6nSQ9LJCVJF14omaZk\nGIHC7dBB6t2bAgYcQMEiqmzfvl1jxoxRQ0OD9u3bF7R5+0n6VM0rV8u43VJMjHTDDdL8+Ww7A0HC\nU8SIKpdeeqm2bNmiyy67TBdccEHQ5p2vwLawI06ckHw+acUKacAA6fnnnUoCRBVWsIhKpmnqySef\n1GOPPaa6ujpbX5reQdI+SV7bZmiB3/5W+uwzp1MAEY0VLKKSYRiaPXu2Vq5cqfbt29u6mp2owOeo\nIWXdusDntM8843QSIGJRsIhqV111lfLy8nTRRRepe/futszRWz//Kk5ImTlTOuccKTfX6SRAxKFg\nEfXS0tL0wQcf6JZbbtHZZ58tr9fazdyzLB3NBocPB77qc//9TicBIgqfwQI/sWbNGk2cOFGJiYna\ns2ePJWO+JmmCJSMFwe9/Ly1d6nQKICKwggV+IisrS7m5uUpNTVVGRoYlY1YoBD+DPZ233pL+8Aen\nUwARgRUscAo+n09z5szRO++8o/LyctXV1bV4rGoFPoMNm9esG0bg5Kh+/ZxOAoQ1ChZoxNKlS5Wd\nna127do1e8v45OESYVWuJ116qcSL4YFWoWCBMygqKtLo0aOVkJCgvLy8Jt0zTdJzCnwGE3blelJZ\nGccrAq3AZ7DAGfTs2VO5ubnq0aOHunbtKo/H0+j10yQ9rcBh/mFbrpI0caLTCYCwxgoWaCLTNPXC\nCy/ogQceUNu2bbV3795fXOPomcN24McD0GKsYIEmMgxDM2bM0Jo1a+T3+3X55Zf/4pr5CrEjEVur\nqMjpBEDYomCBZsrMzFReXp5SUlJ0ySWXKC4uTlLgzOEsRdj/qe64w+kEQNiKqJ8FQLCkpKTo3Xff\n1W233ab27durc+fOishPLDdvdjoBELb4DBZopbVr12r8+PFacuKErisvdzqO9fgRAbQIBQtY4MCB\nA9rbq5cGVFY6HcV6/IgAWoQtYsAC6enp6n/99U7HABBCKFjAIq4+fQLHDAKA2CIGrFNWJnXsGFFb\nqn5JZkOD3G6301GAsMMKFrBKWpqUmup0CkuZkmJjY1VSUuJ0FCDsULCAlS67zOkEljElHVfgBKtu\n3brpiSeecDoSEFYoWMBK11zjdAJL/b+f/O+5c+ee8vQqAKfGZ7CAlcrKpLPPdjqFJUyd+k/gHo9H\nBw8eVHJycrAjAWGFFSxgpbQ0KSPD6RSW2H+aX/f5fEpJSdHbb78d1DxAuKFgAatFwGeVpqRnznDN\nmDFjNHbs2GDEAcISW8SAHfr0kbZvdzpFi9VKOl/SkSZcm5ycrEOHDv340gMAAaxgATu8/LIUE+N0\nihbxS1qtppWrJFVUVMjj8WjLli02pgLCDwUL2CEzU/rb36QwPKChVtLCFtzXr18/3X///VbHAcIW\nW8SAnZ5/Xrr77rA53ckv6S5JL7ZijK5du2rXrl1yufjzO6IbBQvY7T//ka67zukUZ2RKWixpigVj\nuVwu7d+/X+np6RaMBoQn/ogJ2O13v5MGDXI6RaNMSWtlTblKkt/vV6dOnfTyyy9bNCIQfljBAsGQ\nmysNGCDV1zud5BdMBb7zeoFN4w8cOFA5OTk2jQ6ELlawQDBkZkpPPy3Fxjqd5Bd8ksbYOP5nn32m\nNm3aqLq62sZZgNBDwQLBMmNGoGQ9HqeT/Oi4pHsl2f0Fm5qaGrVt21YffvihzTMBoYOCBYJpxgzp\n88+l0aMDRevQ13j8CpTrHLXuieHm+t3vfqfJkycHcUbAOXwGCzilvFxaskTKz5fy8qTiYunECVun\nbPjvf95T4LuuTh0NkZaWpoMHD/Iid0Q0ChYIJUVF0ty5UkGBVFEh+f2B79D6/YEHpPz+Jg1z8v/U\nPkkVkiolFUjKlfR3Nf2UJrvt3LlTPXv2dDoGYAsKFgg35eXSs89Kq1ZJpaWB0jUM/ZCUpF3ffadd\n332n2m7dNHvHjpAp0sY88sgjWrBggdMxAMtRsECE2bhxo7KzsxUXF6fvv/9ehYWFTkc6o4yMDBUU\nFDgdA7AUDzkBEaZ///7atGmTpkyZoiNHjujmm2+W1+t1OlajCgsLFRsbq6NHjzodBbAMBQtEIJfL\npSlTpqi4uFjp6elKTEzUTTfd5HSsRjU0NCg1NVVLly51OgpgCbaIgShQWFiomTNnqrS0VKZpaufO\nnU5HalRWVpZWr17tdAygVShYIEqYpqm3335bc+bM0cUXX6x169appqbG6VinlZiYqPLycsXHxzsd\nBWgRtoiBKGEYhsaMGaOdO3fqiiuukNfr1bBhw5yOdVrV1dXyer364osvnI4CtAgFC0SZhIQEPfzw\nw9q8ebPi4+PVpUsXZWRkOB3rtPr376+ZM2c6HQNoNraIgSj30UcfadasWUpJSVFeXp6OHz/udKRT\n6tSpk/bt28eL3BE2+DcViHJDhgzRtm3bNGbMGHm9Xg0dOtTpSKf07bffyu12a+/evU5HAZqEggWg\n2NhYzZo1S4WFhTr//PPVsWNH/epXv3I61il16dJFTz31lNMxgDNiixjAL+Tm5io7O1s+n08lJSUh\n+S7XzMxMbdq0yekYwGlRsABOye/36/XXX9f8+fPVtWtXrVu3zulIvxAbG6sjR46oXbt2TkcBfoEt\nYgCn5HK5NHHiRBUVFek3v/mNUlJSdPHFFzsd62fq6+uVlJSk9957z+kowC+wggXQJMXFxZo1a5b2\n7NmjQ4cOhdy28ZgxY7R8+XKnYwA/omABNJlpmnrnnXd03333KSUlRZs3b3Y60s8kJSXpyJEjiomJ\ncToKwBYxgKYzDEMjR47Uzp07NXLkSCUnJ6t79+5Ox/pRVVWVYmNjlZ+f73QUgIIF0Hzx8fFasGCB\ntm3bpr59+6pTp05q27at07F+1Lt3b/3xj390OgaiHFvEAFotJydH2dnZMk0zpF6cfsEFF+jrr7+W\nYRhOR0EUYgULoNWuvvpq5eXlafr06UpNTVW3bt2cjiRJ2rt3r1wulw4fPux0FEQhChaAJWJiYnT3\n3XerqKhIgwcPVlpaWshsG59zzjlavHix0zEQZdgiBmCLrVu3Kjs7W6WlpSopKXE6jiRpwIAB+vzz\nz52OgShBwQKwjWmaevPNNzVv3jx5PB7t2bPH6UiKi4vTd999J6/X63QURDi2iAHYxjAMjR8/XsXF\nxbrllluUnJzs+LbxDz/8oISEBH366aeO5kDkYwULIGh2796te++9V9u3b9eBAwecjqMJEybotdde\nczoGIhQFCyDo3nvvPc2aNUs+n0/ffvuto1mSk5NVXl7Oi9xhOf6NAhB0w4YNU2Fhoe655x4lJycr\nMTHRsSwVFRVyu90h8yAWIgcFC8ARHo9H999/v3bs2KGRI0cqNTXV0TzdunXTY4895mgGRBa2iAGE\nhM8//1zZ2dk6dOiQSktLHcvRo0cPFRcXOzY/IgcFCyBknDhxQq+88ooeeOAB1dTU6Pjx445lqays\n1FlnneXY/Ah/bBEDCBlut1vTpk1TcXGxJk2a5GjBtW/fXsuWLXNsfoQ/VrAAQtaOHTs0c+ZMFRQU\n6OjRo45kGDJkiD788ENH5kZ4o2ABhDTTNLVs2TLNnTtXFRUVqqmpCXoGj8ejY8eOKTY2NuhzI3yx\nRQwgpBmGoVtvvVXFxcWaPXu2kpKSgp7B5/MpLi5OmzZtCvrcCF+sYAGEla+//lqzZ8/WJ598ou+/\n/z7o80+fPl3PP/980OdF+KFgAYSlDz74QDNnztT+/ftVV1cX1LlTU1NVWlrK6U9oFP92AAhL1113\nnfLz8/Xoo48G/WnjI0eOyO12h8R5yghdFCyAsBUXF6c5c+Zo586dmjhxotq0aRPU+Tt16qS//e1v\nQZ0T4YMtYgAR44svvtA999yjgoIC+Xy+oM2bkZGhgoKCoM2H8EDBAogofr9fixcv1v333x/U784a\nhqHq6molJCQEbU6ENraIAUQUl8ulKVOmqKSkRLNmzVJ8fHxQ5jVNU23atNHq1auDMh9CHytYABGt\nsLBQ2dnZ+vzzz1VfXx+UOYcNG6ZVq1YFZS6ELgoWQMQzTVMrVqxQdna2Dh48GJQ5PR6Pampq+CpP\nFOOfPICIZxiGRo8erd27d+vhhx+Wx+OxfU6fzye3283DT1GMggUQNRISEvTQQw9p165dGj16tNxu\nt+1z9urVS3PnzrV9HoQetogBRK2PP/5YM2bM0O7du22fKy0tzdEXySP4WMECiFrXXnutCgsL9dRT\nT8nr9do6V1lZmQzD0JEjR2ydB6GDggUQ1WJjYzVr1izt3btXd9xxhwzDsHW+Dh066OWXX7Z1DoQG\ntogB4Cdyc3M1bdo0bd261dZ5evfure3bt9s6B5xFwQLA//D7/Xr99dd1zz33qLq62rZ5DMNQXV2d\n4uLibJsDzmGLGAD+h8vl0sSJE3XgwAHNmTPHtnlM05TH41FOTo5tc8A5rGAB4AyKi4s1ffp0W4tw\n9OjR+te//mXb+Ag+ChYAmsA0Tb377ru64447bHuJQHx8vI4fP87pTxGCf4oA0ASGYejGG2/Ut99+\nq0ceecSWOerq6uR2u7Vnzx5bxkdwUbAA0Azx8fFasGCB9u/fr5tuusmWOS688EItWLDAlrERPGwR\nA0Ar5OTkaPz48Tpw4IDlY3fs2FGHDh2yfFwEBytYAGiFq6++Wnv37tWzzz5r+SEVhw8flmEYOnbs\nmKXjIjgoWABopZiYGN19990qKyvT5MmTLR+/Xbt2evPNNy0fF/ZiixgALLZ161bddttt2rVrl6Xj\n9u3bV3l5eZaOCftQsABgA9M0tXTpUk2cOFENDQ2WjWsYhurr64Pyqj20DlvEAGADwzA0btw4VVRU\n6L777rNsXNM0FRMTo9zcXMvGhD1YwQJAEOzevVvjxo3T5s2bLRvz5ptv1j//+U/LxoO1KFgACKL3\n3ntPY8aMkc/ns2S8+Ph41dbWWjIWrMUWMQAE0bBhw1RVVWXZaVB1dXUyDIPvy4YgChYAgszj8WjB\nggU6cOCABg8ebMmY5557rh566CFLxoI12CIGAIetX79eWVlZlhwokZaWptLSUgtSobVYwQKAwwYM\nGKDKyko999xzrR6rrKxMhmGopqbGgmRoDQoWAEKA2+3WXXfdpaNHj2rUqFGtHq9NmzZavny5BcnQ\nUmwRA0AI2rFjh6655hpVVFS0apw+ffpo69atFqVCc1CwABCiTNPUW2+9pXHjxrV6rBMnTvAi9yDj\n7zYAhCjDMHTbbbepurq61S8RcLvdys/PtygZmoIVLACEia+//loDBgzQ4cOHWzwGpz8FDwULAGFm\n9erVGjZsWIvvj4uLs+wkKZweW8QAEGZuuOEG+Xw+3XvvvS26/4cffpBhGK1+gAqNo2ABIAzFxcXp\nySef1KFDh3ThhRe2aIyUlBTLjmzEL7FFDAARYMOGDRowYECL7k1OTtbRo0ctTgRWsAAQAa688kqd\nOHFCf/nLX5p9b0VFxY8vcod1KFgAiBAul0sPPPCAKisr1bNnz2bfHxcXp3feeceGZNGJLWIAiFCF\nhYXq1auXmvtjPiMjQwUFBTalih6sYAEgQmVkZOjEiRN65plnmnVfYWGhDMOwKVX0YAULAFGgtrZW\nV111lfLy8pp135dffqlu3brZlCqysYIFgCjg9Xq1ZcsW7dmzp1mr0+7du1vydp9oxAoWAKLQG2+8\nodtvv71Z91AXzUPBAkCUqq+v16BBg7Rhw4Ym33Ps2DElJibamCpysEUMAFEqNjZW69evV2lpqdxu\nd5Puadu2rR5++GF7g0UIVrAAAEnSqlWrNGLEiCZd6/V6VVNTY3Oi8EbBAgB+5Pf7NXToUK1du7ZJ\n1zc0NDR59Rtt2CIGAPzI5XLp448/VlVVVZOuj4mJ0cqVK21OFZ5YwQIATmvdunUaOHDgGa/r1KmT\nvvnmmyAkCh8ULACgUaZpavjw4Vq9enWTrkUABQsAaJK6ujp5vd4zXrdr1y517949CIlCG5/BAgCa\nJD4+XqZpnvG4xR49eui3v/1tkFKFLlawAIAWGTVqlP797383ek00VwwFCwBosYaGBsXGxjZ6TXV1\ntdq0aROkRKGDLWIAQIvFxMTINE3t3r37tNckJiZq+vTpQUwVGljBAgAsc9NNNzX6vdhoqhwKFgBg\nKdM05XKdfoM0WmqHLWIAgKUMw5Bpmtq/f/9pf/+VV145/QBlZdLjj0u33y6NGBH478cfl8rLbUps\nD1awAABnE4a/AAACi0lEQVRbZWVl6f333z/l7/2sgnJzpYULpTVrAn9dV/d/v+f1SqYpZWVJ8+dL\nmZk2JrYGBQsACArDME7566ZpSs8/L82dK9XWBor09IMEynbRImnGDJuSWoOCBQAETWlpqTp27Piz\nX5sm6bn4eLl/umI9k4SEkC9ZChYAEHT9+vXTli1b1E/Sp5Ja9C3ZhAQpJ0fq18/SbFahYAEAjnnb\nMDRSUoveKGsY0qhR0r/+ZXEqa1CwAABnlJVJnTv//GGm5oqPl/bvlzp0sC6XRfiaDgDAGUuWtH4M\nw7BmHBtQsAAAZ+zY0brVqxR46jg/35o8FqNgAQDOqKqyZpzKSmvGsRgFCwBwRlKSNeO0b2/NOBaj\nYAEAzujdO/CQUmt4vVKvXtbksRhPEQMAnMFTxAAA2CAtLXC28GmOUDwjw5BuuCEky1ViBQsAcFJu\nrjRokFRT0/x7Q/wkJ1awAADnZGYGzhROSGjefSfPIg7RcpWkGKcDAACi3MkD+3mbDgAANti8OfA+\n2NWrA0VaW/t/v3fyfbA33BB4H2wIr1xPomABAKGlvDxw/GF+fuAQifbtA1/FmTQpZB9oOhUKFgAA\nG/CQEwAANqBgAQCwAQULAIANKFgAAGxAwQIAYAMKFgAAG1CwAADYgIIFAMAGFCwAADagYAEAsAEF\nCwCADShYAABsQMECAGADChYAABtQsAAA2ICCBQDABhQsAAA2oGABALABBQsAgA0oWAAAbEDBAgBg\nAwoWAAAbULAAANiAggUAwAYULAAANqBgAQCwAQULAIANKFgAAGxAwQIAYAMKFgAAG1CwAADYgIIF\nAMAGFCwAADagYAEAsAEFCwCADShYAABsQMECAGADChYAABv8f4noJqN/OpfrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f31beac128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### apply Spring-force\n",
    "#######################\n",
    "pos = nx.spring_layout(G, k = None, dim = 3, scale = 1.0)\n",
    "nx.draw_spring(G, k = 30, dim = 2, scale = 1.0, iterations =1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### APPLY community detector\n",
    "# maximize betweenness and modularity\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### LOAD IN DATA\n",
    "###################\n",
    "# https://stackoverflow.com/questions/14529838/apply-multiple-functions-to-multiple-groupby-columns\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = _helpers._preprocess(Rocket.DATA_merged) \n",
    "df = _helpers._group_patients(df, method = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y =_helpers._get_matrix(df, features = 'genomic', target = 'Treatment_risk_group_in_ALL10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Prepping data, this may take a while..\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Grouping probesets\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.775862068966 +/-: 0.00553543761035\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.7344 - acc: 0.4348 - val_loss: 0.7280 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.7230 - acc: 0.4348 - val_loss: 0.7044 - val_acc: 0.4167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.7053 - acc: 0.4348 - val_loss: 0.6736 - val_acc: 0.4167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6843 - acc: 0.4565 - val_loss: 0.6219 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6567 - acc: 0.4565 - val_loss: 0.5629 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5953 - acc: 0.6522 - val_loss: 0.6228 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5544 - acc: 0.7174 - val_loss: 0.6010 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5203 - acc: 0.7609 - val_loss: 0.5868 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4949 - acc: 0.7609 - val_loss: 0.5767 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4808 - acc: 0.7391 - val_loss: 0.5656 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5133 - acc: 0.7609 - val_loss: 0.3942 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5120 - acc: 0.7826 - val_loss: 0.4007 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.4918 - acc: 0.7826 - val_loss: 0.3677 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4877 - acc: 0.7609 - val_loss: 0.3662 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4819 - acc: 0.7826 - val_loss: 0.3850 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4327 - acc: 0.8298 - val_loss: 0.5608 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4376 - acc: 0.8298 - val_loss: 0.6739 - val_acc: 0.6364\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4329 - acc: 0.8298 - val_loss: 0.6811 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4278 - acc: 0.8298 - val_loss: 0.5982 - val_acc: 0.7273\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4248 - acc: 0.8298 - val_loss: 0.5458 - val_acc: 0.7273\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4550 - acc: 0.8085 - val_loss: 0.4090 - val_acc: 0.9091\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4563 - acc: 0.8085 - val_loss: 0.4096 - val_acc: 0.8182\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4551 - acc: 0.8085 - val_loss: 0.4134 - val_acc: 0.8182\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4531 - acc: 0.8085 - val_loss: 0.4115 - val_acc: 0.8182\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4537 - acc: 0.8085 - val_loss: 0.4214 - val_acc: 0.8182\n",
      "MODEL: DNN accuracy:  0.775862068966 +/-: 0.00174755882247\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.775862068966 +/-: 0.00553543761035\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.7172 - acc: 0.4348 - val_loss: 0.6991 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.7047 - acc: 0.4348 - val_loss: 0.6660 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6847 - acc: 0.5652 - val_loss: 0.6228 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6654 - acc: 0.6087 - val_loss: 0.5734 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6395 - acc: 0.6522 - val_loss: 0.5351 - val_acc: 0.9167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5970 - acc: 0.7609 - val_loss: 0.6478 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5760 - acc: 0.7826 - val_loss: 0.6499 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5628 - acc: 0.8043 - val_loss: 0.6508 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5561 - acc: 0.8261 - val_loss: 0.6517 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5488 - acc: 0.8261 - val_loss: 0.6520 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5895 - acc: 0.8043 - val_loss: 0.4852 - val_acc: 0.8333\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5852 - acc: 0.8043 - val_loss: 0.4764 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5827 - acc: 0.8043 - val_loss: 0.4766 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5854 - acc: 0.8043 - val_loss: 0.4942 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5737 - acc: 0.8043 - val_loss: 0.4707 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5208 - acc: 0.8298 - val_loss: 0.7007 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5144 - acc: 0.8298 - val_loss: 0.7152 - val_acc: 0.6364\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5105 - acc: 0.8298 - val_loss: 0.7198 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5047 - acc: 0.8298 - val_loss: 0.7329 - val_acc: 0.6364\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4959 - acc: 0.8298 - val_loss: 0.7428 - val_acc: 0.6364\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5341 - acc: 0.8085 - val_loss: 0.5310 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5239 - acc: 0.8085 - val_loss: 0.5025 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5124 - acc: 0.8085 - val_loss: 0.4843 - val_acc: 0.8182\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5073 - acc: 0.8085 - val_loss: 0.4780 - val_acc: 0.8182\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.5058 - acc: 0.7872 - val_loss: 0.4762 - val_acc: 0.8182\n",
      "MODEL: DNN accuracy:  0.793103448276 +/-: 0.00865672179584\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.775862068966 +/-: 0.00553543761035\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6970 - acc: 0.4348 - val_loss: 0.6798 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6817 - acc: 0.4565 - val_loss: 0.6522 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6646 - acc: 0.5435 - val_loss: 0.6157 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6429 - acc: 0.6087 - val_loss: 0.5662 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6201 - acc: 0.6739 - val_loss: 0.5161 - val_acc: 0.9167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5710 - acc: 0.7609 - val_loss: 0.6146 - val_acc: 0.6667\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5445 - acc: 0.7609 - val_loss: 0.6101 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5270 - acc: 0.7609 - val_loss: 0.6055 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5169 - acc: 0.7826 - val_loss: 0.6028 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5053 - acc: 0.8043 - val_loss: 0.5978 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5417 - acc: 0.7609 - val_loss: 0.4260 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5350 - acc: 0.7826 - val_loss: 0.4426 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5283 - acc: 0.8043 - val_loss: 0.4353 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5253 - acc: 0.8043 - val_loss: 0.4268 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5237 - acc: 0.8043 - val_loss: 0.4139 - val_acc: 0.9167\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4741 - acc: 0.8298 - val_loss: 0.6142 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4752 - acc: 0.8298 - val_loss: 0.6147 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4651 - acc: 0.8298 - val_loss: 0.6563 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4656 - acc: 0.8298 - val_loss: 0.6704 - val_acc: 0.6364\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4646 - acc: 0.8298 - val_loss: 0.6610 - val_acc: 0.6364\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4974 - acc: 0.8085 - val_loss: 0.4987 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4927 - acc: 0.8085 - val_loss: 0.4607 - val_acc: 0.8182\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4924 - acc: 0.8085 - val_loss: 0.4537 - val_acc: 0.9091\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4934 - acc: 0.7872 - val_loss: 0.4546 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4930 - acc: 0.7872 - val_loss: 0.4553 - val_acc: 0.8182\n",
      "MODEL: DNN accuracy:  0.810344827586 +/-: 0.0111834756603\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.793103448276 +/-: 0.00199527978957\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 1.1381 - acc: 0.4348 - val_loss: 1.1327 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 1.1013 - acc: 0.4348 - val_loss: 1.0725 - val_acc: 0.4167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 1.0593 - acc: 0.4348 - val_loss: 0.9961 - val_acc: 0.4167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.9996 - acc: 0.4348 - val_loss: 0.9162 - val_acc: 0.4167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.9373 - acc: 0.4348 - val_loss: 0.8421 - val_acc: 0.4167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.8603 - acc: 0.4348 - val_loss: 0.8493 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.7929 - acc: 0.4348 - val_loss: 0.7935 - val_acc: 0.4167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.7381 - acc: 0.4348 - val_loss: 0.7442 - val_acc: 0.4167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6890 - acc: 0.4348 - val_loss: 0.7090 - val_acc: 0.4167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6578 - acc: 0.4348 - val_loss: 0.6810 - val_acc: 0.4167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6512 - acc: 0.4348 - val_loss: 0.5949 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6307 - acc: 0.4348 - val_loss: 0.5887 - val_acc: 0.4167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6144 - acc: 0.4348 - val_loss: 0.5780 - val_acc: 0.4167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6063 - acc: 0.4348 - val_loss: 0.5646 - val_acc: 0.4167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5961 - acc: 0.4348 - val_loss: 0.5772 - val_acc: 0.4167\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5830 - acc: 0.4255 - val_loss: 0.5828 - val_acc: 0.4545\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5729 - acc: 0.4255 - val_loss: 0.6549 - val_acc: 0.4545\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5846 - acc: 0.4255 - val_loss: 0.7060 - val_acc: 0.4545\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5540 - acc: 0.4255 - val_loss: 0.5967 - val_acc: 0.4545\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.5564 - acc: 0.4255 - val_loss: 0.5570 - val_acc: 0.4545\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5611 - acc: 0.4255 - val_loss: 0.5452 - val_acc: 0.4545\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5565 - acc: 0.4255 - val_loss: 0.5377 - val_acc: 0.4545\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5530 - acc: 0.4255 - val_loss: 0.5264 - val_acc: 0.4545\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5475 - acc: 0.6809 - val_loss: 0.5248 - val_acc: 0.7273\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.5445 - acc: 0.7872 - val_loss: 0.5221 - val_acc: 0.7273\n",
      "MODEL: DNN accuracy:  0.48275862069 +/-: 0.0142011674414\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.793103448276 +/-: 0.00199527978957\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6832 - acc: 0.5652 - val_loss: 0.6557 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6711 - acc: 0.5652 - val_loss: 0.6378 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6609 - acc: 0.5870 - val_loss: 0.6079 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6433 - acc: 0.7174 - val_loss: 0.5758 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6257 - acc: 0.7826 - val_loss: 0.5398 - val_acc: 0.8333\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5762 - acc: 0.7826 - val_loss: 0.6244 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5500 - acc: 0.7826 - val_loss: 0.6105 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5283 - acc: 0.8043 - val_loss: 0.6019 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5122 - acc: 0.8043 - val_loss: 0.5909 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5061 - acc: 0.8043 - val_loss: 0.5835 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5384 - acc: 0.7609 - val_loss: 0.4298 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5261 - acc: 0.7826 - val_loss: 0.4207 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5240 - acc: 0.7609 - val_loss: 0.4315 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5223 - acc: 0.7609 - val_loss: 0.4151 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5204 - acc: 0.7826 - val_loss: 0.4510 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4926 - acc: 0.8085 - val_loss: 0.5813 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4658 - acc: 0.8298 - val_loss: 0.6755 - val_acc: 0.6364\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4678 - acc: 0.8298 - val_loss: 0.7401 - val_acc: 0.5455\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4671 - acc: 0.8085 - val_loss: 0.7797 - val_acc: 0.4545\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4668 - acc: 0.8298 - val_loss: 0.7919 - val_acc: 0.4545\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5189 - acc: 0.7660 - val_loss: 0.5598 - val_acc: 0.6364\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5064 - acc: 0.8085 - val_loss: 0.5478 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4984 - acc: 0.8085 - val_loss: 0.4809 - val_acc: 0.7273\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4912 - acc: 0.7872 - val_loss: 0.4576 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3452 - acc: 0.900 - 0s - loss: 0.4877 - acc: 0.7872 - val_loss: 0.4562 - val_acc: 0.9091\n",
      "MODEL: DNN accuracy:  0.758620689655 +/-: 0.0241550463013\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6857 - acc: 0.5652 - val_loss: 0.6706 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6815 - acc: 0.5652 - val_loss: 0.6569 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6744 - acc: 0.5652 - val_loss: 0.6395 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6682 - acc: 0.5652 - val_loss: 0.6128 - val_acc: 0.5833\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6577 - acc: 0.5652 - val_loss: 0.5885 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6296 - acc: 0.5652 - val_loss: 0.6547 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6141 - acc: 0.5652 - val_loss: 0.6539 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6043 - acc: 0.5652 - val_loss: 0.6542 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5958 - acc: 0.5652 - val_loss: 0.6547 - val_acc: 0.5833\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5876 - acc: 0.5652 - val_loss: 0.6543 - val_acc: 0.5833\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6166 - acc: 0.5652 - val_loss: 0.5279 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6088 - acc: 0.5652 - val_loss: 0.5303 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6044 - acc: 0.6522 - val_loss: 0.5180 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5972 - acc: 0.8043 - val_loss: 0.5120 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5885 - acc: 0.8043 - val_loss: 0.5032 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5418 - acc: 0.8085 - val_loss: 0.6600 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5235 - acc: 0.8298 - val_loss: 0.6703 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5132 - acc: 0.8085 - val_loss: 0.6645 - val_acc: 0.7273\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5034 - acc: 0.8298 - val_loss: 0.6732 - val_acc: 0.6364\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4925 - acc: 0.8298 - val_loss: 0.6758 - val_acc: 0.6364\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5230 - acc: 0.8085 - val_loss: 0.5253 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5158 - acc: 0.7872 - val_loss: 0.4964 - val_acc: 0.8182\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5080 - acc: 0.8085 - val_loss: 0.4909 - val_acc: 0.8182\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5087 - acc: 0.8085 - val_loss: 0.4851 - val_acc: 0.8182\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.5020 - acc: 0.7872 - val_loss: 0.4835 - val_acc: 0.8182\n",
      "MODEL: DNN accuracy:  0.689655172414 +/-: 0.0126202572695\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.810344827586 +/-: 0.00413018412424\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.758620689655 +/-: 0.00534626887183\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6983 - acc: 0.4130 - val_loss: 0.6653 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6836 - acc: 0.5870 - val_loss: 0.6339 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6646 - acc: 0.6304 - val_loss: 0.6005 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6473 - acc: 0.7174 - val_loss: 0.5624 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6318 - acc: 0.7391 - val_loss: 0.5195 - val_acc: 0.9167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5772 - acc: 0.8043 - val_loss: 0.6349 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5471 - acc: 0.8043 - val_loss: 0.6292 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5206 - acc: 0.7826 - val_loss: 0.6243 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5005 - acc: 0.7826 - val_loss: 0.6199 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4914 - acc: 0.7609 - val_loss: 0.6154 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5427 - acc: 0.7609 - val_loss: 0.3796 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5265 - acc: 0.7609 - val_loss: 0.3915 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5171 - acc: 0.8043 - val_loss: 0.4016 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5135 - acc: 0.7826 - val_loss: 0.3911 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5027 - acc: 0.8043 - val_loss: 0.3915 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4447 - acc: 0.8298 - val_loss: 0.6401 - val_acc: 0.6364\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4354 - acc: 0.8298 - val_loss: 0.6968 - val_acc: 0.6364\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4384 - acc: 0.8298 - val_loss: 0.7421 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4319 - acc: 0.8298 - val_loss: 0.7284 - val_acc: 0.6364\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4334 - acc: 0.8298 - val_loss: 0.6465 - val_acc: 0.6364\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4669 - acc: 0.8085 - val_loss: 0.4441 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4621 - acc: 0.8085 - val_loss: 0.4282 - val_acc: 0.8182\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4593 - acc: 0.8085 - val_loss: 0.4280 - val_acc: 0.8182\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4618 - acc: 0.7872 - val_loss: 0.4213 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4574 - acc: 0.7872 - val_loss: 0.4258 - val_acc: 0.8182\n",
      "MODEL: DNN accuracy:  0.793103448276 +/-: 0.00865672179584\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.758620689655 +/-: 0.00534626887183\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.7084 - acc: 0.4348 - val_loss: 0.6983 - val_acc: 0.4167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6983 - acc: 0.4348 - val_loss: 0.6794 - val_acc: 0.4167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6870 - acc: 0.4783 - val_loss: 0.6543 - val_acc: 0.6667\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6719 - acc: 0.5870 - val_loss: 0.6227 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6527 - acc: 0.6087 - val_loss: 0.5945 - val_acc: 0.9167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6182 - acc: 0.7391 - val_loss: 0.6412 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5963 - acc: 0.7609 - val_loss: 0.6266 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5743 - acc: 0.7609 - val_loss: 0.6123 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5577 - acc: 0.7609 - val_loss: 0.6005 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5436 - acc: 0.8043 - val_loss: 0.5905 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5606 - acc: 0.7826 - val_loss: 0.4803 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5550 - acc: 0.7609 - val_loss: 0.4830 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5419 - acc: 0.8043 - val_loss: 0.4646 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5403 - acc: 0.7609 - val_loss: 0.4620 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5314 - acc: 0.7826 - val_loss: 0.4467 - val_acc: 0.9167\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4936 - acc: 0.8298 - val_loss: 0.5859 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4886 - acc: 0.8298 - val_loss: 0.5880 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4835 - acc: 0.8298 - val_loss: 0.6166 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4815 - acc: 0.8298 - val_loss: 0.6125 - val_acc: 0.6364\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4758 - acc: 0.8298 - val_loss: 0.6147 - val_acc: 0.6364\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4942 - acc: 0.8085 - val_loss: 0.5005 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4908 - acc: 0.8085 - val_loss: 0.4784 - val_acc: 0.8182\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4861 - acc: 0.8085 - val_loss: 0.4804 - val_acc: 0.8182\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3979 - acc: 0.900 - 0s - loss: 0.4828 - acc: 0.8085 - val_loss: 0.4779 - val_acc: 0.8182\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4847 - acc: 0.7872 - val_loss: 0.4912 - val_acc: 0.7273\n",
      "MODEL: DNN accuracy:  0.793103448276 +/-: 0.0121833675639\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.793103448276 +/-: 0.00199527978957\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.758620689655 +/-: 0.00534626887183\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6772 - acc: 0.5652 - val_loss: 0.6579 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6592 - acc: 0.6957 - val_loss: 0.6315 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6377 - acc: 0.7609 - val_loss: 0.5933 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6170 - acc: 0.7174 - val_loss: 0.5520 - val_acc: 0.9167\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5997 - acc: 0.7174 - val_loss: 0.5139 - val_acc: 0.9167\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5544 - acc: 0.7609 - val_loss: 0.6011 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5353 - acc: 0.7609 - val_loss: 0.5891 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5133 - acc: 0.7609 - val_loss: 0.5816 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.4988 - acc: 0.8043 - val_loss: 0.5769 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4840 - acc: 0.8043 - val_loss: 0.5775 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.5244 - acc: 0.7609 - val_loss: 0.3850 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5166 - acc: 0.7826 - val_loss: 0.3944 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5062 - acc: 0.7826 - val_loss: 0.4039 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5045 - acc: 0.7826 - val_loss: 0.4068 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.4982 - acc: 0.8043 - val_loss: 0.3985 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4462 - acc: 0.8085 - val_loss: 0.6139 - val_acc: 0.6364\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4506 - acc: 0.8298 - val_loss: 0.6949 - val_acc: 0.6364\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4426 - acc: 0.8298 - val_loss: 0.6949 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4399 - acc: 0.8298 - val_loss: 0.6809 - val_acc: 0.6364\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4369 - acc: 0.8298 - val_loss: 0.6378 - val_acc: 0.6364\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.4693 - acc: 0.8085 - val_loss: 0.4480 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.4727 - acc: 0.8085 - val_loss: 0.4262 - val_acc: 0.8182\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.4708 - acc: 0.8085 - val_loss: 0.4285 - val_acc: 0.8182\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.4679 - acc: 0.8085 - val_loss: 0.4504 - val_acc: 0.7273\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.4667 - acc: 0.8085 - val_loss: 0.4695 - val_acc: 0.7273\n",
      "MODEL: DNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: XGB accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ET accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: CART accuracy:  0.741379310345 +/-: 0.0108321622888\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: RF accuracy:  0.775862068966 +/-: 0.0024006413721\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GBM accuracy:  0.620689655172 +/-: 0.0207004648146\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: ADA accuracy:  0.586206896552 +/-: 0.020912153641\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: LR accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: SVM accuracy:  0.793103448276 +/-: 0.00826487226606\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: GNB accuracy:  0.758620689655 +/-: 0.0280735415991\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "MODEL: MLNN accuracy:  0.775862068966 +/-: 0.00906208337837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Initial alpha = [[ 0.29814633]]\n",
      "   1 - L=-1804.8496513 - Gamma= 0.9999702 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=3.8079164694610025e-17\n",
      "L=-1804.849651326964 - Gamma=0.999970186255669 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.19279166]]\n",
      "   1 - L=-1605.6273696 - Gamma= 0.9999807 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=2.171454640930561e-17\n",
      "L=-1605.6273696478304 - Gamma=0.9999807212053788 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.26693412]]\n",
      "   1 - L=-1762.2220489 - Gamma= 0.9999733 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-1.961257271395433e-17\n",
      "L=-1762.2220488781888 - Gamma=0.9999733073004535 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.291159]]\n",
      "   1 - L=-1757.7879086 - Gamma= 0.9999709 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=5.711096660288379e-18\n",
      "L=-1757.7879086498006 - Gamma=0.9999708849475173 (M=1) - s=0.01\n",
      "Initial alpha = [[ 0.40861195]]\n",
      "   1 - L=-1862.8098123 - Gamma= 0.9999591 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-8.61143219275297e-18\n",
      "L=-1862.8098123457012 - Gamma=0.9999591404741313 (M=1) - s=0.01\n",
      "MODEL: RVM accuracy:  0.706896551724 +/-: 0.0277267322452\n",
      "Initial alpha = [[ 0.22332277]]\n",
      "   1 - L=-1764.6402811 - Gamma= 0.9999777 (M=   1) - s=0.0100\n",
      "Stopping at iteration 1 - max_delta_ml=-4.0743135112679486e-17\n",
      "L=-1764.6402810798684 - Gamma=0.9999776682216228 (M=1) - s=0.01\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +  Creating X,y\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Reducing dimensionality\n",
      "++++++++++++++++++++++++++++++  RESULTS FOR CLASSIFICATION WITH GENOMIC DATA ++++++++++++++++++++++++++++++\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6927 - acc: 0.5652 - val_loss: 0.6762 - val_acc: 0.5833\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.6846 - acc: 0.5652 - val_loss: 0.6661 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.6751 - acc: 0.5652 - val_loss: 0.6489 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.6580 - acc: 0.5652 - val_loss: 0.6275 - val_acc: 0.5833\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.6434 - acc: 0.6087 - val_loss: 0.5990 - val_acc: 0.6667\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6117 - acc: 0.7391 - val_loss: 0.6379 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5995 - acc: 0.8261 - val_loss: 0.6329 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5892 - acc: 0.8261 - val_loss: 0.6310 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5831 - acc: 0.8043 - val_loss: 0.6300 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5781 - acc: 0.7826 - val_loss: 0.6293 - val_acc: 0.7500\n",
      "Train on 46 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 0s - loss: 0.6057 - acc: 0.7391 - val_loss: 0.5099 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 0s - loss: 0.5954 - acc: 0.7609 - val_loss: 0.5027 - val_acc: 0.9167\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 0s - loss: 0.5909 - acc: 0.7609 - val_loss: 0.5004 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 0s - loss: 0.5854 - acc: 0.7826 - val_loss: 0.5019 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 0s - loss: 0.5805 - acc: 0.8261 - val_loss: 0.4978 - val_acc: 0.8333\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5364 - acc: 0.8085 - val_loss: 0.6641 - val_acc: 0.7273\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5237 - acc: 0.8298 - val_loss: 0.6862 - val_acc: 0.6364\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5142 - acc: 0.8298 - val_loss: 0.7089 - val_acc: 0.6364\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5088 - acc: 0.8298 - val_loss: 0.7378 - val_acc: 0.5455\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.5035 - acc: 0.8085 - val_loss: 0.7591 - val_acc: 0.4545\n",
      "Train on 47 samples, validate on 11 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 0s - loss: 0.5511 - acc: 0.7660 - val_loss: 0.5409 - val_acc: 0.6364\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s - loss: 0.5479 - acc: 0.7872 - val_loss: 0.5376 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s - loss: 0.5385 - acc: 0.8085 - val_loss: 0.5272 - val_acc: 0.7273\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s - loss: 0.5301 - acc: 0.8298 - val_loss: 0.5113 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s - loss: 0.5283 - acc: 0.8085 - val_loss: 0.5077 - val_acc: 0.9091\n",
      "MODEL: DNN accuracy:  0.724137931034 +/-: 0.0235605159803\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "METHOD_LIST = ['XGB', 'ExtraTrees', 'CART', 'RandomForest', 'GBM', 'AdaBoost', 'LR', 'SVM', 'NaiveBayes', 'MLNN']\n",
    "Runs = []\n",
    "nruns = 10\n",
    "SCALER = \"minmax\"\n",
    "GROUPING = \"mean\"\n",
    "DIM_TYPE = \"LDA\"\n",
    "DIM_NUM = 1000\n",
    "Results = None\n",
    "ACC = pd.DataFrame()\n",
    "Rocket.VIZ = False\n",
    "for i in range(0, nruns):\n",
    "    Rocket.SEED = np.random.randint(0,10000)\n",
    "    MODELS  = []\n",
    "    for idx, METHOD in enumerate(METHOD_LIST):\n",
    "        preds, class_model, accuracy = Rocket.classify_treatment(model_type = METHOD, \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "        MODELS.append(class_model)\n",
    "        ACC = ACC.append(accuracy, ignore_index= True)\n",
    "        preds = [pred_[1]for pred_ in preds]\n",
    "        #len(Rocket.DATA_merged[Rocket.DATA_merged[\"array-batch\"].isin([\"cohort 1\", \"cohort 2\", \"JB\", \"IA\", \"ALL-10\"])])\n",
    "        if Results is None:\n",
    "            Results = Rocket.DATA_merged_processed.copy()\n",
    "        Results['pred'] = preds\n",
    "        Results['method'] = METHOD\n",
    "        if idx == 0:\n",
    "            AllResults = Results[['labnr_patient', 'pred', 'method', 'Treatment_risk_group_in_ALL10']]\n",
    "        else:\n",
    "            AllResults = AllResults.append(Results[['labnr_patient', 'pred', 'method', 'Treatment_risk_group_in_ALL10']], \n",
    "                                      ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"RVM\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append(class_model)\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"RVM\"\n",
    "    AllResults = AllResults.append(Results[['labnr_patient', 'pred', 'method', 'Treatment_risk_group_in_ALL10']], ignore_index = True)\n",
    "\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    preds, class_model, accuracy = Rocket.classify_treatment(model_type = \"DNN\", \n",
    "                                                      features = 'genomic',\n",
    "                                                      parameters = {},\n",
    "                                                      pipeline = {\"scaler\": {\"type\": SCALER},\n",
    "                                                                  \"pre_processing\": {\"patient_grouping\": GROUPING, \n",
    "                                                                                     \"bias_removal\": False},\n",
    "                                                                  \"dim_reduction\": {\"type\": DIM_TYPE, \"n_comp\": DIM_NUM},\n",
    "                                                                  \"feature_selection\": {\"type\": \"RFECV\", \"top_n\": 100}})\n",
    "    MODELS.append(class_model)\n",
    "    ACC = ACC.append(accuracy, ignore_index = True)\n",
    "    Results = Rocket.DATA_merged_processed.copy()\n",
    "    preds = [pred_ for pred_ in preds]\n",
    "    Results['pred'] = preds\n",
    "    Results['method'] = \"DNN\"\n",
    "    AllResults = AllResults.append(Results[['labnr_patient', 'pred', 'method', 'Treatment_risk_group_in_ALL10']], ignore_index = True)\n",
    "\n",
    "    AllResults['labnr_patient'] = AllResults['labnr_patient'].astype('str')\n",
    "    AllResults = AllResults.sort_values(by='labnr_patient')\n",
    "    #AllResults[AllResults['Treatment_risk_group_in_ALL10'].notnull()]\n",
    "    ####\n",
    "    ####\n",
    "    Runs.append(AllResults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.586206896552, 0.020912153641]</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[0.689655172414, 0.0126202572695]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[0.793103448276, 0.00865672179584]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[0.793103448276, 0.0121833675639]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[0.775862068966, 0.00906208337837]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.48275862069, 0.0142011674414]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.810344827586, 0.0111834756603]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[0.758620689655, 0.0241550463013]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>[0.724137931034, 0.0235605159803]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.775862068966, 0.00174755882247]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.793103448276, 0.00865672179584]</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[0.706896551724, 0.0277267322452]</td>\n",
       "      <td>RVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[0.793103448276, 0.00826487226606]</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.741379310345, 0.0108321622888]</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    acc model\n",
       "113    [0.586206896552, 0.020912153641]   ADA\n",
       "41     [0.586206896552, 0.020912153641]   ADA\n",
       "5      [0.586206896552, 0.020912153641]   ADA\n",
       "101    [0.586206896552, 0.020912153641]   ADA\n",
       "53     [0.586206896552, 0.020912153641]   ADA\n",
       "89     [0.586206896552, 0.020912153641]   ADA\n",
       "17     [0.586206896552, 0.020912153641]   ADA\n",
       "65     [0.586206896552, 0.020912153641]   ADA\n",
       "77     [0.586206896552, 0.020912153641]   ADA\n",
       "29     [0.586206896552, 0.020912153641]   ADA\n",
       "74    [0.741379310345, 0.0108321622888]  CART\n",
       "38    [0.741379310345, 0.0108321622888]  CART\n",
       "50    [0.741379310345, 0.0108321622888]  CART\n",
       "62    [0.741379310345, 0.0108321622888]  CART\n",
       "26    [0.741379310345, 0.0108321622888]  CART\n",
       "86    [0.741379310345, 0.0108321622888]  CART\n",
       "98    [0.741379310345, 0.0108321622888]  CART\n",
       "110   [0.741379310345, 0.0108321622888]  CART\n",
       "2     [0.741379310345, 0.0108321622888]  CART\n",
       "14    [0.741379310345, 0.0108321622888]  CART\n",
       "71    [0.689655172414, 0.0126202572695]   DNN\n",
       "83   [0.793103448276, 0.00865672179584]   DNN\n",
       "95    [0.793103448276, 0.0121833675639]   DNN\n",
       "107  [0.775862068966, 0.00906208337837]   DNN\n",
       "47     [0.48275862069, 0.0142011674414]   DNN\n",
       "35    [0.810344827586, 0.0111834756603]   DNN\n",
       "59    [0.758620689655, 0.0241550463013]   DNN\n",
       "119   [0.724137931034, 0.0235605159803]   DNN\n",
       "11   [0.775862068966, 0.00174755882247]   DNN\n",
       "23   [0.793103448276, 0.00865672179584]   DNN\n",
       "..                                  ...   ...\n",
       "106   [0.706896551724, 0.0277267322452]   RVM\n",
       "46    [0.706896551724, 0.0277267322452]   RVM\n",
       "34    [0.706896551724, 0.0277267322452]   RVM\n",
       "58    [0.706896551724, 0.0277267322452]   RVM\n",
       "22    [0.706896551724, 0.0277267322452]   RVM\n",
       "118   [0.706896551724, 0.0277267322452]   RVM\n",
       "10    [0.706896551724, 0.0277267322452]   RVM\n",
       "82    [0.706896551724, 0.0277267322452]   RVM\n",
       "70    [0.706896551724, 0.0277267322452]   RVM\n",
       "94    [0.706896551724, 0.0277267322452]   RVM\n",
       "31   [0.793103448276, 0.00826487226606]   SVM\n",
       "91   [0.793103448276, 0.00826487226606]   SVM\n",
       "7    [0.793103448276, 0.00826487226606]   SVM\n",
       "43   [0.793103448276, 0.00826487226606]   SVM\n",
       "67   [0.793103448276, 0.00826487226606]   SVM\n",
       "55   [0.793103448276, 0.00826487226606]   SVM\n",
       "103  [0.793103448276, 0.00826487226606]   SVM\n",
       "19   [0.793103448276, 0.00826487226606]   SVM\n",
       "115  [0.793103448276, 0.00826487226606]   SVM\n",
       "79   [0.793103448276, 0.00826487226606]   SVM\n",
       "84    [0.741379310345, 0.0108321622888]   XGB\n",
       "24    [0.741379310345, 0.0108321622888]   XGB\n",
       "96    [0.741379310345, 0.0108321622888]   XGB\n",
       "36    [0.741379310345, 0.0108321622888]   XGB\n",
       "48    [0.741379310345, 0.0108321622888]   XGB\n",
       "12    [0.741379310345, 0.0108321622888]   XGB\n",
       "72    [0.741379310345, 0.0108321622888]   XGB\n",
       "60    [0.741379310345, 0.0108321622888]   XGB\n",
       "108   [0.741379310345, 0.0108321622888]   XGB\n",
       "0     [0.741379310345, 0.0108321622888]   XGB\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACC.sort_values(by='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "###########\n",
    "##Runs.append(AllResults)\n",
    "final_df = pandas.DataFrame()\n",
    "for idx, df in enumerate(Runs):\n",
    "    df['run'] = idx\n",
    "    final_df = final_df.append(df, ignore_index = True)\n",
    "final_df = final_df.sort_values(by='labnr_patient')\n",
    "final_df['pred']= pandas.to_numeric(final_df['pred'])\n",
    "final_df = final_df.groupby(['labnr_patient', 'method']).agg({'pred': [numpy.mean, numpy.median, numpy.std]})\n",
    "final_df.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/patient_results.csv\")\n",
    "final_df = final_df.groupby(['labnr_patient', 'method']).agg({'pred': [numpy.mean, numpy.median, numpy.std]})\n",
    "final_df.to_csv(\"C:/Users/Bram van Es/DEV/RexR/out/patient_results_agg.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
